{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Qkb6bYy3rOx"
      },
      "source": [
        "# **Optimizing Multi-label AUROC loss on Chest X-Ray Dataset (CheXpert)**\n",
        "\n",
        "**Author**: Zhuoning Yuan\n",
        "\n",
        "**Introduction**\n",
        "\n",
        "In this tutorial, you will learn how to quickly train a DenseNet121 model by optimizing AUROC using our novel AUCMLoss and PESG optimizer on Chest X-Ray dataset, e.g.,[CheXpert](https://stanfordmlgroup.github.io/competitions/chexpert/). After completion of this tutorial, you should be able to use LibAUC to train your own models on your own datasets.\n",
        "\n",
        "\n",
        "\n",
        "**Useful Resources**:\n",
        "* Website: https://libauc.org\n",
        "* Github: https://github.com/Optimization-AI/LibAUC\n",
        "\n",
        "**Reference**:  \n",
        "\n",
        "If you find this tutorial helpful in your work,  please acknowledge our library and cite the following paper:\n",
        "\n",
        "<pre>\n",
        "@inproceedings{yuan2021large,\n",
        "  title={Large-scale robust deep auc maximization: A new surrogate loss and empirical studies on medical image classification},\n",
        "  author={Yuan, Zhuoning and Yan, Yan and Sonka, Milan and Yang, Tianbao},\n",
        "  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},\n",
        "  pages={3040--3049},\n",
        "  year={2021}\n",
        "}\n",
        "</pre>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTJ3ca0u4YQ4"
      },
      "source": [
        "# **Installing LibAUC**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h8iVw1kU3guh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: libauc==1.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/main/lib/python3.10/site-packages (1.2.0)\n",
            "Requirement already satisfied: torch>=1.2 in /opt/homebrew/Caskroom/miniforge/base/envs/main/lib/python3.10/site-packages (from libauc==1.2.0) (1.12.1)\n",
            "Requirement already satisfied: opencv-python in /opt/homebrew/Caskroom/miniforge/base/envs/main/lib/python3.10/site-packages (from libauc==1.2.0) (4.6.0.66)\n",
            "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniforge/base/envs/main/lib/python3.10/site-packages (from libauc==1.2.0) (1.23.4)\n",
            "Requirement already satisfied: scikit-image in /opt/homebrew/Caskroom/miniforge/base/envs/main/lib/python3.10/site-packages (from libauc==1.2.0) (0.19.3)\n",
            "Requirement already satisfied: Pillow in /opt/homebrew/Caskroom/miniforge/base/envs/main/lib/python3.10/site-packages (from libauc==1.2.0) (9.2.0)\n",
            "Requirement already satisfied: scikit-learn in /opt/homebrew/Caskroom/miniforge/base/envs/main/lib/python3.10/site-packages (from libauc==1.2.0) (1.1.2)\n",
            "Requirement already satisfied: pandas in /opt/homebrew/Caskroom/miniforge/base/envs/main/lib/python3.10/site-packages (from libauc==1.2.0) (1.5.0)\n",
            "Requirement already satisfied: typing-extensions in /opt/homebrew/Caskroom/miniforge/base/envs/main/lib/python3.10/site-packages (from torch>=1.2->libauc==1.2.0) (4.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/homebrew/Caskroom/miniforge/base/envs/main/lib/python3.10/site-packages (from pandas->libauc==1.2.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniforge/base/envs/main/lib/python3.10/site-packages (from pandas->libauc==1.2.0) (2022.4)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/main/lib/python3.10/site-packages (from scikit-image->libauc==1.2.0) (1.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /opt/homebrew/Caskroom/miniforge/base/envs/main/lib/python3.10/site-packages (from scikit-image->libauc==1.2.0) (2022.10.10)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /opt/homebrew/Caskroom/miniforge/base/envs/main/lib/python3.10/site-packages (from scikit-image->libauc==1.2.0) (2.22.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Caskroom/miniforge/base/envs/main/lib/python3.10/site-packages (from scikit-image->libauc==1.2.0) (21.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /opt/homebrew/Caskroom/miniforge/base/envs/main/lib/python3.10/site-packages (from scikit-image->libauc==1.2.0) (1.9.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /opt/homebrew/Caskroom/miniforge/base/envs/main/lib/python3.10/site-packages (from scikit-image->libauc==1.2.0) (2.8.7)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/main/lib/python3.10/site-packages (from scikit-learn->libauc==1.2.0) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/main/lib/python3.10/site-packages (from scikit-learn->libauc==1.2.0) (3.1.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/homebrew/Caskroom/miniforge/base/envs/main/lib/python3.10/site-packages (from packaging>=20.0->scikit-image->libauc==1.2.0) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniforge/base/envs/main/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->libauc==1.2.0) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install libauc==1.2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlD-4SrE4dVW"
      },
      "source": [
        "# **Downloading CheXpert**\n",
        " \n",
        "*   To request dataset access, you need to apply from CheXpert website: https://stanfordmlgroup.github.io/competitions/chexpert/\n",
        "*   In this tutorial, we use the smaller version of dataset with lower image resolution, i.e., *CheXpert-v1.0-small.zip*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcsJ4eoj3VST"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/chexpert-dataset/CheXpert-v1.0-small.zip /content/\n",
        "!mkdir CheXpert\n",
        "!unzip CheXpert-v1.0-small.zip -d /content/CheXpert/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVvrt3ku4qpq"
      },
      "source": [
        "\n",
        "# **Importing LibAUC**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XGHWer3v4qJo"
      },
      "outputs": [],
      "source": [
        "from libauc.losses import AUCM_MultiLabel, CrossEntropyLoss\n",
        "from libauc.optimizers import PESG, Adam\n",
        "from libauc.models import densenet121 as DenseNet121\n",
        "from libauc.datasets import CheXpert, CIFAR100, download_dataset\n",
        "from libauc.metrics import auc_roc_score # for multi-task\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch \n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn.functional as F   \n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2swK5Mo7Kca"
      },
      "source": [
        "# **Reproducibility**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OiiT5oEp7J3C"
      },
      "outputs": [],
      "source": [
        "def set_all_seeds(SEED):\n",
        "    # REPRODUCIBILITY\n",
        "    torch.manual_seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Bjd5Q5wkAT7"
      },
      "source": [
        "# **Datasets, Loss and Optimizer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CIFAR-100 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "root = '/Users/personal-macbook/Documents/PhD/dataset/cifar-100'\n",
        "traindSet = CIFAR100(root=root, train=True)\n",
        "testdSet = CIFAR100(root=root, train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CheXpert Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "root = '/Users/personal-macbook/Documents/PhD/dataset/chexpert/CheXpert-v1.0-small/'\n",
        "pathologies = [\"No Finding\", \"Enlarged Cardiomediastinum\" , \"Cardiomegaly\" , \"Lung Opacity\" , \"Lung Lesion\", \"Edema\" , \"Consolidation\" , \"Pneumonia\" , \"Atelectasis\" , \"Pneumothorax\" , \"Pleural Effusion\" , \"Pleural Other\" , \"Fracture\" , \"Support Devices\"]\n",
        "\n",
        "num_classes = len(pathologies)\n",
        "\n",
        "args = dict(image_root_path=root, use_upsampling=False, use_frontal=True, image_size=224, class_index=-1, verbose=False, train_cols=pathologies, seed=123)\n",
        "traindSet = CheXpert(csv_path=root+'train.csv',  mode='train',  shuffle=True,  **args)\n",
        "testSet    = CheXpert(csv_path=root+'valid.csv',  mode='valid',  shuffle=False,   **args)\n",
        "\n",
        "trainloader =  torch.utils.data.DataLoader(traindSet, batch_size=32, num_workers=2, shuffle=True)\n",
        "testloader =  torch.utils.data.DataLoader(testSet, batch_size=32, num_workers=2, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0.0</th>\n",
              "      <th>1.0</th>\n",
              "      <th>ratio</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pathologies</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>No Finding</th>\n",
              "      <td>174053</td>\n",
              "      <td>16974</td>\n",
              "      <td>0.089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Enlarged Cardiomediastinum</th>\n",
              "      <td>181840</td>\n",
              "      <td>9187</td>\n",
              "      <td>0.048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cardiomegaly</th>\n",
              "      <td>167642</td>\n",
              "      <td>23385</td>\n",
              "      <td>0.122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lung Opacity</th>\n",
              "      <td>96816</td>\n",
              "      <td>94211</td>\n",
              "      <td>0.493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lung Lesion</th>\n",
              "      <td>183987</td>\n",
              "      <td>7040</td>\n",
              "      <td>0.037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Edema</th>\n",
              "      <td>129534</td>\n",
              "      <td>61493</td>\n",
              "      <td>0.322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Consolidation</th>\n",
              "      <td>178044</td>\n",
              "      <td>12983</td>\n",
              "      <td>0.068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pneumonia</th>\n",
              "      <td>186352</td>\n",
              "      <td>4675</td>\n",
              "      <td>0.024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Atelectasis</th>\n",
              "      <td>131444</td>\n",
              "      <td>59583</td>\n",
              "      <td>0.312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pneumothorax</th>\n",
              "      <td>173334</td>\n",
              "      <td>17693</td>\n",
              "      <td>0.093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pleural Effusion</th>\n",
              "      <td>114128</td>\n",
              "      <td>76899</td>\n",
              "      <td>0.403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pleural Other</th>\n",
              "      <td>188522</td>\n",
              "      <td>2505</td>\n",
              "      <td>0.013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fracture</th>\n",
              "      <td>183591</td>\n",
              "      <td>7436</td>\n",
              "      <td>0.039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Support Devices</th>\n",
              "      <td>83857</td>\n",
              "      <td>107170</td>\n",
              "      <td>0.561</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               0.0     1.0  ratio\n",
              "pathologies                                      \n",
              "No Finding                  174053   16974  0.089\n",
              "Enlarged Cardiomediastinum  181840    9187  0.048\n",
              "Cardiomegaly                167642   23385  0.122\n",
              "Lung Opacity                 96816   94211  0.493\n",
              "Lung Lesion                 183987    7040  0.037\n",
              "Edema                       129534   61493  0.322\n",
              "Consolidation               178044   12983  0.068\n",
              "Pneumonia                   186352    4675  0.024\n",
              "Atelectasis                 131444   59583  0.312\n",
              "Pneumothorax                173334   17693  0.093\n",
              "Pleural Effusion            114128   76899  0.403\n",
              "Pleural Other               188522    2505  0.013\n",
              "Fracture                    183591    7436  0.039\n",
              "Support Devices              83857  107170  0.561"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(traindSet.class_counts).T\n",
        "df['pathologies'] = pathologies\n",
        "df = df.set_index('pathologies')\n",
        "df2 = pd.DataFrame( dict(pathologies=traindSet.select_cols , ratio=np.round(traindSet.imratio_list,3) ,)).set_index('pathologies')\n",
        "\n",
        "pd.concat([df, df2], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkxJ2ZNNj_uN",
        "outputId": "93c1f0c9-c94f-4a39-dcba-e22e647c606f"
      },
      "outputs": [],
      "source": [
        "# paramaters\n",
        "SEED = 123\n",
        "BATCH_SIZE = 32\n",
        "lr = 0.1 \n",
        "epoch_decay = 2e-3\n",
        "weight_decay = 1e-5\n",
        "margin = 1.0\n",
        "total_epochs = 2\n",
        "\n",
        "# model\n",
        "set_all_seeds(SEED)\n",
        "model = DenseNet121(pretrained=True, last_activation=None, activations='relu', num_classes=num_classes)\n",
        "# model = model.cuda()\n",
        "\n",
        "# define loss & optimizer\n",
        "loss_fn = AUCM_MultiLabel(num_classes=num_classes)\n",
        "optimizer = PESG(model, \n",
        "                 loss_fn=loss_fn,\n",
        "                 lr=lr, \n",
        "                 margin=margin, \n",
        "                 epoch_decay=epoch_decay, \n",
        "                 weight_decay=weight_decay)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3Bge6KM7lBP"
      },
      "source": [
        "# **Multi-label Training**\n",
        "Optimizing Multi-label AUROC loss (e.g., 5 tasks)   \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6p0oVY8AouP",
        "outputId": "01c2b44b-7c08-4a5e-8209-fceb75aab393"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start Training\n",
            "------------------------------\n",
            "Epoch=0, BatchID=0, Val_AUC=0.4573, Best_Val_AUC=0.4573\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [11], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(y_pred, train_labels)\n\u001b[1;32m     16\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 17\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     18\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     20\u001b[0m \u001b[39m# validation  \u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/main/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/main/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# training\n",
        "print ('Start Training')\n",
        "print ('-'*30)\n",
        "\n",
        "best_val_auc = 0 \n",
        "for epoch in range(total_epochs):\n",
        "    if epoch > 0:\n",
        "        optimizer.update_regularizer(decay_factor=10)    \n",
        "\n",
        "    for idx, data in enumerate(trainloader):\n",
        "      train_data, train_labels = data\n",
        "    #   train_data, train_labels  = train_data.cuda(), train_labels.cuda()\n",
        "      y_pred = model(train_data)\n",
        "      y_pred = torch.sigmoid(y_pred)\n",
        "      loss = loss_fn(y_pred, train_labels)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "        \n",
        "      # validation  \n",
        "      if idx % 400 == 0:\n",
        "         model.eval()\n",
        "         with torch.no_grad():    \n",
        "              test_pred = []\n",
        "              test_true = [] \n",
        "              for jdx, data in enumerate(testloader):\n",
        "                  test_data, test_labels = data\n",
        "                #   test_data = test_data.cuda()\n",
        "                  y_pred = model(test_data)\n",
        "                  y_pred = torch.sigmoid(y_pred)\n",
        "                  test_pred.append(y_pred.cpu().detach().numpy())\n",
        "                  test_true.append(test_labels.numpy())\n",
        "            \n",
        "              test_true = np.concatenate(test_true)\n",
        "              test_pred = np.concatenate(test_pred)\n",
        "              val_auc_mean = np.mean(auc_roc_score(test_true, test_pred)) \n",
        "              model.train()\n",
        "\n",
        "              if best_val_auc < val_auc_mean:\n",
        "                 best_val_auc = val_auc_mean\n",
        "                 torch.save(model.state_dict(), 'aucm_pretrained_model.pth')\n",
        "\n",
        "              print ('Epoch=%s, BatchID=%s, Val_AUC=%.4f, Best_Val_AUC=%.4f'%(epoch, idx, val_auc_mean, best_val_auc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFKAu80J1vzD"
      },
      "source": [
        "# **Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-TTAuL51u4e"
      },
      "outputs": [],
      "source": [
        "# show auc roc scores for each task \n",
        "auc_roc_score(test_true, test_pred)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "07_Optimizing_Multi_Label_AUROC_Loss_with_DenseNet121_on_CheXpert.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 ('main')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "c7fa6e65c4f227d77882d4bcc641a942485d93f6372413baaff8defdf53a058c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
