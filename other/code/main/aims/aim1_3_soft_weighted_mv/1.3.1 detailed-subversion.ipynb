{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-13 21:22:24.714037: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-13 21:22:36.812652: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-13 21:22:36.814781: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-13 21:22:37.432371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:0b:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2022-01-13 21:22:37.432466: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-13 21:22:37.484936: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-13 21:22:37.485060: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-01-13 21:22:37.527095: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-13 21:22:37.592837: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-13 21:22:37.633105: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-13 21:22:37.666405: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-13 21:22:37.736340: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-13 21:22:37.736987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-01-13 21:22:37.737438: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-13 21:22:37.742214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:0b:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2022-01-13 21:22:37.742264: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-13 21:22:37.742294: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-13 21:22:37.742316: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-01-13 21:22:37.742338: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-13 21:22:37.742359: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-13 21:22:37.742380: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-13 21:22:37.742402: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-13 21:22:37.742423: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-13 21:22:37.742811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-01-13 21:22:37.742851: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-13 21:22:38.601316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-01-13 21:22:38.601358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-01-13 21:22:38.601369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-01-13 21:22:38.602222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14957 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:0b:00.0, compute capability: 6.0)\n",
      "2022-01-13 21:22:38.602471: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import funcs \n",
    "import load_data\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%reload_ext load_data\n",
    "%reload_ext funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22199317 0.87073231 0.20671916 0.91861091]\n",
      "[0.48841119 0.61174386 0.76590786 0.51841799]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "def test():\n",
    "    np.random.seed(5)\n",
    "    return np.random.random(4)\n",
    "\n",
    "\n",
    "print(test())\n",
    "print(np.random.random(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?1h\u001b=\u001b[H\u001b[2J\u001b[mtop - 15:12:49 up 6 days,  2:46,  0 users,  load average: 3.97, 1.54, 0.60\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "Tasks:\u001b[m\u001b[m\u001b[1m 363 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m   6 \u001b[m\u001b[mrunning,\u001b[m\u001b[m\u001b[1m 357 \u001b[m\u001b[msleeping,\u001b[m\u001b[m\u001b[1m   0 \u001b[m\u001b[mstopped,\u001b[m\u001b[m\u001b[1m   0 \u001b[m\u001b[mzombie\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "%Cpu(s):\u001b[m\u001b[m\u001b[1m 16.2 \u001b[m\u001b[mus,\u001b[m\u001b[m\u001b[1m  2.0 \u001b[m\u001b[msy,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mni,\u001b[m\u001b[m\u001b[1m 81.8 \u001b[m\u001b[mid,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mwa,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mhi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[msi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mst\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Mem :\u001b[m\u001b[m\u001b[1m 26343524+\u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m 23084059+\u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m  5062132 \u001b[m\u001b[mused,\u001b[m\u001b[m\u001b[1m 27532532 \u001b[m\u001b[mbuff/cache\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Swap:\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mused.\u001b[m\u001b[m\u001b[1m 25725833+\u001b[m\u001b[mavail Mem \u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\u001b[K\n",
      "\u001b[7m  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 4720 mohamma+  20   0   32.1g   1.1g 109236 R 100.0  0.5   0:09.17 python      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 4721 mohamma+  20   0   32.1g   1.1g 109016 R 100.0  0.5   0:09.19 python      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 4722 mohamma+  20   0   32.1g   1.1g 109032 R 100.0  0.5   0:09.15 python      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 4718 mohamma+  20   0   32.1g   1.1g 109024 R 100.0  0.5   0:09.18 python      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 4719 mohamma+  20   0   32.1g   1.1g 108956 R 100.0  0.5   0:09.19 python      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3763 mohamma+  20   0    9720   1580   1224 S   0.0  0.0   0:00.01 slurm_scri+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3788 mohamma+  20   0    9716   1608   1212 S   0.0  0.0   0:00.00 bash        \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3809 mohamma+  20   0  382876  58472   8344 S   0.0  0.0   0:03.30 jupyter-no+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 4388 mohamma+  20   0   32.1g   1.3g 274328 S   0.0  0.5   0:05.56 python      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 4591 mohamma+  20   0  671568  47608   8032 S   0.0  0.0   0:01.23 python3.6   \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 4746 mohamma+  20   0   69268   2364   1544 R   0.0  0.0   0:00.01 top         \u001b[m\u001b[m\u001b[K\n",
      "\u001b[J\u001b[H\u001b[mtop - 15:12:52 up 6 days,  2:46,  0 users,  load average: 3.97, 1.58, 0.62\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\n",
      "%Cpu(s):\u001b[m\u001b[m\u001b[1m 17.7 \u001b[m\u001b[mus,\u001b[m\u001b[m\u001b[1m  0.2 \u001b[m\u001b[msy,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mni,\u001b[m\u001b[m\u001b[1m 82.1 \u001b[m\u001b[mid,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mwa,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mhi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[msi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mst\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Mem :\u001b[m\u001b[m\u001b[1m 26343524+\u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m 23060539+\u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m  5297324 \u001b[m\u001b[mused,\u001b[m\u001b[m\u001b[1m 27532532 \u001b[m\u001b[mbuff/cache\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Swap:\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mused.\u001b[m\u001b[m\u001b[1m 25702315+\u001b[m\u001b[mavail Mem \u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\u001b[K\n",
      "\n",
      "\u001b[m\u001b[1m 4718 mohamma+  20   0   32.1g   1.1g 109472 R 100.0  0.5   0:12.20 python      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 4719 mohamma+  20   0   32.1g   1.1g 109412 R 100.0  0.5   0:12.20 python      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 4720 mohamma+  20   0   32.1g   1.1g 109480 R 100.0  0.5   0:12.18 python      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 4722 mohamma+  20   0   32.1g   1.1g 109480 R 100.0  0.5   0:12.16 python      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 4721 mohamma+  20   0   32.1g   1.1g 109412 R  99.7  0.5   0:12.19 python      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 4591 mohamma+  20   0  671568  47608   8032 S   1.0  0.0   0:01.26 python3.6   \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 4746 mohamma+  20   0   69268   2532   1596 R   0.3  0.0   0:00.02 top         \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3763 mohamma+  20   0    9720   1580   1224 S   0.0  0.0   0:00.01 slurm_scri+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3788 mohamma+  20   0    9716   1608   1212 S   0.0  0.0   0:00.00 bash        \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3809 mohamma+  20   0  382876  58472   8344 S   0.0  0.0   0:03.30 jupyter-no+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 4388 mohamma+  20   0   32.1g   1.3g 274328 S   0.0  0.5   0:05.56 python      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[J\u001b[?1l\u001b>\u001b[25;1H\n",
      "\u001b[K"
     ]
    }
   ],
   "source": [
    "!top -u mohammadsmajdi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange; font-family:PT Sans Narrow; font-size:1.31em\"> 1 Loading the Data </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4128967d5d480ba529da8d15fd18e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='WHICH_DATASET', index=3, options=(('1. kr-vs-kp', 'kr-vs-kp'), ('2…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_dict = {1:'kr-vs-kp', \n",
    "                2:'mushroom',\n",
    "                3:'sick',\n",
    "                4:'spambase',\n",
    "                5:'tic-tac-toe',\n",
    "                6:'splice',\n",
    "                8:'waveform',\n",
    "                9:'biodeg',\n",
    "                10:'horse-colic',\n",
    "                11:'ionosphere',\n",
    "                12:'vote'}\n",
    "\n",
    "dataset = dataset_dict[4]\n",
    "\n",
    "data, feature_columns = load_data.aim1_3_read_download_UCI_database(WHICH_DATASET=dataset, mode='read')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange; font-family:PT Sans Narrow; font-size:1.3em\"> 1. More detailed version. Repeating the experiments for only 20 workers => to measure confidence score </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-family:PT Sans Narrow; font-size:1.3em\"> 1.1 Measuring prob/uncertainties </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARLS = {'num_labelers': 10, \n",
    "        'low_dis':      0.3, \n",
    "        'high_dis':     0.9}\n",
    "    \n",
    "predicted_labels, uncertainty, true_labels, labelers_strength = funcs.apply_technique_aim_1_3( data = data,\n",
    "                                                                                               ARLS = ARLS,\n",
    "                                                                                               num_simulations = 20, \n",
    "                                                                                               feature_columns = feature_columns)\n",
    "\n",
    "labels_all_workers         = predicted_labels['test']['mv'] \n",
    "uncertainty_all_workers    = uncertainty['test']\n",
    "truth                      = true_labels['test'].truth\n",
    "\n",
    "uncertainty['test'].head(3).append(labelers_strength.T).round(decimals=3)                                                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-family:PT Sans Narrow; font-size:1.3em\"> 1.2 Measuring weights for each labeler </span>\n",
    "\n",
    "***\n",
    "<span style=\"color:grey; font-family:PT Sans narrow; font-size:1.3em\"> 1.2.1 First Method: </span>\n",
    "\n",
    "$ T_{x,a,j} = 1 - u_{j} $\n",
    "\n",
    "***\n",
    "<span style=\"color:grey; font-family:PT Sans narrow; font-size:1.3em\"> 1.2.2 Second Method: </span>\n",
    "\n",
    "$ T_{x,a,j} = \\begin{array}{cc} 1 - u_{j} & y_{a,j} = y'_{j}  \\\\ 0 & y_{a,j} \\neq y'_{j} \\end{array} $\n",
    "\n",
    "***\n",
    "\n",
    "<span style=\"color:grey; font-family:PT Sans narrow; font-size:1.3em\"> 1.2.3 Measuring average weight </span>\n",
    "\n",
    "$ \\hat{w}_{a,j} = \\frac {1}{N} \\sum_{x} T_{x,a,j}$\n",
    "\n",
    "$ w_{a,j} = \\frac {\\hat{w}_{a,j}} {\\sum_{a=1}^{L} \\hat{w}_{a,j}} $\n",
    "\n",
    "***\n",
    "## <span style=\"font-family:PT Sans Narrow; font-size:1.3em\"> 1.3 Weighted majority voting </span>\n",
    "\n",
    "\n",
    "<span style=\"color:grey; font-family:PT Sans narrow; font-size:1.3em\"> 1.3.1 Applying the weights to predicted probabilities </span>\n",
    "\n",
    "$ \\hat{p}^{prob}_{j} = \\sum_{a=1}^{L} p_{a,j} * w_{a,j} $\n",
    "\n",
    "\n",
    "\n",
    "<span style=\"color:grey; font-family:PT Sans narrow; font-size:1.3em\"> 1.3.2 Applying the weights to predicted labels </span>\n",
    "\n",
    "$ \\hat{p}^{binary}_{j} = \\sum_{a=1}^{L} y_{a,j} * w_{a,j}$ where $y_{a,j} = (p_{a,j} > 0.5) $\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, prob_weighted = funcs.aim1_3_measuring_weights( labels_all_workers=labels_all_workers, uncertainty_all_workers=uncertainty_all_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:grey; font-family:PT Sans narrow; font-size:1.3em\"> 1.3.3 Measuring the weighted MV using only the measured weights (without confidence scores) </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measuring the new accuracies\n",
    "acc2 = ( (prob_weighted > 0.5).T == truth ).mean(axis=1)\n",
    "acc2['num_labelers'] = ARLS['num_labelers']\n",
    "\n",
    "accuracy2 = pd.DataFrame( {'accuracy': acc2}).T.set_index('num_labelers')\n",
    "\n",
    "accuracy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F, acc = funcs.aim1_3_measure_confidense_score(delta=labels_all_workers, weights=weights, conf_score_strategy=1, num_labelers=ARLS['num_labelers'], truth=true_labels['test'].truth)\n",
    "\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc2 = ((F1.method1>0.5) == (truth > 0.5) ).mean(axis=0)\n",
    "# acc2\n",
    "# truth\n",
    "# F1.method1>0.5\n",
    "F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange; font-family:PT Sans Narrow; font-size:1.3em\"> 2. Benchmark </span>\n",
    "\n",
    "## <span style=\"font-family:PT Sans Narrow; font-size:1.3em\"> 2.1 Overall quality of different workers </span>\n",
    "\n",
    "\n",
    "Estimating the overall qualities of different workers is not a new research topic in the crowdsourcing learning community. To the best of the authors’ knowledge, there exist many state-of-the-art algorithms, such as Dawid–Skene [1], ZenCrowd , KOS [9], and DEW [15, 23]. However, none of them exploit feature vectors of instances, which makes it impossible to take full advantage of the statistical characteristics of the available data when evaluating the label qualities. According to the observation by [30], in traditional supervised learning, there exists a schema to exhibit the relationship between data features and the ground-truth labels. For example, suppose there exists a high-quality worker; the data schema will be well-inherited in their labels, because the difference between their labels and ground-truth labels is small. Meanwhile, suppose there exists a low-quality worker, the data schema may be broken because their labels will be very different from the ground-truth labels. Therefore, we can estimate the overall quality of a worker by evaluating how well the schema is inherited in their labels. Specifically, we can first extract all training instances’ feature vectors and the corresponding crowd labels provided by the jth worker to form a new single-label data set. Then, we use tenfold cross-validation to evaluate the classification accuracy of a classifier. In theory, this classifier can be any classifier. Finally, we define the overall quality of the jth worker as the classification accuracy of the built classifier. The detailed formula can be expressed as\n",
    "\n",
    "\n",
    "$ \\tau_{a} = \\frac {\\sum_{i=1}^{n} \\delta \\Big( f_{a}(x_{i}) , I_{i,a}  \\Big)}{n} $\n",
    "\n",
    "where n is the size of the extracted data set and $f_{j}(x_{i})$ is the class label of the feature vector $x_{i}$ predicted by the built classifier.\n",
    "\n",
    "***\n",
    "\n",
    "## <span style=\"font-family:PT Sans Narrow; font-size:1.3em\"> 2.2 Specific quality of the $j_{th}$ worker for the $i_{th}$ instance ($s_{ij}$) </span>\n",
    "\n",
    "$ s_{x,a} = \\sum^{a'=L}_{ (a'=1) \\land (a' \\neq a) } \\delta \\Big( l_{x,a},l_{x,a'} \\Big) $\n",
    "\n",
    "***\n",
    "$ \\gamma_{x,a} =\\tau_{x,a}(1 + s_{x,a}^{2}) $\n",
    "\n",
    "***\n",
    "$ w'_{x,a} = \\frac {1} {1 + e^{-\\gamma_{x,a}} } $\n",
    "\n",
    "***\n",
    "$ Z = \\frac {1}{L} \\sum_{a=1}^{L}w'_{x,a}  $\n",
    "\n",
    "‍‍‍``` Z is a normalization constant, which ensures that the sum of all crowd label weights for the ith instance is still equal to m ```\n",
    "\n",
    "***\n",
    "$ w_{x,j} = \\frac {1}{Z} w'_{x,j}  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = funcs.measuring_Tao_Weights(delta=predicted_labels['test']['simulation_0'] , true_labels=true_labels['test'].drop(columns=['truth']))\n",
    "\n",
    "# measuring accuracy\n",
    "accuracy2['WMV_Tao'] = ( labels['WMV_Tao'] == true_labels['test'].truth ).mean(axis=0)\n",
    "accuracy2['MV']      = ( labels['MV']      == true_labels['test'].truth ).mean(axis=0)\n",
    "\n",
    "accuracy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange; font-family:PT Sans Narrow; font-size:1.3em\"> 3. Confidense score: _Weighted-soft-MV_ </span>\n",
    "\n",
    "## <span style=\"font-family:PT Sans Narrow; font-size:1.3em\"> 3.1 Measuring the certainty score of majority class $ P_{x,j} $ </span>\n",
    "\n",
    "\n",
    "In actual formula this is divided by weights.sum(axis=1). But because weights sum to 1, its values would be 1.\n",
    "\n",
    "Also pandas automatically transfers the binary values in delta\\[disease\\] to float before doing the multiplication.\n",
    "\n",
    "where $\\delta(y_{a,j},+)$ is $1$ if $y_{a,j}$ is positive (TRUE) otherwise $0$. $\\delta(y_{a,j},-)$ is $1$ if $y_{a,j}$ is negative (FALSE) otherwise $0$\n",
    "\n",
    "$ P_{x,j} = \\frac { \\sum_{a=1}^{L} {ω_{a,j} δ(y_{a,j},+)} } { \\sum_{a=1}^{L} {ω_{a,j} δ(y_{a,j},+)}  +  \\sum_{a=1}^{L} {ω_{a,j} δ(y_{a,j},-)} }$\n",
    "\n",
    "***\n",
    "## <span style=\"font-family:PT Sans Narrow; font-size:1.3em\"> 3.2 Certainty of majority class for both positive & negative labels </span>\n",
    "\n",
    "$F_{x,j} = max \\Big(P_{x,j} , 1-P_{x,j} \\Big)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1 = funcs.aim1_3_measure_confidense_score(delta=labels_all_workers, weights=weights, conf_score_strategy=1, num_labelers=ARLS['num_labelers'], truth=true_labels['test'].truth)\n",
    "F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <span style=\"color:orange; font-family:PT Sans Narrow; font-size:1.3em\"> 4. Confidense score: _Beta-soft-MV_ </span>\n",
    "\n",
    "> Note: _This is measured only for METHOD1 since it has a higher accuracy_\n",
    "\n",
    "## <span style=\"font-family:PT Sans Narrow; font-size:1.3em\"> 4.1 Measuring the certainty score of majority class  $f_{x,j}^{-+}$ </span>\n",
    "\n",
    "\n",
    "\n",
    "$f^{+}_{x,j}≔1+\\sum_{a=1}^{L}ω_{a,j}  \\delta \\big( y_{a,j},+ \\big) $\n",
    "\n",
    "$f_{x,j}^{-}≔1+\\sum_{a=1}^{L}ω_{a,j}  \\delta \\big( y_{a,j},- \\big) $\n",
    "\n",
    "***\n",
    "## <span style=\"font-family:PT Sans Narrow; font-size:1.3em\"> 4.2 Measuring the regularized incomplete beta function </span>\n",
    "\n",
    "\n",
    "$I_{x} (α,β)=F(x;α,β)=\\frac{ B(x;α,β) }{B(α,β)} $\n",
    "\n",
    "$ bdtrc(k,n,p) = I_{p} \\Big( \\lfloor {k} \\rfloor + 1 , n - \\lfloor {k} \\rfloor \\Big) = \\sum_{j = \\lfloor {k} \\rfloor + 1} ^ {n} \\binom {n}{j}p^{j}(1-p)^{n-j} $\n",
    "\n",
    "> [source](https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.bdtrc.html)\n",
    "\n",
    "\n",
    "## <span style=\"font-family:PT Sans Narrow; font-size:1.3em\"> 4.3 Certainty of majority class for both positive & negative labels </span>\n",
    "\n",
    "$F_{x,j} = max(I_{p} , 1-I_{p})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F2 = funcs.aim1_3_measure_confidense_score(delta=labels_all_workers, weights=weights, method=2, num_labelers=ARLS['num_labelers'], truth=true_labels['test'].truth)\n",
    "F2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper_miniforge_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:42:03) [Clang 12.0.1 ]"
  },
  "metadata": {
   "interpreter": {
    "hash": "97f50b47c5db4a373caba7d351ed0bd803d6a9b66b6e99b50d57389022e4f55d"
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "39d0623b5cf60cf814ab926a8c0ffabd85a4083e4a4c6e6e930baebba28dd02d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
