@inproceedings{abad_SelfCrowdsourcing_2017,
  title = {Self-{{Crowdsourcing Training}} for {{Relation Extraction}}},
  booktitle = {Proc. 55th {{Annu}}. {{Meet}}. {{Assoc}}. {{Comput}}. {{Linguist}}. {{Vol}}. 2 {{Short Pap}}.},
  author = {Abad, Azad and Nabi, Moin and Moschitti, Alessandro},
  date = {2017},
  pages = {518--523},
  publisher = {{Association for Computational Linguistics}},
  location = {{Vancouver, Canada}},
  doi = {10.18653/v1/P17-2082},
  url = {http://aclweb.org/anthology/P17-2082},
  urldate = {2022-12-28},
  eventtitle = {Proceedings of the 55th {{Annual Meeting}} of the {{Association}} for           {{Computational Linguistics}} ({{Volume}} 2: {{Short Papers}})},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {13 citations (Semantic Scholar/DOI) [2022-12-28]},
  file = {/Users/personal-macbook/Zotero/storage/DALGBTL2/Abad et al. - 2017 - Self-Crowdsourcing Training for Relation Extractio.pdf;/Users/personal-macbook/Zotero/storage/QTXHSQDL/P17-2082.html;/Users/personal-macbook/Zotero/storage/T9LFDB9I/P17-2082.html}
}

@online{abadi_tensorflowlarge_2016,
  ids = {Abadi:2016kic,abadi15},
  title = {Tensorflow: {{Large-Scale Machine Learning}} on {{Heterogeneous Distributed Systems}}},
  shorttitle = {Tensorflow},
  author = {Abadi, Mart\'in and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S. and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jia, Yangqing and Jozefowicz, Rafal and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Mane, Dan and Monga, Rajat and Moore, Sherry and Murray, Derek and Olah, Chris and Schuster, Mike and Shlens, Jonathon and Steiner, Benoit and Sutskever, Ilya and Talwar, Kunal and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Viegas, Fernanda and Vinyals, Oriol and Warden, Pete and Wattenberg, Martin and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
  date = {2016},
  number = {1603.04467},
  eprint = {1603.04467},
  eprinttype = {arxiv},
  doi = {10.48550/ARXIV.1603.04467},
  url = {https://arxiv.org/abs/1603.04467},
  urldate = {2023-06-03},
  abstract = {TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.},
  pubstate = {preprint},
  version = {2},
  keywords = {⛔ No INSPIRE recid found,{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Machine Learning,{Distributed, Parallel, and Cluster Computing (cs.DC)},FOS: Computer and information sciences,Machine Learning (cs.LG)},
  annotation = {9922 citations (Semantic Scholar/arXiv) [2023-06-02] 281 citations (INSPIRE 2023/6/2) 279 citations w/o self (INSPIRE 2023/6/2)},
  file = {/Users/personal-macbook/Zotero/storage/LIX5QTM6/Abadi et al. - 2016 - TensorFlow Large-Scale Machine Learning on Hetero.pdf}
}

@article{abdar_Review_2021,
  title = {A {{Review}} of {{Uncertainty Quantification}} in {{Deep Learning}}: {{Techniques}}, {{Applications}} and {{Challenges}}},
  shorttitle = {A {{Review}} of {{Uncertainty Quantification}} in {{Deep Learning}}},
  author = {Abdar, Moloud and Pourpanah, Farhad and Hussain, Sadiq and Rezazadegan, Dana and Liu, Li and Ghavamzadeh, Mohammad and Fieguth, Paul and Cao, Xiaochun and Khosravi, Abbas and Acharya, U. Rajendra and Makarenkov, Vladimir and Nahavandi, Saeid},
  date = {2021-12},
  journaltitle = {Information Fusion},
  volume = {76},
  pages = {243--297},
  issn = {15662535},
  doi = {10.1016/j.inffus.2021.05.008},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1566253521001081},
  urldate = {2022-12-20},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Artificial intelligence,Bayesian statistics,Deep learning,Ensemble learning,Machine learning,Uncertainty quantification},
  annotation = {620 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/X95EWTMS/Abdar et al. - 2021 - A Review of Uncertainty Quantification in Deep Lea.pdf}
}

@article{abdelmaguid_Left_2018,
  title = {Left {{Ventricle Segmentation}} and {{Volume Estimation}} on {{Cardiac MRI Using Deep Learning}}},
  author = {Abdelmaguid, Ehab and Huang, Jolene and Kenchareddy, Sanjay and Singla, Disha and Wilke, Laura and Nguyen, Mai H. and Altintas, Ilkay},
  date = {2018-09},
  abstract = {In the United States, heart disease is the leading cause of death for both men and women, accounting for 610,000 deaths each year [1]. Physicians use Magnetic Resonance Imaging (MRI) scans to take images of the heart in order to non-invasively estimate its structural and functional parameters for cardiovascular diagnosis and disease management. The end-systolic volume (ESV) and end-diastolic volume (EDV) of the left ventricle (LV), and the ejection fraction (EF) are indicators of heart disease. These measures can be derived from the segmented contours of the LV; thus, consistent and accurate segmentation of the LV from MRI images are critical to the accuracy of the ESV, EDV, and EF, and to non-invasive cardiac disease detection. In this work, various image preprocessing techniques, model configurations using the U-Net deep learning architecture, postprocessing methods, and approaches for volume estimation are investigated. An end-to-end analytics pipeline with multiple stages is provided for automated LV segmentation and volume estimation. First, image data are reformatted and processed from DICOM and NIfTI formats to raw images in array format. Secondly, raw images are processed with multiple image preprocessing methods and cropped to include only the Region of Interest (ROI). Thirdly, preprocessed images are segmented using U-Net models. Lastly, post processing of segmented images to remove extra contours along with intelligent slice and frame selection are applied, followed by calculation of the ESV, EDV, and EF. This analytics pipeline is implemented and runs on a distributed computing environment with a GPU cluster at the San Diego Supercomputer Center at UCSD.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{abdolali_Automated_2020,
  ids = {abdolali_Automated_2020a},
  title = {Automated {{Thyroid Nodule Detection From Ultrasound Imaging Using Deep Convolutional Neural Networks}}},
  author = {Abdolali, Fatemeh and Kapur, Jeevesh and Jaremko, Jacob L. and Noga, Michelle and Hareendranathan, Abhilash R. and Punithakumar, Kumaradevan},
  date = {2020-07-01},
  journaltitle = {Computers in Biology and Medicine},
  volume = {122},
  pages = {103871},
  issn = {0010-4825},
  doi = {10.1016/j.compbiomed.2020.103871},
  url = {https://www.sciencedirect.com/science/article/pii/S0010482520302262},
  urldate = {2022-05-16},
  abstract = {Thyroid cancer is the most common endocrine cancer and its incidence has continuously increased worldwide. In this paper, we focus on the challenging problem of nodule detection from ultrasound scans. In current clinical practice, this task is performed manually, which is tedious, subjective and highly depends on the clinical experience of radiologists. We propose a novel deep neural network architecture with carefully designed loss function regularization, and network hyperparameters to perform nodule detection without complex post-processing refinement steps. The local training and validation datasets consist of 2461 and 820 ultrasound frames acquired from 60 and 20 patients with a high degree of variability, respectively. The core of the proposed method is a deep learning framework based on multi-task model Mask R-CNN. We have developed a loss function with regularization that prioritizes detection over segmentation. Validation was conducted for 821 ultrasound frames from 20 patients. The proposed model can detect various types of thyroid nodules. The experimental results indicate that our proposed method is effective in thyroid nodule detection. Comparisons with the results by Faster R-CNN and conventional Mask R-CNN demonstrate that the proposed model outperforms the prior state-of-the-art detection methods.},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Computer aided diagnosis,Convolutional neural network,Deep learning,Mask R-CNN,Thyroid nodules,Ultrasound},
  annotation = {31 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/4CEL382N/Abdolali et al. - 2020 - Automated thyroid nodule detection from ultrasound.pdf;/Users/personal-macbook/Zotero/storage/69TL4SDJ/Abdolali et al. - 2020 - Automated thyroid nodule detection from ultrasound.html;/Users/personal-macbook/Zotero/storage/WI2QKELA/Abdolali et al. - 2020 - Automated thyroid nodule detection from ultrasound.html}
}

@article{abdu_Application_2021a,
  ids = {abdu_Application_2021},
  title = {Application of {{Deep Learning}} on {{Millimeter-Wave Radar Signals}}: {{A Review}}},
  shorttitle = {Application of {{Deep Learning}} on {{Millimeter-Wave Radar Signals}}},
  author = {Abdu, Fahad Jibrin and Zhang, Yixiong and Fu, Maozhong and Li, Yuhan and Deng, Zhenmiao},
  date = {2021-01},
  journaltitle = {Sensors},
  volume = {21},
  number = {6},
  pages = {1951},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {1424-8220},
  doi = {10.3390/s21061951},
  url = {https://www.mdpi.com/1424-8220/21/6/1951},
  urldate = {2022-07-19},
  abstract = {The progress brought by the deep learning technology over the last decade has inspired many research domains, such as radar signal processing, speech and audio recognition, etc., to apply it to their respective problems. Most of the prominent deep learning models exploit data representations acquired with either Lidar or camera sensors, leaving automotive radars rarely used. This is despite the vital potential of radars in adverse weather conditions, as well as their ability to simultaneously measure an object's range and radial velocity seamlessly. As radar signals have not been exploited very much so far, there is a lack of available benchmark data. However, recently, there has been a lot of interest in applying radar data as input to various deep learning algorithms, as more datasets are being provided. To this end, this paper presents a survey of various deep learning approaches processing radar signals to accomplish some significant tasks in an autonomous driving application, such as detection and classification. We have itemized the review based on different radar signal representations, as it is one of the critical aspects while using radar data with deep learning models. Furthermore, we give an extensive review of the recent deep learning-based multi-sensor fusion models exploiting radar signals and camera images for object detection tasks. We then provide a summary of the available datasets containing radar data. Finally, we discuss the gaps and important innovations in the reviewed papers and highlight some possible future research prospects.},
  issue = {6},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,automotive radars,autonomous driving,datasets,deep learning,multi-sensor fusion,object classification,object detection},
  annotation = {24 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/CI3YZ9MU/Abdu et al. - 2021 - Application of Deep Learning on Millimeter-Wave Ra.pdf;/Users/personal-macbook/Zotero/storage/XH3SCFED/Abdu et al. - 2021 - Application of Deep Learning on Millimeter-Wave Ra.html}
}

@article{abidi_Intelligent_2019,
  title = {Intelligent {{Health Data Analytics}}: {{A Convergence}} of {{Artificial Intelligence}} and {{Big Data}}},
  author = {Abidi, Syed Sibte Raza and Abidi, Samina Raza},
  date = {2019},
  journaltitle = {Healthc. Manage. Forum},
  eprint = {31117831},
  eprinttype = {pmid},
  issn = {08404704},
  doi = {10.1177/0840470419846134},
  abstract = {Healthcare is a living system that generates a significant volume of heterogeneous data. As healthcare systems are pivoting to value-based systems, intelligent and interactive analysis of health data is gaining significance for health system management, especially for resource optimization whilst improving care quality and health outcomes. Health data analytics is being influenced by new concepts and intelligent methods emanating from artificial intelligence and big data. In this article, we contextualize health data and health data analytics in terms of the emerging trends of artificial intelligence and big data. We examine the nature of health data using the big data criterion to understand ``how big'' is health data. Next, we explain the working of artificial intelligence\textendash based data analytics methods and discuss ``what insights'' can be derived from a broad spectrum of health data analytics methods to improve health system management, health outcomes, knowledge discovery, and healthcare innovation.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {20 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{abosch_Assessment_2010,
  title = {An {{Assessment}} of {{Current Brain Targets}} for {{Deep Brain Stimulation Surgery With Susceptibility-Weighted Imaging}} at 7 {{Tesla}}},
  author = {Abosch, Aviva and Yacoub, Essa and Ugurbil, Kamil and Harel, Noam},
  date = {2010-12},
  journaltitle = {Neurosurgery},
  volume = {67},
  number = {6},
  pages = {1745--1756},
  issn = {0148-396X},
  doi = {10.1227/NEU.0b013e3181f74105},
  url = {https://journals.lww.com/00006123-201012000-00041},
  urldate = {2023-05-12},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,7-Tesla,Deep brain stimulation,Globus pallidum,Subthalamic,Susceptibility-weighted,Thalamus},
  annotation = {208 citations (Semantic Scholar/DOI) [2023-05-12]},
  file = {/Users/personal-macbook/Zotero/storage/2PVFRT9K/Abosch et al. - 2010 - An Assessment of Current Brain Targets for Deep Br.pdf}
}

@article{abrams_Agreement_1994,
  title = {Agreement {{Among Optometrists}}, {{Ophthalmologists}}, and {{Residents}} in {{Evaluating}} the {{Optic Disc}} for {{Glaucoma}}},
  author = {Abrams, Lisa S. and Scott, Ingrid U. and Spaeth, George L. and Quigley, Harry A. and Varma, Rohit},
  date = {1994},
  journaltitle = {Ophthalmology},
  eprint = {7936564},
  eprinttype = {pmid},
  issn = {01616420},
  doi = {10.1016/S0161-6420(94)31118-3},
  abstract = {Purpose: To determine the agreement among optometrists, ophthalmologists, and ophthalmology residents in assessing glaucomatous optic nerve damage. The authors also determined the sensitivity of each group of observers for identifying glaucomatous optic nerve damage. Methods: Six optometrists, six general ophthalmologists, and six third-year ophthalmology residents evaluated 75 stereoscopic optic disc photographs. Observers estimated the vertical cup:disc ratio (C:D) and assessed the presence of glaucomatous damage. Agreement among and within observers was estimated by the kappa statistic (Kw, k). The sensitivity and specificity for the identification of glaucomatous optic nerve damage were determined for each group of participants. Results: lntraobserver agreement (Kw 0.69-0.79) was greater than interobserver agreement (Kw 0.56-0.68) in assessing the C:D ratio and glaucomatous optic nerve damage for optometrists, ophthalmologists, and residents. Interobserver agreement for ophthalmologists (Kw 0.68) was substantial and significantly higher than for optometrists (Kw 0.56) and residents (Kw 0.56) when estimating the C:D ratio. Ophthalmologists and residents had higher sensitivity (78\%) in identifying glaucomatous optic nerve damage than did optometrists (56\%). The specificity for all three groups was relatively poor (range, 47\%-60\%). Conclusion: The moderate interobserver agreement across all three groups of observers suggests the need to develop standardized criteria for assessing glaucomatous optic disc damage. Ophthalmologists in this study have a higher interobserver agreement in estimating the C:D ratio and are more sensitive than optometrists in assessing glaucomatous optic nerve damage. \textcopyright{} 1994, American Academy of Ophthalmology, Inc. All rights reserved.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {164 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{acsady_Models_2007,
  title = {Models, {{Structure}}, {{Function}}: {{The Transformation}} of {{Cortical Signals}} in the {{Dentate Gyrus}}},
  author = {Acs\'ady, L\'aszl\'o and K\'ali, Szabolcs},
  date = {2007},
  journaltitle = {Prog. Brain Res.},
  volume = {163},
  pages = {577--599},
  doi = {10.1016/S0079-6123(07)63031-3},
  abstract = {Our central question is why the hippocampal CA3 region is the only cortical area capable of forming interference-free representations of complex environmental events (episodes), given that apparently all cortical regions have recurrent excitatory circuits with modifiable synapses, the basic substrate for autoassociative memory networks. We review evidence for the radical (but classic) view that a unique transformation of incoming cortical signals by the dentate gyrus and the subsequent faithful transfer of the resulting code by the mossy fibers are absolutely critical for the appropriate association of memory items by CA3 and, in general, for hippocampal function. In particular, at the gate of the hippocampal formation, the dentate gyrus possesses a set of unusual properties, which selectively evolved for the task of code transformation between cortical afferents and the hippocampus. These evolutionarily conserved anatomical features enable the dentate gyrus to translate the noisy signal of the upstream cortical areas into the sparse and specific code of hippocampal formation, which is indispensable for the efficient storage and recall of multiple, multidimensional memory items. To achieve this goal the mossy fiber pathway maximally utilizes the opportunity to differentially regulate its postsynaptic partners. Selective innervation of CA3 pyramidal cells and interneurons by distinct terminal types creates a favorable condition to differentially regulate the short-term and long-term plasticity and the motility of various mossy terminal types. The utility of this highly dynamic system appears to be the frequency-dependent fine-tuning the excitation and inhibition evoked by the large and the small mossy terminals respectively. This will determine exactly which CA3 cell population is active and induces permanent modification in the autoassociational network of the CA3 region.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{adler_Characterizing_2018,
  title = {Characterizing the {{Human Hippocampus}} in {{Aging}} and {{Alzheimer}}'s {{Disease Using}} a {{Computational Atlas Derived From Ex Vivo MRI}} and {{Histology}}},
  author = {Adler, Daniel H. and Wisse, Laura E. M. and Ittyerah, Ranjit and Pluta, John B. and Ding, Song-Lin and Xie, Long and Wang, Jiancong and Kadivar, Salmon and Robinson, John L. and Schuck, Theresa and Trojanowski, John Q. and Grossman, Murray and Detre, John A. and Elliott, Mark A. and Toledo, Jon B. and Liu, Weixia and Pickup, Stephen and Miller, Michael I. and Das, Sandhitsu R. and Wolk, David A. and Yushkevich, Paul A.},
  date = {2018-04},
  journaltitle = {Proc Natl Acad Sci U A},
  volume = {115},
  number = {16},
  pages = {4252--4257},
  doi = {10.1073/pnas.1801093115},
  abstract = {Although the hippocampus is one of the most studied structures in the human brain, limited quantitative data exist on its 3D organization, anatomical variability, and effects of disease on its subregions. Histological studies provide restricted reference information due to their 2D nature. In this paper, high-resolution ( 200 \$\textbackslash times\$ 200 \$\textbackslash times\$ 200 \${$\mu\$$}m3) ex vivo MRI scans of 31 human hippocampal specimens are combined using a groupwise diffeomorphic registration approach into a 3D probabilistic atlas that captures average anatomy and anatomic variability of hippocampal subfields. Serial histological imaging in 9 of the 31 specimens was used to label hippocampal subfields in the atlas based on cytoarchitecture. Specimens were obtained from autopsies in patients with a clinical diagnosis of Alzheimer's disease (AD; 9 subjects, 13 hemispheres), of other dementia (nine subjects, nine hemispheres), and in subjects without dementia (seven subjects, nine hemispheres), and morphometric analysis was performed in atlas space to measure effects of age and AD on hippocampal subfields. Disproportional involvement of the cornu ammonis (CA) 1 subfield and stratum radiatum lacunosum moleculare was found in AD, with lesser involvement of the dentate gyrus and CA2/3 subfields. An association with age was found for the dentate gyrus and, to a lesser extent, for CA1. Three-dimensional patterns of variability and disease and aging effects discovered via the ex vivo hippocampus atlas provide information highly relevant to the active field of in vivo hippocampal subfield imaging.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Alzheimer's disease,computational anatomy,ex viv},
  annotation = {113 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{aggleton_Hippocampalanterior_2010,
  title = {Hippocampal-{{Anterior Thalamic Pathways}} for {{Memory}}: {{Uncovering}} a {{Network}} of {{Direct}} and {{Indirect Actions}}},
  author = {Aggleton, John P. and O'Mara, Shane M. and Vann, Seralynne D. and Wright, Nick F. and Tsanov, Marian and Erichsen, Jonathan T.},
  date = {2010-06},
  journaltitle = {Eur. J. Neurosci.},
  volume = {31},
  number = {12},
  pages = {2292--2307},
  doi = {10.1111/j.1460-9568.2010.07251.x},
  abstract = {This review charts recent advances from a variety of disciplines that create a new perspective on why the multiple hippocampal-anterior thalamic interconnections are together vital for human episodic memory and rodent event memory. Evidence has emerged for the existence of a series of parallel temporal-diencephalic pathways that function in a reciprocal manner, both directly and indirectly, between the hippocampal formation and the anterior thalamic nuclei. These extended pathways also involve the mammillary bodies, the retrosplenial cortex and parts of the prefrontal cortex. Recent neuropsychological findings reveal the disproportionate importance of these hippocampal-anterior thalamic systems for recollective rather than familiarity-based recognition, while anatomical studies highlight the precise manner in which information streams are kept separate but can also converge at key points within these pathways. These latter findings are developed further by electrophysiological stimulation studies showing how the properties of the direct hippocampal-anterior thalamic projections are often opposed by the indirect hippocampal projections via the mammillary bodies to the thalamus. Just as these hippocampal-anterior thalamic interactions reflect an interdependent system, so it is also the case that pathology in one of the component sites within this system can induce dysfunctional changes to distal sites both directly and indirectly across the system. Such distal effects challenge more traditional views of neuropathology as they reveal how extensive covert pathology might accompany localised overt pathology, and so impair memory.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Amnesia,Fornix,Hippocampus,Mammillary bodies,Recognition memory,Spatial memory,Thalamus},
  annotation = {394 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{agrawal_Exploring_2019,
  title = {Exploring the {{Impact}} of {{Artificial Intelligence}}: {{Prediction Versus Judgment}}},
  author = {Agrawal, Ajay and Gans, Joshua S. and Goldfarb, Avi},
  date = {2019},
  journaltitle = {Inf. Econ. Policy},
  issn = {01676245},
  doi = {10.1016/j.infoecopol.2019.05.001},
  abstract = {Based on recent developments in the field of artificial intelligence (AI), we examine what type of human labor will be a substitute versus a complement to emerging technologies. We argue that these recent developments reduce the costs of providing a particular set of tasks \textendash{} prediction tasks. Prediction about uncertain states of the world is an input into decision-making. We show that prediction allows riskier decisions to be taken and this is its impact on observed productivity although it could also increase the variance of outcomes as well. We consider the role of human judgment in decision-making as prediction technology improves. Judgment is exercised when the objective function for a particular set of decisions cannot be described (i.e., coded). However, we demonstrate that better prediction impacts the returns to different types of judgment in opposite ways. Hence, not all human judgment will be a complement to AI. Finally, we show that humans will delegate some decisions to machines even when the decision would be superior with human input.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{agu_AnaXNet_2021,
  title = {{{AnaXNet}}: {{Anatomy Aware Multi-Label Finding Classification}} in {{Chest X-Ray}}},
  shorttitle = {{{AnaXNet}}},
  booktitle = {Med. {{Image Comput}}. {{Comput}}. {{Assist}}. {{Interv}}. \textendash{} {{MICCAI}} 2021},
  author = {Agu, Nkechinyere N. and Wu, Joy T. and Chao, Hanqing and Lourentzou, Ismini and Sharma, Arjun and Moradi, Mehdi and Yan, Pingkun and Hendler, James},
  editor = {family=Bruijne, given=Marleen, prefix=de, useprefix=true and Cattin, Philippe C. and Cotin, St\'ephane and Padoy, Nicolas and Speidel, Stefanie and Zheng, Yefeng and Essert, Caroline},
  date = {2021},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {12905},
  pages = {804--813},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-87240-3_77},
  url = {https://link.springer.com/10.1007/978-3-030-87240-3_77},
  urldate = {2022-11-21},
  isbn = {978-3-030-87239-7 978-3-030-87240-3},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Graph convolutional networks,Graph representation,Multi-label chest X-ray image classification},
  annotation = {11 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/PX2P87KV/Agu et al. - 2021 - AnaXNet Anatomy Aware Multi-label Finding Classif.pdf}
}

@article{akhondi-asl_Logarithmic_2014,
  title = {A {{Logarithmic Opinion Pool Based Staple Algorithm}} for the {{Fusion}} of {{Segmentations With Associated Reliability Weights}}},
  author = {Akhondi-Asl, Alireza and Hoyte, Lennox and Lockhart, Mark E. and Warfield, Simon K.},
  date = {2014-10},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {33},
  number = {10},
  pages = {1997--2009},
  issn = {0278-0062, 1558-254X},
  doi = {10.1109/TMI.2014.2329603},
  url = {https://ieeexplore.ieee.org/document/6832625/},
  urldate = {2023-01-27},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {59 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/QXQDLDSV/Akhondi-Asl et al. - 2014 - A Logarithmic Opinion Pool Based STAPLE Algorithm .pdf}
}

@article{akkus_Deep_2017,
  title = {Deep {{Learning}} for {{Brain MRI Segmentation}}: {{State}} of the {{Art}} and {{Future Directions}}},
  author = {Akkus, Zeynettin and Galimzianova, Alfiia and Hoogi, Assaf and Rubin, Daniel L. and Erickson, Bradley J.},
  date = {2017-08},
  journaltitle = {J. Digit. Imaging},
  volume = {30},
  number = {4},
  pages = {449--459},
  doi = {10.1007/s10278-017-9983-4},
  abstract = {Quantitative analysis of brain MRI is routine for many neurological diseases and conditions and relies on accurate segmentation of structures of interest. Deep learning-based segmentation approaches for brain MRI are gaining interest due to their self-learning and generalization ability over large amounts of data. As the deep learning architectures are becoming more mature, they gradually outperform previous state-of-the-art classical machine learning algorithms. This review aims to provide an overview of current deep learning-based segmentation approaches for quantitative brain MRI. First we review the current deep learning architectures used for segmentation of anatomical brain structures and brain lesions. Next, the performance, speed, and properties of deep learning approaches are summarized and discussed. Finally, we provide a critical assessment of the current state and identify likely future developments and trends.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Brain lesion segmentation,Convolutional neural ne},
  annotation = {700 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{akkus_Predicting_2016,
  title = {Predicting 1p19q {{Chromosomal Deletion}} of {{Low-Grade Gliomas From MR Images Using Deep Learning}}},
  author = {Akkus, Zeynettin and Ali, Issa and Sedlar, Jiri and Kline, Timothy L. and Agrawal, Jay P. and Parney, Ian F. and Giannini, Caterina and Erickson, Bradley J.},
  date = {2016-11},
  abstract = {Objective: Several studies have associated codeletion of chromosome arms 1p/19q in low-grade gliomas (LGG) with positive response to treatment and longer progression free survival. Therefore, predicting 1p/19q status is crucial for effective treatment planning of LGG. In this study, we predict the 1p/19q status from MR images using convolutional neural networks (CNN), which could be a noninvasive alternative to surgical biopsy and histopathological analysis. Method: Our method consists of three main steps: image registration, tumor segmentation, and classification of 1p/19q status using CNN. We included a total of 159 LGG with 3 image slices each who had biopsy-proven 1p/19q status (57 nondeleted and 102 codeleted) and preoperative postcontrast-T1 (T1C) and T2 images. We divided our data into training, validation, and test sets. The training data was balanced for equal class probability and then augmented with iterations of random translational shift, rotation, and horizontal and vertical flips to increase the size of the training set. We shuffled and augmented the training data to counter overfitting in each epoch. Finally, we evaluated several configurations of a multi-scale CNN architecture until training and validation accuracies became consistent. Results: The results of the best performing configuration on the unseen test set were 93.3\% (sensitivity), 82.22\% (specificity), and 87.7\% (accuracy). Conclusion: Multi-scale CNN with their self-learning capability provides promising results for predicting 1p/19q status noninvasively based on T1C and T2 images. Significance: Predicting 1p/19q status noninvasively from MR images would allow selecting effective treatment strategies for LGG patients without the need for surgical biopsy.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{akram_Connectivity_2018,
  title = {Connectivity {{Derived Thalamic Segmentation}} in {{Deep Brain Stimulation}} for {{Tremor}}},
  author = {Akram, Harith and Dayal, Viswas and Mahlknecht, Philipp and Georgiev, Dejan and Hyam, Jonathan and Foltynie, Thomas and Limousin, Patricia and Vita, Enrico De and Jahanshahi, Marjan and Ashburner, John and Behrens, Tim and Hariz, Marwan and Zrinzo, Ludvic},
  date = {2018-01},
  journaltitle = {Neuroimage Clin},
  volume = {18},
  pages = {130--142},
  doi = {10.1016/j.nicl.2018.01.008},
  abstract = {The ventral intermediate nucleus (VIM) of the thalamus is an established surgical target for stereotactic ablation and deep brain stimulation (DBS) in the treatment of tremor in Parkinson's disease (PD) and essential tremor (ET). It is centrally placed on a cerebello-thalamo-cortical network connecting the primary motor cortex, to the dentate nucleus of the contralateral cerebellum through the dentato-rubro-thalamic tract (DRT). The VIM is not readily visible on conventional MR imaging, so identifying the surgical target traditionally involved indirect targeting that relies on atlas-defined coordinates. Unfortunately, this approach does not fully account for individual variability and requires surgery to be performed with the patient awake to allow for intraoperative targeting confirmation. The aim of this study is to identify the VIM and the DRT using probabilistic tractography in patients that will undergo thalamic DBS for tremor. Four male patients with tremor dominant PD and five patients (three female) with ET underwent high angular resolution diffusion imaging (HARDI) (128 diffusion directions, 1.5 mm isotropic voxels and b value = 1500) preoperatively. Patients received VIM-DBS using an MR image guided and MR image verified approach with indirect targeting. Postoperatively, using parallel Graphical Processing Unit (GPU) processing, thalamic areas with the highest diffusion connectivity to the primary motor area (M1), supplementary motor area (SMA), primary sensory area (S1) and contralateral dentate nucleus were identified. Additionally, volume of tissue activation (VTA) corresponding to active DBS contacts were modelled. Response to treatment was defined as 40\% reduction in the total Fahn-Tolosa-Martin Tremor Rating Score (FTMTRS) with DBS-ON, one year from surgery. Three out of nine patients had a suboptimal, long-term response to treatment. The segmented thalamic areas corresponded well to anatomically known counterparts in the ventrolateral (VL) and ventroposterior (VP) thalamus. The dentate-thalamic area, lay within the M1-thalamic area in a ventral and lateral location. Streamlines corresponding to the DRT connected M1 to the contralateral dentate nucleus via the dentate-thalamic area, clearly crossing the midline in the mesencephalon. Good response was seen when the active contact VTA was in the thalamic area with highest connectivity to the contralateral dentate nucleus. Non-responders had active contact VTAs outside the dentate-thalamic area. We conclude that probabilistic tractography techniques can be used to segment the VL and VP thalamus based on cortical and cerebellar connectivity. The thalamic area, best representing the VIM, is connected to the contralateral dentate cerebellar nucleus. Connectivity based segmentation of the VIM can be achieved in individual patients in a clinically feasible timescale, using HARDI and high performance computing with parallel GPU processing. This same technique can map out the DRT tract with clear mesencephalic crossing.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,1-methyl-4-phenyl-1,2,3,6-tetrahydropyridine,AC,anterior commissure,Bayesian estimation of diffusion parameters obtai,BEDPOSTX,brain extraction tool,caudal zona incerta,CI,CON,confidence interval,connectivity,Connectivity,D,DBS,Deep brain stimulatio,deep brain stimulation,degrees of freedom,DF,DICOM,diffusion weighted imaging,digital imaging and communications in medicine,explanatory variable,field of view,FLIRT,FMRIB,FMRIB's linear image registration tool,FMRIB's non-linear image registration tool,FMRIB's software library,FN,FoV,FSL,general linear model,GLM,HARDI,HFS,high angular resolution diffusion imaging,high frequency stimulation,implantable pulse generator,IPG,l-DOPA equivalent daily dose,LC,LEDD,Levodopa challenge,M1,magnetization-prepared rapid gradient-echo,mini-mental score,MMS,MNI,Montreal neurological institute,MPRAGE,MPTP,National Hospital for Neurology and Neurosurgery,neuroimaging informatics technology initiative,NHNN,Oxford centre for functional MRI of the brain,P,Parkinson's disease,PD,PFC,PMC,posterior commissure,prefrontal cortex,premotor cortex,primary motor cortex,primary sensory cortex,S1,SAR,SD,SE,signal-to-noise ratio,single-shot echo planar imaging,SMA,SNR,specific absorption rate,SSEPI,standard deviation,standard error,STN,subthalamic nucleus,supplementary motor area,TFCE,threshold-free cluster enhancement,TMS,transcranial magnetic stimulation,Tremor,unified Parkinson's disease rating scale,UPDRS,VBM,ventral lateral,ventral posterior,Ventrointermedialis,VIM,VL,volume of tissue activated,voxel based morphometry,VP,VTA},
  annotation = {119 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{akselrod-ballin_Prior_2007,
  title = {Prior {{Knowledge Driven Multiscale Segmentation}} of {{Brain MRI}}},
  author = {Akselrod-Ballin, Ayelet and Galun, Meirav and Gomori, John Moshe and Brandt, Achi and Basri, Ronen},
  date = {2007},
  journaltitle = {Med. Image Comput. Comput. Assist. Interv.},
  volume = {10},
  pages = {118--126},
  abstract = {We present a novel automatic multiscale algorithm applied to segmentation of anatomical structures in brain MRI. The algorithm which is derived from algebraic multigrid, uses a graph representation of the image and performs a coarsening process that produces a full hierarchy of segments. Our main contribution is the incorporation of prior knowledge information into the multiscale framework through a Bayesian formulation. The probabilistic information is based on an atlas prior and on a likelihood function estimated from a manually labeled training set. The significance of our new approach is that the constructed pyramid, reflects the prior knowledge formulated. This leads to an accurate and efficient methodology for detection of various anatomical structures simultaneously. Quantitative validation results on gold standard MRI show the benefit of our approach.},
  issue = {Pt 2},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@incollection{alaydie_Exploiting_2012,
  title = {Exploiting {{Label Dependency}} for {{Hierarchical Multi-Label Classification}}},
  booktitle = {Advances in {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Alaydie, Noor and Reddy, Chandan K. and Fotouhi, Farshad},
  editor = {Tan, Pang-Ning and Chawla, Sanjay and Ho, Chin Kuan and Bailey, James},
  editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
  editorbtype = {redactor},
  date = {2012},
  volume = {7301},
  pages = {294--305},
  publisher = {{Springer Berlin Heidelberg}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-30217-6_25},
  url = {http://link.springer.com/10.1007/978-3-642-30217-6_25},
  urldate = {2022-12-01},
  isbn = {978-3-642-30216-9 978-3-642-30217-6},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{albahli_AIDriven_2021,
  title = {{{AI-Driven Deep CNN Approach}} for {{Multi-Label Pathology Classification Using Chest X-Rays}}},
  author = {Albahli, Saleh and Rauf, Hafiz Tayyab and Algosaibi, Abdulelah and Balas, Valentina Emilia},
  date = {2021-04-20},
  journaltitle = {PeerJ Comput. Sci.},
  volume = {7},
  pages = {e495},
  publisher = {{PeerJ Inc.}},
  issn = {2376-5992},
  doi = {10.7717/peerj-cs.495},
  url = {https://peerj.com/articles/cs-495},
  urldate = {2022-06-23},
  abstract = {Artificial intelligence (AI) has played a significant role in image analysis and feature extraction, applied to detect and diagnose a wide range of chest-related diseases. Although several researchers have used current state-of-the-art approaches and have produced impressive chest-related clinical outcomes, specific techniques may not contribute many advantages if one type of disease is detected without the rest being identified. Those who tried to identify multiple chest-related diseases were ineffective due to insufficient data and the available data not being balanced. This research provides a significant contribution to the healthcare industry and the research community by proposing a synthetic data augmentation in three deep Convolutional Neural Networks (CNNs) architectures for the detection of 14 chest-related diseases. The employed models are DenseNet121, InceptionResNetV2, and ResNet152V2; after training and validation, an average ROC-AUC score of 0.80 was obtained competitive as compared to the previous models that were trained for multi-class classification to detect anomalies in x-ray images. This research illustrates how the proposed model practices state-of-the-art deep neural networks to classify 14 chest-related diseases with better accuracy.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {31 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/KKZ6SRSH/Albahli et al. - 2021 - AI-driven deep CNN approach for multi-label pathol.pdf;/Users/personal-macbook/Zotero/storage/ZNX6CJDA/cs-495.html}
}

@article{aljabar_Multiatlas_2009,
  title = {Multi-{{Atlas Based Segmentation}} of {{Brain Images}}: {{Atlas Selection}} and {{Its Effect}} on {{Accuracy}}},
  author = {Aljabar, P. and Heckemann, R. A. and Hammers, A. and Hajnal, J. V. and Rueckert, D.},
  date = {2009-07},
  journaltitle = {Neuroimage},
  volume = {46},
  number = {3},
  pages = {726--738},
  doi = {10.1016/j.neuroimage.2009.02.018},
  abstract = {Quantitative research in neuroimaging often relies on anatomical segmentation of human brain MR images. Recent multi-atlas based approaches provide highly accurate structural segmentations of the brain by propagating manual delineations from multiple atlases in a database to a query subject and combining them. The atlas databases which can be used for these purposes are growing steadily. We present a framework to address the consequent problems of scale in multi-atlas segmentation. We show that selecting a custom subset of atlases for each query subject provides more accurate subcortical segmentations than those given by non-selective combination of random atlas subsets. Using a database of 275 atlases, we tested an image-based similarity criterion as well as a demographic criterion (age) in a leave-one-out cross-validation study. Using a custom ranking of the database for each subject, we combined a varying number n of atlases from the top of the ranked list. The resulting segmentations were compared with manual reference segmentations using Dice overlap. Image-based selection provided better segmentations than random subsets (mean Dice overlap 0.854 vs. 0.811 for the estimated optimal subset size, n=20). Age-based selection resulted in a similar marked improvement. We conclude that selecting atlases from large databases for atlas-based brain image segmentation improves the accuracy of the segmentations achieved. We show that image similarity is a suitable selection criterion and give results based on selecting atlases by age that demonstrate the value of meta-information for selection.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{allahbakhsh_Quality_2013,
  title = {Quality {{Control}} in {{Crowdsourcing Systems}}: {{Issues}} and {{Directions}}},
  shorttitle = {Quality {{Control}} in {{Crowdsourcing Systems}}},
  author = {Allahbakhsh, M. and Benatallah, B. and Ignjatovic, A. and Motahari-Nezhad, H. R. and Bertino, E. and Dustdar, S.},
  date = {2013-03},
  journaltitle = {IEEE Internet Comput.},
  volume = {17},
  number = {2},
  pages = {76--81},
  issn = {1089-7801},
  doi = {10.1109/MIC.2013.20},
  url = {http://ieeexplore.ieee.org/document/6488672/},
  urldate = {2022-12-28},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {369 citations (Semantic Scholar/DOI) [2022-12-28]},
  file = {/Users/personal-macbook/Zotero/storage/BWYQYPVU/Allahbakhsh et al. - 2013 - Quality Control in Crowdsourcing Systems Issues a.pdf}
}

@article{allaouzi_Novel_2019,
  title = {A {{Novel Approach}} for {{Multi-Label Chest X-Ray Classification}} of {{Common Thorax Diseases}}},
  author = {Allaouzi, Imane and Ben Ahmed, Mohamed},
  date = {2019},
  journaltitle = {IEEE Access},
  volume = {7},
  pages = {64279--64288},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2019.2916849},
  url = {https://ieeexplore.ieee.org/document/8719904/},
  urldate = {2022-11-21},
  keywords = {⛔ No INSPIRE recid found,Biomedical imaging,CAD,CNN,computer vision,CXR,deep learning,Diseases,Feature extraction,image classification,Image classification,image feature extraction,multi-label classification,problem transformation method,Solid modeling,Task analysis,thoracic pathologies,Thorax,transfer learning},
  annotation = {69 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/56H9NHSH/Allaouzi and Ben Ahmed - 2019 - A Novel Approach for Multi-Label Chest X-Ray Class.pdf;/Users/personal-macbook/Zotero/storage/NXHAJ2BH/8719904.html}
}

@article{allassonniere_Coherent_2007,
  title = {Towards a {{Coherent Statistical Framework}} for {{Dense Deformable Template Estimation}}},
  author = {Allassonni\`ere, S. and Amit, Y. and Trouv\'e, A.},
  date = {2007-02},
  journaltitle = {J R Stat Soc Ser. B Stat Methodol},
  volume = {69},
  number = {1},
  pages = {3--29},
  publisher = {{Blackwell Publishing Ltd}},
  doi = {10.1111/j.1467-9868.2007.00574.x},
  abstract = {Summary. The problem of estimating probabilistic deformable template models in the field of computer vision or of probabilistic atlases in the field of computational anatomy has not yet received a coherent statistical formulation and remains a challenge. We provide a careful definition and analysis of a well-defined statistical model based on dense deformable templates for grey level images of deformable objects. We propose a rigorous Bayesian framework for which we prove asymptotic consistency of the maximum a posteriori estimate and which leads to an effective iterative estimation algorithm of the geometric and photometric parameters in the small sample setting. The model is extended to mixtures of finite numbers of such components leading to a fine description of the photometric and geometric variations of an object class. We illustrate some of the ideas with images of handwritten digits and apply the estimated models to classification through maximum likelihood.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Bayesian estimation,Deformable templates,Expecta}
}

@article{alqershi_Robust_2020,
  title = {A {{Robust Consistency Model}} of {{Crowd Workers}} in {{Text Labeling Tasks}}},
  author = {Alqershi, Fattoh and Al-Qurishi, Muhammad and Aksoy, Mehmet Sabih and Alrubaian, Majed and Imran, Muhammad},
  date = {2020},
  journaltitle = {IEEE Access},
  volume = {8},
  pages = {168381--168393},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.3022773},
  url = {https://ieeexplore.ieee.org/document/9187781/},
  urldate = {2022-12-20},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {2 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/HS75YFCP/Alqershi et al. - 2020 - A Robust Consistency Model of Crowd Workers in Tex.pdf}
}

@thesis{alven_Improving_2017,
  ids = {alven_improvingmultiatlassegmentationmethodsmedicalimages_},
  title = {Improving {{Multi-Atlas Segmentation Methods}} for {{Medical Images}}},
  author = {Alv\'en, Jennifer},
  date = {2017},
  institution = {{Chalmers Tekniska Hogskola}},
  location = {{Sweden}},
  url = {https://www.semanticscholar.org/paper/Improving-Multi-Atlas-Segmentation-Methods-for-Alv%C3%A9n/0f6e3415c4947e21d1fd057300d6583af7b91ca3},
  urldate = {2023-05-28},
  abstract = {This thesis includes four papers addressing the difficulties associated with multi-atlas segmentation in several ways; by speeding up and increasing the accuracy of feature-based registration methods, by incorporating explicit shape models into the label fusion framework using robust optimization techniques and by refining the solutions with means of machine learning algorithms, such as random decision forests and convolutional neural networks. Semantic segmentation of organs or tissues, i.e. delineating anatomically or physiologically meaningful boundaries, is an essential task in medical image analysis. One particular class of automatic segmentation algorithms has proved to excel at a diverse set of medical applications, namely multi-atlas segmentation. However, these multi-atlas methods exhibit several issues recognized in the literature. Firstly, multi-atlas segmentation requires several computationally expensive image registrations. In addition, the registration procedure needs to be executed with a high accuracy in order to enable competitive segmentation results. Secondly, up-to-date multi-atlas frameworks require large sets of labelled data to model all possible anatomical variations. Unfortunately, acquisition of manually annotated medical data is time-consuming which needless to say limits the applicability. Finally, standard multi-atlas approaches pose no explicit constraints on the output shape and thus allow for implausibly segmented anatomies. This thesis includes four papers addressing the difficulties associated with multi-atlas segmentation in several ways; by speeding up and increasing the accuracy of feature-based registration methods, by incorporating explicit shape models into the label fusion framework using robust optimization techniques and by refining the solutions with means of machine learning algorithms, such as random decision forests and convolutional neural networks, taking both performance and data-efficiency into account. The proposed improvements are evaluated on three medical segmentation tasks with vastly different characteristics; pericardium segmentation in cardiac CTA images, region parcellation in brain MRI and multi-organ segmentation in whole-body CT images. Extensive experimental comparisons to previously published methods show promising results on par or better than state-of-the-art as of date.},
  langid = {english},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/J4AKZE9R/Alvén - Improving Multi-Atlas Segmentation Methods for Med.pdf;/Users/personal-macbook/Zotero/storage/942EY9T9/0f6e3415c4947e21d1fd057300d6583af7b91ca3.html}
}

@inproceedings{aly_Hierarchical_2019,
  title = {Hierarchical {{Multi-Label Classification}} of {{Text With Capsule Networks}}},
  booktitle = {Proc. 57th {{Annu}}. {{Meet}}. {{Assoc}}. {{Comput}}. {{Linguist}}. {{Stud}}. {{Res}}. {{Workshop}}},
  author = {Aly, Rami and Remus, Steffen and Biemann, Chris},
  date = {2019},
  pages = {323--330},
  publisher = {{Association for Computational Linguistics}},
  location = {{Florence, Italy}},
  doi = {10.18653/v1/P19-2045},
  url = {https://www.aclweb.org/anthology/P19-2045},
  urldate = {2022-12-01},
  eventtitle = {Proceedings of the 57th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}: {{Student Research Workshop}}},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {52 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{amini_Automatic_2004,
  title = {Automatic {{Segmentation}} of {{Thalamus From Brain MRI Integrating Fuzzy Clustering}} and {{Dynamic Contours}}},
  author = {Amini, L. and Soltanian-Zadeh, H. and Lucas, C. and Gity, M.},
  date = {2004-05},
  journaltitle = {IEEE Trans. Biomed. Eng.},
  volume = {51},
  number = {5},
  pages = {800--811},
  issn = {0018-9294},
  doi = {10.1109/TBME.2004.826654},
  url = {http://ieeexplore.ieee.org/document/1288401/},
  urldate = {2023-05-12},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {50 citations (Semantic Scholar/DOI) [2023-05-12]}
}

@article{andersson_How_2003,
  title = {How to {{Correct Susceptibility Distortions}} in {{Spin-Echo Echo-Planar Images}}: {{Application}} to {{Diffusion Tensor Imaging}}},
  author = {Andersson, Jesper L. R. and Skare, Stefan and Ashburner, John},
  date = {2003-10},
  journaltitle = {Neuroimage},
  volume = {20},
  number = {2},
  pages = {870--888},
  doi = {10.1016/S1053-8119(03)00336-7},
  abstract = {Diffusion tensor imaging is often performed by acquiring a series of diffusion-weighted spin-echo echo-planar images with different direction diffusion gradients. A problem of echo-planar images is the geometrical distortions that obtain near junctions between tissues of differing magnetic susceptibility. This results in distorted diffusion-tensor maps. To resolve this we suggest acquiring two images for each diffusion gradient; one with bottom-up and one with top-down traversal of k-space in the phase-encode direction. This achieves the simultaneous goals of providing information on the underlying displacement field and intensity maps with adequate spatial sampling density even in distorted areas. The resulting DT maps exhibit considerably higher geometric fidelity, as assessed by comparison to an image volume acquired using a conventional 3D MR technique.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {2129 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{andreasen_Role_1997,
  title = {The {{Role}} of the {{Thalamus}} in {{Schizophrenia}}},
  author = {Andreasen, N. C.},
  date = {1997-02},
  journaltitle = {Can. J. Psychiatry},
  volume = {42},
  number = {1},
  pages = {27--33},
  doi = {10.1177/070674379704200104},
  abstract = {BACKGROUND: Explaining the diversity of symptoms that occur in schizophrenia is a major conceptual challenge. Perhaps the most powerful strategy is to identify a fundamental cognitive process and/or a fundamental neural circuit. METHODS: Convergent data from our research group in Iowa and from investigators in other centres are summarized. RESULTS: The thalamus plays a key role in information processing. A defect in circuitry connecting the thalamus, frontal cortex, and cerebellum could explain a wide range of symptoms. Neuropathology and imaging studies suggest that patients with schizophrenia may have abnormalities in this circuitry. CONCLUSION: The fundamental deficit in schizophrenia may be conceptualized as a ``cognitive dysmetria'' characterized by impairments in coordinating the perception, encoding, retrieval, and prioritization of experience and information.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{andreassen_Customer_2018,
  title = {Customer {{Inconvenience}} and {{Price Compensation}}: {{A Multiperiod Approach}} to {{Labor-Automation Trade-Offs}} in {{Services}}},
  author = {Andreassen, Tor W. and family=Oest, given=Rutger D., prefix=van, useprefix=false and Lervik-Olsen, Line},
  date = {2018},
  journaltitle = {J. Serv. Res.},
  issn = {15527379},
  doi = {10.1177/1094670517738370},
  abstract = {Managers are faced with complex decisions when considering automating the front end of a service, where the firm interacts with its customers (e.g., check-in at airports). We develop an analytical model for the optimal decisions as to whether to automate the service and which price to charge. The model accounts for automation-induced customer inconvenience in the short run and differences in service quality and production costs in the long run. We show that it may be optimal not to automate, even if automated service reduces production costs for the firm and is ultimately desired by customers. In other situations, automated service is optimal, even though customer inconvenience may trigger financial losses in the short run. Automated service may also become optimal, as customers become more sensitive to service quality, but only if the quality of the automation technology is sufficiently high. We show that the firm should compensate customers for automation-induced inconvenience, but this price compensation can be reduced as customers become more comfortable with the service. Although automated service is cheaper to produce than labor-produced service, the firm should charge a price premium if the quality of the automated service is sufficiently superior.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,analytical model,customer inconvenience,labor-automation trade-offs,price compensation,self-service technology},
  annotation = {16 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{andriluka_2D_2014,
  ids = {mykhayloandriluka_2D_},
  title = {{{2D Human Pose Estimation}}: {{New Benchmark}} and {{State}} of the {{Art Analysis}}},
  shorttitle = {{{2D Human Pose Estimation}}},
  booktitle = {2014 {{IEEE Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}.},
  author = {Andriluka, Mykhaylo and Pishchulin, Leonid and Gehler, Peter and Schiele, Bernt},
  date = {2014-06},
  pages = {3686--3693},
  publisher = {{IEEE}},
  location = {{Columbus, OH, USA}},
  doi = {10.1109/CVPR.2014.471},
  url = {https://ieeexplore.ieee.org/document/6909866},
  urldate = {2023-05-08},
  eventtitle = {2014 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-4799-5118-5},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {1869 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@online{angelopoulos_Gentle_2021,
  ids = {angelopoulos_gentleintroductionconformalpredictiondistributionfreeuncertaintyquantification_2021},
  title = {A {{Gentle Introduction}} to {{Conformal Prediction}} and {{Distribution-Free Uncertainty Quantification}}},
  author = {Angelopoulos, Anastasios N. and Bates, Stephen},
  date = {2021},
  doi = {10.48550/ARXIV.2107.07511},
  url = {https://arxiv.org/abs/2107.07511},
  urldate = {2023-05-03},
  abstract = {Black-box machine learning models are now routinely used in high-risk settings, like medical diagnostics, which demand uncertainty quantification to avoid consequential model failures. Conformal prediction is a user-friendly paradigm for creating statistically rigorous uncertainty sets/intervals for the predictions of such models. Critically, the sets are valid in a distribution-free sense: they possess explicit, non-asymptotic guarantees even without distributional assumptions or model assumptions. One can use conformal prediction with any pre-trained model, such as a neural network, to produce sets that are guaranteed to contain the ground truth with a user-specified probability, such as 90\%. It is easy-to-understand, easy-to-use, and general, applying naturally to problems arising in the fields of computer vision, natural language processing, deep reinforcement learning, and so on. This hands-on introduction is aimed to provide the reader a working understanding of conformal prediction and related distribution-free uncertainty quantification techniques with one self-contained document. We lead the reader through practical theory for and examples of conformal prediction and describe its extensions to complex machine learning tasks involving structured outputs, distribution shift, time-series, outliers, models that abstain, and more. Throughout, there are many explanatory illustrations, examples, and code samples in Python. With each code sample comes a Jupyter notebook implementing the method on a real-data example; the notebooks can be accessed and easily run using our codebase.},
  pubstate = {preprint},
  version = {6},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Artificial Intelligence (cs.AI),FOS: Computer and information sciences,FOS: Mathematics,Machine Learning (cs.LG),Machine Learning (stat.ML),Methodology (stat.ME),Statistics Theory (math.ST)},
  annotation = {126 citations (Semantic Scholar/arXiv) [2023-05-08]}
}

@article{angluin_Learning_1988,
  title = {Learning {{From Noisy Examples}}},
  author = {Angluin, Dana and Laird, Philip},
  date = {1988},
  journaltitle = {Mach. Learn.},
  issn = {15730565},
  doi = {10.1023/A:1022873112823},
  abstract = {The basic question addressed in this paper is: how can a learning algorithm cope with incorrect training examples? Specifically, how can algorithms that produce an ``approximately correct'' identification with ``high probability'' for reliable data be adapted to handle noisy data? We show that when the teacher may make independent random errors in classifying the example data, the strategy of selecting the most consistent rule for the sample is sufficient, and usually requires a feasibly small number of examples, provided noise affects less than half the examples on average. In this setting we are able to estimate the rate of noise using only the knowledge that the rate is less than one half. The basic ideas extend to other types of random noise as well. We also show that the search problem associated with this strategy is intractable in general. However, for particular classes of rules the target rule may be efficiently identified if we use techniques specific to that class. For an important class of formulas \textendash{} the k-CNF formulas studied by Valiant \textendash{} we present a polynomial-time algorithm that identifies concepts in this form when the rate of classification errors is less than one half. \textcopyright{} 1988, Kluwer Academic Publishers. All rights reserved.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Concept learning,learning from examples,noisy data,probably approximately correct learning,theoretical limitations},
  annotation = {568 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{annarumma_Automated_2019,
  title = {Automated {{Triaging}} of {{Adult Chest Radiographs With Deep Artificial Neural Networks}}},
  author = {Annarumma, Mauro and Withey, Samuel J. and Bakewell, Robert J. and Pesce, Emanuele and Goh, Vicky and Montana, Giovanni},
  date = {2019-04},
  journaltitle = {Radiology},
  volume = {291},
  number = {1},
  pages = {196--202},
  issn = {0033-8419, 1527-1315},
  doi = {10.1148/radiol.2018180921},
  url = {http://pubs.rsna.org/doi/10.1148/radiol.2018180921},
  urldate = {2022-11-21},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {161 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/FUR8S959/Annarumma et al. - 2019 - Automated Triaging of Adult Chest Radiographs with.pdf;/Users/personal-macbook/Zotero/storage/EY7WWMHC/radiol.html;/Users/personal-macbook/Zotero/storage/JTFPZHVS/radiol.html}
}

@article{anwar_Medical_2018,
  title = {Medical {{Image Analysis Using Convolutional Neural Networks}}: {{A Review}}},
  author = {Anwar, Syed Muhammad and Majid, Muhammad and Qayyum, Adnan and Awais, Muhammad and Alnowami, Majdi and Khan, Muhammad Khurram},
  date = {2018-10},
  journaltitle = {J. Med. Syst.},
  volume = {42},
  number = {11},
  pages = {226},
  doi = {10.1007/s10916-018-1088-1},
  abstract = {The science of solving clinical problems by analyzing images generated in clinical practice is known as medical image analysis. The aim is to extract information in an affective and efficient manner for improved clinical diagnosis. The recent advances in the field of biomedical engineering have made medical image analysis one of the top research and development area. One of the reasons for this advancement is the application of machine learning techniques for the analysis of medical images. Deep learning is successfully used as a tool for machine learning, where a neural network is capable of automatically learning features. This is in contrast to those methods where traditionally hand crafted features are used. The selection and calculation of these features is a challenging task. Among deep learning techniques, deep convolutional networks are actively used for the purpose of medical image analysis. This includes application areas such as segmentation, abnormality detection, disease classification, computer aided diagnosis and retrieval. In this study, a comprehensive review of the current state-of-the-art in medical image analysis using deep convolutional networks is presented. The challenges and potential of these techniques are also highlighted.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Classification,Computer aided diagnosis,Convolut},
  annotation = {599 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inreference{appen_wawa_2023,
  title = {Calculating {{Worker Agreement}} with {{Aggregate}} ({{Wawa}})},
  url = {https://success.appen.com/hc/en-us/articles/202703205-Calculating-Worker-Agreement-with-Aggregate-Wawa-},
  urldate = {2023-06-30},
  abstract = {Worker agreement with aggregate, or "Wawa", is a common, simple~metric used in jobs that do not employ test questions. It is also known as "inter-rater agreement" or "co-worker agreement."~These al...},
  keywords = {⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/AQBMH9LB/202703205-Calculating-Worker-Agreement-with-Aggregate-Wawa-.html}
}

@article{appenzeller_Determination_2007,
  title = {Determination of the {{Volume}} of {{Sweat Accumulated}} in a {{Sweat-Patch Using Sodium}} and {{Potassium}} as {{Internal Reference}}},
  author = {Appenzeller, Brice M. R. and Schummer, Claude and Rodrigues, Sophie Boura and Wennig, Robert},
  date = {2007},
  journaltitle = {J. Chromatogr. B Analyt. Technol. Biomed. Life. Sci.},
  issn = {15700232},
  doi = {10.1016/j.jchromb.2007.01.037},
  abstract = {In the present work, we assessed the suitability of sodium and potassium physiologically present in sweat, as internal reference allowing to re-calculate the corresponding volume of sweat collected on a PharmChek\texttrademark{} Patch. A method using capillary electrophoresis with indirect ultra-violet detection was developed for the determination of sodium and potassium in sweat. The concentrations determined in specimens collected from 12 females and 10 males, using a home-made system composed of polypropylene copolymer bag, were 1039 {$\pm$} 89 mg/L and 711 {$\pm$} 45 mg/L for sodium, and 489 {$\pm$} 293 mg/L and 474 {$\pm$} 196 mg/L for potassium, respectively. In parallel, for seven females and eight males, the comparison of the volume of sweat collected in the same way to the re-calculated volume of sweat accumulated in a patch using sodium as internal standard, gave an average agreement of 98.4 {$\pm$} 15.0\%. Results demonstrated the usefulness of sodium as internal standard to determine the volume of sweat accumulated in a patch, and confirm the suitability of PharmChek\texttrademark{} patch for the collection and determination of cations in sweat. \textcopyright{} 2007 Elsevier B.V. All rights reserved.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Capillary electrophoresis,Internal reference,Potassium,Sodium,Sweat patch},
  annotation = {38 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{arnold_Racial_2018,
  title = {Racial {{Bias}} in {{Bail Decisions}}},
  author = {Arnold, David and Dobbie, Will and Yang, Crystal S.},
  date = {2018},
  journaltitle = {Q. J. Econ.},
  issn = {15314650},
  doi = {10.1093/qje/qjy012},
  abstract = {This article develops a new test for identifying racial bias in the context of bail decisions-a high-stakes setting with large disparities between white and black defendants. We motivate our analysis using Becker's model of racial bias, which predicts that rates of pretrial misconduct will be identical for marginal white and marginal black defendants if bail judges are racially unbiased. In contrast, marginal white defendants will have higher rates of misconduct than marginal black defendants if bail judges are racially biased, whether that bias is driven by racial animus, inaccurate racial stereotypes, or any other form of bias. To test the model, we use the release tendencies of quasi-randomly assigned bail judges to identify the relevant race-specific misconduct rates. Estimates from Miami and Philadelphia show that bail judges are racially biased against black defendants, with substantially more racial bias among both inexperienced and part-time judges. We find suggestive evidence that this racial bias is driven by bail judges relying on inaccurate stereotypes that exaggerate the relative danger of releasing black defendants.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{artaechevarria_Combination_2009,
  title = {Combination {{Strategies}} in {{Multi-Atlas Image Segmentation}}: {{Application}} to {{Brain MR Data}}},
  author = {Artaechevarria, Xabier and Munoz-Barrutia, Arrate and Ortiz-de-Solorzano, Carlos},
  date = {2009-08},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {28},
  number = {8},
  pages = {1266--1277},
  doi = {10.1109/TMI.2009.2014372},
  abstract = {It has been shown that employing multiple atlas images improves segmentation accuracy in atlas-based medical image segmentation. Each atlas image is registered to the target image independently and the calculated transformation is applied to the segmentation of the atlas image to obtain a segmented version of the target image. Several independent candidate segmentations result from the process, which must be somehow combined into a single final segmentation. Majority voting is the generally used rule to fuse the segmentations, but more sophisticated methods have also been proposed. In this paper, we show that the use of global weights to ponderate candidate segmentations has a major limitation. As a means to improve segmentation accuracy, we propose the generalized local weighting voting method. Namely, the fusion weights adapt voxel-by-voxel according to a local estimation of segmentation performance. Using digital phantoms and MR images of the human brain, we demonstrate that the performance of each combination technique depends on the gray level contrast characteristics of the segmented region, and that no fusion method yields better results than the others for all the regions. In particular, we show that local combination strategies outperform global methods in segmenting high-contrast structures, while global techniques are less sensitive to noise when contrast between neighboring structures is low. We conclude that, in order to achieve the highest overall segmentation accuracy, the best combination method for each particular structure must be selected.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {546 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{arts_Korsakoff_2017,
  title = {Korsakoff's {{Syndrome}}: {{A Critical Review}}},
  shorttitle = {Korsakoff\&rsquo;s Syndrome},
  author = {Arts, Nicolaas and Walvoort, Serge and Kessels, Roy},
  date = {2017-11},
  journaltitle = {NDT},
  volume = {Volume 13},
  pages = {2875--2890},
  issn = {1178-2021},
  doi = {10.2147/NDT.S130078},
  url = {https://www.dovepress.com/korsakoffs-syndrome-a-critical-review-peer-reviewed-article-NDT},
  urldate = {2023-05-12},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,alc,Alcohol amnestic disorder,Ethanol neurotoxicity,Executive function,History,Korsakoff's syndrome,Korsakoff's syndrome,Memory,Thalamus,Thiamine deficiency,Wernicke encephalopathy},
  annotation = {141 citations (Semantic Scholar/DOI) [2023-05-12]},
  file = {/Users/personal-macbook/Zotero/storage/R5CIVWBI/Arts et al. - 2017 - Korsakoff&rsquo\;s syndrome a critical review.pdf}
}

@incollection{artstein_InterAnnotator_2017,
  title = {Inter-{{Annotator Agreement}}},
  booktitle = {Handbook of {{Linguistic Annotation}}},
  author = {Artstein, Ron},
  editor = {Ide, Nancy and Pustejovsky, James},
  date = {2017},
  pages = {297--313},
  publisher = {{Springer Netherlands}},
  location = {{Dordrecht}},
  url = {http://link.springer.com/10.1007/978-94-024-0881-2_11},
  urldate = {2023-02-28},
  isbn = {978-94-024-0879-9 978-94-024-0881-2},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{artstein_InterCoder_2008,
  title = {Inter-{{Coder Agreement}} for {{Computational Linguistics}}},
  author = {Artstein, Ron and Poesio, Massimo},
  date = {2008-12},
  journaltitle = {Computational Linguistics},
  volume = {34},
  number = {4},
  pages = {555--596},
  issn = {0891-2017, 1530-9312},
  doi = {10.1162/coli.07-034-R2},
  url = {https://direct.mit.edu/coli/article/34/4/555-596/1999},
  urldate = {2023-02-28},
  abstract = {This article is a survey of methods for measuring agreement among corpus annotators. It exposes the mathematics and underlying assumptions of agreement coefficients, covering Krippendorff's alpha as well as Scott's pi and Cohen's kappa; discusses the use of coefficients in several annotation tasks; and argues that weighted, alpha-like coefficients, traditionally less used than kappa-like measures in computational linguistics, may be more appropriate for many corpus annotation tasks\textemdash but that their use makes the interpretation of the value of the coefficient even harder.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {865 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/B5XV76J2/Artstein and Poesio - 2008 - Inter-Coder Agreement for Computational Linguistic.pdf}
}

@book{ashbaugh_QuantitativeQualitative_1999,
  title = {Quantitative-{{Qualitative Friction Ridge Analysis}}},
  author = {Ashbaugh, David R.},
  date = {1999},
  doi = {10.1201/9781420048810},
  abstract = {A thumb print left at the scene of a grisly murder. Fingerprints taken from a getaway car used in a bank robbery. A palm print recovered from the shattered glass door of a burglarized home. Indeed, where crimes are committed, careless perpetrators will invariably leave behind the critical pieces of evidencea "most likely in the form of fingerprintsa "needed to catch and convict them. But the science of fingerprint identification isna (TM)t always as cut and dry as detective novels and movies make it out to be. Quantitative-Qualitative Friction Ridge Analysis, a new book in the ongoing Practical Aspects of Criminal and Forensic Investigations series, examines the latest methods and techniques in the science of friction ridge identification, or ridgeology. David R. Ashbaugh examines every facet of the discipline, from the history of friction ridge identification and its earliest pioneers and researchers, to the scientific basis and the various steps of the identification process. The structure and growth of friction skin and how it can leave latent or visible prints are examined, as well as advanced identification methods in ridgeology, including Poroscopy, Edgeoscopy, Pressure Distortion andA Complex or Problem Print Analysis. The book, which features several detailed illustrations and photographs, also includes a new method for Palmar Flexion Crease Identification (palm lines) designed by the author and which has helped solve several criminal cases where fingerprints were not available. For crime scene technicians, forensic identification specialists, or anyone else pursuing a career in forensic science, this book is arguably the definitive source in the science of friction ridge identification.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{ashburner_Unified_2005,
  title = {Unified {{Segmentation}}. {{NeuroImage}}, 26, 839e851},
  author = {Ashburner, J. and Friston, K. J.},
  date = {2005},
  journaltitle = {32Japanese J. Cogn. Neurosci.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{asman_Formulating_2012,
  title = {Formulating {{Spatially Varying Performance}} in the {{Statistical Fusion Framework}}},
  author = {Asman, A. J. and Landman, B. A.},
  date = {2012-06},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {31},
  number = {6},
  pages = {1326--1336},
  issn = {0278-0062, 1558-254X},
  doi = {10.1109/TMI.2012.2190992},
  url = {http://ieeexplore.ieee.org/document/6170564/},
  urldate = {2023-01-27},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {98 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/H7X8SL3E/Asman and Landman - 2012 - Formulating Spatially Varying Performance in the S.pdf}
}

@article{asman_NonLocal_2013,
  title = {Non-{{Local Statistical Label Fusion}} for {{Multi-Atlas Segmentation}}},
  author = {Asman, Andrew J. and Landman, Bennett A.},
  date = {2013-02},
  journaltitle = {Benchmarking Ischemic Stroke Lesion},
  volume = {17},
  number = {2},
  pages = {194--208},
  issn = {13618415},
  doi = {10.1016/j.media.2012.10.002},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1361841512001478},
  urldate = {2023-01-27},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {213 citations (Semantic Scholar/DOI) [2023-01-26]},
  file = {/Users/personal-macbook/Zotero/storage/WFQ9ETKP/Asman and Landman - 2013 - Non-local statistical label fusion for multi-atlas.pdf}
}

@article{asman_Robust_2011,
  title = {Robust {{Statistical Label Fusion Through Consensus Level}}, {{Labeler Accuracy}}, and {{Truth Estimation}} ({{COLLATE}})},
  author = {Asman, A. J. and Landman, B. A.},
  date = {2011-10},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {30},
  number = {10},
  pages = {1779--1794},
  issn = {0278-0062, 1558-254X},
  doi = {10.1109/TMI.2011.2147795},
  url = {http://ieeexplore.ieee.org/document/5756482/},
  urldate = {2023-01-27},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {83 citations (Semantic Scholar/DOI) [2023-01-26]},
  file = {/Users/personal-macbook/Zotero/storage/NDYE45BN/Asman and Landman - 2011 - Robust Statistical Label Fusion Through Consensus .pdf}
}

@article{aubry_Fast_2014,
  title = {Fast {{Local Laplacian Filters}}: {{Theory}} and {{Applications}}},
  author = {Aubry, Mathieu and Paris, Sylvain and Hasinoff, Samuel W. and Kautz, Jan and Durand, Fr\'edo},
  date = {2014},
  journaltitle = {ACM Trans. Graph.},
  issn = {15577368},
  doi = {10.1145/2629645},
  abstract = {Multiscale manipulations are central to image editing but also prone to halos. Achieving artifact-free results requires sophisticated edge-aware techniques and careful parameter tuning. These shortcomings were recently addressed by the local Laplacian filters, which can achieve a broad range of effects using standard Laplacian pyramids. However, these filters are slow to evaluate and their relationship to other approaches is unclear. In this article, we show that they are closely related to anisotropic diffusion and to bilateral filtering. Our study also leads to a variant of the bilateral filter that produces cleaner edges while retaining its speed. Building upon this result, we describe an acceleration scheme for local Laplacian filters on gray-scale images that yields speedups on the order of 50x. Finally, we demonstrate how to use local Laplacian filters to alter the distribution of gradients in an image. We illustrate this property with a robust algorithm for photographic style transfer.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Algorithms,Bilateral filter,Computational photography,Experimentaion,I.3.3 [computer graphics]: picture/image generatio,Image processing,Laplacian pyramid,Photo editing,Photographic style transfer,Theory},
  annotation = {123 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{ausawalaithong_Automatic_2018,
  ids = {ausawalaithong_automaticlungcancerpredictionchestxrayimagesusingdeeplearningapproach_2018},
  title = {Automatic {{Lung Cancer Prediction From Chest X-Ray Images Using}} the {{Deep Learning Approach}}},
  booktitle = {11th {{Biomed}}. {{Eng}}. {{Int}}. {{Conf}}. {{BMEiCON}}},
  author = {Ausawalaithong, Worawate and Thirach, Arjaree and Marukatat, Sanparith and Wilaiprasitporn, Theerawit},
  date = {2018-11},
  pages = {1--5},
  publisher = {{IEEE}},
  location = {{Chiang Mai}},
  doi = {10.1109/BMEiCON.2018.8609997},
  url = {https://ieeexplore.ieee.org/document/8609997/},
  urldate = {2022-11-21},
  eventtitle = {11th {{Biomedical Engineering International Conference}} ({{BMEiCON}})},
  isbn = {978-1-5386-5724-9},
  keywords = {⛔ No INSPIRE recid found,Cancer,Computed tomography,Lung,Sensitivity,Task analysis,Training,X-ray imaging},
  annotation = {79 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/NGRLC2W5/Ausawalaithong et al. - 2018 - Automatic Lung Cancer Prediction from Chest X-ray .pdf;/Users/personal-macbook/Zotero/storage/JLTGK4Y9/8609997.html;/Users/personal-macbook/Zotero/storage/UZ5MC5WK/8609997.html;/Users/personal-macbook/Zotero/storage/YDRENH66/4276ea2f0d543288bf89968cb87cfffbc3799432.html}
}

@article{avants_Symmetric_2008,
  title = {Symmetric {{Diffeomorphic Image Registration With Cross-Correlation}}: {{Evaluating Automated Labeling}} of {{Elderly}} and {{Neurodegenerative Brain}}},
  author = {Avants, B. B. and Epstein, C. L. and Grossman, M. and Gee, J. C.},
  date = {2008-02},
  journaltitle = {Med. Image Anal.},
  volume = {12},
  number = {1},
  pages = {26--41},
  doi = {10.1016/j.media.2007.06.004},
  abstract = {One of the most challenging problems in modern neuroimaging is detailed characterization of neurodegeneration. Quantifying spatial and longitudinal atrophy patterns is an important component of this process. These spatiotemporal signals will aid in discriminating between related diseases, such as frontotemporal dementia (FTD) and Alzheimer's disease (AD), which manifest themselves in the same at-risk population. Here, we develop a novel symmetric image normalization method (SyN) for maximizing the cross-correlation within the space of diffeomorphic maps and provide the Euler-Lagrange equations necessary for this optimization. We then turn to a careful evaluation of our method. Our evaluation uses gold standard, human cortical segmentation to contrast SyN's performance with a related elastic method and with the standard ITK implementation of Thirion's Demons algorithm. The new method compares favorably with both approaches, in particular when the distance between the template brain and the target brain is large. We then report the correlation of volumes gained by algorithmic cortical labelings of FTD and control subjects with those gained by the manual rater. This comparison shows that, of the three methods tested, SyN's volume measurements are the most strongly correlated with volume measurements gained by expert labeling. This study indicates that SyN, with cross-correlation, is a reliable method for normalizing and making anatomical measurements in volumetric MRI of patients and at-risk elderly individuals.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{ayhan_TestTime_2018,
  title = {Test-{{Time Data Augmentation}} for {{Estimation}} of {{Heteroscedastic Aleatoric Uncertainty}} in {{Deep Neural Networks}}},
  author = {Ayhan, M. and Berens, Philipp},
  date = {2018},
  url = {https://www.semanticscholar.org/paper/Test-time-Data-Augmentation-for-Estimation-of-in-Ayhan-Berens/172df6d55b81f184ab0042c49634ccf9b72ed253},
  urldate = {2022-04-25},
  abstract = {This work proposes a simple but effective method using traditional data augmentation methods such as geometric and color transformations at test time to examine how much the network output varies in the vicinity of examples in the input spaces. Deep neural networks (DNNs) have revolutionized medical image analysis and disease diagnosis. Despite their impressive increase in performance, it is difficult to generate well-calibrated probabilistic outputs for such networks such that state-of-the-art networks fail to provide reliable uncertainty estimates regarding their decisions. We propose a simple but effective method using traditional data augmentation methods such as geometric and color transformations at test time. This allows to examine how much the network output varies in the vicinity of examples in the input spaces. Despite its simplicity, our method yields useful estimates for the input-dependent predictive uncertainties of deep neural networks. We showcase the impact of our method via the well-known collection of fundus images obtained from a previous Kaggle competition.},
  eventtitle = {1st {{Conference}} on {{Medical Imaging}} with {{Deep Learning}}},
  langid = {english},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/JPKSJE3Q/Ayhan and Berens - 2018 - Test-Time Data Augmentation for Estimation of Hete.pdf}
}

@article{babalola_Comparison_2008,
  title = {Comparison and {{Evaluation}} of {{Segmentation Techniques}} for {{Subcortical Structures}} in {{Brain MRI}}},
  author = {Babalola, K. O. and Patenaude, B. and Aljabar, P. and Schnabel, J. and Kennedy, D. and Crum, W. and Smith, S. and Cootes, T. F. and Jenkinson, M. and Rueckert, D.},
  date = {2008},
  journaltitle = {Med. Image Comput. Comput. Assist. Interv.},
  volume = {11},
  pages = {409--416},
  abstract = {The automation of segmentation of medical images is an active research area. However, there has been criticism of the standard of evaluation of methods. We have comprehensively evaluated four novel methods of automatically segmenting subcortical structures using volumetric, spatial overlap and distance-based measures. Two of the methods are atlas-based - classifier fusion and labelling (CFL) and expectation-maximisation segmentation using a dynamic brain atlas (EMS), and two model-based - profile active appearance models (PAM) and Bayesian appearance models (BAM). Each method was applied to the segmentation of 18 subcortical structures in 270 subjects from a diverse pool varying in age, disease, sex and image acquisition parameters. Our results showed that all four methods perform on par with recently published methods. CFL performed significantly better than the other three methods according to all three classes of metrics.},
  issue = {Pt 1},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{baccanari_Purification_1975,
  title = {Purification and {{Properties}} of {{Escherichia Coli Dihydrofolate Reductase}}},
  author = {Baccanari, D. and Phillips, A. and Smith, S. and Sinski, D. and Burchall, J.},
  date = {1975-12-02},
  journaltitle = {Biochemistry},
  volume = {14},
  number = {24},
  eprint = {46},
  eprinttype = {pmid},
  pages = {5267--5273},
  issn = {0006-2960},
  doi = {10.1021/bi00695a006},
  abstract = {Dihydrofolate reductase has been purified 40-fold to apparent homogeneity from a trimethoprim-resistant strain of Escherichia coli (RT 500) using a procedure that includes methotrexate affinity column chromatography. Determinations of the molecular weight of the enzyme based on its amino acid composition, sedimentation velocity, and sodium dodecyl sulfate gel electrophoresis gave values of 17680, 17470 and 18300, respectively. An aggregated form of the enzyme with a low specific activity can be separated from the monomer by gel filtration; treatment of the aggregate with mercaptoethanol or dithiothreitol results in an increase in enzymic activity and a regeneration of the monomer. Also, multiple molecular forms of the monomer have been detected by polyacrylamide gel electrophoresis. The unresolved enzyme exhibits two pH optima (pH 4.5 and pH 7.0) with dihydrofolate as a substrate. Highest activities are observed in buffers containing large organic cations. In 100 mM imidazolium chloride (pH 7), the specific activity is 47 mumol of dihydrofolate reduced per min per mg at 30 degrees. Folic acid also serves as a substrate with a single pH optimum of pH 4.5. At this pH the Km for folate is 16 muM, and the Vmax is 1/1000 of the rate observed with dihydrofolate as the substrate. Monovalent cations (Na+, K+, Rb+, and Cs+) inhibit dihydrofolate reductase; at a given ionic strength the degree of inhibition is a function of the ionic radius of the cation. Divalent cations are more potent inhibitors; the I50 of BaCl2 is 250 muM, as compared to 125 mM for KCl. Anions neither inhibit nor activate the enzyme.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Amino Acids,{Chromatography, Affinity},Escherichia coli,Hydrogen-Ion Concentration,Isoenzymes,Kinetics,Macromolecular Substances,Methotrexate,Molecular Weight,Osmolar Concentration,Potassium Chloride,Protein Conformation,Sodium Chloride,Tetrahydrofolate Dehydrogenase},
  file = {/Users/personal-macbook/Zotero/storage/UT3XKK9J/Baccanari et al. - 1975 - Purification and properties of Escherichia coli di.pdf}
}

@online{bahrampour_comparativestudydeeplearningsoftwareframeworks_2015,
  ids = {bahrampour_Comparative_2016,bahrampour_Comparative_2016a},
  title = {Comparative {{Study}} of {{Deep Learning Software Frameworks}}},
  author = {Bahrampour, Soheil and Ramakrishnan, Naveen and Schott, Lukas and Shah, Mohak},
  date = {2015},
  doi = {10.48550/ARXIV.1511.06435},
  url = {https://arxiv.org/abs/1511.06435},
  urldate = {2023-05-08},
  abstract = {Deep learning methods have resulted in significant performance improvements in several application domains and as such several software frameworks have been developed to facilitate their implementation. This paper presents a comparative study of five deep learning frameworks, namely Caffe, Neon, TensorFlow, Theano, and Torch, on three aspects: extensibility, hardware utilization, and speed. The study is performed on several types of deep learning architectures and we evaluate the performance of the above frameworks when employed on a single machine for both (multi-threaded) CPU and GPU (Nvidia Titan X) settings. The speed performance metrics used here include the gradient computation time, which is important during the training phase of deep networks, and the forward time, which is important from the deployment perspective of trained networks. For convolutional networks, we also report how each of these frameworks support various convolutional algorithms and their corresponding performance. From our experiments, we observe that Theano and Torch are the most easily extensible frameworks. We observe that Torch is best suited for any deep architecture on CPU, followed by Theano. It also achieves the best performance on the GPU for large convolutional and fully connected networks, followed closely by Neon. Theano achieves the best performance on GPU for training and deployment of LSTM networks. Caffe is the easiest for evaluating the performance of standard deep architectures. Finally, TensorFlow is a very flexible framework, similar to Theano, but its performance is currently not competitive compared to the other studied frameworks.},
  pubstate = {preprint},
  version = {3},
  keywords = {⛔ No INSPIRE recid found,Computer Science - Machine Learning,FOS: Computer and information sciences,Machine Learning (cs.LG)},
  annotation = {146 citations (Semantic Scholar/arXiv) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/SUX2FM5R/Bahrampour et al. - 2016 - Comparative Study of Deep Learning Software Framew.pdf;/Users/personal-macbook/Zotero/storage/QCTKTRMD/Bahrampour et al. - 2016 - Comparative Study of Deep Learning Software Framew.html}
}

@article{bai_Multiatlas_2015,
  title = {Multi-{{Atlas Segmentation With Augmented Features}} for {{Cardiac MR Images}}},
  author = {Bai, Wenjia and Shi, Wenzhe and Ledig, Christian and Rueckert, Daniel},
  date = {2015-01},
  journaltitle = {Med. Image Anal.},
  volume = {19},
  number = {1},
  pages = {98--109},
  doi = {10.1016/j.media.2014.09.005},
  abstract = {Multi-atlas segmentation infers the target image segmentation by combining prior anatomical knowledge encoded in multiple atlases. It has been quite successfully applied to medical image segmentation in the recent years, resulting in highly accurate and robust segmentation for many anatomical structures. However, to guide the label fusion process, most existing multi-atlas segmentation methods only utilise the intensity information within a small patch during the label fusion process and may neglect other useful information such as gradient and contextual information (the appearance of surrounding regions). This paper proposes to combine the intensity, gradient and contextual information into an augmented feature vector and incorporate it into multi-atlas segmentation. Also, it explores the alternative to the K nearest neighbour (KNN) classifier in performing multi-atlas label fusion, by using the support vector machine (SVM) for label fusion instead. Experimental results on a short-axis cardiac MR data set of 83 subjects have demonstrated that the accuracy of multi-atlas segmentation can be significantly improved by using the augmented feature vector. The mean Dice metric of the proposed segmentation framework is 0.81 for the left ventricular myocardium on this data set, compared to 0.79 given by the conventional multi-atlas patch-based segmentation (Coup\'e et al., 2011; Rousseau et al., 2011). A major contribution of this paper is that it demonstrates that the performance of non-local patch-based segmentation can be improved by using augmented features.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Augmented features,Cardiac image segmentation,Mu}
}

@inproceedings{bai_Semisupervised_2017,
  title = {Semi-{{Supervised Learning}} for {{Network-Based Cardiac MR Image Segmentation}}},
  booktitle = {Lect. {{Notes Comput}}. {{Sci}}.},
  author = {Bai, Wenjia and Oktay, Ozan and Sinclair, Matthew and Suzuki, Hideaki and Rajchl, Martin and Tarroni, Giacomo and Glocker, Ben and King, Andrew and Matthews, Paul M. and Rueckert, Daniel},
  date = {2017},
  issn = {16113349},
  doi = {10.1007/978-3-319-66185-8_29},
  abstract = {Training a fully convolutional network for pixel-wise (or voxel-wise) image segmentation normally requires a large number of training images with corresponding ground truth label maps. However, it is a challenge to obtain such a large training set in the medical imaging domain, where expert annotations are time-consuming and difficult to obtain. In this paper, we propose a semi-supervised learning approach, in which a segmentation network is trained from both labelled and unlabelled data. The network parameters and the segmentations for the unlabelled data are alternately updated. We evaluate the method for short-axis cardiac MR image segmentation and it has demonstrated a high performance, outperforming a baseline supervised method. The mean Dice overlap metric is 0.92 for the left ventricular cavity, 0.85 for the myocardium and 0.89 for the right ventricular cavity. It also outperforms a state-of-the-art multi-atlas segmentation method by a large margin and the speed is substantially faster.},
  isbn = {978-3-319-66184-1},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{bailey_National_2021,
  title = {National {{Audit}} of {{Seven-Day Working Care}} in {{Radiology}}},
  author = {family=Bailey, given=HS, given-i=HS and Mehrotra, P and family=Drinkwater, given=KJ, given-i=KJ and family=Howlett, given=DC, given-i=DC},
  date = {2021-07-05},
  journaltitle = {BJR Open},
  volume = {3},
  number = {1},
  eprint = {34381943},
  eprinttype = {pmid},
  pages = {20200046},
  issn = {2513-9878},
  doi = {10.1259/bjro.20200046},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8320131/},
  urldate = {2022-11-21},
  abstract = {Objectives To evaluate the extent to which our current provision of diagnostic and interventional radiology services matches existing clinical demand and future government proposals as set out in the Royal College of Radiologists published guidance on providing seven-day acute care. Methods In June 2018, all UK radiology department audit leads were sent a questionnaire designed to assess compliance for each standard of the Royal College of Radiologists published guidance on providing seven-day acute care. Results 135 hospitals (68\%) responded. Of those that responded, 96\% of departments have a diagnostic radiologist rota for clinicians to discuss acute cases and review imaging and 48\% of departments do not have a fully staffed consultant rota 24\,h a day, seven days a week for interventional radiology. There is significant variance in MRI radiographer availability within departments, ranging from 18.8\% during Saturday/Sunday evening/overnight up to a maximum of 63.9\% during Saturday daytime. 11\% of departments participate in a regional out of hours cross-organisation reporting rota. 40\% of departments have no 24/7 RIS technical support and 34\% have no PACS technical support out of hours. Conclusion There is a wide variation in practice across radiology departments in the UK. Although there are some standards that the majority of hospitals are achieving, there is a significant short-fall in fundamental aspects of providing acute seven-day care. The multifactorial nature in which these problems have arisen means there is no easy solution to combat these issues. There is a requirement for significant investment and political commitment to improve staffing and infrastructure in order to address the current situation. Advances in knowledge A UK wide evaluation of the current provision of seven-day working in radiology showing 54\% of hospitals do not have a UK working-time regulations compliant Interventional radiology rota, severe lack of availability of acute MRI out of hours and significant deficiencies in providing technical support out of hours. A sustainable and efficient seven-day service is currently not being provided.},
  pmcid = {PMC8320131},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {0 citations (Semantic Scholar/DOI) [2022-11-20]},
  file = {/Users/personal-macbook/Zotero/storage/CJQG59AN/Bailey et al. - 2021 - National audit of seven-day working care in radiol.pdf}
}

@inproceedings{bakas_2018_2018,
  title = {2018 {{International MICCAI BraTS Challenge}}},
  booktitle = {Proc. 7th {{MICCAI BraTS Chall}}.},
  author = {Bakas, Spyridon},
  date = {2018},
  eprint = {3257872},
  eprinttype = {pmid},
  issn = {02731223},
  abstract = {Scope BraTS has always been focused on the evaluation of state-of-the-art methods for the segmentation of brain tumors in magnetic resonance imaging (MRI) scans. BraTS 2017 utilizes multi-institutional pre-operative MRI scans and focuses on the segmentation of intrinsically heterogeneous (in appearance, shape, and histology) brain tumors, namely gliomas. Furthermore, in order to pinpoint the clinical relevance of this segmentation task, BraTS'17 also focuses on the prediction of patient overall survival, via integrative analyses of radiomic features and machine learning algorithms. Clinical Relevance Gliomas are the most common primary brain malignancies, with different degrees of aggressiveness, variable prognosis and various heterogeneous histological sub-regions, i.e. peritumoral edema, necrotic core, enhancing and non-enhancing tumor core. This intrinsic heterogeneity of gliomas is also portrayed in their imaging phenotype (appearance and shape), as their sub-regions are described by varying intensity profiles disseminated across multimodal MRI scans, reflecting varying tumor biological properties. Due to this highly heterogeneous appearance and shape, segmentation of brain tumors in multimodal MRI scans is one of the most challenging tasks in medical image analysis. There is a growing body of literature on computational algorithms addressing this important task. Unfortunately, open data sets for designing and testing these algorithms are not currently available, and private data sets differ so widely that it is hard to compare the different segmentation strategies that have been reported so far. Critical factors leading to these differences include, but not limited to, i) the imaging modalities employed, ii) the type of the tumor (GBM or LGG, primary or secondary tumors, solid or infiltratively growing), and iii) the state of disease (images may not only be acquired prior to treatment, but also post-operatively and therefore show radiotherapy effects and surgically-imposed cavities). Towards this end, BraTS is making available a large dataset with accompanying delineations of the relevant tumor sub-regions.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{bakas_Identifying_2018,
  title = {Identifying the {{Best Machine Learning Algorithms}} for {{Brain Tumor Segmentation}}, {{Progression Assessment}}, and {{Overall Survival Prediction}} in the {{Brats Challenge}}},
  author = {Bakas, Spyridon and Reyes, Mauricio and Jakab, Andras and Bauer, Stefan and Rempfler, Markus and Crimi, Alessandro and Shinohara, Russell Takeshi and Berger, Christoph and Ha, Sung Min and Rozycki, Martin and Prastawa, Marcel and Alberts, Esther and Lipkova, Jana and Freymann, John and Kirby, Justin and Bilello, Michel and Fathallah-Shaykh, Hassan M. and Wiest, Roland and Kirschke, Jan and Wiestler, Benedikt and Colen, Rivka and Kotrotsou, Aikaterini and Lamontagne, Pamela and Marcus, Daniel and Milchenko, Mikhail and Nazeri, Arash and Weber, Marc-Andre Andr and Mahajan, Abhishek and Baid, Ujjwal and Gerstner, Elizabeth and Kwon, Dongjin and Acharya, Gagan and Agarwal, Manu and Alam, Mahbubul and Albiol, Alberto Antonio and Albiol, Alberto Antonio and Albiol, Francisco J. and Alex, Varghese and Allinson, Nigel and Amorim, Pedro H. A. A. and Amrutkar, Abhijit and Anand, Ganesh and Andermatt, Simon and Arbel, Tal and Arbelaez, Pablo and Avery, Aaron and Azmat, Muneeza and Pranjal, B. and Bai, Wenjia and Banerjee, Subhashis and Barth, Bill and Batchelder, Thomas and Batmanghelich, Kayhan and Battistella, Enzo and Beers, Andrew and Belyaev, Mikhail and Bendszus, Martin and Benson, Eze and Bernal, Jose and Bharath, Halandur Nagaraja and Biros, George and Bisdas, Sotirios and Brown, James and Cabezas, Mariano and Cao, Shilei and Cardoso, Jorge M. and Carver, Eric N. and Casamitjana, Adri\`a and Castillo, Laura Silvana and Cat, Marcel and Cattin, Philippe and C\'erigues, Albert and Chagas, Vinicius S. and Chandra, Siddhartha and Chang, Yi-Ju Ju and Chang, Shiyu and Chang, Ken and Chazalon, Joseph and Chen, Shengcong and Chen, Wei and Chen, Jefferson W. and Chen, Zhaolin and Cheng, Kun and Choudhury, Ahana Roy and Chylla, Roger and Clrigues, Albert and Colleman, Steven and Colmeiro, Ramiro German Rodriguez and Combalia, Marc and Costa, Anthony and Cui, Xiaomeng and Dai, Zhenzhen and Dai, Lutao and Daza, Laura Alexandra and Deutsch, Eric and Ding, Changxing and Dong, Chao and Dong, Shidu and Dudzik, Wojciech and Eaton-Rosen, Zach and Egan, Gary and Escudero, Guilherme and Estienne, Tho and Everson, Richard and Fabrizio, Jonathan and Fan, Yong and Fang, Longwei and Feng, Xue and Ferrante, Enzo and Fidon, Lucas and Fischer, Martin and French, Andrew P. and Fridman, Naomi and Fu, Huan and Fuentes, David and Gao, Yaozong and Gates, Evan and Gering, David and Gholami, Amir and Gierke, Willi and Glocker, Ben and Gong, Mingming and Gonzlez-Vill, Sandra and Grosges, T. and Guan, Yuanfang and Guo, Sheng and Gupta, Sudeep and Han, Woo Sup and Han, Il Song and Harmuth, Konstantin and He, Huiguang and Hernndez-Sabat, Aura and Herrmann, Evelyn and Himthani, Naveen and Hsu, Winston and Hsu, Cheyu and Hu, Xiaojun Xiaobin and Hu, Xiaojun Xiaobin and Hu, Yifan Yan and Hu, Yifan Yan and Hua, Rui and Huang, Teng Yi and Huang, Weilin and family=Huffel, given=Sabine, prefix=van, useprefix=false and Huo, Quan and Vivek, H. V. and Iftekharuddin, Khan M. and Isensee, Fabian and Islam, Mobarakol and Jackson, Aaron S. and Jambawalikar, Sachin R. and Jesson, Andrew and Jian, Weijian and Jin, Peter and Jose, V. Jeya Maria and Jungo, Alain and Kainz, Bernhard and Kamnitsas, Konstantinos and Kao, Po Yu and Karnawat, Ayush and Kellermeier, Thomas and Kermi, Adel and Keutzer, Kurt and Khadir, Mohamed Tarek and Khened, Mahendra and Kickingereder, Philipp and Kim, Geena and King, Nik and Knapp, Haley and Knecht, Urspeter and Kohli, Lisa and Kong, Deren and Kong, Xiangmao and Koppers, Simon and Kori, Avinash and Krishnamurthi, Ganapathy and Krivov, Egor and Kumar, Piyush and Kushibar, Kaisar and Lachinov, Dmitrii and Lambrou, Tryphon and Lee, Joon and Lee, Chengen and Lee, Yuehchou and Lee, Matthew Chung Hai and Lefkovits, Szidonia and Lefkovits, Laszlo and Levitt, James and Li, Tengfei and Li, Hongyang Heng Hongwei and Li, Wenqi and Li, Hongyang Heng Hongwei and Li, Xiaoyu Xiaochuan Gang and Li, Yuexiang and Li, Hongyang Heng Hongwei and Li, Zhenye Zeju and Li, Xiaoyu Xiaochuan Gang and Li, Zhenye Zeju and Li, Xiaoyu Xiaochuan Gang and Li, Wenqi and Lin, Zheng Shen and Lin, Fengming and Lio, Pietro and Liu, Chang and Liu, Boqiang and Liu, Xiang and Liu, Mingyuan and Liu, Ju and Liu, Luyan and Llad\'o, Xavier and Lopez, Marc Moreno and Lorenzo, Pablo Ribalta and Lu, Zhentai and Luo, Lin and Luo, Zhigang and Ma, Jun and Ma, Kai and Mackie, Thomas and Madabhushi, Anant and Mahmoudi, Issam and Maier-Hein, Klaus H. and Maji, Pradipta and Mammen, C. P. and Mang, Andreas and Manjunath, B. S. and Marcinkiewicz, Michal and McDonagh, Steven and McKenna, Stephen and McKinley, Richard and Mehl, Miriam and Mehta, Sachin and Mehta, Raghav and Meier, Raphael and Meinel, Christoph and Merhof, Dorit and Meyer, Craig and Miller, Robert and Mitra, Sushmita and Moiyadi, Aliasgar and Molina-Garcia, David and Monteiro, Miguel A. B. and Mrukwa, Grzegorz and Myronenko, Andriy and Nalepa, Jakub and Ngo, Thuyen and Nie, Dong and Ning, Holly and Niu, Chen and Nuechterlein, Nicholas K. and Oermann, Eric and Oliveira, Arlindo and Oliveira, Diego D. C. and Oliver, Arnau and Osman, Alexander F. I. and Ou, Yu Nian and Ourselin, Sebastien and Paragios, Nikos and Park, Moo Sung and Paschke, Brad and Pauloski, J. Gregory and Pawar, Kamlesh and Pawlowski, Nick and Pei, Linmin and Peng, Suting and Pereira, Silvio M. and Perez-Beteta, Julian and Perez-Garcia, Victor M. and Pezold, Simon and Pham, Bao and Phophalia, Ashish and Piella, Gemma and Pillai, G. N. and Piraud, Marie and Pisov, Maxim and Popli, Anmol and Pound, Michael P. and Pourreza, Reza and Prasanna, Prateek and Pr, Vesnakovska and Pridmore, Tony P. and Puch, Santi and Puybareau, Lodie and Qian, Buyue and Qiao, Xu and Rajchl, Martin and Rane, Swapnil and Rebsamen, Michael and Ren, Hongliang and Ren, Xuhua and Revanuru, Karthik and Rezaei, Mina and Rippel, Oliver and Rivera, Luis Carlos and Robert, Charlotte and Rosen, Bruce and Rueckert, Daniel and Safwan, Mohammed and Salem, Mostafa and Salvi, Joaquim and Sanchez, Irina and Snchez, Irina and Santos, Heitor M. and Sartor, Emmett and Schellingerhout, Dawid and Scheufele, Klaudius and Scott, Matthew R. and Scussel, Artur A. and Sedlar, Sara and Serrano-Rubio, Juan Pablo and Shah, N. Jon and Shah, Nameetha and Shaikh, Mazhar and Shankar, B. Uma and Shboul, Zeina and Shen, Haipeng Haocheng and Shen, Dinggang and Shen, Linlin and Shen, Haipeng Haocheng and Shenoy, Varun and Shi, Feng and Shin, Hyung Eun and Shu, Hai and Sima, Diana and Sinclair, Matthew and Smedby, Orjan and Snyder, James M. and Soltaninejad, Mohammadreza and Song, Guidong and Soni, Mehul and Stawiaski, Jean and Subramanian, Shashank and Sun, Li and Sun, Roger and Sun, Jiawei and Sun, Kay and Sun, Yu and Sun, Guoxia and Sun, Shuang and Suter, Yannick R. and Szilagyi, Laszlo and Talbar, Sanjay and Tao, Dacheng and Tao, Dacheng and Teng, Zhongzhao and Thakur, Siddhesh and Thakur, Meenakshi H. and Tharakan, Sameer and Tiwari, Pallavi and Tochon, Guillaume and Tran, Tuan and Tsai, Yuhsiang M. and Tseng, Kuan Lun and Tuan, Tran Anh and Turlapov, Vadim and Tustison, Nicholas and Vakalopoulou, Maria and Valverde, Sergi and Vanguri, Rami and Vasiliev, Evgeny and Ventura, Jonathan and Vera, Luis and Vercauteren, Tom and Verrastro, C. A. and Vidyaratne, Lasitha and Vilaplana, Veronica and Vivekanandan, Ajeet and Wang, Guotai and Wang, Qian and Wang, Chunliang Chiatse J. and Wang, Weichung and Wang, Duo and Wang, Ruixuan and Wang, Yuanyuan and Wang, Chunliang Chiatse J. and Wang, Guotai and Wen, Ning and Wen, Xin and Weninger, Leon and Wick, Wolfgang and Wu, Shaocheng and Wu, Qiang and Wu, Yihong and Xia, Yong and Xu, Yanwu and Xu, Xiaowen and Xu, Peiyuan and Yang, Tsai Ling and Yang, Xiaoping and Yang, Haojin Yu and Yang, Junlin and Yang, Haojin Yu and Yang, Guang and Yao, Hongdou and Ye, Xujiong and Yin, Changchang and Young-Moxon, Brett and Yu, Jinhua and Yue, Xiangyu and Zhang, Songtao and Zhang, Angela and Zhang, Kun and Zhang, Xiang Xuejie Xiaoyue and Zhang, Lichi Lei and Zhang, Xiang Xuejie Xiaoyue and Zhang, Yazhuo and Zhang, Lichi Lei and Zhang, Jianguo and Zhang, Xiang Xuejie Xiaoyue and Zhang, Tianhao and Zhao, Sicheng and Zhao, Yu and Zhao, Xiaomei and Zhao, Liang and Zheng, Yefeng and Zhong, Liming and Zhou, Chenhong and Zhou, Xiaobing and Zhou, Fan and Zhu, Hongtu and Zhu, Jin and Zhuge, Ying and Zong, Weiwei and Kalpathy-Cramer, Jayashree and Farahani, Keyvan and Davatzikos, Christos and family=Leemput, given=Koen, prefix=van, useprefix=false and Menze, Bjoern and B, Pranjal and Bai, Wenjia and Banerjee, Subhashis and Barth, Bill and Batchelder, Thomas and Batmanghelich, Kayhan and Battistella, Enzo and Beers, Andrew and Belyaev, Mikhail and Bendszus, Martin and Benson, Eze and Bernal, Jose and Bharath, Halandur Nagaraja and Biros, George and Bisdas, Sotirios and Brown, James and Cabezas, Mariano and Cao, Shilei and Cardoso, Jorge M. and Carver, Eric N. and Casamitjana, Adri\`a and Castillo, Laura Silvana and Cat\`a, Marcel and Cattin, Philippe and Cerigues, Albert and Chagas, Vinicius S. and Chandra, Siddhartha and Chang, Yi-Ju Ju and Chang, Shiyu and Chang, Ken and Chazalon, Joseph and Chen, Shengcong and Chen, Wei and Chen, Jefferson W. and Chen, Zhaolin and Cheng, Kun and Choudhury, Ahana Roy and Chylla, Roger and Cl\'erigues, Albert and Colleman, Steven and Colmeiro, Ramiro German Rodriguez and Combalia, Marc and Costa, Anthony and Cui, Xiaomeng and Dai, Zhenzhen and Dai, Lutao and Daza, Laura Alexandra and Deutsch, Eric and Ding, Changxing and Dong, Chao and Dong, Shidu and Dudzik, Wojciech and Eaton-Rosen, Zach},
  date = {2018-11},
  journaltitle = {arXiv},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Brain,BraTS,Challenge,Glioblastoma,Glioma,Machine learning,Progression,Radiomics,RANO,RECIST,Segmentation,Survival,Tumor}
}

@article{baker_Creating_2005,
  title = {Creating {{Something From Nothing}}: {{Resource Construction Through Entrepreneurial Bricolage}}},
  author = {Baker, Ted and Nelson, Reed E.},
  date = {2005},
  journaltitle = {Adm. Sci. Q.},
  issn = {00018392},
  doi = {10.2189/asqu.2005.50.3.329},
  abstract = {A field study of 29 resource-constrained firms that varied dramatically in their responses to similar objective environments is used to examine the process by which entrepreneurs in resource-poor environments were able to render unique services by recombining elements at hand for new purposes that challenged institutional definitions and limits. We found that L\'evi-Strauss's concept of bricolage - making do with what is at hand-explained many of the behaviors we observed in small firms that were able to create something from nothing by exploiting physical, social, or institutional inputs that other firms rejected or ignored. We demonstrate the socially constructed nature of resource environments and the role of bricolage in this construction. Using our field data and the existing literature on bricolage, we advance a formal definition of entrepreneurial bricolage and induce the beginnings of a process model of bricolage and firm growth. Central to our contribution is the notion that companies engaging in bricolage refuse to enact the limitations imposed by dominant definitions of resource environments, suggesting that, for understanding entrepreneurial behavior, a constructivist approach to resource environments is more fruitful than objectivist views. \textcopyright{} 2005 by Johnson Graduate School, Cornell University.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {2899 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{baltruschat_Comparison_2019,
  title = {Comparison of {{Deep Learning Approaches}} for {{Multi-Label Chest X-Ray Classification}}},
  author = {Baltruschat, Ivo M. and Nickisch, Hannes and Grass, Michael and Knopp, Tobias and Saalbach, Axel},
  date = {2019-04-23},
  journaltitle = {Sci Rep},
  volume = {9},
  number = {1},
  pages = {6381},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/s41598-019-42294-8},
  url = {https://www.nature.com/articles/s41598-019-42294-8},
  urldate = {2022-11-21},
  abstract = {The increased availability of labeled X-ray image archives (e.g. ChestX-ray14 dataset) has triggered a growing interest in deep learning techniques. To provide better insight into the different approaches, and their applications to chest X-ray classification, we investigate a powerful network architecture in detail: the ResNet-50. Building on prior work in this domain, we consider transfer learning with and without fine-tuning as well as the training of a dedicated X-ray network from scratch. To leverage the high spatial resolution of X-ray data, we also include an extended ResNet-50 architecture, and a network integrating non-image data (patient age, gender and acquisition type) in the classification process. In a concluding experiment, we also investigate multiple ResNet depths (i.e. ResNet-38 and ResNet-101). In a systematic evaluation, using 5-fold re-sampling and a multi-label loss function, we compare the performance of the different approaches for pathology classification by ROC statistics and analyze differences between the classifiers using rank correlation. Overall, we observe a considerable spread in the achieved performance and conclude that the X-ray-specific ResNet-38, integrating non-image data yields the best overall results. Furthermore, class activation maps are used to understand the classification process, and a detailed analysis of the impact of non-image features is provided.},
  issue = {1},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Computational science,Pathology,Radiography},
  annotation = {233 citations (Semantic Scholar/DOI) [2023-05-08] 167 citations (Crossref) [2022-11-20]},
  file = {/Users/personal-macbook/Zotero/storage/J65TM2J9/Baltruschat et al. - 2019 - Comparison of Deep Learning Approaches for Multi-L.pdf;/Users/personal-macbook/Zotero/storage/J68I6D3W/s41598-019-42294-8.html;/Users/personal-macbook/Zotero/storage/VZ626ELQ/s41598-019-42294-8.html}
}

@inproceedings{barandela_Decontamination_2000,
  title = {Decontamination of {{Training Samples}} for {{Supervised Pattern Recognition Methods}}},
  booktitle = {Adv. {{Pattern Recognit}}.},
  author = {Barandela, Ricardo and Gasca, Eduardo},
  date = {2000},
  pages = {621--630},
  publisher = {{Springer Berlin Heidelberg}},
  doi = {10.1007/3-540-44522-6_64},
  abstract = {The present work discusses what have been called' imperfectly supervised situations': pattern recognition applications where the assumption of label correctness does not hold for all the elements of the training sample. A methodology for contending with these practical situations and to avoid their negative impact on the performance of supervised methods is presented. This methodology can be regarded as a cleaning process removing some suspicious instances of the training sample or correcting the class labels of some others while retaining them. It has been conceived for doing classification with the Nearest Neighbor rule, a supervised nonparametric classifier that combines conceptual simplicity and an asymptotic error rate bounded in terms of the optimal Bayes error. However, initial experiments concerning the learning phase of a Multilayer Perceptron (not reported in the present work) seem to indicate a broader applicability. Results with both simulated and real data sets are presented to support the methodology and to clarify the ideas behind it. Related works are briefly reviewed and some issues deserving further research are also exposed.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Depuration methodology,Generalized edition,Learning,Nearest neighbor classifier,Supervised methods},
  annotation = {93 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{bartlett_Convexity_2006,
  title = {Convexity, {{Classification}}, and {{Risk Bounds}}},
  author = {Bartlett, Peter L. and Jordan, Michael I. and McAuliffe, Jon D. and Peter L. BARTLETT, Michael I. JORDAN and MCAULIFFE, Jon D. and Bartlett, Peter L. and Jordan, Michael I. and McAuliffe, Jon D.},
  date = {2006},
  journaltitle = {J. Am. Stat. Assoc.},
  issn = {01621459},
  doi = {10.1198/016214505000000907},
  abstract = {Many of the classification algorithms developed in the machine learning literature, including the support vector machine and boosting, can be viewed as minimum contrast methods that minimize a convex surrogate of the 0-1 loss function. The convexity makes these algorithms computationally efficient. The use of a surrogate, however, has statistical consequences that must be balanced against the computational virtues of convexity. To study these issues, we provide a general quantitative relationship between the risk as assessed using the 0-1 loss and the risk as assessed using any nonnegative surrogate loss function. We show that this relationship gives nontrivial upper bounds on excess risk under the weakest possible condition on the loss function - that it satisfies a pointwise form of Fisher consistency for classification. The relationship is based on a simple variational transformation of the loss function that is easy to compute in many applications. We also present a refined version of this result in the case of low noise, and show that in this case, strictly convex loss functions lead to faster rates of convergence of the risk than would be implied by standard uniform convergence arguments. Finally, we present applications of our results to the estimation of convergence rates in function classes that are scaled convex hulls of a finite-dimensional base class, with a variety of commonly used loss functions. \textcopyright{} 2006 American Statistical Association.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Boosting,Convex optimization,Empirical process theory,Machine learning,Rademacher complexity,Support vector machine},
  annotation = {1295 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{bartoletti_AI_2019,
  title = {{{AI}} in {{Healthcare}}: {{Ethical}} and {{Privacy Challenges}}},
  booktitle = {Lect. {{Notes Comput}}. {{Sci}}. {{Subser}}. {{Lect}}. {{Notes Artif}}. {{Intell}}. {{Lect}}. {{Notes Bioinforma}}.},
  author = {Bartoletti, Ivana},
  date = {2019},
  issn = {16113349},
  doi = {10.1007/978-3-030-21642-9_2},
  abstract = {The deployment of Artificial Intelligence in healthcare is extremely promising and although AI is no panacea, harnessing patient data will lead to precision medicine, help detect disease before they manifest and support independent living for the elderly, amongst many other things. However, this progress will not be without challenges from both an ethical and privacy standpoint. These issues need understanding from policy makers and developers alike for AI to be embraced responsibly.},
  isbn = {978-3-030-21641-2},
  keywords = {\#nosource,⛔ No INSPIRE recid found,AI,Ethics,Healthcare,Privacy},
  annotation = {40 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@book{bartsch_Clinical_2012,
  title = {The {{Clinical Neurobiology}} of the {{Hippocampus}}: {{An Integrative View}}},
  author = {Bartsch, Thorsten},
  date = {2012-07},
  publisher = {{OUP Oxford}},
  abstract = {The hippocampus is one of the most studied structures in the human brain and plays a pivotal role in human memory function. Its recognized function is reflected by the presence of an extensive body of neurophysiological, neuropsychological, anatomical and neurocomputational literature that presents basic mechanisms, theoretical models and psychological concepts. However, in the rapidly growing field of hippocampal research, the clinical aspects of diseases that affect the hippocampus are greatly under-represented in current literature, and clinical approaches and concepts are scattered throughout various clinical and basic scientific disciplines. The Clinical Neurobiology of the Hippocampus explores clinical approaches to the range of diseases that affect the hippocampus. It brings together and reviews the common methods, clinical findings, concepts, mechanisms and, where applicable, therapeutic strategies for these clinical approaches. The clinical spectrum of hippocampal dysfunction encompasses a wide range of neurological, behavioural and psychiatric symptoms and surpasses the ability to encode, store and retrieve information. The relevance of hippocampal involvement in clinical diseases goes beyond mere neuropsychological deficits and includes psychopathological states in various conditions, such as acute amnesic syndromes, Alzheimer's disease, temporal lobe epilepsy (TLE), sleep, stroke medicine, limbic encephalitis, neurodevelopmental disorders, stress- and trauma-related disorders, depression, and schizophrenia. The first part of the book covers the basic and integrative features of the hippocampus, such as the anatomy and imaging of this structure, and the basic mechanisms of hippocampal function, including the principles of hippocampus-dependent memory processing in amnesia and sleep, the mechanisms of vulnerability and adult neurogenesis as well as the effects of stress. The second part covers the various clinical manifestations in which the hippocampus is involved and in which the preceding basic mechanisms are reflected. Bringing together a broad team of experts on the basic and clinical aspects of the hippocampus, the book provides an integrative view of the hippocampus. It is invaluable for neurologists, neuroscientists, and psychiatrists, and will stimulate interdisciplinary discussions in clinical neuroscience.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{bates_Big_2014,
  title = {Big {{Data}} in {{Health Care}}: {{Using Analytics}} to {{Identify}} and {{Manage High-Risk}} and {{High-Cost Patients}}},
  author = {Bates, David W. and Saria, Suchi and Ohno-Machado, Lucila and Shah, Anand and Escobar, Gabriel},
  date = {2014},
  journaltitle = {Health Aff. (Millwood)},
  eprint = {25006137},
  eprinttype = {pmid},
  issn = {15445208},
  doi = {10.1377/hlthaff.2014.0041},
  abstract = {The US health care system is rapidly adopting electronic health records, which will dramatically increase the quantity of clinical data that are available electronically. Simultaneously, rapid progress has been made in clinical analytics-techniques for analyzing large quantities of data and gleaning new insights from that analysis-which is part of what is known as big data. As a result, there are unprecedented opportunities to use big data to reduce the costs of health care in the United States. We present six use cases-that is, key examples-where some of the clearest opportunities exist to reduce costs through the use of big data: high-cost patients, readmissions, triage, decompensation (when a patient's condition worsens), adverse events, and treatment optimization for diseases affecting multiple organ systems. We discuss the types of insights that are likely to emerge from clinical analytics, the types of data needed to obtain such insights, and the infrastructure-analytics, algorithms, registries, assessment scores, monitoring devices, and so forth-that organizations will need to perform the necessary analyses and to implement changes that will improve care while reducing costs. Our findings have policy implications for regulatory oversight, ways to address privacy concerns, and the support of research on analytics. \textcopyright{} 2014 by Project HOPE - The People-to-People Health Foundation.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {839 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{batista_Basal_2012,
  title = {Basal {{Ganglia}}, {{Thalamus}} and {{Neocortical Atrophy Predicting Slowed Cognitive Processing}} in {{Multiple Sclerosis}}},
  author = {Batista, Sonia and Zivadinov, Robert and Hoogs, Marietta and Bergsland, Niels and Heininen-Brown, Mari and Dwyer, Michael G. and Weinstock-Guttman, Bianca and Benedict, Ralph H. B.},
  date = {2012-01},
  journaltitle = {J. Neurol.},
  volume = {259},
  number = {1},
  pages = {139--146},
  doi = {10.1007/s00415-011-6147-1},
  abstract = {Information-processing speed (IPS) slowing is a primary cognitive deficit in multiple sclerosis (MS). Basal ganglia, thalamus and neocortex are thought to have a key role for efficient information-processing, yet the specific relative contribution of these structures for MS-related IPS impairment is poorly understood. To determine if basal ganglia and thalamus atrophy independently contribute to visual and auditory IPS impairment in MS, after controlling for the influence of neocortical volume, we enrolled 86 consecutive MS patients and 25 normal controls undergoing 3T brain MRI and neuropsychological testing. Using Sienax and FIRST software, neocortical and deep gray matter (DGM) volumes were calculated. Neuropsychological testing contributed measures of auditory and visual IPS using the Paced Auditory Serial Addition Test (PASAT) and the Symbol Digit Modalities Test (SDMT), respectively. MS patients exhibited significantly slower IPS relative to controls and showed reduction in neocortex, caudate, putamen, globus pallidus, thalamus and nucleus accumbens volume. SDMT and PASAT were significantly correlated with all DGM regions. These effects were mitigated by controlling for the effects of neocortical volume, but all DGM volumes remained significantly correlated with SDMT, putamen (r = 0.409, p {$<$} 0.001) and thalamus (r = 0.362, p {$<$} 0.001) having the strongest effects, whereas for PASAT, the correlation was significant for putamen (r = 0.313, p {$<$} 0.01) but not for thalamus. We confirm the significant role of thalamus atrophy in MS-related IPS slowing and find that putamen atrophy is also a significant contributor to this disorder. These DGM structures have independent, significant roles, after controlling for the influence of neocortex atrophy.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {282 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{battistella_Robust_2017,
  title = {Robust {{Thalamic Nuclei Segmentation Method Based}} on {{Local Diffusion Magnetic Resonance Properties}}},
  author = {Battistella, Giovanni and Najdenovska, Elena and Maeder, Philippe and Ghazaleh, Naghmeh and Daducci, Alessandro and Thiran, Jean-Philippe and Jacquemont, S\'ebastien and Tuleasca, Constantin and Levivier, Marc and Cuadra, Meritxell Bach and Fornari, Eleonora},
  date = {2017-07},
  journaltitle = {Brain Struct. Funct.},
  volume = {222},
  number = {5},
  pages = {2203--2216},
  doi = {10.1007/s00429-016-1336-4},
  abstract = {The thalamus is an essential relay station in the cortical-subcortical connections. It is characterized by a complex anatomical architecture composed of numerous small nuclei, which mediate the involvement of the thalamus in a wide range of neurological functions. We present a novel framework for segmenting the thalamic nuclei, which explores the orientation distribution functions (ODFs) from diffusion magnetic resonance images at 3 T. The differentiation of the complex intra-thalamic microstructure is improved by using the spherical harmonic (SH) representation of the ODFs, which provides full angular characterization of the diffusion process in each voxel. The clustering was performed using the k-means algorithm initialized in a data-driven manner. The method was tested on 35 healthy volunteers and our results show a robust, reproducible and accurate segmentation of the thalamus in seven nuclei groups. Six of them closely matched the anatomy and were labeled as anterior, ventral anterior, medio-dorsal, ventral latero-ventral, ventral latero-dorsal and pulvinar, while the seventh cluster included the centro-lateral and the latero-posterior nuclei. Results were evaluated both qualitatively, by comparing the segmented nuclei to the histological atlas of Morel, and quantitatively, by measuring the clusters' extent and the clusters' spatial distribution across subjects and hemispheres. We also showed the robustness of our approach across different sequences and scanners, as well as intra-subject reproducibility of the segmented clusters using additional two scan-rescan datasets. We also observed an overlap between the path of the main long-connection tracts passing through the thalamus and the spatial distribution of the nuclei identified with our clustering algorithm. Our approach, based on SH representations of the ODFs, outperforms the one based on angular differences between the principle diffusion directions, which is considered so far as state-of-the-art method. Our findings show an anatomically reliable segmentation of the main groups of thalamic nuclei that could be of potential use in many clinical applications.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Orientation distribution function,S,Segmentation,Spherical harmonics,Thalamic nuclei}
}

@article{bazin_Homeomorphic_2008,
  title = {Homeomorphic {{Brain Image Segmentation With Topological}} and {{Statistical Atlases}}},
  author = {Bazin, Pierre-Louis and Pham, Dzung L.},
  date = {2008-10},
  journaltitle = {Med. Image Anal.},
  volume = {12},
  number = {5},
  pages = {616--625},
  doi = {10.1016/j.media.2008.06.008},
  abstract = {Atlas-based segmentation techniques are often employed to encode anatomical information for the delineation of multiple structures in magnetic resonance images of the brain. One of the primary challenges of these approaches is to efficiently model qualitative and quantitative anatomical knowledge without introducing a strong bias toward certain anatomical preferences when segmenting new images. This paper explores the use of topological information as a prior and proposes a segmentation framework based on both topological and statistical atlases of brain anatomy. Topology can be used to describe continuity of structures, as well as the relationships between structures, and is often a critical component in cortical surface reconstruction and deformation-based morphometry. Our method guarantees strict topological equivalence between the segmented image and the atlas, and relies only weakly on a statistical atlas of shape. Tissue classification and fast marching methods are used to provide a powerful and flexible framework to handle multiple image contrasts, high levels of noise, gain field inhomogeneities, and variable anatomies. The segmentation algorithm has been validated on simulated and real brain image data and made freely available to researchers. Our experiments demonstrate the accuracy and robustness of the method and the limited influence of the statistical atlas.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {117 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{beam_Challenges_2020,
  title = {Challenges to the {{Reproducibility}} of {{Machine Learning Models}} in {{Health Care}}},
  author = {Beam, Andrew L. and Manrai, Arjun K. and Ghassemi, Marzyeh},
  date = {2020-01-28},
  journaltitle = {JAMA},
  volume = {323},
  number = {4},
  pages = {305--306},
  issn = {0098-7484},
  doi = {10.1001/jama.2019.20866},
  url = {https://doi.org/10.1001/jama.2019.20866},
  urldate = {2022-06-14},
  abstract = {Reproducibility has been an important and intensely debated topic in science and medicine for the past few decades. As the scientific enterprise has grown in scope and complexity, concerns regarding how well new findings can be reproduced and validated across different scientific teams and study populations have emerged. In some instances, the failure to replicate numerous previous studies has added to the growing concern that science and biomedicine may be in the midst of a ``reproducibility crisis.'' Against this backdrop, high-capacity machine learning models are beginning to demonstrate early successes in clinical applications, and some have received approval from the US Food and Drug Administration. This new class of clinical prediction tools presents unique challenges and obstacles to reproducibility, which must be carefully considered to ensure that these techniques are valid and deployed safely and effectively.},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {145 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/XP3EQW7A/Beam et al. - 2020 - Challenges to the Reproducibility of Machine Learn.pdf;/Users/personal-macbook/Zotero/storage/QWHBTKMU/2758612.html}
}

@article{beam_Translating_2016,
  title = {Translating {{Artificial Intelligence Into Clinical Care}}},
  author = {Beam, Andrew L. and Kohane, Isaac S.},
  date = {2016},
  journaltitle = {JAMA - J. Am. Med. Assoc.},
  eprint = {27898974},
  eprinttype = {pmid},
  issn = {15383598},
  doi = {10.1001/jama.2016.17217},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{beck_Serum_1975,
  title = {A {{Serum Haemagglutinating Property Dependent Upon Polycarboxyl Groups}}},
  author = {Beck, M. L. and Freihaut, B. and Henry, R. and Pierce, S. and Bayer, W. L.},
  date = {1975-01},
  journaltitle = {Br J Haematol},
  volume = {29},
  number = {1},
  eprint = {32},
  eprinttype = {pmid},
  pages = {149--156},
  issn = {0007-1048},
  doi = {10.1111/j.1365-2141.1975.tb01808.x},
  abstract = {A serum agglutinin reactive with red cells in the presence of polycarboxyl groups is reported. It is likely that this represents an additional example of the type of agglutinin previously described as agglutinating red cells in the absence of ionized calcium. Experimental evidence is presented indicating that it is free polycarboxyl groups that potentiate agglutination and that any metal ion, such as calcium, capable of chelating with these groups will prove to be inhibitory.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,ABO Blood-Group System,Aged,Agglutinins,Antibody Specificity,Carboxylic Acids,{Cations, Divalent},Citrates,Edetic Acid,Ficain,Hemagglutination,Humans,Hydrogen-Ion Concentration,Neuraminidase,Papain},
  annotation = {22 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{behrens_Noninvasive_2003,
  ids = {mckhann_noninvasivemappingconnectionshumanthalamuscortexusingdiffusionimaging_2004},
  title = {Non-{{Invasive Mapping}} of {{Connections Between Human Thalamus}} and {{Cortex Using Diffusion Imaging}}},
  author = {Behrens, T E J and Johansen-Berg, H and Woolrich, M W and Smith, S M and Wheeler-Kingshott, C A M and Boulby, P A and Barker, G J and Sillery, E L and Sheehan, K and Ciccarelli, O and Thompson, A J and Brady, J M and Matthews, P M},
  date = {2003-07},
  journaltitle = {Nat Neurosci},
  volume = {6},
  number = {7},
  pages = {750--757},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn1075},
  url = {http://www.nature.com/articles/nn1075},
  urldate = {2023-05-18},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {2166 citations (Semantic Scholar/DOI) [2023-05-17]}
}

@inproceedings{beigman_Learning_2009,
  ids = {beigman_Learning_},
  title = {Learning {{With Annotation Noise}}},
  booktitle = {Proc. {{Jt}}. {{Conf}}. 47th {{Annu}}. {{Meet}}. {{ACL}} 4th {{Int}}. {{Jt}}. {{Conf}}. {{Nat}}. {{Lang}}. {{Process}}. {{AFNLP Vol}}. 1 - {{ACL-IJCNLP}} 09},
  author = {Beigman, Eyal and Klebanov, Beata Beigman},
  date = {2009},
  volume = {1},
  pages = {280},
  publisher = {{Association for Computational Linguistics}},
  location = {{Suntec, Singapore}},
  doi = {10.3115/1687878.1687919},
  url = {http://portal.acm.org/citation.cfm?doid=1687878.1687919},
  urldate = {2023-05-09},
  eventtitle = {The {{Joint Conference}} of the 47th {{Annual Meeting}} of the {{ACL}} and the 4th {{International Joint Conference}}},
  isbn = {978-1-932432-45-9},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {89 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/N3MQ4LE8/Beigman and Klebanov - 2009 - Learning with annotation noise.pdf}
}

@article{belkin_Manifold_2004,
  title = {Manifold {{Regularization}}: {{A Geometric Framework}} for {{Learning From Examples}}},
  author = {Belkin, Mikhail and Niyogi, Partha and Sindhwani, Vikas},
  date = {2004},
  journaltitle = {Learning},
  issn = {15324435},
  abstract = {We propose a family of learning algorithms based on a new form of regularization that allows us to exploit the geometry of the marginal distribution. We focus on a semi-supervised framework that incorporates labeled and unlabeled data in a general-purpose learner. Some transductive graph learning algorithms and standard methods including Support Vector Machines and Regularized Least Squares can be obtained as special cases. We utilize properties of Reproducing Kernel Hilbert spaces to prove new Representer theorems that provide theoretical basis for the algorithms. As a result (in contrast to purely graph based approaches) we obtain a natural out-of-sample extension to novel examples and so are able to handle both transductive and truly semi-supervised settings. We present experimental evidence suggesting that our semi-supervised algorithms are able to use unlabeled data effectively. Finally we have a brief discussion of unsupervised and fully supervised learning within our general framework.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{bellaviti_Increased_2016,
  title = {Increased {{Incidence}} of {{Spontaneous Pneumothorax}} in {{Very Young People}}: {{Observations}} and {{Treatment}}},
  shorttitle = {Increased {{Incidence}} of {{Spontaneous Pneumothorax}} in {{Very Young People}}},
  author = {Bellaviti, Nadia and Bini, Francesco and Pennacchi, Luca and Pepe, Giuseppe and Bodini, Bruno and Ceriani, Roberto and D'Urbano, Corrado and Vaghi, Adriano},
  date = {2016-10-01},
  journaltitle = {CHEST},
  volume = {150},
  number = {4},
  pages = {560A},
  publisher = {{Elsevier}},
  issn = {0012-3692},
  doi = {10.1016/j.chest.2016.08.649},
  url = {https://journal.chestnet.org/article/S0012-3692(16)56848-2/abstract},
  urldate = {2022-12-15},
  abstract = {SESSION TITLE: Disorders of the Pleura},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {3 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/Z9GISQCB/Bellaviti et al. - 2016 - Increased Incidence of Spontaneous Pneumothorax in.pdf;/Users/personal-macbook/Zotero/storage/HL4GS7HH/fulltext.html;/Users/personal-macbook/Zotero/storage/UVGB29EC/fulltext.html}
}

@article{bello_Review_2020,
  title = {Review: {{Deep Learning}} on {{3D Point Clouds}}},
  shorttitle = {Review},
  author = {Bello, Saifullahi Aminu and Yu, Shangshu and Wang, Cheng and Adam, Jibril Muhmmad and Li, Jonathan},
  date = {2020-01},
  journaltitle = {Remote Sens.},
  volume = {12},
  number = {11},
  pages = {1729},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2072-4292},
  doi = {10.3390/rs12111729},
  url = {https://www.mdpi.com/2072-4292/12/11/1729},
  urldate = {2022-07-19},
  abstract = {A point cloud is a set of points defined in a 3D metric space. Point clouds have become one of the most significant data formats for 3D representation and are gaining increased popularity as a result of the increased availability of acquisition devices, as well as seeing increased application in areas such as robotics, autonomous driving, and augmented and virtual reality. Deep learning is now the most powerful tool for data processing in computer vision and is becoming the most preferred technique for tasks such as classification, segmentation, and detection. While deep learning techniques are mainly applied to data with a structured grid, the point cloud, on the other hand, is unstructured. The unstructuredness of point clouds makes the use of deep learning for its direct processing very challenging. This paper contains a review of the recent state-of-the-art deep learning techniques, mainly focusing on raw point cloud data. The initial work on deep learning directly with raw point cloud data did not model local regions; therefore, subsequent approaches model local regions through sampling and grouping. More recently, several approaches have been proposed that not only model the local regions but also explore the correlation between points in the local regions. From the survey, we conclude that approaches that model local regions and take into account the correlation between points in the local regions perform better. Contrary to existing reviews, this paper provides a general structure for learning with raw point clouds, and various methods were compared based on the general structure. This work also introduces the popular 3D point cloud benchmark datasets and discusses the application of deep learning in popular 3D vision tasks, including classification, segmentation, and detection.},
  issue = {11},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,classification,datasets,deep learning,object detection,point cloud,segmentation},
  annotation = {69 citations (Semantic Scholar/DOI) [2022-07-20]},
  file = {/Users/personal-macbook/Zotero/storage/WVBVQRYL/Bello et al. - 2020 - Review Deep Learning on 3D Point Clouds.pdf}
}

@article{benabid_Chronic_1993,
  title = {Chronic {{VIM Thalamic Stimulation}} in {{Parkinson}}'s {{Disease}}, {{Essential Tremor}} and {{Extra-Pyramidal Dyskinesias}}.},
  author = {Benabid, A. L. and Pollak, P. and Seigneuret, E. and Hoffmann, D. and Gay, E. and Perret, J.},
  date = {1993},
  journaltitle = {Acta Neurochir. Suppl. (Wien)},
  eprint = {8109299},
  eprinttype = {pmid},
  issn = {00651419},
  doi = {10.1007/978-3-7091-9297-9_8},
  abstract = {Stereotactic thalamotomy of the VIM (ventral intermediate) nucleus is considered as the best neurosurgical treatment for Parkinsonian and essential tremors. However, this surgery, especially when bilateral, still presents a risk of recurrence and neurological complications. We observed that acute VIM stimulation at frequencies higher than 60 Hz during the mapping phase of the target suppressed the tremor of Parkinson's disease (PD) and essential tremor (ET). This effect was immediately reversible at the end of the stimulation. This was initially proposed as an additional treatment for patients already thalamotomized on the contralateral side, and then extended as a regular procedure for extra-pyramidal dyskinesias. Since January 1987, we implanted 126 thalami in 87 patients (61 PD, 13 ET, 13 dyskinesias of various origins). Deep brain stimulation electrodes were stereotactically implanted under local anaesthesia, using stimulation and micro-recording to delineate the best site of stimulation. Electrodes were subsequently connected to implantable programmable stimulators. The optimal frequency was around 130 to 185 Hz. The results (evaluated by a neurologist from 0 = no effect to 4 = perfect relief) are related to the type of tremor. Altogether, 71\% of the 80 patients benefited from the procedure with grade 3 and 4 results. In 88\% of the PD cases, the results were good (grade 3) or excellent (grade 4) and stable with time. Rigidity was moderately for a long improved but akinesia was not. The same level of improvement was observed in 68\% of the ET patients and only in 18\% of the other types of dyskinesias.(ABSTRACT TRUNCATED AT 250 WORDS)},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {230 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{benabid_Chronic_1996,
  title = {Chronic {{Electrical Stimulation}} of the {{Ventralis Intermedius Nucleus}} of the {{Thalamus}} as a {{Treatment}} of {{Movement Disorders}}},
  author = {Benabid, Alim Louis and Pollak, Pierre and Gao, Dongming and Hoffmann, Dominique and Limousin, Patricia and Gay, Emmanuel and Payen, Isabelle and Benazzouz, Abdhelhamid},
  date = {1996},
  journaltitle = {J. Neurosurg.},
  volume = {84},
  number = {2},
  eprint = {8592222},
  eprinttype = {pmid},
  pages = {203--214},
  publisher = {{American Association of Neurological Surgeons}},
  issn = {00223085},
  doi = {10.3171/jns.1996.84.2.0203},
  abstract = {Tremor was suppressed by test stimulation of the thalamic ventralis intermedius (VIM) nucleus at high frequency (130 Hz) during stereotaxy in nonanesthetized patients suffering from Parkinson's disease or essential tremor. Ventralis intermedius stimulation has since been used by the authors over the last 8 years as a treatment in 117 patients with movement disorders (80 cases of Parkinson's disease, 20 cases of essential tremor, and 17 cases of various dyskinesias and dystonias including four multiple sclerosis). Chronic electrodes were stereotactically implanted in the VIM and connected to a programmable stimulator. Results depend on the indication. In Parkinson's disease patients, tremor, but not bradykinesia and rigidity, was selectively suppressed for as long as 8 years. Administration of L-DOPA was decreased by more than 30\% in 40 Parkinson's disease patients. In essential tremor patients, results were satisfactory but deteriorated with time in 18.5\% of cases, mainly for patients who presented an action component of their tremor. In other types of dyskinesias (except multiple sclerosis), results were much less favorable. Fifty-nine patients underwent bilateral implantation and 14 other patients received implantation contralateral to a previous thalamotomy. Thirty-seven patients (31.6\%) experienced minor side effects, which were always well tolerated and immediately reversible. Three secondary scalp infections led to temporary removal of the implanted material. There was no permanent morbidity. This tremor suppression effect could be due to the inhibition or jamming of a retroactive loop. Chronic VIM stimulation, which is reversible, adaptable, and well tolerated even by patients undergoing bilateral surgery (74 of 117 patients) and by elderly patients, should replace thalamotomy in the regular surgical treatment of parkinsonian and essential tremors.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,deep brain stimulation,essential tremor,Parkinson's disease,stereotaxy,thalamus,ventralis intermedius nucleus},
  annotation = {1100 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{berk_Forecasting_2009,
  title = {Forecasting {{Murder Within}} a {{Population}} of {{Probationers}} and {{Parolees}}: {{A High Stakes Application}} of {{Statistical Learning}}},
  author = {Berk, Richard and Sherman, Lawrence and Barnes, Geoffrey and Kurtz, Ellen and Ahlman, Lindsay},
  date = {2009},
  journaltitle = {J. R. Stat. Soc. Ser. A Stat. Soc.},
  issn = {09641998},
  doi = {10.1111/j.1467-985X.2008.00556.x},
  abstract = {Forecasts of future dangerousness are often used to inform the sentencing decisions of convicted offenders. For individuals who are sentenced to probation or paroled to community supervision, such forecasts affect the conditions under which they are to be supervised. The statistical criterion for these forecasts is commonly called recidivism, which is defined as a charge or conviction for any new offence, no matter how minor. Only rarely do such forecasts make distinctions on the basis of the seriousness of offences. Yet seriousness may be central to public concerns, and judges are increasingly required by law and sentencing guidelines to make assessments of seriousness. At the very least, information about seriousness is essential for allocating scarce resources for community supervision of convicted offenders. The paper focuses only on murderous conduct by individuals on probation or parole. Using data on a population of over 60000 cases from Philadelphia's Adult Probation and Parole Department, we forecast whether each offender will be charged with a homicide or attempted homicide within 2 years of beginning community supervision. We use a statistical learning approach that makes no assumptions about how predictors are related to the outcome. We also build in the costs of false negative and false positive charges and use half of the data to build the forecasting model, and the other half of the data to evaluate the quality of the forecasts. Forecasts that are based on this approach offer the possibility of concentrating rehabilitation, treatment and surveillance resources on a small subset of convicted offenders who may be in greatest need, and who pose the greatest risk to society. \textcopyright{} 2009 Royal Statistical Society.},
  keywords = {'Random forests',\#nosource,⛔ No INSPIRE recid found,Forecasting,Homicide,Parole,Probation,Statistical learning},
  annotation = {185 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{berman_Mapping_2014,
  title = {Mapping the {{Stereotyped Behaviour}} of {{Freely Moving Fruit Flies}}},
  author = {Berman, Gordon J. and Choi, Daniel M. and Bialek, William and Shaevitz, Joshua W.},
  date = {2014-10},
  journaltitle = {J. R. Soc. Interface},
  volume = {11},
  number = {99},
  doi = {10.1098/rsif.2014.0672},
  abstract = {A frequent assumption in behavioural science is that most of an animal's activities can be described in terms of a small set of stereotyped motifs. Here, we introduce a method for mapping an animal's actions, relying only upon the underlying structure of postural movement data to organize and classify behaviours. Applying this method to the ground-based behaviour of the fruit fly, Drosophila melanogaster, we find that flies perform stereotyped actions roughly 50\% of the time, discovering over 100 distinguishable, stereotyped behavioural states. These include multiple modes of locomotion and grooming. We use the resulting measurements as the basis for identifying subtle sex-specific behavioural differences and revealing the low-dimensional nature of animal motions.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,behaviour,Drosophila,phase reconstruction,stere},
  annotation = {397 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@thesis{bernardis_FINDING_2011,
  title = {Finding {{Dots}} in {{Microscopic Images}}},
  author = {Bernardis, Elena and Yu, Jianbo Shi Stella X.},
  date = {2011},
  institution = {{University of Pennsylvania}},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{bernasconi_Wholebrain_2004,
  title = {Whole-{{Brain Voxel-Based Statistical Analysis}} of {{Gray Matter}} and {{White Matter}} in {{Temporal Lobe Epilepsy}}},
  author = {Bernasconi, N. and Duchesne, S. and Janke, A. and Lerch, J. and Collins, D. L. and Bernasconi, A.},
  date = {2004-10},
  journaltitle = {Neuroimage},
  volume = {23},
  number = {2},
  pages = {717--723},
  doi = {10.1016/j.neuroimage.2004.06.015},
  abstract = {Volumetric MRI studies based on manual labeling of selected anatomical structures have provided in vivo evidence that brain abnormalities associated with temporal lobe epilepsy (TLE) extend beyond the hippocampus. Voxel-based morphometry (VBM) is a fully automated image analysis technique allowing identification of regional differences in gray matter (GM) and white matter (WM) between groups of subjects without a prior region of interest. The purpose of this study was to determine whole-brain GM and WM changes in TLE and to investigate the relationship between these abnormalities and clinical parameters. We studied 85 patients with pharmacologically intractable TLE and unilateral hippocampal atrophy and 47 age- and sex-matched healthy control subjects. The seizure focus was right sided in 40 patients and left sided in 45. Student's t test statistical maps of differences between patients' and controls' GM and WM concentrations were obtained using a general linear model. A further regression against duration of epilepsy, age of onset, presence of febrile convulsions, and secondary generalized seizures was performed with the TLE population. Voxel-based morphometry revealed that GM pathology in TLE extends beyond the hippocampus involving other limbic areas such as the cingulum and the thalamus, as well as extralimbic areas, particularly the frontal lobe. White matter reduction was found only ipsilateral to the seizure focus, including the temporopolar, entorhinal, and perirhinal areas. This pattern of structural changes is suggestive of disconnection involving preferentially frontolimbic pathways in patients with pharmacologically intractable TLE.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{bi_BayesOptimal_2015,
  title = {Bayes-{{Optimal Hierarchical Multilabel Classification}}},
  author = {Bi, Wei and Kwok, Jame T.},
  date = {2015-11-01},
  journaltitle = {IEEE Trans. Knowl. Data Eng.},
  volume = {27},
  number = {11},
  pages = {2907--2918},
  issn = {1041-4347},
  doi = {10.1109/TKDE.2015.2441707},
  url = {http://ieeexplore.ieee.org/document/7118216/},
  urldate = {2022-12-15},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {39 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{bi_Learning_2014,
  title = {Learning to {{Predict From Crowdsourced Data}}},
  booktitle = {Proc. 13th {{Conf}}. {{Uncertain}}. {{Artif}}. {{Intell}}.},
  author = {Bi, Wei and Wang, Liwei and Kwok, James T. and Tu, Zhuowen},
  date = {2014-07-23},
  series = {{{UAI}}'14},
  pages = {82--91},
  publisher = {{AUAI Press}},
  location = {{Arlington, Virginia, USA}},
  abstract = {Crowdsourcing services like Amazon's Mechanical Turk have facilitated and greatly expedited the manual labeling process from a large number of human workers. However, spammers are often unavoidable and the crowdsourced labels can be very noisy. In this paper, we explicitly account for four sources for a noisy crowdsourced label: worker's dedication to the task, his/her expertise, his/her default labeling judgement, and sample difficulty. A novel mixture model is employed for worker annotations, which learns a prediction model directly from samples to labels for efficient out-of-sample testing. Experiments on both simulated and real-world crowdsourced data sets show that the proposed method achieves significant improvements over the state-of-the-art.},
  eventtitle = {Uncertainty in {{Artificial Intelligence}}},
  isbn = {978-0-9749039-1-0},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/STBECXWN/Bi et al. - 2014 - Learning to Predict from Crowdsourced Data.pdf}
}

@article{bi_Mandatory_2014,
  title = {Mandatory {{Leaf Node Prediction}} in {{Hierarchical Multilabel Classification}}},
  author = {Bi, Wei and Kwok, James T.},
  date = {2014-12},
  journaltitle = {IEEE Trans. Neural Netw. Learning Syst.},
  volume = {25},
  number = {12},
  pages = {2275--2287},
  issn = {2162-237X, 2162-2388},
  doi = {10.1109/TNNLS.2014.2309437},
  url = {http://ieeexplore.ieee.org/document/6810887/},
  urldate = {2022-12-01},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {41 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{biederman_Recognitionbycomponents_1987,
  title = {Recognition-by-{{Components}}: {{A Theory}} of {{Human Image Understanding}}},
  author = {Biederman, Irving},
  date = {1987-04},
  journaltitle = {Psychol. Rev.},
  volume = {94},
  number = {2},
  pages = {115--147},
  doi = {10.1037/0033-295X.94.2.115},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{bien_Deeplearningassisted_2018,
  title = {Deep-{{Learning-Assisted Diagnosis}} for {{Knee Magnetic Resonance Imaging}}: {{Development}} and {{Retrospective Validation}} of {{MRNet}}},
  shorttitle = {Deep-Learning-Assisted Diagnosis for Knee Magnetic Resonance Imaging},
  author = {Bien, Nicholas and Rajpurkar, Pranav and Ball, Robyn L. and Irvin, Jeremy and Park, Allison and Jones, Erik and Bereket, Michael and Patel, Bhavik N. and Yeom, Kristen W. and Shpanskaya, Katie and Halabi, Safwan and Zucker, Evan and Fanton, Gary and Amanatullah, Derek F. and Beaulieu, Christopher F. and Riley, Geoffrey M. and Stewart, Russell J. and Blankenberg, Francis G. and Larson, David B. and Jones, Ricky H. and Langlotz, Curtis P. and Ng, Andrew Y. and Lungren, Matthew P.},
  date = {2018-11-27},
  journaltitle = {PLOS Medicine},
  volume = {15},
  number = {11},
  pages = {e1002699},
  publisher = {{Public Library of Science}},
  issn = {1549-1676},
  doi = {10.1371/journal.pmed.1002699},
  url = {https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1002699},
  urldate = {2021-11-09},
  abstract = {Background Magnetic resonance imaging (MRI) of the knee is the preferred method for diagnosing knee injuries. However, interpretation of knee MRI is time-intensive and subject to diagnostic error and variability. An automated system for interpreting knee MRI could prioritize high-risk patients and assist clinicians in making diagnoses. Deep learning methods, in being able to automatically learn layers of features, are well suited for modeling the complex relationships between medical images and their interpretations. In this study we developed a deep learning model for detecting general abnormalities and specific diagnoses (anterior cruciate ligament [ACL] tears and meniscal tears) on knee MRI exams. We then measured the effect of providing the model's predictions to clinical experts during interpretation. Methods and findings Our dataset consisted of 1,370 knee MRI exams performed at Stanford University Medical Center between January 1, 2001, and December 31, 2012 (mean age 38.0 years; 569 [41.5\%] female patients). The majority vote of 3 musculoskeletal radiologists established reference standard labels on an internal validation set of 120 exams. We developed MRNet, a convolutional neural network for classifying MRI series and combined predictions from 3 series per exam using logistic regression. In detecting abnormalities, ACL tears, and meniscal tears, this model achieved area under the receiver operating characteristic curve (AUC) values of 0.937 (95\% CI 0.895, 0.980), 0.965 (95\% CI 0.938, 0.993), and 0.847 (95\% CI 0.780, 0.914), respectively, on the internal validation set. We also obtained a public dataset of 917 exams with sagittal T1-weighted series and labels for ACL injury from Clinical Hospital Centre Rijeka, Croatia. On the external validation set of 183 exams, the MRNet trained on Stanford sagittal T2-weighted series achieved an AUC of 0.824 (95\% CI 0.757, 0.892) in the detection of ACL injuries with no additional training, while an MRNet trained on the rest of the external data achieved an AUC of 0.911 (95\% CI 0.864, 0.958). We additionally measured the specificity, sensitivity, and accuracy of 9 clinical experts (7 board-certified general radiologists and 2 orthopedic surgeons) on the internal validation set both with and without model assistance. Using a 2-sided Pearson's chi-squared test with adjustment for multiple comparisons, we found no significant differences between the performance of the model and that of unassisted general radiologists in detecting abnormalities. General radiologists achieved significantly higher sensitivity in detecting ACL tears (p-value = 0.002; q-value = 0.019) and significantly higher specificity in detecting meniscal tears (p-value = 0.003; q-value = 0.019). Using a 1-tailed t test on the change in performance metrics, we found that providing model predictions significantly increased clinical experts' specificity in identifying ACL tears (p-value {$<$} 0.001; q-value = 0.006). The primary limitations of our study include lack of surgical ground truth and the small size of the panel of clinical experts. Conclusions Our deep learning model can rapidly generate accurate clinical pathology classifications of knee MRI exams from both internal and external datasets. Moreover, our results support the assertion that deep learning models can improve the performance of clinical experts during medical imaging interpretation. Further research is needed to validate the model prospectively and to determine its utility in the clinical setting.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Adult,Anterior Cruciate Ligament Injuries,Automation,{Databases, Factual},Deep learning,Deep Learning,{Diagnosis, Computer-Assisted},Diagnostic medicine,Female,Humans,{Image Interpretation, Computer-Assisted},Knee,Knees,Ligaments,Magnetic resonance imaging,Magnetic Resonance Imaging,Male,Middle Aged,Orthopedic surgery,Predictive Value of Tests,Radiologists,Reproducibility of Results,Retrospective Studies,Surgeons,Tibial Meniscus Injuries,Young Adult},
  annotation = {360 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/8AGVY8SM/Bien et al. - 2018 - Deep-learning-assisted diagnosis for knee magnetic.pdf}
}

@article{bilic_Liver_2019,
  title = {The {{Liver Tumor Segmentation Benchmark}} ({{LiTS}})},
  author = {Bilic, Patrick and Christ, Patrick Ferdinand and Vorontsov, Eugene and Chlebus, Grzegorz and Chen, Hao and Dou, Qi and Fu, Chi-Wing and Han, Xiao and Heng, Pheng-Ann and Hesser, J\"urgen and Kadoury, Samuel and Konopczynski, Tomasz and Le, Miao and Li, Chunming and Li, Xiaomeng and Lipkov\`a, Jana and Lowengrub, John and Meine, Hans and Moltz, Jan Hendrik and Pal, Chris and Piraud, Marie and Qi, Xiaojuan and Qi, Jin and Rempfler, Markus and Roth, Karsten and Schenk, Andrea and Sekuboyina, Anjany and Vorontsov, Eugene and Zhou, Ping and H\"ulsemeyer, Christian and Beetz, Marcel and Ettlinger, Florian and Gruen, Felix and Kaissis, Georgios and Loh\"ofer, Fabian and Braren, Rickmer and Holch, Julian and Hofmann, Felix and Sommer, Wieland and Heinemann, Volker and Jacobs, Colin and Mamani, Gabriel Efrain Humpire and family=Ginneken, given=Bram, prefix=van, useprefix=false and Chartrand, Gabriel and Tang, An and Drozdzal, Michal and Ben-Cohen, Avi and Klang, Eyal and Amitai, Marianne M. and Konen, Eli and Greenspan, Hayit and Moreau, Johan and Hostettler, Alexandre and Soler, Luc and Vivanti, Refael and Szeskin, Adi and Lev-Cohain, Naama and Sosna, Jacob and Joskowicz, Leo and Menze, Bjoern H.},
  date = {2019-01},
  url = {http://arxiv.org/abs/1901.04056},
  abstract = {In this work, we report the set-up and results of the Liver Tumor Segmentation Benchmark (LITS) organized in conjunction with the IEEE International Symposium on Biomedical Imaging (ISBI) 2016 and International Conference On Medical Image Computing Computer Assisted Intervention (MICCAI) 2017. Twenty four valid state-of-the-art liver and liver tumor segmentation algorithms were applied to a set of 131 computed tomography (CT) volumes with different types of tumor contrast levels (hyper-/hypo-intense), abnormalities in tissues (metastasectomie) size and varying amount of lesions. The submitted algorithms have been tested on 70 undisclosed volumes. The dataset is created in collaboration with seven hospitals and research institutions and manually reviewed by independent three radiologists. We found that not a single algorithm performed best for liver and tumors. The best liver segmentation algorithm achieved a Dice score of 0.96(MICCAI) whereas for tumor segmentation the best algorithm evaluated at 0.67(ISBI) and 0.70(MICCAI). The LITS image data and manual annotations continue to be publicly available through an online evaluation system as an ongoing benchmarking resource.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{bioethics_Artificial_2018,
  title = {Artificial {{Intelligence}} ( {{AI}} ) in {{Healthcare}} and {{Research}}},
  author = {family=Bioethics, given=Nuffield Council, prefix=on, useprefix=false},
  date = {2018},
  journaltitle = {Bioeth. Brief. Note},
  abstract = {AI is being used or trialled for a range of healthcare and research purposes, including detection of disease, management of chronic conditions, delivery of health services, and drug discovery. \textbullet{} AI has the potential to help address important health challenges, but might be limited by the quality of available health data, and by the inability of AI to display some human characteristics. \textbullet{} The use of AI raises ethical issues, including: the potential for AI to make erroneous decisions; the question of who is responsible when AI is used to support decision-making; difficulties in validating the outputs of AI systems; inherent biases in the data used to train AI systems; ensuring the protection of potentially sensitive data; securing public trust in the development and use of AI technologies; effects on people's sense of dignity and social isolation in care situations; effects on the roles and skill-requirements of healthcare professionals; and the potential for AI to be used for malicious purposes. \textbullet{} A key challenge will be ensuring that AI is developed and used in a way that is transparent and compatible with the public interest, whilst stimulating and driving innovation in the sector},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@book{bird_Natural_2009,
  title = {Natural {{Language Processing With Python}}: {{Analyzing Text With}} the {{Natural Language Toolkit}}},
  author = {Bird, Steven and Klein, Ewan and Loper, Edward},
  date = {2009},
  journaltitle = {Text},
  eprint = {12043876},
  eprinttype = {pmid},
  issn = {00992399},
  doi = {10.1097/00004770-200204000-00018},
  abstract = {This book offers a highly accessible introduction to natural language processing, the field that supports a variety of language technologies, from predictive text and email filtering to automatic summarization and translation. With it, you'll learn how to write Python programs that work with large collections of unstructured text. You'll access richly annotated datasets using a comprehensive range of linguistic data structures, and you'll understand the main algorithms for analyzing the content and structure of written communication. Packed with examples and exercises, Natural Language Processing with Python will help you:Extract information from unstructured text, either to guess the topic or identify "named entities" Analyze linguistic structure in text, including parsing and semantic analysis Access popular linguistic databases, including WordNet and treebanks Integrate techniques drawn from fields as diverse as linguistics and artificial intelligence This book will help you gain practical skills in natural language processing using the Python programming language and the Natural Language Toolkit (NLTK) open source library. If you're interested in developing web applications, analyzing multilingual news sources, or documenting endangered languages - or if you're simply curious to have a programmer's perspective on how human language works - you'll find Natural Language Processing with Python both fascinating and immensely useful.},
  isbn = {978-0-596-51649-9},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{bland_Rapid_1976,
  title = {Rapid {{Infusion}} of {{Sodium Bicarbonate}} and {{Albumin Into High-Risk Premature Infants Soon After Birth}}: {{A Controlled}}, {{Prospective Trial}}},
  shorttitle = {Rapid Infusion of Sodium Bicarbonate and Albumin into High-Risk Premature Infants Soon after Birth},
  author = {Bland, R. D. and Clarke, T. L. and Harden, L. B.},
  date = {1976-02-01},
  journaltitle = {Am J Obstet Gynecol},
  volume = {124},
  number = {3},
  eprint = {2013},
  eprinttype = {pmid},
  pages = {263--267},
  issn = {0002-9378},
  doi = {10.1016/0002-9378(76)90154-x},
  abstract = {We conducted a controlled, prospective trial to evaluate the effectiveness of rapidly infusing sodium bicarbonate (NaHCO3) and salt-poor albumin into high-risk, premature infants in the first 2 hours of life. Fifty-three infants, randomized into one of four treatment groups, received 8 ml. per kilogram of a solution containing either (A) glucose in water, (B) salt-poor albumin, (C) NaHCO3, or (D) a combination of albumin and NaHCO3. After the initial infusion, the babies received no colloid or alkali solutions until 4 hours of age. We managed them supportively with warmth, appropriate oxygen administration, isotonic fluid infusion, and close monitoring. Among the infants who received alkali, 14 of 26 acquired the respiratory distress syndrome (RDS), 11 died, and four had intracranial hemorrhage. Among babies who received no alkali, RDS occurred in 11 of 27, 5 died, and none had intracranial hemorrhage. These results do not support the common practice of rapidly infusing NaHCO3 into high-risk, premature infants, and they suggest that the early management of such infants needs renewed critical evaluation.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Acidosis,Albumins,Bicarbonates,Carbon Dioxide,Cerebral Hemorrhage,Female,Hawaii,Humans,Hydrogen-Ion Concentration,{Infant, Newborn},{Infant, Premature, Diseases},{Infusions, Parenteral},Male,Prospective Studies,{Respiratory Distress Syndrome, Newborn},Sodium,Time Factors}
}

@article{blezek_atlasstratification_2007,
  ids = {blezek_Atlas_2007},
  title = {Atlas {{Stratification}}},
  author = {Blezek, Daniel J. and Miller, James V.},
  date = {2007-10},
  journaltitle = {Medical Image Analysis},
  volume = {11},
  number = {5},
  pages = {443--457},
  issn = {13618415},
  doi = {10.1016/j.media.2007.07.001},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1361841507000722},
  urldate = {2023-05-10},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {87 citations (Semantic Scholar/DOI) [2023-05-09]},
  file = {/Users/personal-macbook/Zotero/storage/QDPYHP3Z/Blezek and Miller - 2007 - Atlas stratification.pdf}
}

@article{block_Transition_2016,
  title = {Transition {{From Part-Time Entrepreneurship}} to {{Full-Time Entrepreneurship}}: {{The Role}} of {{Financial}} and {{Non-Financial Motives}}},
  author = {Block, J\"orn H. and Landgraf, Andreas},
  date = {2016},
  journaltitle = {Int. Entrep. Manag. J.},
  issn = {15551938},
  doi = {10.1007/s11365-014-0331-6},
  abstract = {Part-time entrepreneurship is often a first step towards full-time entrepreneurship. This study analyzes how financial and non-financial motives of part-time entrepreneurs influence the propensity of part-time entrepreneurs to become full-time entrepreneurs. Our results show that the motivation to supplement wage income or the motivation to achieve social recognition is negatively associated with transition behavior, whereas the motivation to achieve independence or self-realization is positively associated with transition behavior. The motivation to follow a role model, financial success, and innovation are not significantly related to transition behavior. The implications of these results with regard to part-time entrepreneurship are discussed.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Entrepreneurship motivation,Full-time entrepreneurship,Hybrid entrepreneurship,Part-time entrepreneurship,Transition behavior}
}

@inproceedings{blum_Combining_1998,
  title = {Combining {{Labeled}} and {{Unlabeled Data With Co-Training}}},
  booktitle = {Proc. {{Annu}}. {{ACM Conf}}. {{Comput}}. {{Learn}}. {{Theory}}},
  author = {Blum, Avrim and Mitchell, Tom},
  date = {1998},
  doi = {10.1145/279943.279962},
  abstract = {The problem of using a large unlabeled sample is considered to boost the performance of a learning algorithm when only a small set of labeled examples is available. In particular, a problem setting is considered to classify web pages, in which the description of each example can be partitioned into two distinct views. A PAC-style analysis for this setting, and, more broadly, a PAC-style framework for the general problem of learning from both labeled and unlabeled data are presented. Also, empirical results on real web-page is giving, indicating that this use of unlabeled examples can lead to significant improvement of hypotheses in practice.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {5773 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{blumberg_Amygdala_2003,
  title = {Amygdala and {{Hippocampal Volumes}} in {{Adolescents}} and {{Adults With Bipolar Disorder}}},
  author = {Blumberg, Hilary P. and Kaufman, Joan and Martin, Andres and Whiteman, Ronald and Zhang, Jane Hongyuan and Gore, John C. and Charney, Dennis S. and Krystal, John H. and Peterson, Bradley S.},
  date = {2003-12},
  journaltitle = {Arch. Gen. Psychiatry},
  volume = {60},
  number = {12},
  pages = {1201--1208},
  doi = {10.1001/archpsyc.60.12.1201},
  abstract = {BACKGROUND: The purported functions of medial temporal lobe structures suggest their involvement in the pathophysiology of bipolar disorder (BD). Previous reports of abnormalities in the volume of the amygdala and hippocampus in patients with BD have been inconsistent in their findings and limited to adult samples. Appreciation of whether volumetric abnormalities are early features of BD or whether the abnormalities represent neurodegenerative changes associated with illness duration is limited by the paucity of data in juvenile samples. OBJECTIVE: To investigate amygdala and hippocampal volume in adults and adolescents with BD. SETTING AND PARTICIPANTS: Subjects included 36 individuals (14 adolescents and 22 adults) in outpatient treatment for BD type I at a university hospital or Veterans Affairs medical center or in the surrounding community, and 56 healthy comparison subjects (23 adolescents and 33 adults). DESIGN AND MAIN OUTCOME MEASURES: Amygdala and hippocampal volumes were defined and measured on high-resolution anatomic magnetic resonance imaging scans. We used a mixed-model, repeated-measures statistical analysis to compare amygdala and hippocampal volumes across groups while covarying for total brain volume, age, and sex. Potential effects of illness features were explored, including rapid cycling, medication, alcohol or other substance dependence, duration, and mood state. RESULTS: For both the amygdala and hippocampal regions, we found an overall significant volume reduction in the BD compared with the control group (P{$<$}.0001). Amygdala volume reductions (15.6\%) were highly significant (P{$<$}.0001). We observed a nonsignificant trend (P =.054) toward reductions in hippocampal volumes of lesser magnitude (5.3\%). Effects of illness features were not detected. CONCLUSIONS: These results suggest that BD is associated with decreased volumes of medial temporal lobe structures, with greater effect sizes in the amygdala than in the hippocampus. These abnormalities are likely manifested early in the course of illness, as they affected adolescent and adult subjects similarly in this sample.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {378 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{bodart_Coma_2013,
  title = {Coma and {{Disorders}} of {{Consciousness}}: {{Scientific Advances}} and {{Practical Considerations}} for {{Clinicians}}},
  shorttitle = {Coma and {{Disorders}} of {{Consciousness}}},
  author = {Bodart, Olivier and Laureys, Steven and Gosseries, Olivia},
  date = {2013-07-25},
  journaltitle = {Semin Neurol},
  volume = {33},
  number = {02},
  pages = {083--090},
  issn = {0271-8235, 1098-9021},
  doi = {10.1055/s-0033-1348965},
  url = {http://www.thieme-connect.de/DOI/DOI?10.1055/s-0033-1348965},
  urldate = {2023-05-08},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,consciousness,functional magnetic resonance imaging (fMRI),minimally conscious state,neuroimaging,thalamus,unresponsive wakefulness syndrome-vegetative state},
  annotation = {43 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/9MA7KC2P/Bodart et al. - 2013 - Coma and Disorders of Consciousness Scientific Ad.pdf}
}

@article{bohanec_DEX_1990,
  title = {{{DEX}}: {{An Expert System Shell}} for {{Decision Support}}},
  shorttitle = {Dex},
  author = {Bohanec, Marko and Rajkovi\v{c}, Vladislav},
  date = {1990},
  journaltitle = {Sistemica},
  volume = {1},
  number = {1},
  pages = {145--157},
  publisher = {{Citeseer}},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/8JNSG7Q5/Bohanec and Rajkovič - 1990 - DEX An Expert System Shell for Decision Support.pdf}
}

@inproceedings{bonald_Minimax_2017,
  ids = {NIPS2017_743394be,bonald_Minimax_2017a},
  title = {A {{Minimax Optimal Algorithm}} for {{Crowdsourcing}}},
  booktitle = {Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.},
  author = {Bonald, Thomas and Combes, Richard},
  date = {2017},
  volume = {30},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2017/hash/743394beff4b1282ba735e5e3723ed74-Abstract.html},
  urldate = {2022-12-28},
  abstract = {We consider the problem of accurately estimating the reliability of workers based on noisy labels they provide, which is a fundamental question in crowdsourcing. We propose a novel lower bound on the minimax estimation error which applies to any estimation procedure. We further propose Triangular Estimation (TE), an algorithm for estimating the reliability of workers. TE has low complexity, may be implemented in a streaming setting when labels are provided by workers in real time, and does not rely on an iterative procedure. We prove that TE is minimax optimal and matches our lower bound. We conclude by assessing the performance of TE and other state-of-the-art algorithms on both synthetic and real-world data.},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found,Computer Science - Human-Computer Interaction,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  file = {/Users/personal-macbook/Zotero/storage/GZ5MM8VR/Bonald and Combes - 2017 - A Minimax Optimal Algorithm for Crowdsourcing.pdf}
}

@article{bonechi_Confidence_2019,
  title = {Confidence {{Measures}} for {{Deep Learning}} in {{Domain Adaptation}}},
  author = {Bonechi, Simone and Andreini, Paolo and Bianchini, Monica and Pai, Akshay and Scarselli, Franco},
  date = {2019-05},
  journaltitle = {Appl. Sci.},
  volume = {9},
  number = {11},
  pages = {2192},
  publisher = {{MDPI AG}},
  issn = {2076-3417},
  doi = {10.3390/app9112192},
  url = {https://www.mdpi.com/2076-3417/9/11/2192},
  abstract = {{$<$}p{$>$}In recent years, Deep Neural Networks (DNNs) have led to impressive results in a wide variety of machine learning tasks, typically relying on the existence of a huge amount of supervised data. However, in many applications (e.g., bio\textendash medical image analysis), gathering large sets of labeled data can be very difficult and costly. Unsupervised domain adaptation exploits data from a source domain, where annotations are available, to train a model able to generalize also to a target domain, where labels are unavailable. Recent research has shown that Generative Adversarial Networks (GANs) can be successfully employed for domain adaptation, although deciding when to stop learning is a major concern for GANs. In this work, we propose some confidence measures that can be used to early stop the GAN training, also showing how such measures can be employed to predict the reliability of the network output. The effectiveness of the proposed approach has been tested in two domain adaptation tasks, with very promising results.{$<$}/p{$>$}},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Confidence measures,Generative Adversarial Networks,Uncertainty estimation,Unsupervised domain adaptation},
  annotation = {3 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{borchers_UNDERSTANDING_2010,
  title = {Understanding {{Entrepreneurial Mindset}}: {{A Study}} of {{Entrepreneurial Self-Efficacy}}, {{Locus}} of {{Control}} and {{Intent}} to {{Start}} a {{Business}}},
  author = {Borchers, A. and Park, S.},
  date = {2010},
  journaltitle = {J. Eng. Entrep.},
  abstract = {With growing interest in entrepreneurship in higher education, faculty are facing increased calls to instill an ``entrepreneurial mindset'' in students. The authors base this study on a rich literature history on self-efficacy and expectancy theory. Starting with work by Chen, Greene, and Crick (1998) and Rotter (1966), the study measures entrepreneurial self-efficacy (ESE) with 22 items, locus of control (LOC) with 23 items and intention to start a business (ITSB) with five items among a sample of engineering and business students (n=191). We also collected paired data from students before and after taking a course in innovation and new ventures. Along with basic analyses using correlation and paired sample t-tests, we performed confirmatory factor analysis and a Multi-Group SEM to test the effects of LOC on the link between ESE and ITSB. We support Chen et al.'s (1998) work in showing that ESE and ITSB are in fact related, and we demonstrate a moderating role for LOC in the relationship between ESE and ITSB. The authors discuss conclusions and further areas for study. 1.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{borji_Salient_2019,
  title = {Salient {{Object Detection}}: {{A Survey}}},
  shorttitle = {Salient {{Object Detection}}},
  author = {Borji, Ali and Cheng, Ming-Ming and Hou, Qibin and Jiang, Huaizu and Li, Jia},
  date = {2019-06},
  journaltitle = {Comp. Visual Media},
  volume = {5},
  number = {2},
  pages = {117--150},
  issn = {2096-0433, 2096-0662},
  doi = {10.1007/s41095-019-0149-9},
  url = {http://link.springer.com/10.1007/s41095-019-0149-9},
  urldate = {2023-01-11},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {570 citations (Semantic Scholar/DOI) [2023-01-11]},
  file = {/Users/personal-macbook/Zotero/storage/ZV9LKASP/Borji et al. - 2019 - Salient object detection A survey.pdf}
}

@inproceedings{borrmann_Thermal_2013,
  title = {Thermal {{3D Mapping}} of {{Building Fa\c{c}ades}}},
  booktitle = {Adv. {{Intell}}. {{Syst}}. {{Comput}}.},
  author = {Borrmann, Dorit and Elseberg, Jan and N\"uchter, Andreas},
  date = {2013},
  volume = {193 AISC},
  pages = {173--182},
  publisher = {{Springer Verlag}},
  issn = {21945357},
  doi = {10.1007/978-3-642-33926-4_16},
  abstract = {Never before in history were humans as dependant on energy as we are today. But the natural ressources are limited and a waste of energy has drastic influences on the environment. In their Action Plan for Energy Efficiency [6] the European Commission estimates that the largest and cost-effictive energy savings potential lies in residential ({$\approx$} 27\%) and commercial ({$\approx$} 30\%) buildings. To eliminate heat and air conditioning losses in buildings and factories heat and air leaks need to be localized and identified. Imagine the availability of a complete 3D model of every building that architects can use to analyze the heat insulation of buildings and to identify necessary modifications. In these 3D models temperature peaks are not only detectable but also their extent is visible. A robot equiped with a 3D laser scanner, a thermal camera, and a color camera constitutes the basis for our approach. The data from all three sensors and from different locations are joined into one high-precise 3D model that shows the heat distribution. This paper describes the setup of the hardware and the methods applied to create the 3D model, including the automatic co-calibration of the sensors. Challenges unique to the task of thermal mapping of outdoor environments are discussed. \textcopyright{} 2013 Springer-Verlag.},
  isbn = {978-3-642-33925-7},
  issue = {VOL. 1},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{bos_Diagnosis_2018,
  title = {Diagnosis of {{Acute Respiratory Distress Syndrome}} by {{Exhaled Breath Analysis}}},
  author = {Bos, Lieuwe D. J.},
  date = {2018},
  journaltitle = {Ann. Transl. Med.},
  issn = {23055839},
  doi = {10.21037/atm.2018.01.17},
  abstract = {\textcopyright{} Annals of Translational Medicine. The acute respiratory distress syndrome (ARDS) is a complication of critical illness that is characterized by acute onset, protein rich, pulmonary edema. There is no treatment for ARDS, other than the reduction of additional ventilator induced lung injury. Prediction or earlier recognition of ARDS could result in preventive measurements and might decrease mortality and morbidity. Exhaled breath contains volatile organic compounds (VOCs), a collection of hundreds of small molecules linked to several physiological and pathophysiological processes. Analysis of exhaled breath through gas-chromatography and mass-spectrometry (GC-MS) has resulted in an accurate diagnosis of ARDS in several studies. Most identified markers are linked to lipid peroxidation. Octane is one of the few markers that was validated as a marker of ARDS and is pathophysiologically likely to be increased in ARDS. None of the currently studied breath analysis methods is directly applicable in clinical practice. Two steps have to be taken before any breath test can be allowed into the intensive care unit. External validation in a multi-center study is a prerequisite for any of the candidate breath markers and the breath test should outperform clinical prediction scores. Second, the technology for breath analysis should be adapted so that it is available at a decentralized lab inside the intensive care unit and can be operated by trained nurses, in order to reduce the analysis time. In conclusion, exhaled analysis might be used for the early diagnosis and prediction of ARDS in the near future but several obstacles have to be taken in the coming years. Most of the candidate markers can be linked to lipid peroxidation. Only octane has been validated in a temporal external validation cohort and is, at this moment, the top-ranking breath biomarker for ARDS.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {22 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{bosch_Image_2007,
  ids = {bosch07},
  title = {Image {{Classification Using Random Forests}} and {{Ferns}}},
  booktitle = {2007 {{IEEE}} 11th {{Int}}. {{Conf}}. {{Comput}}. {{Vis}}.},
  author = {Bosch, Anna and Zisserman, Andrew and Munoz, Xavier},
  date = {2007},
  pages = {1--8},
  publisher = {{IEEE}},
  location = {{Rio de Janeiro, Brazil}},
  doi = {10.1109/ICCV.2007.4409066},
  url = {http://ieeexplore.ieee.org/document/4409066/},
  urldate = {2023-01-11},
  eventtitle = {2007 {{IEEE}} 11th {{International Conference}} on {{Computer Vision}}},
  isbn = {978-1-4244-1630-1},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {1426 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/2LDFZ7JI/Bosch et al. - 2007 - Image classification using random forests and fern.pdf;/Users/personal-macbook/Zotero/storage/LY4CTY2W/4409066.html}
}

@article{bose_Delineation_1975,
  title = {Delineation of the {{Intimate Details}} of the {{Backbone Conformation}} of {{Pyridine Nucleotide Coenzymes}} in {{Aqueous Solution}}},
  author = {Bose, K. S. and Sarma, R. H.},
  date = {1975-10-27},
  journaltitle = {Biochem Biophys Res Commun},
  volume = {66},
  number = {4},
  eprint = {2},
  eprinttype = {pmid},
  pages = {1173--1179},
  issn = {1090-2104},
  doi = {10.1016/0006-291x(75)90482-9},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Fourier Analysis,Magnetic Resonance Spectroscopy,{Models, Molecular},Molecular Conformation,NAD,NADP,Structure-Activity Relationship,Temperature},
  annotation = {57 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{bouslimani_Molecular_2015,
  title = {Molecular {{Cartography}} of the {{Human Skin Surface}} in {{3D}}},
  author = {Bouslimani, Amina and Porto, Carla and Rath, Christopher M. and Wang, Mingxun and Guo, Yurong and Gonzalez, Antonio and Berg-Lyon, Donna and Ackermann, Gail and Christensen, Gitte Julie Moeller and Nakatsuji, Teruaki and Zhang, Lingjuan and Borkowski, Andrew W. and Meehan, Michael J. and Dorrestein, Kathleen and Gallo, Richard L. and Bandeira, Nuno and Knight, Rob and Alexandrov, Theodore and Dorrestein, Pieter C.},
  date = {2015},
  journaltitle = {Proc. Natl. Acad. Sci. U. S. A.},
  eprint = {25825778},
  eprinttype = {pmid},
  issn = {10916490},
  doi = {10.1073/pnas.1424409112},
  abstract = {The human skin is an organ with a surface area of 1.5-2 m\textsuperscript{2} that provides our interface with the environment. The molecular composition of this organ is derived from host cells, microbiota, and external molecules. The chemical makeup of the skin surface is largely undefined. Here we advance the technologies needed to explore the topographical distribution of skin molecules, using 3D mapping of mass spectrometry data and microbial 16S rRNA amplicon sequences. Our 3D maps reveal that the molecular composition of skin has diverse distributions and that the composition is defined not only by skin cells and microbes but also by our daily routines, including the application of hygiene products. The technological development of these maps lays a foundation for studying the spatial relationships of human skin with hygiene, the microbiota, and environment, with potential for developing predictive models of skin phenotypes tailored to individual health.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,16S rRNA,3D mapping,Human skin,Mass spectrometry}
}

@article{bozhang_Wavelets_2008,
  ids = {zhang08},
  title = {Wavelets, {{Ridgelets}}, and {{Curvelets}} for {{Poisson Noise Removal}}},
  author = {{Bo Zhang} and Fadili, J.M. and Starck, J.L.},
  date = {2008-07},
  journaltitle = {IEEE Trans. on Image Process.},
  volume = {17},
  number = {7},
  pages = {1093--1108},
  issn = {1057-7149, 1941-0042},
  doi = {10.1109/TIP.2008.924386},
  url = {http://ieeexplore.ieee.org/document/4531116/},
  urldate = {2023-06-03},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {381 citations (Semantic Scholar/DOI) [2023-06-02]},
  file = {/Users/personal-macbook/Zotero/storage/L7J62XXC/Bo Zhang et al. - 2008 - Wavelets, Ridgelets, and Curvelets for Poisson Noi.pdf}
}

@article{bozorgtabar_Informative_2019,
  title = {Informative {{Sample Generation Using Class Aware Generative Adversarial Networks}} for {{Classification}} of {{Chest Xrays}}},
  author = {Bozorgtabar, Behzad and Mahapatra, Dwarikanath and family=Teng, given=Hendrik, prefix=von, useprefix=false and Pollinger, Alexander and Ebner, Lukas and Thiran, Jean Phillipe and Reyes, Mauricio},
  date = {2019-07},
  journaltitle = {Comput. Vis. Image Underst.},
  volume = {184},
  pages = {57--65},
  publisher = {{Academic Press Inc.}},
  issn = {1090235X},
  doi = {10.1016/j.cviu.2019.04.007},
  abstract = {Training robust deep learning (DL) systems for disease detection from medical images is challenging due to limited images covering different disease types and severity. The problem is especially acute, where there is a severe class imbalance. We propose an active learning (AL) framework to select most informative samples for training our model using a Bayesian neural network. Informative samples are then used within a novel class aware generative adversarial network (CAGAN) to generate realistic chest xray images for data augmentation by transferring characteristics from one class label to another. Experiments show our proposed AL framework is able to achieve state-of-the-art performance by using about 35\% of the full dataset, thus saving significant time and effort over conventional methods.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Active learning,Chest xray,Classification,GAN,Informative samples},
  annotation = {28 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{braak_Alzheimer_1991,
  title = {Alzheimer's {{Disease Affects Limbic Nuclei}} of the {{Thalamus}}},
  author = {Braak, H. and Braak, E.},
  date = {1991-02},
  journaltitle = {Acta Neuropathol},
  volume = {81},
  number = {3},
  pages = {261--268},
  issn = {0001-6322, 1432-0533},
  doi = {10.1007/BF00305867},
  url = {http://link.springer.com/10.1007/BF00305867},
  urldate = {2023-05-12},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Alzheimer's disease,Amyloid,Limbic system,Neurofibrillary changes,Thalamus},
  annotation = {253 citations (Semantic Scholar/DOI) [2023-05-12]}
}

@article{braak_Alzheimer_1997,
  title = {Alzheimer's {{Disease}}: {{Transiently Developing Dendritic Changes}} in {{Pyramidal Cells}} of {{Sector CA1}} of the {{Ammon}}'s {{Horn}}},
  author = {Braak, E. and Braak, H.},
  date = {1997-04},
  journaltitle = {Acta Neuropathol.},
  volume = {93},
  number = {4},
  pages = {323--325},
  doi = {10.1007/s004010050622},
  abstract = {In the course of Alzheimer's disease, specific CA1 pyramidal cells develop dendritic changes, which can only be observed transiently. Distal segments of the apical dendrite running through the stratum lacunosum-moleculare show spindle-shaped dilations filled with abnormal tau protein. The alteration eventually leads to amputation of the changed segment. The damage first appears at stage II in the evolution of the neurofibrillary changes [5], is best developed at stage III, and vanishes from the tissue at stage IV. It is usually not observed in stages V and VI (fully developed Alzheimer's disease).},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {124 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{brebisson_Deep_2015,
  title = {Deep {{Neural Networks}} for {{Anatomical Brain Segmentation}}},
  booktitle = {{{IEEE Comput}}. {{Soc}}. {{Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}. {{Workshop}}},
  author = {Br\'ebisson, Alexandre De and Montana, Giovanni},
  date = {2015-10},
  volume = {2015-Octob},
  pages = {20--28},
  publisher = {{IEEE Computer Society}},
  issn = {21607516},
  doi = {10.1109/CVPRW.2015.7301312},
  abstract = {We present a novel approach to automatically segment magnetic resonance (MR) images of the human brain into anatomical regions. Our methodology is based on a deep artificial neural network that assigns each voxel in an MR image of the brain to its corresponding anatomical region. The inputs of the network capture information at different scales around the voxel of interest: 3D and orthogonal 2D intensity patches capture a local spatial context while downscaled large 2D orthogonal patches and distances to the regional centroids enforce global spatial consistency. Contrary to commonly used segmentation methods, our technique does not require any non-linear registration of the MR images. To benchmark our model, we used the dataset provided for the MICCAI 2012 challenge on multi-atlas labelling, which consists of 35 manually segmented MR images of the brain. We obtained competitive results (mean dice coefficient 0.725, error rate 0.163) showing the potential of our approach. To our knowledge, our technique is the first to tackle the anatomical segmentation of the whole brain using deep neural networks.},
  isbn = {978-1-4673-6759-2},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Biological neural networks,Feature extraction,Image segmentation,Magnetic resonance imaging,Neurons,Three-dimensional displays,Training},
  annotation = {308 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{bremner_Magnetic_1997,
  title = {Magnetic {{Resonance Imaging-Based Measurement}} of {{Hippocampal Volume}} in {{Posttraumatic Stress Disorder Related}} to {{Childhood Physical}} and {{Sexual Abuse}}\textemdash a {{Preliminary Report}}},
  author = {Bremner, J. Douglas and Randall, Penny and Vermetten, Eric and Staib, Lawrence and Bronen, Richard A. and Mazure, Carolyn and Capelli, Sandi and McCarthy, Gregory and Innis, Robert B. and Charney, Dennis S.},
  date = {1997-01},
  journaltitle = {Biol. Psychiatry},
  volume = {41},
  number = {1},
  pages = {23--32},
  doi = {10.1016/S0006-3223(96)00162-X},
  abstract = {We have previously reported smaller hippocampal volume and deficits in short-term memory in patients with combat-related posttraumatic stress disorder (PTSD) relative to comparison subjects. The purpose of this study was to compare hippocampal volume in adult survivors of childhood abuse to matched controls. Magnetic resonance imaging was used to measure volume of the hippocampus in adult survivors of childhood abuse (n = 17) and healthy subjects (n = 17) matched on a case-by-case basis for age, sex, race, handedness, years of education, body size, and years of alcohol abuse. All patients met criteria for PTSD secondary to childhood abuse. PTSD patients had a 12\% smaller left hippocampal volume relative to the matched controls (p {$<$} .05), without smaller volumes of comparison regions (amygdala, caudate, and temporal lobe). The findings were significant after controlling for alcohol, age, and education, with multiple linear regression. These findings suggest that a decrease in left hippocampal volume is associated with abuse-related PTSD.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Hippocampus,posttraumatic stress disorder,stress},
  annotation = {1192 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{bressan_Semantic_2022,
  title = {Semantic {{Segmentation With Labeling Uncertainty}} and {{Class Imbalance Applied}} to {{Vegetation Mapping}}},
  author = {Bressan, Patrik Ol\~a and Junior, Jos\'e Marcato and Correa Martins, Jos\'e Augusto and family=Melo, given=Maximilian Jaderson, prefix=de, useprefix=true and Gon\c{c}alves, Diogo Nunes and Freitas, Daniel Matte and Marques Ramos, Ana Paula and Garcia Furuya, Michelle Ta\'is and Osco, Lucas Prado and family=Andrade Silva, given=Jonathan, prefix=de, useprefix=true and Luo, Zhipeng and Garcia, Raymundo Cordero and Ma, Lingfei and Li, Jonathan and Gon\c{c}alves, Wesley Nunes},
  date = {2022-04-01},
  journaltitle = {International Journal of Applied Earth Observation and Geoinformation},
  volume = {108},
  pages = {102690},
  issn = {1569-8432},
  doi = {10.1016/j.jag.2022.102690},
  url = {https://www.sciencedirect.com/science/article/pii/S0303243422000162},
  urldate = {2022-07-11},
  abstract = {Recently, Convolutional Neural Networks (CNN) methods achieved impressive success in semantic segmentation tasks. However, challenges like class imbalance around samples and the uncertainty in human pixel-labeling are not completely addressed. Here we present an approach that calculates a weight for each pixel considering its class and uncertainty during the labeling process. The pixel-wise weights are used at the training phase to increase or decrease the importance of the pixels accordingly. Experimental results were conducted adapting well-known CNN methods FCN and SegNet; however, this strategy can be applied to any segmentation method. We evaluated the experiments for semantic segmentation of urban trees in aerial imageries. The robustness of the approach was assessed using a dataset with terrestrial images from vegetation with a drastic imbalance condition. We achieved significant improvements in the tasks compared to the baseline methods. We also verified that the proposed strategy proved to be more invariant to noise. The approach presented in this paper could be used within a wide range of semantic segmentation methods to improve their robustness.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Class weighting,Labeling uncertainty,Loss function,Semantic segmentation},
  annotation = {6 citations (Semantic Scholar/DOI) [2022-07-10]},
  file = {/Users/personal-macbook/Zotero/storage/PBN6Q262/Bressan et al. - 2022 - Semantic segmentation with labeling uncertainty an.pdf}
}

@article{bressem_Comparing_2020,
  title = {Comparing {{Different Deep Learning Architectures}} for {{Classification}} of {{Chest Radiographs}}},
  author = {Bressem, K. and Adams, L. and Erxleben, C. and Hamm, B. and Niehues, S. and Vahldiek, J.},
  date = {2020},
  journaltitle = {Sci. Rep.},
  doi = {10.1038/s41598-020-70479-z},
  abstract = {It could be observed, that more shallow networks may achieve results comparable to their deeper and more complex counterparts with shorter training times, enabling classification performances on medical image data close to the state-of-the-art methods even when using limited hardware. Chest radiographs are among the most frequently acquired images in radiology and are often the subject of computer vision research. However, most of the models used to classify chest radiographs are derived from openly available deep neural networks, trained on large image datasets. These datasets differ from chest radiographs in that they are mostly color images and have substantially more labels. Therefore, very deep convolutional neural networks (CNN) designed for ImageNet and often representing more complex relationships, might not be required for the comparably simpler task of classifying medical image data. Sixteen different architectures of CNN were compared regarding the classification performance on two openly available datasets, the CheXpert and COVID-19 Image Data Collection. Areas under the receiver operating characteristics curves (AUROC) between 0.83 and 0.89 could be achieved on the CheXpert dataset. On the COVID-19 Image Data Collection, all models showed an excellent ability to detect COVID-19 and non-COVID pneumonia with AUROC values between 0.983 and 0.998. It could be observed, that more shallow networks may achieve results comparable to their deeper and more complex counterparts with shorter training times, enabling classification performances on medical image data close to the state-of-the-art methods even when using limited hardware.},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {110 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/HVPDYCCJ/Bressem et al. - 2020 - Comparing different deep learning architectures fo.pdf}
}

@article{brodkey_Tremor_2004,
  title = {Tremor {{Cells}} in the {{Human Thalamus}}: {{Differences Among Neurological Disorders}}},
  shorttitle = {Tremor {{Cells}} in the {{Human Thalamus}}},
  author = {Brodkey, Jason A. and Tasker, Ronald R. and Hamani, Clement and McAndrews, Mary Pat and Dostrovsky, Jonathan O. and Lozano, Andres M.},
  date = {2004-07},
  journaltitle = {J. Neurosurg.},
  volume = {101},
  number = {1},
  pages = {43--47},
  issn = {0022-3085},
  doi = {10.3171/jns.2004.101.1.0043},
  url = {https://thejns.org/view/journals/j-neurosurg/101/1/article-p43.xml},
  urldate = {2023-05-12},
  abstract = {Object.               Thalamic neurons firing at frequencies synchronous with tremor are thought to play a critical role in the generation and maintenance of tremor. The authors studied the incidence and locations of neurons with tremor-related activity (TRA) in the thalamus of patients with varied pathological conditions\textemdash including Parkinson disease (PD), essential tremor (ET), multiple sclerosis (MS), and cerebellar disorders\textemdash to determine whether known differences in the effectiveness of thalamic stereotactic procedures for these tremors could be correlated to differences in the incidence or locations of TRA cells.                                         Methods.               Seventy-five operations were performed in 61 patients during which 686 TRA cells were recorded from 440 microelectrode trajectories in the thalamus. The locations of the TRA cells in relation to electrophysiologically defined thalamic nuclei and the commissural coordinates were compared among patient groups.                          The authors found that TRA cells are present in patients with each of these disorders and that these cells populate several nuclei in the ventral lateral tier of the thalamus. There were no large differences in the locations of TRA cells among the different diagnostic classes, although there was a difference in the incidence of TRA cells in patients with PD, who had greater than 3.8 times more cells per thalamic trajectory than patients with ET and approximately five times more cells than patients with MS or cerebellar disorders.                            Conclusions.               There was an increased incidence of TRA in the thalamus of patients with PD. The location of thalamic TRA cells in patients with basal ganglia and other tremor disorders was similar.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Movement disorder,Parkinson disease,Thalamus,Tremor},
  annotation = {69 citations (Semantic Scholar/DOI) [2023-05-12]}
}

@article{brodley_Identifying_1999,
  title = {Identifying {{Mislabeled Training Data}}},
  author = {Brodley, C. E. and Friedl, M. A.},
  date = {1999-08-01},
  journaltitle = {jair},
  volume = {11},
  pages = {131--167},
  issn = {1076-9757},
  doi = {10.1613/jair.606},
  url = {https://jair.org/index.php/jair/article/view/10238},
  urldate = {2022-12-29},
  abstract = {This paper presents a new approach to identifying and    eliminating mislabeled training instances for supervised learning. The    goal of this approach is to improve classification accuracies produced    by learning algorithms by improving the quality of the training data.    Our approach uses a set of learning algorithms to create classifiers    that serve as noise filters for the training data.  We evaluate single    algorithm, majority vote and consensus filters on five datasets that    are prone to labeling errors.  Our experiments illustrate that    filtering significantly improves classification accuracy for noise    levels up to 30 percent.  An analytical and empirical evaluation of    the precision of our approach shows that consensus filters are    conservative at throwing away good data at the expense of retaining    bad data and that majority filters are better at detecting bad data at    the expense of throwing away good data.  This suggests that for    situations in which there is a paucity of data, consensus filters are    preferable, whereas majority vote filters are preferable for    situations with an abundance of data.},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {895 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/N99NZH5X/Brodley and Friedl - 1999 - Identifying Mislabeled Training Data.pdf}
}

@article{brosch_Deep_2016,
  title = {Deep {{3D Convolutional Encoder Networks With Shortcuts}} for {{Multiscale Feature Integration Applied}} to {{Multiple Sclerosis Lesion Segmentation}}},
  author = {Brosch, Tom and Tang, Lisa Y. W. and Yoo, Youngjin and Li, David K. B. and Traboulsee, Anthony and Tam, Roger},
  date = {2016-05},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {35},
  number = {5},
  pages = {1229--1239},
  doi = {10.1109/TMI.2016.2528821},
  abstract = {We propose a novel segmentation approach based on deep 3D convolutional encoder networks with shortcut connections and apply it to the segmentation of multiple sclerosis (MS) lesions in magnetic resonance images. Our model is a neural network that consists of two interconnected pathways, a convolutional pathway, which learns increasingly more abstract and higher-level image features, and a deconvolutional pathway, which predicts the final segmentation at the voxel level. The joint training of the feature extraction and prediction pathways allows for the automatic learning of features at different scales that are optimized for accuracy for any given combination of image types and segmentation task. In addition, shortcut connections between the two pathways allow high- and low-level features to be integrated, which enables the segmentation of lesions across a wide range of sizes. We have evaluated our method on two publicly available data sets (MICCAI 2008 and ISBI 2015 challenges) with the results showing that our method performs comparably to the top-ranked state-of-the-art methods, even when only relatively small data sets are available for training. In addition, we have compared our method with five freely available and widely used MS lesion segmentation methods (EMS, LST-LPA, LST-LGA, Lesion-TOADS, and SLS) on a large data set from an MS clinical trial. The results show that our method consistently outperforms these other methods across a wide range of lesion sizes.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {391 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{brueck_Artificial_2019,
  title = {An {{Artificial Sweating System}} for {{Sweat Sensor Testing Applications}}},
  author = {Brueck, Andrew and Bates, Kyle and Wood, Trent and House, William and Martinez, Zackary and Peters, Shannon and Root, Blain and Yelamarthi, Kumar and Kaya, Tolga},
  date = {2019},
  journaltitle = {Electron. Switz.},
  issn = {20799292},
  doi = {10.3390/electronics8060606},
  abstract = {This research proposes a completely automated, computer-controlled fluid mixing and dispensing system, which is suitable for testing sweat sensing devices, as an alternative to requiring human trials during the development phase of a sweat sensor device. An arm mold was designed and implemented with dragon skin and pores to simulate sweating action. The relay controlled mixing tanks allow for the different concentration of fluid solutions at various rates of fluid dispensing through pores. The onboard single board computer controls a dozen electronic relays and it switches and presents an easy to use graphical user interface to allow end users to conduct the experiments with ease and not require further programming. With the recent advances in sweat sensors, this platform offers a unique way of testing sensing devices during development, allowing for researchers to focus on their design parameters one at a time before actual validation through human trials are conducted. The current device can provide sweat rates from 1 ffL/min to 500 ffL/min. Furthermore, concentrations of 10 mM up to 200 mM of salt concentrations were able to be repeatedly produced. In an ANOVA test with salt concentrations varying from 40\textendash 60 mM, a p-value of 0.365 shows that the concentration does not have any effect on the flow rate. Similarly, a p-value of 0.329 and 0.167 for different relative humidity and temperature shows that the system does not present a statistical difference. Lastly, when the interactions among all the factors were considered, a p-value of 0.416 clearly presents that the system performance is insensitive to different factors, thus validating the system reliability.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Hydration,Relays,Single board computer,Sweat sensing},
  annotation = {5 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{brush_Factors_1993,
  title = {Factors {{Motivating Small Companies}} to {{Internationalize}}: {{The Effect}} of {{Firm Age}}},
  author = {Brush, Candida G.},
  date = {1993},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@inproceedings{buades_NonLocal_2005,
  ids = {buades_Nonlocal_2005},
  title = {A {{Non-Local Algorithm}} for {{Image Denoising}}},
  booktitle = {2005 {{IEEE Comput}}. {{Soc}}. {{Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}. {{CVPR05}}},
  author = {Buades, A. and Coll, B. and Morel, J.-M.},
  date = {2005},
  volume = {2},
  pages = {60--65},
  publisher = {{IEEE}},
  location = {{San Diego, CA, USA}},
  doi = {10.1109/CVPR.2005.38},
  url = {http://ieeexplore.ieee.org/document/1467423/},
  urldate = {2023-05-08},
  eventtitle = {2005 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}}'05)},
  isbn = {978-0-7695-2372-9},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {6520 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{buda_Management_2019b,
  ids = {buda_Management_2019,buda_Management_2019a},
  title = {Management of {{Thyroid Nodules Seen}} on {{US Images}}: {{Deep Learning May Match Performance}} of {{Radiologists}}},
  shorttitle = {Management of {{Thyroid Nodules Seen}} on {{US Images}}},
  author = {Buda, Mateusz and Wildman-Tobriner, Benjamin and Hoang, Jenny K. and Thayer, David and Tessler, Franklin N. and Middleton, William D. and Mazurowski, Maciej A.},
  date = {2019-09},
  journaltitle = {Radiology},
  volume = {292},
  number = {3},
  pages = {695--701},
  issn = {0033-8419, 1527-1315},
  doi = {10.1148/radiol.2019181343},
  url = {http://pubs.rsna.org/doi/10.1148/radiol.2019181343},
  urldate = {2023-05-08},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {105 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/V2I6YXFX/Buda et al. - 2019 - Management of Thyroid Nodules Seen on US Images D.pdf;/Users/personal-macbook/Zotero/storage/W9667FYT/Buda et al. - 2019 - Management of thyroid nodules seen on US images d.html}
}

@mvbook{budinger_Comprehensive_2014,
  ids = {budinger_Comprehensive_2014a},
  title = {Comprehensive {{Biomedical Physics}}},
  editor = {Budinger, Thomas F. and Brahme, Anders},
  date = {2014},
  publisher = {{Elsevier}},
  location = {{Amsterdam}},
  url = {https://www.sciencedirect.com/referencework/9780444536334/comprehensive-biomedical-physics?via=ihub=},
  isbn = {978-0-444-53633-4},
  langid = {english},
  volumes = {10},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {OCLC: 886540666}
}

@article{bughin_Can_2019,
  title = {Can {{Artificial Intelligence Help Society}} as {{Much}} as {{It Helps Business}} ?},
  author = {Bughin, Jacques and Hazan, Eric},
  date = {2019},
  journaltitle = {McKinsey Q.},
  abstract = {Building and expanding on existing theories of welfare economics, we simulated how technology adoption today could play out across the economy. The key finding is that two dimensions will be decisive\textemdash and in both cases, business has a central role to play (Exhibit 1). The first Can artificial intelligence help society as much as it helps business? The answer is yes\textemdash but only if leaders start embracing technological social responsibility (TSR) as a new business imperative for the AI era. Jacques Bughin is a director of the McKinsey Global Institute and a senior partner in McKinsey's Brussels office. Eric Hazan is a senior partner in the Paris office. August 2019 dimension is the extent to which firms adopt technologies with a view to accelerating innovation-led growth, compared with a narrower focus on labor substitution and cost reduction. The second is the extent to which technology adoption is accompanied by measures to actively manage the labor transitions that will accompany it\textemdash in particular, raising skill levels and ensuring a more fluid labor market.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{bughin_Notes_2018,
  title = {Notes {{From}} the {{AI Frontier}}: {{Modeling}} the {{Impact}} of {{AI}} on the {{World Economy}}},
  author = {Bughin, Jacques and Seong, Jeongmin and Manyika, James and Joshi, Raoul},
  date = {2018},
  journaltitle = {McKinsey Glob. Inst.},
  abstract = {Continuing the McKinsey Global Institute's ongoing exploration of artificial intelligence (AI) and its broader implications, this discussion paper focuses on modeling AI's potential impact on the economy.We take a micro-to-macro and simulation-based approach in which the adoption of AI by firms arises from economic and competition-related incentives, and macro factors have an influence. We consider not only the possible benefits but also the costs related to implementation and disruption.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found,automation,futures}
}

@article{bui_3D_2017,
  title = {{{3D Densely Convolutional Networks}} for {{Volumetric Segmentation}}},
  author = {Bui, Toan Duc and Shin, Jitae and Moon, Taesup},
  date = {2017},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.1709.03199},
  url = {https://arxiv.org/abs/1709.03199},
  urldate = {2023-05-08},
  abstract = {In the isointense stage, the accurate volumetric image segmentation is a challenging task due to the low contrast between tissues. In this paper, we propose a novel very deep network architecture based on a densely convolutional network for volumetric brain segmentation. The proposed network architecture provides a dense connection between layers that aims to improve the information flow in the network. By concatenating features map of fine and coarse dense blocks, it allows capturing multi-scale contextual information. Experimental results demonstrate significant advantages of the proposed method over existing methods, in terms of both segmentation accuracy and parameter efficiency in MICCAI grand challenge on 6-month infant brain MRI segmentation.},
  version = {2},
  keywords = {⛔ No INSPIRE recid found,Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences},
  annotation = {64 citations (Semantic Scholar/arXiv) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/P5NHU4D8/Bui et al. - 2017 - 3D Densely Convolutional Networks for Volumetric S.pdf}
}

@article{bui_improvingmultiatlascardiacstructuresegmentationcomputedtomographyangiographyperformanceevaluationbasedheterogeneousdataset_2020,
  title = {Improving {{Multi-Atlas Cardiac Structure Segmentation}} of {{Computed Tomography Angiography}}: {{A Performance Evaluation Based}} on a {{Heterogeneous Dataset}}},
  shorttitle = {Improving {{Multi-Atlas Cardiac Structure Segmentation}} of {{Computed Tomography Angiography}}},
  author = {Bui, Vy and Hsu, Li-Yueh and Shanbhag, Sujata M. and Tran, Loc and Bandettini, W. Patricia and Chang, Lin-Ching and Chen, Marcus Y.},
  date = {2020-10},
  journaltitle = {Computers in Biology and Medicine},
  volume = {125},
  pages = {104019},
  issn = {00104825},
  doi = {10.1016/j.compbiomed.2020.104019},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0010482520303504},
  urldate = {2023-05-28},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,conditional random fields,convolutional neural networks,feature-based registration,image registration,label fusion,medical image segmentation,multi-atlas segmentation,random decision forests,semantic segmentation,Supervised learning},
  file = {/Users/personal-macbook/Zotero/storage/WRHYNLJ4/Bui et al. - 2020 - Improving multi-atlas cardiac structure segmentati.pdf}
}

@article{bulat_Human_2016,
  title = {Human {{Pose Estimation}} via {{Convolutional Part Heatmap Regression}}},
  author = {Bulat, Adrian and Tzimiropoulos, Georgios},
  date = {2016-09},
  abstract = {This paper is on human pose estimation using Convolutional Neural Networks. Our main contribution is a CNN cascaded architecture specifically designed for learning part relationships and spatial context, and robustly inferring pose even for the case of severe part occlusions. To this end, we propose a detection-followed-by-regression CNN cascade. The first part of our cascade outputs part detection heatmaps and the second part performs regression on these heatmaps. The benefits of the proposed architecture are multi-fold: It guides the network where to focus in the image and effectively encodes part constraints and context. More importantly, it can effectively cope with occlusions because part detection heatmaps for occluded parts provide low confidence scores which subsequently guide the regression part of our network to rely on contextual information in order to predict the location of these parts. Additionally, we show that the proposed cascade is flexible enough to readily allow the integration of various CNN architectures for both detection and regression, including recent ones based on residual learning. Finally, we illustrate that our cascade achieves top performance on the MPII and LSP data sets. Code can be downloaded from http://www.cs.nott.ac.uk/ psxab5/},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{burkhardt_Online_2018,
  title = {Online {{Multi-Label Dependency Topic Models}} for {{Text Classification}}},
  author = {Burkhardt, Sophie and Kramer, Stefan},
  date = {2018-05-01},
  journaltitle = {Mach Learn},
  volume = {107},
  number = {5},
  pages = {859--886},
  issn = {1573-0565},
  doi = {10.1007/s10994-017-5689-6},
  url = {https://doi.org/10.1007/s10994-017-5689-6},
  urldate = {2022-06-19},
  abstract = {Multi-label text classification is an increasingly important field as large amounts of text data are available and extracting relevant information is important in many application contexts. Probabilistic generative models are the basis of a number of popular text mining methods such as Naive Bayes or Latent Dirichlet Allocation. However, Bayesian models for multi-label text classification often are overly complicated to account for label dependencies and skewed label frequencies while at the same time preventing overfitting. To solve this problem we employ the same technique that contributed to the success of deep learning in recent years: greedy layer-wise training. Applying this technique in the supervised setting prevents overfitting and leads to better classification accuracy. The intuition behind this approach is to learn the labels first and subsequently add a more abstract layer to represent dependencies among the labels. This allows using a relatively simple hierarchical topic model which can easily be adapted to the online setting. We show that our method successfully models dependencies online for large-scale multi-label datasets with many labels and improves over the baseline method not modeling dependencies. The same strategy, layer-wise greedy training, also makes the batch variant competitive with existing more complex multi-label topic models.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,LDA,Multi-label classification,Online learning,Topic model},
  file = {/Users/personal-macbook/Zotero/storage/5BKSC34U/Burkhardt and Kramer - 2018 - Online multi-label dependency topic models for tex.pdf}
}

@article{bustos_Padchest_2020,
  ids = {bustos_PadChest_2019},
  title = {Padchest: {{A Large Chest X-Ray Image Dataset With Multi-Label Annotated Reports}}},
  shorttitle = {Padchest},
  author = {Bustos, Aurelia and Pertusa, Antonio and Salinas, Jose-Maria and family=Iglesia-Vay\'a, given=Maria, prefix=de la, useprefix=true},
  date = {2020-12},
  journaltitle = {Medical Image Analysis},
  volume = {66},
  pages = {101797},
  issn = {13618415},
  doi = {10.1016/j.media.2020.101797},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1361841520301614},
  urldate = {2023-01-07},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {275 citations (Semantic Scholar/DOI) [2023-01-06]},
  file = {/Users/personal-macbook/Zotero/storage/E69BLSJ4/Bustos et al. - 2020 - PadChest A large chest x-ray image dataset with m.pdf}
}

@book{butler_Design_2015,
  title = {Design to {{Grow}}: {{How Coca-Cola Learned}} to {{Combine Scale}} and {{Agility}} ({{And How You Can Too}})},
  author = {Butler, David and Tischler, Linda},
  date = {2015-02},
  publisher = {{Simon and Schuster}},
  abstract = {Expert advice from Coca-Cola's vice president of Innovation and Entrepreneurship: Learn how Coca-Cola uses design to grow its business by combining the advantages of scale with the agility to respond to fast-changing market conditions.In today's world, every company is at risk of having a ``Kodak Moment''\textemdash watching its industry and the competitive advantages it has developed over years, even decades, vanish overnight. The reason? An inability to adapt quickly to new business realities. Established companies are at risk, but it's no easier being an agile startup, because most of those fail due to their inability to scale. Tomorrow's business winners\textemdash regardless of size or industry\textemdash will be the ones that know how to combine scale with agility. In Design to Grow, a Coca-Cola senior executive shares both the successes and failures of one of the world's largest companies as it learns to use design to be both agile and big. In this rare and unprecedented behind-the-scenes look, David Butler and senior Fast Company editor, Linda Tischler, use plain language and easy-to-understand case studies to show how this works at Coca-Cola\textemdash and how other companies can use the same approach to grow their business. This book is a must-read for managers inside large corporations as well as entrepreneurs just getting started.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{byne_Magnetic_2001,
  title = {Magnetic {{Resonance Imaging}} of the {{Thalamic Mediodorsal Nucleus}} and {{Pulvinar}} in {{Schizophrenia}} and {{Schizotypal Personality Disorder}}},
  author = {Byne, William and Buchsbaum, Monte S. and Kemether, Eileen and Hazlett, Erin A. and Shinwari, Akbar and Mitropoulou, Vivian and Siever, Larry J.},
  date = {2001-02-01},
  journaltitle = {Arch Gen Psychiatry},
  volume = {58},
  number = {2},
  pages = {133},
  issn = {0003-990X},
  doi = {10.1001/archpsyc.58.2.133},
  url = {http://archpsyc.jamanetwork.com/article.aspx?doi=10.1001/archpsyc.58.2.133},
  urldate = {2023-05-12},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {195 citations (Semantic Scholar/DOI) [2023-05-12]},
  file = {/Users/personal-macbook/Zotero/storage/A8UABDKE/Byne et al. - 2001 - Magnetic Resonance Imaging of the Thalamic Mediodo.pdf}
}

@article{cabezas_Review_2011,
  title = {A {{Review}} of {{Atlas-Based Segmentation}} for {{Magnetic Resonance Brain Images}}},
  author = {Cabezas, Mariano and Oliver, Arnau and Llad\'o, Xavier and Freixenet, Jordi and Bach Cuadra, Meritxell},
  date = {2011-12},
  journaltitle = {Computer Methods and Programs in Biomedicine},
  volume = {104},
  number = {3},
  pages = {e158-e177},
  issn = {01692607},
  doi = {10.1016/j.cmpb.2011.07.015},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0169260711002033},
  urldate = {2023-05-08},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {393 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@thesis{cabiscol_Understanding_2019,
  title = {Understanding {{Uncertainty}} in {{Bayesian Neural Networks}}},
  author = {Cabiscol, Javier Antor\'an},
  date = {2019},
  institution = {{University of Cambridge}},
  abstract = {n applications with strict safety or fairness requirements, such as self-driving cars, drugtoxicity prediction or loan default prediction, understanding why a model made a decisioncan be as crucial as the prediction's accuracy. Critical applications are also behind thesurging mainstream interest in Bayesian deep learning. Bayesian neural networks are ableto provide reliable uncertainty estimates together with their predictions. These can preventautomated systems from behaving erratically when faced with unforeseen circumstances.Surprisingly, there has been very little work in leveraging the uncertainty estimates providedby probabilistic models to make automated decisions more interpretable.This work develops CLUE, a new method for interpreting predictive uncertainty estimatesusing counterfactual generation. By searching for low uncertainty points that are near theinput we wish to explain, CLUE answers the question: "How should we change an input suchthat it makes our model less uncertain?" A generative model is used to ensure that CLUE'sexplanations consist of plausible input configurations. Unlike traditional interpretabilitymethods, which are often limited to asking questions in terms of class probabilities, anuncertainty-based approach can provide insight into both regression and classification pre-dictions. We also propose a clustering algorithm that groups similar CLUE explanations,allowing for the identification of the main sources of uncertainty within datasets.A novel functionally-grounded framework for the quantitative evaluation of uncertaintyexplanations is proposed. It uses a conditional generative model as a ground-truth generativeprocess. This allows for the generation of data with which to train models as well as theevaluation of explanations' uncertainty. CLUE is found to perform favourably compared tobaseline methods using the aforementioned framework. Our qualitative assessment matchesour numerical results, finding that CLUE generates cleaner and more intuitive saliency mapsthan the baselines.},
  pagetotal = {94},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{cabitza_Unintended_2017,
  title = {Unintended {{Consequences}} of {{Machine Learning}} in {{Medicine}}},
  author = {Cabitza, Federico and Rasoini, Raffaele and Gensini, Gian Franco},
  date = {2017},
  journaltitle = {JAMA - J. Am. Med. Assoc.},
  eprint = {28727867},
  eprinttype = {pmid},
  issn = {15383598},
  doi = {10.1001/jama.2017.7797},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{cabrelles_Integration_2009,
  title = {Integration of {{3D Laser Scanning}}, {{Photogrammetry}} and {{Thermography}} to {{Record Architectural Monuments}}},
  booktitle = {22nd {{CIPA Symp}}.},
  author = {Cabrelles, M. and Galcer\'a, S. and Navarro, S. and Lerma, J. L. and Akasheh, T. and Haddad, N. and S, Navarro and J.L, Lerma and T, Akasheh and N, Haddad},
  date = {2009},
  volume = {9},
  number = {9},
  pages = {3--8},
  abstract = {In this paper we present a methodology to record accurately and exhaustively a World Heritage Monument by means of terrestrial laser scanning (TLS), close range photogrammetry and thermal imagery. On the one hand, TLS will provide 3D point clouds as well as rough photo models tant can substantially improve the draping of texture with external imagery. On the other hand, thermal imagery will provide further information about the actual state of conservation of the monument. As a case study, we present the complete documentation of a tomb, Djin Block No. 9. This monument is one of the park's archaeological monuments in Petra (Jordan), declared a World Heritage Site in 1985. Today, corrosion of the clay water management systems surrounding Djin Blocks has contributed to the weathering of the monuments, and erosion from wind, water and salt threatens to destroy these monuments despite efforts to preserve them for future generations. This study aims to contribute both metric and non-metric data in order to record the actual state of the tomb at present, before archaeologists, architects and further specialists start any kinds of intervention activities. Furthermore, the 3D photo-models will be used to visualize and disseminate the monument virtually through the Internet.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found,cultural heritage recording,Cultural heritage recording,laser scanning,Laser Scanning,photogrammetry,Photogrammetry,sensor integration,Sensor integration,thermal imagery,Thermal imagery}
}

@article{cagetti_Entrepreneurship_2006,
  title = {Entrepreneurship, {{Frictions}}, and {{Wealth}}},
  author = {Cagetti, Marco and Nardi, Mariacristina De},
  date = {2006},
  journaltitle = {J. Polit. Econ.},
  issn = {00223808},
  doi = {10.1086/508032},
  abstract = {This paper constructs and calibrates a parsimonious model of occupational choice that allows for entrepreneurial entry, exit, and investment decisions in the presence of borrowing constraints. The model fits very well a number of empirical observations, including the observed wealth distribution for entrepreneurs and workers. At the aggregate level, more restrictive borrowing constraints generate less wealth concentration and reduce average firm size, aggregate capital, and the fraction of entrepreneurs. Voluntary bequests allow some high-ability workers to establish or enlarge an entrepreneurial activity. With accidental bequests only, there would be fewer very large firms and less aggregate capital and wealth concentration. \textcopyright{} 2006 by The University of Chicago. All rights reserved.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{cai_Iterative_2018,
  ids = {_Iterative_,cai_iterativeattentionminingweaklysupervisedthoracicdiseasepatternlocalizationchestxrays_2018},
  title = {Iterative {{Attention Mining}} for {{Weakly Supervised Thoracic Disease Pattern Localization}} in {{Chest X-Rays}}},
  booktitle = {Med. {{Image Comput}}. {{Comput}}. {{Assist}}. {{Interv}}. \textendash{} {{MICCAI}} 2018},
  author = {Cai, Jinzheng and Lu, Le and Harrison, Adam P. and Shi, Xiaoshuang and Chen, Pingjun and Yang, Lin},
  editor = {Frangi, Alejandro F. and Schnabel, Julia A. and Davatzikos, Christos and Alberola-L\'opez, Carlos and Fichtinger, Gabor},
  date = {2018},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {589--598},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-00934-2_66},
  abstract = {Given image labels as the only supervisory signal, we focus on harvesting/mining, thoracic disease localizations from chest X-ray images. Harvesting such localizations from existing datasets allows for the creation of improved data sources for computer-aided diagnosis and retrospective analyses. We train a convolutional neural network (CNN) for image classification and propose an attention mining (AM) strategy to improve the model's sensitivity or saliency to disease patterns. The intuition of AM is that once the most salient disease area is blocked or hidden from the CNN model, it will pay attention to alternative image regions, while still attempting to make correct predictions. However, the model requires to be properly constrained during AM, otherwise, it may overfit to uncorrelated image parts and forget the valuable knowledge that it has learned from the original image classification task. To alleviate such side effects, we then design a knowledge preservation (KP) loss, which minimizes the discrepancy between responses for X-ray images from the original and the updated networks. Furthermore, we modify the CNN model to include multi-scale aggregation (MSA), improving its localization ability on small-scale disease findings, e.g., lung nodules. We validate our method on the publicly-available ChestX-ray14 dataset, outperforming a class activation map (CAM)-based approach, and demonstrating the value of our novel framework for mining disease locations.},
  isbn = {978-3-030-00934-2},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Class Activation Map (CAMs),Computer Science - Computer Vision and Pattern Recognition,Computer Vision and Pattern Recognition (cs.CV),Disease Pattern Localization,FOS: Computer and information sciences,Knowledge Preservation (KP),Multi-scale Aggregation (MSA),Thoracic Disease},
  annotation = {48 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/8E65SPIB/Cai et al. - 2018 - Iterative Attention Mining for Weakly Supervised T.pdf;/Users/personal-macbook/Zotero/storage/KX35GWAI/Cai et al. - 2018 - Iterative attention mining for weakly supervised t.pdf;/Users/personal-macbook/Zotero/storage/RS4EBAF3/Cai et al. - 2018 - Iterative Attention Mining for Weakly Supervised T.pdf;/Users/personal-macbook/Zotero/storage/XJEEM8X7/Cai et al. - 2018 - Iterative attention mining for weakly supervised t.pdf;/Users/personal-macbook/Zotero/storage/369EFRZ2/1807.html;/Users/personal-macbook/Zotero/storage/3EYHGZED/978-3-030-00934-2_66.html;/Users/personal-macbook/Zotero/storage/3GQ9KY6E/978-3-030-00934-2_66.html}
}

@inproceedings{cai_Variational_2020,
  title = {Variational {{Bayesian Inference}} for {{Crowdsourcing Predictions}}},
  booktitle = {2020 59th {{IEEE Conf}}. {{Decis}}. {{Control CDC}}},
  author = {Cai, Desmond and Nguyen, Duc Thien and Hong Lim, Shiau and Wynter, Laura},
  date = {2020-12-14},
  pages = {3166--3172},
  publisher = {{IEEE}},
  location = {{Jeju, Korea (South)}},
  doi = {10.1109/CDC42340.2020.9304064},
  url = {https://ieeexplore.ieee.org/document/9304064/},
  urldate = {2022-12-28},
  eventtitle = {2020 59th {{IEEE Conference}} on {{Decision}} and {{Control}} ({{CDC}})},
  isbn = {978-1-72817-447-1},
  keywords = {⛔ No INSPIRE recid found,Artificial Intelligence (cs.AI),FOS: Computer and information sciences,Machine Learning (cs.LG),Machine Learning (stat.ML)},
  annotation = {2 citations (Semantic Scholar/DOI) [2022-12-28]},
  file = {/Users/personal-macbook/Zotero/storage/2N9BB47Z/Cai et al. - 2020 - Variational Bayesian Inference for Crowdsourcing P.pdf}
}

@inproceedings{caldairou_Surface_2016,
  title = {A {{Surface Patch-Based Segmentation Method}} for {{Hippocampal Subfields}}},
  booktitle = {Med. {{Image Comput}}. {{Comput}}.-{{Assist}}. {{Interv}}. \textendash{} {{MICCAI}} 2016},
  author = {Caldairou, Benoit and Bernhardt, Boris C. and Kulaga-Yoskovitz, Jessie and Kim, Hosung and Bernasconi, Neda and Bernasconi, Andrea},
  date = {2016},
  pages = {379--387},
  publisher = {{Springer International Publishing}},
  doi = {10.1007/978-3-319-46723-8_44},
  abstract = {Several neurological disorders are associated with hippocampal pathology. As changes may be localized to specific subfields or spanning across different subfields, accurate subfield segmentation may improve non-invasive diagnostics. We propose an automated subfield segmentation procedure, which combines surface-based processing with a patch-based template library and feature matching. Validation experiments in 25 healthy individuals showed high segmentation accuracy (Dice {$>$}82 \% across all subfields) and robustness to variations in the template library size. Applying the algorithm to a cohort of patients with temporal lobe epilepsy and hippocampal sclerosis, we correctly lateralized the seizure focus in {$>$}90 \%. This advantageously compares to classifiers relying on volumes retrieved from other state-of-the-art algorithms.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {36 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{calli_Handling_2019,
  title = {Handling {{Label Noise Through Model Confidence}} and {{Uncertainty}}: {{Application}} to {{Chest Radiograph Classification}}},
  booktitle = {Med. {{Imaging}} 2019 {{Comput}}.-{{Aided Diagn}}.},
  author = {Calli, Erdi and Sogancioglu, Ecem and Scholten, Ernst Th and Murphy, Keelin and family=Ginneken, given=Bram, prefix=van, useprefix=false},
  date = {2019-03},
  volume = {10950},
  pages = {1095016},
  publisher = {{International Society for Optics and Photonics}},
  abstract = {In this work we analyze the effect of label noise in training and test data when performing classification experiments on chest radiographs (CXRs) with modern deep learning architectures. We use ChestXRay14, the largest publicly available CXR dataset. We simulate situs inversus by horizontal flipping of the CXRs, allowing us to precisely control the amount of label noise. We also perform experiments in classifying emphysema using the ChestXRay14 provided labels that are known to be noisy. Our situs inversus experiments confirm results from the computer vision literature that deep learning architectures are relatively robust but not completely insensitive to label noise in the training data: without or with very low noise, classification results are near perfect; 16\% and 32\% training label noise only lead to a 1.5\% and 4.6\% drop in accuracy. We investigate two metrics that could be used to identify test samples that have an incorrect label: model confidence and model uncertainty. We show, in an observer study with an experienced chest radiologist, that both measures are effective in identifying samples in ChestXRay14 that are erroneously labeled for the presence of emphysema.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,confidenc,deep learning,label noise,uncertainty}
}

@inproceedings{cao_3D_2019,
  title = {{{3D Point Cloud Compression}}: {{A Survey}}},
  shorttitle = {{{3D Point Cloud Compression}}},
  booktitle = {24th {{Int}}. {{Conf}}. {{3D Web Technol}}.},
  author = {Cao, Chao and Preda, Marius and Zaharia, Titus},
  date = {2019-07-26},
  pages = {1--9},
  publisher = {{ACM}},
  location = {{LA CA USA}},
  doi = {10.1145/3329714.3338130},
  url = {https://dl.acm.org/doi/10.1145/3329714.3338130},
  urldate = {2023-05-08},
  eventtitle = {{{Web3D}} '19: {{The}} 24th {{International Conference}} on {{3D Web Technology}}},
  isbn = {978-1-4503-6798-1},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,3D point cloud,compression,survey},
  annotation = {72 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/6PZVWF7X/Cao et al. - 2019 - 3D Point Cloud Compression A Survey.pdf}
}

@article{cao_Binary_2018,
  title = {Binary {{Hashing}} for {{Approximate Nearest Neighbor Search}} on {{Big Data}}: {{A Survey}}},
  shorttitle = {Binary {{Hashing}} for {{Approximate Nearest Neighbor Search}} on {{Big Data}}},
  author = {Cao, Yuan and Qi, Heng and Zhou, Wenrui and Kato, Jien and Li, Keqiu and Liu, Xiulong and Gui, Jie},
  date = {2018},
  journaltitle = {IEEE Access},
  volume = {6},
  pages = {2039--2054},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2017.2781360},
  abstract = {Nearest neighbor search is a fundamental problem in various domains, such as computer vision, data mining, and machine learning. With the explosive growth of data on the Internet, many new data structures using spatial partitions and recursive hyperplane decomposition (e.g., k-d trees) are proposed to speed up the nearest neighbor search. However, these data structures are facing big data challenges. To meet these challenges, binary hashing-based approximate nearest neighbor search methods attract substantial attention due to their fast query speed and drastically reduced storage. Since the most notably locality sensitive hashing was proposed, a large number of binary hashing methods have emerged. In this paper, we first illustrate the development of binary hashing research by proposing an overall and clear classification of them. Then we conduct extensive experiments to compare the performance of these methods on five famous and public data sets. Finally, we present our view on this topic.},
  eventtitle = {{{IEEE Access}}},
  keywords = {⛔ No INSPIRE recid found,Approximate nearest neighbor search,Binary codes,Data mining,Distributed databases,Encoding,Hamming distance,hashing based methods,large-scale database,Nearest neighbor searches,overview},
  annotation = {69 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/SRWTCVI7/Cao et al. - 2018 - Binary Hashing for Approximate Nearest Neighbor Se.pdf}
}

@article{cao_Imaging_2020,
  title = {Imaging and {{Clinical Features}} of {{Patients With}} 2019 {{Novel Coronavirus SARS-CoV-2}}: {{A Systematic Review}} and {{Meta-Analysis}}},
  author = {Cao, Yinghao and Liu, Xiaoling and Xiong, Lijuan and Cai, Kailin},
  date = {2020},
  journaltitle = {J. Med. Virol.},
  number = {613},
  eprint = {32242947},
  eprinttype = {pmid},
  pages = {1275--1280},
  issn = {10969071},
  doi = {10.1002/jmv.25822},
  abstract = {Background: Currently, the epidemic of coronavirus disease 2019 (COVID-19) has begun to spread worldwide. We aim to explore reliable evidence for the diagnosis and treatment of the COVID-19 by analyzing all the published studies by Chinese scholars on the clinical and imaging features in novel coronavirus pneumonia caused by SARS-CoV-2. Methods: We searched five medical databases including two Chinese and three English databases for all published articles on COVID-19 since the outbreak. A random-effects model was designed, and the imaging and clinical data from all studies were collected for meta-analysis. Results: Overall, 31 articles and 46 959 patients were included, including 10 English articles and 21 Chinese articles. The results of meta-analysis showed that the most common clinical manifestations were fever (87.3\%; 0.838-0.909), cough (58.1\%; 0.502-0.660), dyspnea (38.3\%; 0.246-0.520), muscle soreness or fatigue (35.5\%; 0.253-0.456), and chest distress (31.2\%; -0.024 to 0.648). The main imaging findings were bilateral pneumonia (75.7\%; 0.639-0.871) and ground-glass opacification (69.9\%; 0.602-0.796). Among the patients, the incidence that required intensive care unit (ICU) was (29.3\%; 0.190-0.395), the incidence with acute respiratory distress syndrome was (28.8\%; 0.147-0.429), the incidence with multiple organ dysfunction syndrome was (8.5\%; -0.008 to 0.179), and the case fatality rate of patients with COVID-19 was (6.8\%; 0.044-0.093). Conclusion: COVID-19 is a new clinical infectious disease that mainly causes bilateral pneumonia and lung function deteriorates rapidly. Nearly a third of patients need to be admitted to the ICU, and patients are likely to present respiratory failure or even death.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,2019 novel coronavirus pneumonia,clinical features,imaging finding,SARS-CoV-2},
  annotation = {271 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{cao_Multitask_2018,
  title = {Multi-{{Task Neural Networks}} for {{Joint Hippocampus Segmentation}} and {{Clinical Score Regression}}},
  author = {Cao, Liang and Li, Long and Zheng, Jifeng and Fan, Xin and Yin, Feng and Shen, Hui and Zhang, Jun},
  date = {2018-11},
  journaltitle = {Multimed. Tools Appl.},
  volume = {77},
  number = {22},
  pages = {29669--29686},
  doi = {10.1007/s11042-017-5581-1},
  abstract = {Feature representations extracted from hippocampus in magnetic resonance (MR) images are widely used in computer-aided Alzheimer's disease (AD) diagnosis, and thus accurate segmentation for the hippocampus has been remaining an active research topic. Previous studies for hippocampus segmentation require either human annotation which is tedious and error-prone or pre-processing MR images via time-consuming non-linear registration. Although many automatic segmentation approaches have been proposed, their performance is often limited by the small size of hippocampus and complex confounding information around the hippocampus. In particular, human-engineered features extracted from segmented hippocampus regions (e.g., the volume of the hippocampus) are essential for brain disease diagnosis, while these features are independent of diagnosis models, leading to sub-optimal performance. To address these issues, we propose a multi-task deep learning (MDL) method for joint hippocampus segmentation and clinical score regression using MR images. The prominent advantages of our MDL method lie on that we don't need any time-consuming non-linear registration for pre-processing MR images, and features generated by MDL are consistent with subsequent diagnosis models. Specifically, we first align all MR images onto a standard template, followed by a patch extraction process to approximately locate hippocampus regions in the template space. Using image patches as input data, we develop a multi-task convolutional neural network (CNN) for joint hippocampus segmentation and clinical score regression. The proposed CNN network contains two subnetworks, including 1) a U-Net with a Dice-like loss function for hippocampus segmentation, and 2) a convolutional neural network with a mean squared loss function for clinical regression. Note that these two subnetworks share a part of network parameters, to exploit the inherent association between these two tasks. We evaluate the proposed method on 407 subjects with MRI data from baseline Alzheimer's Disease Neuroimaging Initiative (ADNI) database. The experimental results suggest that our MDL method achieves promising results in both tasks of hippocampus segmentation and clinical score regression, compared with several state-of-the-art methods.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{cao_Realtime_2016,
  title = {Realtime {{Multi-Person 2D Pose Estimation Using Part Affinity Fields}}},
  author = {Cao, Zhe and Simon, Tomas and Wei, Shih-En and Sheikh, Yaser},
  date = {2016-11},
  abstract = {We present an approach to efficiently detect the 2D pose of multiple people in an image. The approach uses a nonparametric representation, which we refer to as Part Affinity Fields (PAFs), to learn to associate body parts with individuals in the image. The architecture encodes global context, allowing a greedy bottom-up parsing step that maintains high accuracy while achieving realtime performance, irrespective of the number of people in the image. The architecture is designed to jointly learn part locations and their association via two branches of the same sequential prediction process. Our method placed first in the inaugural COCO 2016 keypoints challenge, and significantly exceeds the previous state-of-the-art result on the MPII Multi-Person benchmark, both in performance and efficiency.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@inproceedings{caplan_Alternative_2001a,
  ids = {caplan_Alternative_2001},
  title = {Alternative {{Specimens}} for {{Workplace Drug Testing}}},
  booktitle = {J. {{Anal}}. {{Toxicol}}.},
  author = {Caplan, Y. H. and Goldberger, B. A.},
  date = {2001},
  eprint = {11499896},
  eprinttype = {pmid},
  issn = {01464760},
  doi = {10.1093/jat/25.5.396},
  abstract = {Recent advances in analytical techniques have enabled the detection of drugs and drug metabolites in alternative biological specimens for the purposes of workplace testing. A wide variety of specimens are available, each providing valuable information concerning prior or current drug use. The present focus is on oral fluid (saliva), hair, and sweat. An extensive evaluation by the Division of Workplace Programs of the Department of Health and Human Services is underway to determine the utility of these specimens in federally regulated programs. In future years, the testing of alternative specimens will expand our ability to understand the patterns of drug use and will become routine in all areas of forensic toxicology.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {169 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{cardenes_Multidimensional_2009,
  title = {A {{Multidimensional Segmentation Evaluation}} for {{Medical Image Data}}},
  author = {C\'ardenes, Rub\'en and De Luis-Garc\'ia, Rodrigo and Bach-Cuadra, Meritxell},
  date = {2009-11},
  journaltitle = {Computer Methods and Programs in Biomedicine},
  volume = {96},
  number = {2},
  pages = {108--124},
  issn = {01692607},
  doi = {10.1016/j.cmpb.2009.04.009},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0169260709001424},
  urldate = {2023-05-08},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {117 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{carletta_Assessing_1996,
  title = {Assessing {{Agreement}} on {{Classification Tasks}}: {{The Kappa Statistic}}},
  shorttitle = {Assessing {{Agreement}} on {{Classification Tasks}}},
  author = {Carletta, Jean},
  date = {1996},
  journaltitle = {Comput. Linguist.},
  volume = {22},
  number = {2},
  pages = {249--254},
  publisher = {{MIT Press}},
  location = {{Cambridge, MA}},
  url = {https://aclanthology.org/J96-2004},
  urldate = {2023-02-28},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/XS7KU6DY/Carletta - 1996 - Assessing Agreement on Classification Tasks The K.pdf}
}

@inproceedings{carlo_DEEP_2018,
  title = {Deep {{Ensemble Bayesian Active Learning}} : {{Adressing}} the {{Mode Collapse Issue}} in {{Monte Carlo Dropout}} via {{Ensembles}}},
  author = {Carlo, Monte and family=VIA, given=DROPOUT, given-i=DROPOUT},
  date = {2018},
  abstract = {In image classification tasks, the ability of deep convolutional neural networks (CNNs) to deal with complex image data has proved to be unrivalled. Deep CNNs, however, require large amounts of labeled training data to reach their full potential. In specialized domains such as healthcare, labeled data can be difficult and expensive to obtain. One way to alleviate this problem is to rely on active learning, a learning technique that aims to reduce the amount of labelled data needed for a specific task while still delivering satisfactory performance. We propose a new active learning strategy designed for deep neural networks. This method improves upon the current state-of-the-art deep Bayesian active learning method, which suffers from the mode collapse problem. We correct for this deficiency by making use of the expressive power and statistical properties of model ensembles. Our proposed method manages to capture superior data uncertainty, which translates into improved classification performance. We demonstrate empirically that our ensemble method yields faster convergence of CNNs trained on the MNIST and CIFAR-10 datasets.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{carreira_Human_2015,
  title = {Human {{Pose Estimation With Iterative Error Feedback}}},
  author = {Carreira, Joao and Agrawal, Pulkit and Fragkiadaki, Katerina and Malik, Jitendra},
  date = {2015-07},
  abstract = {Hierarchical feature extractors such as Convolutional Networks (ConvNets) have achieved impressive performance on a variety of classification tasks using purely feedforward processing. Feedforward architectures can learn rich representations of the input space but do not explicitly model dependencies in the output spaces, that are quite structured for tasks such as articulated human pose estimation or object segmentation. Here we propose a framework that expands the expressive power of hierarchical feature extractors to encompass both input and output spaces, by introducing top-down feedback. Instead of directly predicting the outputs in one go, we use a self-correcting model that progressively changes an initial solution by feeding back error predictions, in a process we call Iterative Error Feedback (IEF). IEF shows excellent performance on the task of articulated pose estimation in the challenging MPII and LSP benchmarks, matching the state-of-the-art without requiring ground truth scale annotation.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{caselles_Geodesic_1997,
  title = {Geodesic {{Active Contours}}},
  author = {Caselles, Vicent and Kimmel, Ron and Sapiro, Guillermo},
  date = {1997-02},
  journaltitle = {Int. J. Comput. Vis.},
  volume = {22},
  number = {1},
  pages = {61--79},
  doi = {10.1023/A:1007979827043},
  abstract = {A novel scheme for the detection of object boundaries is presented. The technique is based on active contours evolving in time according to intrinsic geometric measures of the image. The evolving contours naturally split and merge, allowing the simultaneous detection of several objects and both interior and exterior boundaries. The proposed approach is based on the relation between active contours and the computation of geodesics or minimal distance curves. The minimal distance curve lays in a Riemannian space whose metric is defined by the image content. This geodesic approach for object segmentation allows to connect classical ``snakes'' based on energy minimization and geometric active contours based on the theory of curve evolution. Previous models of geometric active contours are improved, allowing stable boundary detection when their gradients suffer from large variations, including gaps. Formal results concerning existence, uniqueness, stability, and correctness of the evolution are presented as well. The scheme was implemented using an efficient algorithm for curve evolution. Experimental results of applying the scheme to real images including objects with holes and medical data imagery demonstrate its power. The results may be extended to 3D object segmentation as well.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {6330 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{cassatt_Reversible_1975,
  title = {The {{Reversible Reduction}} of {{Horse Metmyoglobin}} by the {{Iron}}({{II}}) {{Complex}} of {{Trans-1}},2-{{Diaminocyclohexane-N}},{{N}},{{N}},n-{{Tetraacetate}}},
  author = {Cassatt, J. C. and Marini, C. P. and Bender, J. W.},
  date = {1975-12-16},
  journaltitle = {Biochemistry},
  volume = {14},
  number = {25},
  eprint = {57},
  eprinttype = {pmid},
  pages = {5470--5475},
  issn = {0006-2960},
  doi = {10.1021/bi00696a014},
  abstract = {The reduction of metmyoglobin by the iron(II) complex of trans-1,2-diaminocyclohexane-N,N,N'N'-tetraacetate (FeCDTA2-) has been investigated. The equilibrium constant, measured spectrophotometrically, is 0.21 with a resulting reduction potential of 0.050 V for Mb0. The rate constant for the reduction is 28 M-1 sec-1 with a deltaH ++ of 13 kcal M-1 and deltaS ++ of -11 eu. Both CN- and OH- inhibit the reduction because of the relatively low reactivity of cyanometmyoglobin (Mb+CN-) and ionized metmyglobin (Mb+OH-). The rate constant for the reduction of Mb+CN- by FeCDTA2- is 4.0 X 10(-2) M-1 sec-1 and that for reduction of Mb+OH- is 4.8 M-1 sec-1. The nitric oxide complex of metmyoglobin is reduced with a rate constant of 10 M-1 sec-1. The kinetics of oxidation of oxymyoglobin by FeCDTA- were studied. The data are consistent with a mechanism where oxidation takes place entirely through the deoxy form. A rate constant of 1.45 X 10(2) M-1 sec-1 was calculated for the oxidation of deoxymyoglobin by FeCDTA-, in equilibrium constant and rate constant for reduction. The above data are discussed in terms of a simple outer-sphere reduction reaction.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Acetates,Animals,Chelating Agents,Cyanides,Cyclohexylamines,Edetic Acid,Ferrous Compounds,Horses,Hydrogen-Ion Concentration,Iron,Kinetics,Myoglobin,Nitric Oxide,Oxidation-Reduction,Oxygen,Protein Binding},
  file = {/Users/personal-macbook/Zotero/storage/7JFGC48P/Cassatt et al. - 1975 - Reversible reduction of horse metmyoglobin by the .pdf}
}

@article{castelvecchi_Can_2016,
  title = {Can {{We Open}} the {{Black Box}} of {{AI}}?},
  author = {Castelvecchi, Davide},
  date = {2016},
  journaltitle = {Nature},
  eprint = {27708329},
  eprinttype = {pmid},
  issn = {14764687},
  doi = {10.1038/538020a},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {820 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{cendes_MRI_1993,
  title = {{{MRI Volumetric Measurement}} of {{Amygdala}} and {{Hippocampus}} in {{Temporal Lobe Epilepsy}}},
  author = {Cendes, F. and Andermann, F. and Gloor, P. and Evans, A. and Jones-Gotman, M. and Watson, C. and Melanson, D. and Olivier, A. and Peters, T. and Lopes-Cendes, I.},
  date = {1993-04},
  journaltitle = {Neurology},
  volume = {43},
  number = {4},
  pages = {719--725},
  doi = {10.1212/WNL.43.4.719},
  abstract = {We performed MRI volumetric measurements of the amygdala (AM), the hippocampal formation (HF), and the anterior temporal lobe in a group of 30 patients with intractable temporal lobe epilepsy (TLE) and in seven patients with extratemporal lobe foci. Measurements were analyzed with a semiautomated software program and the results compared with those of normal controls and correlated with the findings of all other investigations. In particular, we compared the results with the lateralization of epileptic abnormalities in the EEG. Volumetric studies of AM and HF showed lateralization of measurable atrophy consistent with that derived from extracranial and intracranial EEG examinations. The HF volumes were more sensitive and provided a lateralization in 87\%. Combined measurements of AM and HF showed lateralization in 93\%, always congruent with the results of EEG lateralization. This slight but important additional improvement in discrimination justifies using AM measurements in MRI volumetric studies of mesial temporal structures. Volumetric studies combined with other currently employed noninvasive techniques may diminish the need for invasive methods of investigation in patients with TLE.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{chakraborty_SARSCoV2_2020,
  title = {{{SARS-CoV-2 Causing Pneumonia-Associated Respiratory Disorder}} ({{COVID-19}}): {{Diagnostic}} and {{Proposed Therapeutic Options}}},
  author = {Chakraborty, C. and Sharma, A. R. and Sharma, G. and Bhattacharya, M. and Lee, S. S.},
  date = {2020},
  journaltitle = {Eur. Rev. Med. Pharmacol. Sci.},
  eprint = {32329877},
  eprinttype = {pmid},
  issn = {22840729},
  doi = {10.26355/EURREV_202004_20871},
  abstract = {SARS-CoV-2 is responsible for the outbreak of severe respiratory illness (COVID-19) in Wuhan City, China and is now spreading rapidly throughout the world. The prompt outbreak of COVID-19 and its quick spread without any controllable measure defines the severity of the situation. In this crisis, a collective pool of knowledge about the advancement of clinical diagnostic and management for COVID-19 is a prerequisite. Here, we summarize all the available updates on the multidisciplinary approaches for the advancement of diagnosis and proposed therapeutic strategies for COVID-19. Moreover, the review discusses different aspects of the COVID-19, including its epidemiology; incubation period; the general clinical features of patients; the clinical features of intensive care unit (ICU) patients; SARS-CoV-2 infection in the presence of co-morbid diseases and the clinical features of pediatric patients infected with the SARS-CoV-2. Advances in various diagnostic approaches, such as the use of real-time polymerase chain reaction (RT-PCR), chest radiography, and computed tomography (CT) imaging; and other modern diagnostic methods, for this infection have been highlighted. However, due to the unavailability of adequate evidence, presently there are no officially approved drugs or vaccines available against SARS-CoV-2. Additionally, we have discussed various therapeutic strategies for COVID-19 under different categories, like the possible treatment plans with drug (antiviral drugs and anti-cytokines) therapy for disease prevention. Lastly, potentials candidates for the vaccines against SARS-CoV-2 infection have been described. Collectively, the review provides an overview of the SARS-CoV-2 infection outbreak along with the recent advancements and strategies for diagnosis and therapy of COVID-19.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,COVID-19,Diagnosis,Proposed therapy,SARS-CoV-2}
}

@article{chakravarty_Performing_2013,
  title = {Performing {{Label-Fusion-Based Segmentation Using Multiple Automatically Generated Templates}}: {{Maget Brain}}: {{Label Fusion Segmentation Using Automatically Generated Templates}}},
  shorttitle = {Performing {{Label-Fusion-Based Segmentation Using Multiple Automatically Generated Templates}}},
  author = {Chakravarty, M. Mallar and Steadman, Patrick and Van Eede, Matthijs C. and Calcott, Rebecca D. and Gu, Victoria and Shaw, Philip and Raznahan, Armin and Collins, D. Louis and Lerch, Jason P.},
  date = {2013-10},
  journaltitle = {Hum. Brain Mapp.},
  volume = {34},
  number = {10},
  pages = {2635--2654},
  issn = {10659471},
  doi = {10.1002/hbm.22092},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/hbm.22092},
  urldate = {2023-05-12},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,atlases,globus pallidus,label-fusion,mouse imag},
  annotation = {285 citations (Semantic Scholar/DOI) [2023-05-12]},
  file = {/Users/personal-macbook/Zotero/storage/J2VDTCB4/Chakravarty et al. - 2013 - Performing label-fusion-based segmentation using m.pdf}
}

@article{chalmers_Artificial_2020,
  title = {Artificial {{Intelligence}} and {{Entrepreneurship}}: {{Implications}} for {{Venture Creation}} in the {{Fourth Industrial Revolution}}},
  author = {Chalmers, Dominic and MacKenzie, Niall G. and Carter, Sara},
  date = {2020},
  journaltitle = {Entrep. Theory Pract.},
  issn = {15406520},
  doi = {10.1177/1042258720934581},
  abstract = {This article explores the ways artificial intelligence (AI) may impact new venture processes, practices and outcomes. We examine how such technology will augment and replace tasks associated with idea production, selling, and scaling. These changes entail new ways of working, and we consider implications for the organizational design of entrepreneurial ventures. While AI can enhance entrepreneurial activities, liabilities stem from this technological leverage. We advance a research agenda that draws attention towards negative social and economic implications of AI, particularly for more traditional small firms at risk of disintermediation in an AI economy.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,artificial intelligence,entrepreneurship,external enabler,industry 4.0,new venture,opportunity,scaling,selling},
  annotation = {65 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{chang_Common_2019,
  title = {Common {{Misconceptions}} and {{Future Directions}} for {{AI}} in {{Medicine}}: {{A Physician-Data Scientist Perspective}}},
  booktitle = {Lect. {{Notes Comput}}. {{Sci}}. {{Subser}}. {{Lect}}. {{Notes Artif}}. {{Intell}}. {{Lect}}. {{Notes Bioinforma}}.},
  author = {Chang, Anthony},
  date = {2019},
  issn = {16113349},
  doi = {10.1007/978-3-030-21642-9_1},
  abstract = {``Healthcare is an information industry that continues to think that it is a biological industry.'' (Laurence McMahon at the AAHC Thought Leadership Institute meeting, August, 2016)},
  isbn = {978-3-030-21641-2},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {5 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{chang_Fingerprint_2011,
  title = {Fingerprint {{Spoof Detection Using Near Infrared Optical Analysis}}},
  author = {Chang, Shoude and Larin, Kirill V. and Mao, Youxin and Flueraru, Costel and Almuhtadi, Wahab},
  date = {2011},
  journaltitle = {State Art Biom.},
  doi = {10.5772/971},
  abstract = {Fingerprints have been used for several centuries as a means of identifying individuals. Since every fingerprint is considered to be unique, fingerprint recognition is the most popular biometric identification method currently employed in such areas as law enforcement, financial transactions, access control, and information security. Fingerprints consist of ridges and furrows on the surface of a fingertip. The ridges are the raised portions of the fingerprint while the furrows are the spaces between the ridges. Recognition can be performed based on ridge ending and ridge bifurcation (Xiao \& Raffat, 1990), tessellated invariant moment (Yang \& Park, 2008), and image-based features (Nanni \& Lumini, 2009). Since the ridges are created by nature, people may consider that stealing and duplicating a fingerprint is more difficult than stealing a password or token, but it turns out that it is not difficult to make an artifact to fool an automated fingerprint system. It has been reported that an automated fingerprint authentication system could be defeated either using ``a combination of low cunning, cheap kitchen supplies and a digital camera'' , or simply by creating false thumbprint images . These sensor-level attacks are called ``spoofing'' attacks in which an artifact containing a copy of the fingerprint traits of a legitimate enrolled user is used to fool a fingerprint system. The first step is to obtain the fingerprint of a legitimate user, which can be accomplished by lifting a latent print either with or without the co- operation of the fingerprint owner. Next, molding plastic and gelatin can be used to make ``gummy fingers''. Finally, the resulting fake fingers can be used to fool the fingerprint sensor and attack the security system. The vulnerability to fake-finger attack has generated a wave of research concerned with adding ``liveness detection'' to improve system resistance to spoofing. Liveness detection is the ability to determine whether a biometric sample is being provided by a live human being rather than from a copy created using an artifact. The detection methods can be categorized into two groups: hardware-based and software-based. In hardware-based solutions, extra hardware must be integrated with biometric sensors to detect additional information such as heartbeat, temperature, and the tissue under the epidermis. For example, an extra sensor can be used to measure either blood flow or pulse},
  isbn = {978-953-307-489-4},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {34 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{charidimou_Cerebral_2011,
  title = {Cerebral {{Microbleeds}}: {{Detection}}, {{Mechanisms}} and {{Clinical Challenges}}},
  author = {Charidimou, Andreas and Werring, David J.},
  date = {2011-08},
  journaltitle = {Future Neurol.},
  volume = {6},
  number = {5},
  pages = {587--611},
  publisher = {{Future Medicine}},
  doi = {10.2217/fnl.11.42},
  abstract = {In the last decade or so, cerebral microbleeds (CMBs) ? tiny perivascular hemorrhages seen as small, well-demarcated, hypointense, rounded lesions on MRI sequences that are sensitive to magnetic susceptibility ? have generated increasing interest among neurologists and clinical stroke researchers. As MRI techniques become more sophisticated, CMBs are increasingly detected in various patient populations (including all types of stroke, Alzheimer?s disease and vascular cognitive impairment) and healthy community-dwelling older people. Their presence raises many clinical dilemmas and intriguing pathophysiological questions. CMBs are emerging as an important new manifestation and diagnostic marker of cerebral small-vessel disease. They are a potential predictor of future intracerebral hemorrhage risk, a possible contributor to cognitive impairment and dementia and a potential key link between vascular and degenerative pathologies. In this article, we discuss the available pathological, neuroimaging and clinical studies in the field, and we provide a modern overview of the clinical and pathophysiological implications of CMBs in different disease settings.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {65 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{charles_PointNet_2017,
  title = {{{PointNet}}: {{Deep Learning}} on {{Point Sets}} for {{3D Classification}} and {{Segmentation}}},
  shorttitle = {{{PointNet}}},
  booktitle = {2017 {{IEEE Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}. {{CVPR}}},
  author = {Charles, R. Qi and Su, Hao and Kaichun, Mo and Guibas, Leonidas J.},
  date = {2017-07},
  pages = {77--85},
  publisher = {{IEEE}},
  location = {{Honolulu, HI}},
  doi = {10.1109/CVPR.2017.16},
  url = {http://ieeexplore.ieee.org/document/8099499/},
  urldate = {2022-07-15},
  abstract = {Point cloud is an important type of geometric data structure. Due to its irregular format, most researchers transform such data to regular 3D voxel grids or collections of images. This, however, renders data unnecessarily voluminous and causes issues. In this paper, we design a novel type of neural network that directly consumes point clouds, which well respects the permutation invariance of points in the input. Our network, named PointNet, provides a unified architecture for applications ranging from object classification, part segmentation, to scene semantic parsing. Though simple, PointNet is highly efficient and effective. Empirically, it shows strong performance on par or even better than state of the art. Theoretically, we provide analysis towards understanding of what the network has learnt and why the network is robust with respect to input perturbation and corruption.},
  eventtitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-5386-0457-1},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {6282 citations (Semantic Scholar/DOI) [2022-07-18]},
  file = {/Users/personal-macbook/Zotero/storage/AREWVGQI/Charles et al. - 2017 - PointNet Deep Learning on Point Sets for 3D Class.pdf}
}

@article{chavez_Coronavirus_2020,
  title = {Coronavirus {{Disease}} ({{COVID-19}}): {{A Primer}} for {{Emergency Physicians}}},
  author = {Chavez, Summer and Long, Brit and Koyfman, Alex and Liang, Stephen Y.},
  date = {2020},
  journaltitle = {Am. J. Emerg. Med.},
  issn = {15328171},
  doi = {10.1016/j.ajem.2020.03.036},
  abstract = {Introduction: Rapid worldwide spread of Coronavirus Disease 2019 (COVID-19) has resulted in a global pandemic. Objective: This review article provides emergency physicians with an overview of the most current understanding of COVID-19 and recommendations on the evaluation and management of patients with suspected COVID-19. Discussion: Severe Acute Respiratory Syndrome coronavirus 2 (SARS-CoV-2), the virus responsible for causing COVID-19, is primarily transmitted from person-to-person through close contact (approximately 6 ft) by respiratory droplets. Symptoms of COVID-19 are similar to other viral upper respiratory illnesses. Three major trajectories include mild disease with upper respiratory symptoms, non-severe pneumonia, and severe pneumonia complicated by acute respiratory distress syndrome (ARDS). Emergency physicians should focus on identifying patients at risk, isolating suspected patients, and informing hospital infection prevention and public health authorities. Patients with suspected COVID-19 should be asked to wear a facemask. Respiratory etiquette, hand washing, and personal protective equipment are recommended for all healthcare personnel caring for suspected cases. Disposition depends on patient symptoms, hemodynamic status, and patient ability to self-quarantine. Conclusion: This narrative review provides clinicians with an updated approach to the evaluation and management of patients presenting to the emergency department with suspected COVID-19.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Coronavirus Disease,COVID-19,Infectious disease,Pulmonary},
  annotation = {233 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{cheatham_Confronting_2019,
  title = {Confronting the {{Risks}} of {{Artificial Intelligence}}},
  author = {Cheatham, Benjamin and Javanmardian, Kia and Samandari, Hamid},
  date = {2019},
  journaltitle = {McKinsey Q.},
  issn = {00475394},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{chen_3D_2015,
  title = {{{3D Reconstruction From IR Thermal Images}} and {{Reprojective Evaluations}}},
  author = {Chen, Chia-Yen and Yeh, Chia-Hung and Chang, Bao Rong and Pan, Jun-Ming},
  date = {2015},
  journaltitle = {Mathematical Problems in Engineering},
  volume = {2015},
  pages = {1--8},
  issn = {1024-123X, 1563-5147},
  doi = {10.1155/2015/520534},
  url = {http://www.hindawi.com/journals/mpe/2015/520534/},
  urldate = {2022-12-29},
  abstract = {Infrared thermography has been widely used in various domains to measure the temperature distributions of objects and surfaces. The methodology can be further extended to 3D applications if the spatial information of the temperature distribution is available. This paper proposes a 3D infrared imaging approach based on silhouette volume intersection to reconstruct volumetric temperature data of enclosed objects. 3D IR images are taken from various angles and integrated with 2D RGB images to effectively reconstruct a 3D model of the object's temperature distributions. Various automatic thresholding methods are also compared and evaluated by reprojection scoring to systematically assess the effectiveness and accuracy of the different approaches. Experiment results have demonstrated the ability of the system to provide an estimate to the 3D location of an internal heat source from images taken externally.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {14 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/Z49GB2FC/Chen et al. - 2015 - 3D Reconstruction from IR Thermal Images and Repro.pdf}
}

@inproceedings{chen_Accurate_2017,
  title = {Accurate and {{Consistent Hippocampus Segmentation Through Convolutional LSTM}} and {{View Ensemble}}},
  booktitle = {Lect. {{Notes Comput}}. {{Sci}}. {{Subser}}. {{Lect}}. {{Notes Artif}}. {{Intell}}. {{Lect}}. {{Notes Bioinforma}}.},
  author = {Chen, Yani and Shi, Bibo and Wang, Zhewei and Sun, Tao and Smith, Charles D. and Liu, Jundong},
  date = {2017},
  volume = {10541 LNCS},
  pages = {88--96},
  publisher = {{Springer Verlag}},
  issn = {16113349},
  doi = {10.1007/978-3-319-67389-9_11},
  abstract = {In this work, a novel deep neural network is developed to automatically segment human hippocampi from MR images. To take advantage of the efficiency of 2D convolutional operations, as well the inter-slice dependence within 3D volumes, our model stacks fully convolutional neural networks (CNN) through convolutional long short-term memory (CLSTM) to extract voxel labels. Enhanced slice-wise label consistency is ensured, leading to improved segmentation stability and accuracy. We apply our model on ADNI dataset, and demonstrate that our proposed model outperforms the state-of-the-art solutions.},
  isbn = {978-3-319-67388-2},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Brain,CNN,Hippocampus segmentation,LSTM,MRI},
  annotation = {21 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{chen_Confidence_2020,
  title = {Confidence {{Scoring Using Whitebox Meta-Models With Linear Classifier Probes}}},
  booktitle = {{{AISTATS}} 2019 - 22nd {{Int}}. {{Conf}}. {{Artif}}. {{Intell}}. {{Stat}}.},
  author = {Chen, Tongfei and Navr\'atil, Ji\v{r}\'i and Iyengar, Vijay and Shanmugam, Karthikeyan},
  date = {2020},
  abstract = {We propose a novel confidence scoring mechanism for deep neural networks based on a two-model paradigm involving a base model and a meta-model. The confidence score is learned by the meta-model observing the base model succeeding/failing at its task. As features to the meta-model, we investigate linear classifier probes inserted between the various layers of the base model. Our experiments demonstrate that this approach outperforms multiple baselines in a filtering task, i.e., task of rejecting samples with low confidence. Experimental results are presented using CIFAR-10 and CIFAR-100 dataset with and without added noise. We discuss the importance of confidence scoring to bridge the gap between experimental and real-world applications.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@inproceedings{chen_Cotraining_2011,
  title = {Co-{{Training}} for {{Domain Adaptation}}},
  booktitle = {Adv. {{Neural Inf}}. {{Process}}. {{Syst}}. 24 25th {{Annu}}. {{Conf}}. {{Neural Inf}}. {{Process}}. {{Syst}}. 2011 {{NIPS}} 2011},
  author = {Chen, Minmin and Weinberger, Kilian Q. and Blitzer, John C.},
  date = {2011},
  abstract = {Domain adaptation algorithms seek to generalize a model trained in a source domain to a new target domain. In many practical cases, the source and target distributions can differ substantially, and in some cases crucial target features may not have support in the source domain. In this paper we introduce an algorithm that bridges the gap between source and target domains by slowly adding to the training set both the target features and instances in which the current algorithm is the most confident. Our algorithm is a variant of co-training [7], and we name it CODA (Co-training for domain adaptation). Unlike the original co-training work, we do not assume a particular feature split. Instead, for each iteration of cotraining, we formulate a single optimization problem which simultaneously learns a target predictor, a split of the feature space into views, and a subset of source and target features to include in the predictor. CODA significantly out-performs the state-of-the-art on the 12-domain benchmark data set of Blitzer et al. [4]. Indeed, over a wide range (65 of 84 comparisons) of target supervision CODA achieves the best performance.},
  isbn = {978-1-61839-599-3},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{chen_Deep_2019,
  title = {Deep {{Hierarchical Multi-Label Classification}} of {{Chest X-Ray Images}}},
  booktitle = {Proc. 2nd {{Int}}. {{Conf}}. {{Med}}. {{Imaging Deep Learn}}.},
  author = {Chen, Haomin and Miao, Shun and Xu, Daguang and Hager, Gregory D. and Harrison, Adam P.},
  date = {2019-05-24},
  pages = {109--120},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v102/chen19a.html},
  urldate = {2022-12-15},
  abstract = {Chest X-rays (CXRs) are a crucial and extraordinarily common diagnostic tool, leading to heavy research for Computer-Aided Diagnosis (CAD) solutions. However, both high classification accuracy and meaningful model predictions that respect and incorporate clinical taxonomies are crucial for CAD usability. To this end, we present a deep Hierarchical Multi-Label Classification (HMLC) approach for CXR CAD. Different than other hierarchical systems, we show that first training the network to model conditional probability directly and then refining it with unconditional probabilities is key in boosting performance. In addition, we also formulate a numerically stable cross-entropy loss function for unconditional probabilities that provides concrete performance improvements. To the best of our knowledge, we are the first to apply HMLC to medical imaging CAD. We extensively evaluate our approach on detecting 14 abnormality labels from the PLCO dataset, which comprises 198,000 manually annotated CXRs. We report a mean Area Under the Curve (AUC) of 0.887, the highest yet reported for this dataset. These performance improvements, combined with the inherent usefulness of taxonomic predictions, indicate that our approach represents a useful step forward for CXR CAD.},
  eventtitle = {International {{Conference}} on {{Medical Imaging}} with {{Deep Learning}}},
  langid = {english},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found,chest x-ray,computer aided diagnosis,hierarchical multi-label classification},
  file = {/Users/personal-macbook/Zotero/storage/JXC8LR4Q/Chen et al. - 2019 - Deep Hierarchical Multi-label Classification of Ch.pdf;/Users/personal-macbook/Zotero/storage/QHYLKZDF/Chen et al. - 2019 - Deep Hierarchical Multi-label Classification of Ch.pdf;/Users/personal-macbook/Zotero/storage/ECM6MDYN/chen19a.html}
}

@article{chen_Deep_2020,
  title = {Deep {{Hiearchical Multi-Label Classification Applied}} to {{Chest X-Ray Abnormality Taxonomies}}},
  author = {Chen, Haomin and Miao, Shun and Xu, Daguang and Hager, Gregory D. and Harrison, Adam P.},
  date = {2020-12-01},
  journaltitle = {Medical Image Analysis},
  volume = {66},
  pages = {101811},
  issn = {1361-8415},
  doi = {10.1016/j.media.2020.101811},
  url = {https://www.sciencedirect.com/science/article/pii/S1361841520301754},
  urldate = {2022-11-21},
  abstract = {Chest X-rays (CXRs) are a crucial and extraordinarily common diagnostic tool, leading to heavy research for computer-aided diagnosis (CAD) solutions. However, both high classification accuracy and meaningful model predictions that respect and incorporate clinical taxonomies are crucial for CAD usability. To this end, we present a deep hierarchical multi-label classification (HMLC) approach for CXR CAD. Different than other hierarchical systems, we show that first training the network to model conditional probability directly and then refining it with unconditional probabilities is key in boosting performance. In addition, we also formulate a numerically stable cross-entropy loss function for unconditional probabilities that provides concrete performance improvements. Finally, we demonstrate that HMLC can be an effective means to manage missing or incomplete labels. To the best of our knowledge, we are the first to apply HMLC to medical imaging CAD. We extensively evaluate our approach on detecting abnormality labels from the CXR arm of the Prostate, Lung, Colorectal and Ovarian (PLCO) dataset, which comprises over 198,000 manually annotated CXRs. When using complete labels, we report a mean area under the curve (AUC) of 0.887, the highest yet reported for this dataset. These results are supported by ancillary experiments on the PadChest dataset, where we also report significant improvements, 1.2\% and 4.1\% in AUC and average precision, respectively over strong ``flat'' classifiers. Finally, we demonstrate that our HMLC approach can much better handle incompletely labelled data. These performance improvements, combined with the inherent usefulness of taxonomic predictions, indicate that our approach represents a useful step forward for CXR CAD.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Chest X-ray,Computer aided diagnosis,Hierarchical multi-label classification},
  annotation = {15 citations (Semantic Scholar/DOI) [2023-05-08] 11 citations (Crossref) [2022-11-20]},
  file = {/Users/personal-macbook/Zotero/storage/GXM7KQQD/Chen et al. - 2020 - Deep hiearchical multi-label classification applie.pdf;/Users/personal-macbook/Zotero/storage/HV5FK7UW/Chen et al. - 2020 - Deep hiearchical multi-label classification applie.pdf;/Users/personal-macbook/Zotero/storage/MZVHMNLQ/S1361841520301754.html}
}

@article{chen_Domain_2019,
  title = {Domain {{Adversarial Reinforcement Learning}} for {{Partial Domain Adaptation}}},
  author = {Chen, Jin and Wu, Xinxiao and Duan, Lixin and Gao, Shenghua},
  date = {2019-05},
  url = {https://arxiv.org/abs/1905.04094},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found},
  annotation = {22 citations (Semantic Scholar/arXiv) [2023-05-08]}
}

@incollection{chen_EncoderDecoder_2018a,
  ids = {chen_EncoderDecoder_2018},
  title = {Encoder-{{Decoder With Atrous Separable Convolution}} for {{Semantic Image Segmentation}}},
  booktitle = {Computer {{Vision}} \textendash{} {{ECCV}} 2018},
  author = {Chen, Liang-Chieh and Zhu, Yukun and Papandreou, George and Schroff, Florian and Adam, Hartwig},
  editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
  date = {2018},
  volume = {11211},
  pages = {833--851},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-01234-2_49},
  url = {http://link.springer.com/10.1007/978-3-030-01234-2_49},
  urldate = {2022-05-16},
  isbn = {978-3-030-01233-5 978-3-030-01234-2},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/R95WEISC/Chen et al. - 2018 - Encoder-Decoder with Atrous Separable Convolution .pdf}
}

@inproceedings{chen_Hippocampus_2017,
  title = {Hippocampus {{Segmentation Through Multi-View Ensemble ConvNets}}},
  booktitle = {2017 {{IEEE}} 14th {{Int}}. {{Symp}}. {{Biomed}}. {{Imaging ISBI}} 2017},
  author = {Chen, Y. and Shi, B. and Wang, Z. and Zhang, P. and Smith, C. D. and Liu, J.},
  date = {2017-04},
  pages = {192--196},
  abstract = {Automated segmentation of brain structures from MR images is an important practice in many neuroimage studies. In this paper, we explore the utilization of a multi-view ensemble approach that relies on neural networks (NN) to combine multiple decision maps in achieving accurate hippocampus segmentation. Constructed under a general convolutional NN structure, our Ensemble-Net networks explore different convolution configurations to capture the complementary information residing in the multiple label probabilities produced by our U-Seg-Net (a modified U-Net) segmentation neural network. T1-weighted MRI scans and the associated Hippocampal masks of 110 healthy subjects from the ADNI project were used as the training and testing data. The combined U-Seg-Net + Ensemble-Net framework achieves over 89\% Dice ratio on the test dataset.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,ADNI,Alzheimer's Disease,biomedical MRI,brain,Convolutional Neural Networks,diseases,Hippocampal Segmentation,image segmentation,n}
}

@article{chen_Review_2020,
  title = {A {{Review}} of {{Thyroid Gland Segmentation}} and {{Thyroid Nodule Segmentation Methods}} for {{Medical Ultrasound Images}}},
  author = {Chen, Junying and You, Haijun and Li, Kai},
  date = {2020-03-01},
  journaltitle = {Computer Methods and Programs in Biomedicine},
  volume = {185},
  pages = {105329},
  issn = {0169-2607},
  doi = {10.1016/j.cmpb.2020.105329},
  url = {https://www.sciencedirect.com/science/article/pii/S0169260719308454},
  urldate = {2022-05-16},
  abstract = {Background and objective Thyroid image segmentation is an indispensable part in computer-aided diagnosis systems and medical image diagnoses of thyroid diseases. There have been dozens of studies on thyroid gland segmentation and thyroid nodule segmentation in ultrasound images. The aim of this work is to categorize and review the thyroid gland segmentation and thyroid nodule segmentation methods in medical ultrasound. Methods This work proposes a categorization approach of thyroid gland segmentation and thyroid nodule segmentation methods according to the theoretical bases of segmentation methods. The segmentation methods are categorized into four groups, including contour and shape based methods, region based methods, machine and deep learning methods and hybrid methods. The representative articles are reviewed with detailed descriptions of methods and analyses of correlations between methods. The evaluation metrics for the reviewed segmentation methods are named uniformly in this work. The segmentation performance results using the uniformly named evaluation metrics are compared. Results After careful investigation, 28 representative papers are selected for comprehensive analyses and comparisons in this review. The dominant thyroid gland segmentation methods are machine and deep learning methods. The training of massive data makes these models have better segmentation performance and robustness. But deep learning models usually require plenty of marked training data and long training time. For thyroid nodule segmentation, the most common methods are contour and shape based methods, which have good segmentation performance. However, most of them are tested on small datasets. Conclusions Based on the comprehensive consideration of application scenario, image features, method practicability and segmentation performance, the appropriate segmentation method for specific situation can be selected. Furthermore, several limitations of current thyroid ultrasound image segmentation methods are presented, which may be overcome in future studies, such as the segmentation of pathological or abnormal thyroid glands, identification of the specific nodular diseases, and the standard thyroid ultrasound image datasets.},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Gland segmentation method,Nodule segmentation method,Segmentation performance analysis,Thyroid ultrasound image},
  annotation = {46 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/3D4SYHWW/Chen et al. - 2020 - A review of thyroid gland segmentation and thyroid.pdf;/Users/personal-macbook/Zotero/storage/GBIXB975/S0169260719308454.html;/Users/personal-macbook/Zotero/storage/WLMXUZ6H/S0169260719308454.html}
}

@inproceedings{chen_Semanticaware_2018,
  title = {Semantic-{{Aware Generative Adversarial Nets}} for {{Unsupervised Domain Adaptation}} in {{Chest X-Ray Segmentation}}},
  booktitle = {Lect. {{Notes Comput}}. {{Sci}}. {{Subser}}. {{Lect}}. {{Notes Artif}}. {{Intell}}. {{Lect}}. {{Notes Bioinforma}}.},
  author = {Chen, Cheng and Dou, Qi and Chen, Hao and Heng, Pheng Ann},
  date = {2018},
  issn = {16113349},
  doi = {10.1007/978-3-030-00919-9_17},
  abstract = {In spite of the compelling achievements that deep neural networks (DNNs) have made in medical image computing, these deep models often suffer from degraded performance when being applied to new test datasets with domain shift. In this paper, we present a novel unsupervised domain adaptation approach for segmentation tasks by designing semantic-aware generative adversarial networks (GANs). Specifically, we transform the test image into the appearance of source domain, with the semantic structural information being well preserved, which is achieved by imposing a nested adversarial learning in semantic label space. In this way, the segmentation DNN learned from the source domain is able to be directly generalized to the transformed test image, eliminating the need of training a new model for every new target dataset. Our domain adaptation procedure is unsupervised, without using any target domain labels. The adversarial learning of our network is guided by a GAN loss for mapping data distributions, a cycle-consistency loss for retaining pixel-level content, and a semantic-aware loss for enhancing structural information. We validated our method on two different chest X-ray public datasets for left/right lung segmentation. Experimental results show that the segmentation performance of our unsupervised approach is highly competitive with the upper bound of supervised transfer learning.},
  isbn = {978-3-030-00918-2},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{chen_Trinet_2018,
  title = {Tri-{{Net}} for {{Semi-Supervised Deep Learning}}},
  booktitle = {{{IJCAI Int}}. {{Jt}}. {{Conf}}. {{Artif}}. {{Intell}}.},
  author = {Chen, Dong Dong and Wang, Wei and Gao, Wei and Zhou, Zhi Hua},
  date = {2018},
  issn = {10450823},
  doi = {10.24963/ijcai.2018/278},
  abstract = {Deep neural networks have witnessed great successes in various real applications, but it requires a large number of labeled data for training. In this paper, we propose tri-net, a deep neural network which is able to use massive unlabeled data to help learning with limited labeled data. We consider model initialization, diversity augmentation and pseudo-label editing simultaneously. In our work, we utilize output smearing to initialize modules, use fine-tuning on labeled data to augment diversity and eliminate unstable pseudo-labels to alleviate the influence of suspicious pseudo-labeled data. Experiments show that our method achieves the best performance in comparison with state-of-the-art semi-supervised deep learning methods. In particular, it achieves 8.30\% error rate on CIFAR-10 by using only 4000 labeled examples.},
  isbn = {978-0-9992411-2-7},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{chen_VoxResNet_2018,
  title = {{{VoxResNet}}: {{Deep Voxelwise Residual Networks}} for {{Brain Segmentation From 3D MR Images}}},
  shorttitle = {{{VoxResNet}}},
  author = {Chen, Hao and Dou, Qi and Yu, Lequan and Qin, Jing and Heng, Pheng-Ann},
  date = {2018-04},
  journaltitle = {NeuroImage},
  volume = {170},
  pages = {446--455},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2017.04.041},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811917303348},
  urldate = {2023-05-10},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,3D deep learning,Auto-context,Brain segmentation}
}

@article{cheung_Coaching_2015,
  title = {Coaching {{Patients During Pulmonary Function Testing}}: {{A Practical Guide}}},
  author = {Cheung, Heidi J. and Cheung, Lawrence},
  date = {2015},
  journaltitle = {Can. J. Respir. Ther.},
  volume = {51},
  number = {3},
  eprint = {26283871},
  eprinttype = {pmid},
  pages = {65--68},
  issn = {23686820},
  abstract = {Pulmonary function tests are an important tool to assist in the diagnosis and management of patients with respiratory disease. Ensuring that the tests are of acceptable quality is vital. Acceptable pulmonary function test quality requires, among others, optimal patient performance. Optimal patient performance, in turn, requires adequate coaching from registered respiratory therapists (RRTs) and other pulmonary function laboratory personnel. The present article provides techniques and tips to help RRTs coach patients during testing. The authors briefly review the components of pulmonary function testing, then describe factors that may hinder a patient's performance, list common mistakes that patients make during testing, and provide tips that RRTs can use to help patients optimize their performance.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{child_Anterior_2013,
  title = {Anterior {{Nucleus}} of the {{Thalamus}}: {{Functional Organization}} and {{Clinical Implications}}},
  author = {Child, Nicholas D. and Benarroch, Eduardo E.},
  date = {2013-11},
  journaltitle = {Neurology},
  volume = {81},
  number = {21},
  pages = {1869--1876},
  doi = {10.1212/01.wnl.0000436078.95856.56},
  abstract = {The anterior nucleus of thalamus (ANT) is a key component of the hippocampal system for episodic memory. The ANT consist of 3 subnuclei with distinct connectivity with the subicular cortex, retrosplenial cortex, and mammillary bodies. Via its connections with the anterior cingulate and orbitomedial prefrontal cortex, the ANT may also contribute to reciprocal hippocampal-prefrontal interactions involved in emotional and executive functions. As in other thalamic nuclei, neurons of the ANT have 2 different state-dependent patterns of discharge, tonic and burst-firing; some ANT neurons also contribute to propagation of the theta rhythm, which is important for mechanisms of synaptic plasticity of the hippocampal circuit. Clinical and experimental evidence indicate that damage of the ANT or its inputs from the mammillary bodies are primarily responsible for the episodic memory deficit observed in Wernicke-Korsakoff syndrome and thalamic stroke. Experimental models also indicate that the ANT may have a role in the propagation of seizure activity both in absence and in focal seizures. Because of its central connectivity and possible role in propagation of seizure activity, the ANT has become an attractive target for deep brain stimulation (DBS) for treatment of medically refractory epilepsy. The ANT is one of the nuclei preferentially affected in prion disorders, such as fatal familial insomnia, but the relationship between ANT involvement and the clinical manifestations of these disorders remains unclear. The connectivity patterns and electrophysiology of the ANT have been the subject of several reviews.(1-4.)},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {154 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{choi_RETAIN_2016,
  title = {{{RETAIN}}: {{An Interpretable Predictive Model}} for {{Healthcare Using Reverse Time Attention Mechanism}}},
  booktitle = {Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.},
  author = {Choi, Edward and Bahadori, Mohammad Taha and Kulas, Joshua A. and Schuetz, Andy and Stewart, Walter F. and Sun, Jimeng},
  date = {2016},
  issn = {10495258},
  abstract = {Accuracy and interpretability are two dominant features of successful predictive models. Typically, a choice must be made in favor of complex black box models such as recurrent neural networks (RNN) for accuracy versus less accurate but more interpretable traditional models such as logistic regression. This tradeoff poses challenges in medicine where both accuracy and interpretability are important. We addressed this challenge by developing the REverse Time AttentIoN model (RETAIN) for application to Electronic Health Records (EHR) data. RETAIN achieves high accuracy while remaining clinically interpretable and is based on a two-level neural attention model that detects influential past visits and significant clinical variables within those visits (e.g. key diagnoses). RETAIN mimics physician practice by attending the EHR data in a reverse time order so that recent clinical visits are likely to receive higher attention. RETAIN was tested on a large health system EHR dataset with 14 million visits completed by 263K patients over an 8 year period and demonstrated predictive accuracy and computational scalability comparable to state-of-the-art methods such as RNN, and ease of interpretability comparable to traditional models.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@patent{choi_ThermalDepth_2019,
  type = {patentus},
  title = {Thermal-{{Depth Fusion Imaging}}},
  author = {Choi, Min-Hyung and Transue, Shane},
  holder = {{University of Colorado}},
  date = {2020-10-06},
  number = {10796403B2},
  url = {https://patents.google.com/patent/US10796403B2/en?q=(Thermal-Depth+Fusion+Imaging)&oq=Thermal-Depth+Fusion+Imaging},
  urldate = {2023-05-18},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,capture device,depth,fusion,image,thermal},
  file = {/Users/personal-macbook/Zotero/storage/74CHW3EG/Choi and Transue - 2020 - Thermal-depth fusion imaging.pdf}
}

@article{chollet_Deep_2017a,
  title = {Deep {{Learning With Python}}, {{Vol}}. 1},
  author = {Chollet, F.},
  date = {2017},
  journaltitle = {Greenwich CT Manning Publ. CO},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{choudhury_Machine_2018,
  title = {Machine {{Learning}} and {{Human Capital}}: {{Experimental Evidence}} on {{Productivity Complementarities}}},
  author = {Choudhury, Prithwiraj and Starr, Evan and Agarwal, Rajshree},
  date = {2018},
  journaltitle = {SSRN Electron. J.},
  issn = {1556-5068},
  doi = {10.2139/ssrn.3185022},
  abstract = {Machine learning process technologies usher new questions regarding potential complementarity with human capital. We examine productivity differentials between machine learning and older vintage technology based on interactions with two important human capital attributes: domain-specific expertise and vintage-specific human capital. Our experimental setting simulates the US Patent and Trademark Office examination process. We randomize assignment of novice patent examiners to each process technology, and provision of domain-specific expertise. Our analysis of examiner accuracy and speed in patent adjudication reveals, irrespective of process technology, expertise is necessary for identifying prior art that invalidates the patent being examined, and productivity in the machine learning process technology requires computer science and engineering (CS\&E) skills. We discuss implications for artificial intelligence and strategic management of the pace of technological substitution.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {64 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{chromy_3D_2017,
  title = {A {{3D Scan Model}} and {{Thermal Image Data Fusion Algorithms}} for {{3D Thermography}} in {{Medicine}}},
  author = {Chromy, Adam and Klima, Ondrej},
  date = {2017},
  journaltitle = {Journal of Healthcare Engineering},
  volume = {2017},
  pages = {1--9},
  issn = {2040-2295, 2040-2309},
  doi = {10.1155/2017/5134021},
  url = {https://www.hindawi.com/journals/jhe/2017/5134021/},
  urldate = {2023-05-08},
  abstract = {Objectives               . At present, medical thermal imaging is still considered a mere qualitative tool enabling us to distinguish between but lacking the ability to quantify the physiological and nonphysiological states of the body. Such a capability would, however, facilitate solving the problem of medical quantification, whose presence currently manifests itself within the entire healthcare system.               Methods               . A generally applicable method to enhance captured 3D spatial data carrying temperature-related information is presented; in this context, all equations required for other data fusions are derived. The method can be utilized for high-density point clouds or detailed meshes at a high resolution but is conveniently usable in large objects with sparse points.               Results               . The benefits of the approach are experimentally demonstrated on 3D thermal scans of injured subjects. We obtained diagnostic information inaccessible via traditional methods.               Conclusion               . Using a 3D model and thermal image data fusion allows the quantification of inflammation, facilitating more precise injury and illness diagnostics or monitoring. The technique offers a wide application potential in medicine and multiple technological domains, including electrical and mechanical engineering.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {11 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/DX7V9C53/Chromy and Klima - 2017 - A 3D Scan Model and Thermal Image Data Fusion Algo.pdf}
}

@article{chromy_Robotic_2014,
  title = {Robotic {{3D Scanner}} as an {{Alternative}} to {{Standard Modalities}} of {{Medical Imaging}}},
  author = {Chromy, Adam and Zalud, Ludek},
  date = {2014-01},
  journaltitle = {SpringerPlus},
  volume = {3},
  number = {1},
  pages = {1--10},
  publisher = {{SpringerOpen}},
  issn = {21931801},
  doi = {10.1186/2193-1801-3-13},
  abstract = {There are special medical cases, where standard medical imaging modalities are able to offer sufficient results, but not in the optimal way. It means, that desired results are produced with unnecessarily high expenses, with redundant informations or with needless demands on patient. This paper deals with one special case, where information useful for examination is the body surface only, inner sight into the body is needless. New specialized medical imaging device is developed for this situation. In the Introduction section, analysis of presently used medical imaging modalities is presented, which declares, that no available imaging device is best fitting for mentioned purposes. In the next section, development of the new specialized medical imaging device is presented, and its principles and functions are described. Then, the parameters of new device are compared with present ones. It brings significant advantages comparing to present imaging systems. \textcopyright{} 2014 Chromy and Zalud.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,3D model of human body,3D scanner,Medical imaging,MRI alternative}
}

@article{chung_Deep_2018,
  title = {Deep {{Mixed Effect Model Using Gaussian Processes}}: {{A Personalized}} and {{Reliable Prediction}} for {{Healthcare}}},
  author = {Chung, Ingyo and Kim, Saehoon and Lee, Juho and Kim, Kwang Joon and Hwang, Sung Ju and Yang, Eunho},
  date = {2018-06},
  url = {http://arxiv.org/abs/1806.01551},
  abstract = {We present a personalized and reliable prediction model for healthcare, which can provide individually tailored medical services such as diagnosis, disease treatment, and prevention. Our proposed framework targets at making personalized and reliable predictions from time-series data, such as Electronic Health Records (EHR), by modeling two complementary components: i) a shared component that captures global trend across diverse patients and ii) a patient-specific component that models idiosyncratic variability for each patient. To this end, we propose a composite model of a deep neural network to learn complex global trends from the large number of patients, and Gaussian Processes (GP) to probabilistically model individual time-series given relatively small number of visits per patient. We evaluate our model on diverse and heterogeneous tasks from EHR datasets and show practical advantages over standard time-series deep models such as pure Recurrent Neural Network (RNN).},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found},
  annotation = {12 citations (Semantic Scholar/arXiv) [2023-05-08]}
}

@article{ciofolo_Brain_2005,
  title = {Brain {{Segmentation With Competitive Level Sets}} and {{Fuzzy Control}}},
  author = {Ciofolo, Cyb\`ele and Barillot, Christian},
  date = {2005},
  journaltitle = {Inf. Process. Med. Imaging},
  volume = {19},
  pages = {333--344},
  abstract = {We propose to segment 3D structures with competitive level sets driven by fuzzy control. To this end, several contours evolve simultaneously toward previously defined anatomical targets. A fuzzy decision system combines the a priori knowledge provided by an anatomical atlas with the intensity distribution of the image and the relative position of the contours. This combination automatically determines the directional term of the evolution equation of each level set. This leads to a local expansion or contraction of the contours, in order to match the borders of their respective targets. Two applications are presented: the segmentation of the brain hemispheres and the cerebellum, and the segmentation of deep internal structures. Experimental results on real MR images are presented, quantitatively assessed and discussed.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{clarke_Sweat_1991,
  title = {Sweat {{Testing}} to {{Identify Female Carriers}} of {{X Linked Hypohidrotic Ectodermal Dysplasia}}},
  author = {Clarke, A. and Burn, J.},
  date = {1991},
  journaltitle = {J. Med. Genet.},
  issn = {00222593},
  doi = {10.1136/jmg.28.5.330},
  abstract = {X linked hypohidrotic ectodermal dysplasia (XHED) affects many epithelial functions, including sweat gland formation. Female carriers who manifest XHED may have defective dentition or a patchy distribution of sweating or both, as determined by starch and iodine sweat testing. Such sweat testing can be useful in assigning carrier status to at risk females in XHED families, and in obtaining an accurate diagnosis for isolated females who present with features of ectodermal dysplasia. The advantages of diagnosing female carriers of XHED include the optimisation of neonatal and paediatric care for affected male infants, who may be at substantial risk of death in infancy.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{cohen_TorchXRayVision_2022,
  title = {{{TorchXRayVision}}: {{A Library}} of {{Chest X-Ray Datasets}} and {{Models}}},
  shorttitle = {{{TorchXRayVision}}},
  booktitle = {Proc. 5th {{Int}}. {{Conf}}. {{Med}}. {{Imaging Deep Learn}}.},
  author = {Cohen, Joseph Paul and Viviano, Joseph D. and Bertin, Paul and Morrison, Paul and Torabian, Parsa and Guarrera, Matteo and Lungren, Matthew P. and Chaudhari, Akshay and Brooks, Rupert and Hashir, Mohammad and Bertrand, Hadrien},
  date = {2022-12-04},
  pages = {231--249},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v172/cohen22a.html},
  urldate = {2023-04-12},
  abstract = {TorchXRayVision is an open source software library for working with chest X-ray datasets and deep learning models. It provides a common interface and common pre-processing chain for a wide set of publicly available chest X-ray datasets. In addition, a number of classification and representation learning models with different architectures, trained on different data combinations, are available through the library to serve as baselines or feature extractors.},
  eventtitle = {International {{Conference}} on {{Medical Imaging}} with {{Deep Learning}}},
  langid = {english},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/CUAZ5X8U/Cohen et al. - 2022 - TorchXRayVision A library of chest X-ray datasets.pdf;/Users/personal-macbook/Zotero/storage/ICDMYRL3/cohen22a.html}
}

@article{collins_Accurate_2010,
  title = {Towards {{Accurate}}, {{Automatic Segmentation}} of the {{Hippocampus}} and {{Amygdala From MRI}} by {{Augmenting ANIMAL With}} a {{Template Library}} and {{Label Fusion}}},
  author = {Collins, D. Louis and Pruessner, Jens C.},
  date = {2010-10},
  journaltitle = {Neuroimage},
  volume = {52},
  number = {4},
  pages = {1355--1366},
  doi = {10.1016/j.neuroimage.2010.04.193},
  abstract = {We describe progress towards fully automatic segmentation of the hippocampus (HC) and amygdala (AG) in human subjects from MRI data. Three methods are described and tested with a set of MRIs from 80 young normal controls, using manual labeling of the HC and AG as a gold standard. The methods include: 1) our ANIMAL atlas-based method that uses non-linear registration to a pre-labeled non-linear average template (ICBM152). HC and AG labels, defined on the template are mapped through the inverse transformation to segment these structures on the subject's MRI. 2) We select the most similar MRI from the set of 80 labeled datasets to use as a template in the standard ANIMAL segmentation scheme. 3) We use label fusion techniques to combine segmentations from the 'n' most similar templates. The label fusion technique yields an optimal median Dice Kappa of 0.886 and similarity of 0.795 for HC, and 0.826 and 0.703 respectively for AG.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{commowick_Objective_2018,
  title = {Objective {{Evaluation}} of {{Multiple Sclerosis Lesion Segmentation Using}} a {{Data Management}} and {{Processing Infrastructure}}},
  author = {Commowick, Olivier and Istace, Audrey and Kain, Micha\"el and Laurent, Baptiste and Leray, Florent and Simon, Mathieu and Pop, Sorina Camarasu and Girard, Pascal and Am\'eli, Roxana and Ferr\'e, Jean-Christophe and Kerbrat, Anne and Tourdias, Thomas and Cervenansky, Fr\'ed\'eric and Glatard, Tristan and Beaumont, J\'er\'emy and Doyle, Senan and Forbes, Florence and Knight, Jesse and Khademi, April and Mahbod, Amirreza and Wang, Chunliang and McKinley, Richard and Wagner, Franca and Muschelli, John and Sweeney, Elizabeth and Roura, Eloy and Llad\'o, Xavier and Santos, Michel M. and Santos, Wellington P. and Silva-Filho, Abel G. and Tomas-Fernandez, Xavier and Urien, H\'el\`ene and Bloch, Isabelle and Valverde, Sergi and Cabezas, Mariano and Vera-Olmos, Francisco Javier and Malpica, Norberto and Guttmann, Charles and Vukusic, Sandra and Edan, Gilles and Dojat, Michel and Styner, Martin and Warfield, Simon K. and Cotton, Fran\c{c}ois and Barillot, Christian},
  date = {2018-09-12},
  journaltitle = {Sci Rep},
  volume = {8},
  number = {1},
  pages = {13650},
  issn = {2045-2322},
  doi = {10.1038/s41598-018-31911-7},
  url = {https://www.nature.com/articles/s41598-018-31911-7},
  urldate = {2023-01-27},
  abstract = {Abstract             We present a study of multiple sclerosis segmentation algorithms conducted at the international MICCAI 2016 challenge. This challenge was operated using a new open-science computing infrastructure. This allowed for the automatic and independent evaluation of a large range of algorithms in a fair and completely automatic manner. This computing infrastructure was used to evaluate thirteen methods of MS lesions segmentation, exploring a broad range of state-of-theart algorithms, against a high-quality database of 53 MS cases coming from four centers following a common definition of the acquisition protocol. Each case was annotated manually by an unprecedented number of seven different experts. Results of the challenge highlighted that automatic algorithms, including the recent machine learning methods (random forests, deep learning, \ldots ), are still trailing human expertise on both detection and delineation criteria. In addition, we demonstrate that computing a statistically robust consensus of the algorithms performs closer to human expertise on one score (segmentation) although still trailing on detection scores.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {53 citations (Semantic Scholar/DOI) [2023-01-26]},
  file = {/Users/personal-macbook/Zotero/storage/R73BEVYV/Commowick et al. - 2018 - Objective Evaluation of Multiple Sclerosis Lesion .pdf}
}

@article{convit_Specific_1997,
  title = {Specific {{Hippocampal Volume Reductions}} in {{Individuals}} at {{Risk}} for {{Alzheimer}}'s {{Disease}}},
  author = {Convit, A. and Leon, M. J. De and Tarshish, C. and Santi, S. De and Tsui, W. and Rusinek, H. and George, A.},
  date = {1997-03},
  journaltitle = {Neurobiol. Aging},
  volume = {18},
  number = {2},
  pages = {131--138},
  doi = {10.1016/S0197-4580(97)00001-8},
  abstract = {Our goal was to ascertain the involvement of the temporal lobe in the preclinical (not yet diagnosable) stages of dementia of the Alzheimer's type (DAT) by using MRI-derived volumes. We assessed anatomical subdivisions of the temporal lobe on three groups of carefully screened age- and education-matched elderly individuals: 27 normal elderly (NL), 22 individuals with minimal cognitive impairment (MCI), who did not fulfill DAT criteria but were regarded at high risk for future DAT, and 27 DAT individuals. We found hippocampal volume reductions of 14\% for the MCI and 22\% for the DAT group compared to the NL group. Utilizing regression analyses and after accounting for gender, head size, age, generalized atrophy (CSF), and other temporal lobe subvolumes, the hippocampal volume separated NL from MCI individuals, correctly classifying 74\%. For NL and MCI groups combined the hippocampal volume was the only temporal lobe subvolume related to delayed recall memory performance. When contrasting MCI and DAT individuals, the fusiform gyrus volume uniquely improved the ability of the hippocampal volume to separate MCI from DAT individuals from 74 to 80\%. Our cross-sectional data suggest that, within the temporal lobe, specific hippocampal volume reductions separated the group at risk for DAT from the normal group. By the time impairments are sufficient to allow a diagnosis of DAT to be made, in addition to the medial temporal lobe volume reductions, the lateral temporal lobe is also showing volume reductions, most saliently involving the fusiform gyrus.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Fusiform gyrus,Hippocampal volume,Minimal cognit}
}

@article{conway_Editorial_1975,
  title = {Editorial: "{{Old Lamps}} for {{New}}"},
  shorttitle = {Editorial},
  author = {Conway, C. M.},
  date = {1975-08},
  journaltitle = {Br J Anaesth},
  volume = {47},
  number = {8},
  eprint = {27},
  eprinttype = {pmid},
  pages = {811--812},
  issn = {0007-0912},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,{Anesthesia, Inhalation},{Arrhythmias, Cardiac},Enflurane,Ethers,Halothane,Humans,Isoflurane,Kidney Diseases,Methoxyflurane,Trichloroethylene,Trifluoroethanol}
}

@article{cook_Camino_2006,
  title = {Camino: {{Open-Source Diffusion-Mri Reconstruction}} and {{Processing}}},
  author = {Cook, P. A. and Bai, Y. and Nedjati-Gilani, S. and others},
  date = {2006},
  journaltitle = {14th Sci. Meet.},
  publisher = {{cs.ucl.ac.uk}},
  abstract = {Design Camino is written in Java, and designed for a Unix-style interface. The user documentation is in the form of Unix manual pages, and each program has a shell wrapper, so users do not require any knowledge of Java. The data pipeline provides flexibility, by allowing data to be imported and exported to other software, and transparency, because the output of each Camino program can be analyzed in detail. Fig. 1 illustrates the pipeline. Camino processes all data in voxel order, where the measurements for each voxel are \dbend},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@thesis{corbett-davies_Identifying_2018,
  title = {Identifying {{Bias}} in {{Human}} and {{Machine Decisions}}},
  author = {Corbett-Davies, Samuel James},
  date = {2018},
  journaltitle = {Stanford},
  institution = {{STANFORD}},
  issue = {December},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{cordonnier_Spontaneous_2007,
  title = {Spontaneous {{Brain Microbleeds}}: {{Systematic Review}}, {{Subgroup Analyses}} and {{Standards}} for {{Study Design}} and {{Reporting}}},
  author = {Cordonnier, Charlotte and Salman, Rustam Al-Shahi and Wardlaw, Joanna},
  date = {2007-08},
  journaltitle = {Brain},
  volume = {130},
  pages = {1988--2003},
  abstract = {Brain microbleeds (BMBs) are seen as small, homogeneous, round foci of low signal intensity on magnetic resonance imaging gradient echo (GRE) T2 sequences. BMBs might only be a biomarker for microangiopathy, or alternatively BMBs might provide useful diagnostic and prognostic information, potentially with therapeutic implications for the treatment of stroke. Because of the rapid expansion in recent BMB research, we systematically reviewed and critically appraised the published literature according to QUADAS, STARD and Cochrane principles. Our selection criteria were met by 54 studies of 53 case series involving 9073 participants, 4432 of whom were people with cerebrovascular diseases. There were significant biases in many of the studies: variation in MRI magnet strength, flip angle, slice gap and slice thickness; inconsistent definitions of BMB size (23\% did not define size at all, and of those that did 44\% chose a diameter of {$<$} or =5 mm); only 30\% included participants who were representative of the disease under study; and only 53\% mentioned that BMB evaluation was blinded to other factors of interest. By pooling data from similar studies, we found that the prevalence of BMBs was 5\% [95\% confidence interval (CI) 4-6] in healthy adults, 34\% (95\% CI 31-36) in people with ischaemic stroke, and 60\% (95\% CI 57-64) in people with non-traumatic intracerebral haemorrhage (ICH). In the studies where a distinction could be made, BMBs were more prevalent among recurrent strokes than first-ever strokes: they affected 23\% (95\% CI 18-29) with first-ever ischaemic stroke but 44\% (95\% CI 34-54) with recurrent ischaemic stroke, and 52\% (95\% CI 47-56) with first-ever ICH but 83\% (95\% CI 71-90) with recurrent ICH. By pooling data that could be extracted from similar studies, it appears that BMBs are associated with hypertension (OR 3.9, 95\% CI 2.4-6.4) and diabetes mellitus (OR 2.2, 95\% CI 1.2-4.2) in otherwise healthy adults, and that they are associated with hypertension (OR 2.3, 95\% CI 1.7-3.0) in adults with cerebrovascular diseases. The association with hypertension was robust in sensitivity analyses. There is a pressing need for better designed studies to assess the diagnostic utility of BMBs, disentangle the many likely influences on their occurrence, and determine their prognostic utility and whether they should influence treatment. We conclude by proposing criteria for ideal study design and reporting.},
  issue = {Pt 8},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{correll_Thin_2007,
  title = {Across the {{Thin Blue Line}}: {{Police Officers}} and {{Racial Bias}} in the {{Decision}} to {{Shoot}}},
  author = {Correll, Joshua and Park, Bernadette and Judd, Charles M. and Wittenbrink, Bernd and Sadler, Melody S. and Keesee, Tracie},
  date = {2007},
  journaltitle = {J. Pers. Soc. Psychol.},
  eprint = {17547485},
  eprinttype = {pmid},
  issn = {00223514},
  doi = {10.1037/0022-3514.92.6.1006},
  abstract = {Police officers were compared with community members in terms of the speed and accuracy with which they made simulated decisions to shoot (or not shoot) Black and White targets. Both samples exhibited robust racial bias in response speed. Officers outperformed community members on a number of measures, including overall speed and accuracy. Moreover, although community respondents set the decision criterion lower for Black targets than for White targets (indicating bias), police officers did not. The authors suggest that training may not affect the speed with which stereotype-incongruent targets are processed but that it does affect the ultimate decision (particularly the placement of the decision criterion). Findings from a study in which a college sample received training support this conclusion. \textcopyright{} 2007 American Psychological Association.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,bias,police,race,training,weapon},
  annotation = {599 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{coscia_Volumetric_2009,
  title = {Volumetric and {{Shape Analysis}} of the {{Thalamus}} in {{First-Episode Schizophrenia}}},
  author = {Coscia, Denise M. and Narr, Katherine L. and Robinson, Delbert G. and Hamilton, Liberty S. and Sevy, Serge and Burdick, Katherine E. and Gunduz-Bruce, Handan and McCormack, Joanne and Bilder, Robert M. and Szeszko, Philip R.},
  date = {2009-04},
  journaltitle = {Hum. Brain Mapp.},
  volume = {30},
  number = {4},
  pages = {1236--1245},
  doi = {10.1002/hbm.20595},
  abstract = {Thalamic abnormalities have been implicated in the pathogenesis of schizophrenia, although the majority of studies used chronic samples treated extensively with antipsychotics. Moreover, the clinical and neuropsychological correlates of these abnormalities remain largely unknown. Using high-resolution MR imaging and novel methods for shape analysis, we investigated thalamic subregions in 35 (25 M/10 F) first-episode schizophrenia patients compared with 33 (23 M/10 F) healthy volunteers. The right and left thalami were traced bilaterally on coronal brain slices and volumes were compared between groups. In addition, regional abnormalities were identified by comparing distances, measured from homologous thalamic surface points to the central core of each individual's surface model, between groups in 3D space. Patients had significantly less total thalamic volume compared with healthy volunteers. Statistical mapping demonstrated most pronounced shape abnormalities in the pulvinar; however, estimated false discovery rates in these regions were sizable. Smaller thalamus volume was significantly correlated with worse overall neuropsychological functioning and specific deficits were observed in the language, motor, and executive domains. There were no significant associations between thalamus volume and positive or negative symptoms. Our findings suggest that thalamic abnormalities are evident at the onset of a first episode of schizophrenia prior to extensive pharmacologic intervention and that these abnormalities have neuropsychological correlates.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{coupe_Patchbased_2011,
  title = {Patch-{{Based Segmentation Using Expert Priors}}: {{Application}} to {{Hippocampus}} and {{Ventricle Segmentation}}},
  author = {Coup\'e, Pierrick and Manj\'on, Jos\'e V. and Fonov, Vladimir and Pruessner, Jens and Robles, Montserrat and Collins, D. Louis},
  date = {2011-01},
  journaltitle = {Neuroimage},
  volume = {54},
  number = {2},
  pages = {940--954},
  doi = {10.1016/j.neuroimage.2010.09.018},
  abstract = {Quantitative magnetic resonance analysis often requires accurate, robust, and reliable automatic extraction of anatomical structures. Recently, template-warping methods incorporating a label fusion strategy have demonstrated high accuracy in segmenting cerebral structures. In this study, we propose a novel patch-based method using expert manual segmentations as priors to achieve this task. Inspired by recent work in image denoising, the proposed nonlocal patch-based label fusion produces accurate and robust segmentation. Validation with two different datasets is presented. In our experiments, the hippocampi of 80 healthy subjects and the lateral ventricles of 80 patients with Alzheimer's disease were segmented. The influence on segmentation accuracy of different parameters such as patch size and number of training subjects was also studied. A comparison with an appearance-based method and a template-based method was also carried out. The highest median kappa index values obtained with the proposed method were 0.884 for hippocampus segmentation and 0.959 for lateral ventricle segmentation.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{courtland_Bias_2018,
  title = {Bias {{Detectives}}: {{The Researchers Striving}} to {{Make Algorithms Fair News-Feature}}},
  author = {Courtland, Rachel},
  date = {2018},
  journaltitle = {Nature},
  eprint = {29925973},
  eprinttype = {pmid},
  issn = {14764687},
  doi = {10.1038/d41586-018-05469-3},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Computer science,Society,Technology},
  annotation = {113 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{crisp_Child_2004,
  title = {Child {{Protection}} and {{Public Health}}: {{Nurses}}' {{Responsibilities}}},
  shorttitle = {Child Protection and Public Health},
  author = {Crisp, Beth R. and Lister, Pam Green},
  date = {2004-09},
  journaltitle = {J Adv Nurs},
  volume = {47},
  number = {6},
  eprint = {15324435},
  eprinttype = {pmid},
  pages = {656--663},
  issn = {0309-2402},
  doi = {10.1111/j.1365-2648.2004.03154.x},
  abstract = {BACKGROUND: Health care workers have been recognized as having a key role in the protection and care of Scotland's children, particularly in respect of identification and detection of child abuse. Nurses, especially health visitors, are often the first professionals to suspect that child abuse has taken place. While previous research has found that health visitors have primarily perceived their role as that of providing support and advice to vulnerable families, there are pressures on them to fulfil a more narrow surveillance role. Concurrent with a lack of clarity about the role of health visitors in child protection, there has been increasing recognition that other nurses can also make an important contribution, including those who do not work directly with children. AIMS: The aim of the study was to explore nurses' understanding of their professional responsibilities in relation to child protection, and the potential for nurses to be involved in the protection of children from abuse. METHODS: A qualitative interview-based design was used, and 99 nurses working in an National Health Service trust in a Scottish city were interviewed, either individually or in groups, about their professional involvements in child protection issues. Interview data were subjected to thematic analysis. FINDINGS: There was lack of consensus among interviewees about the nursing remit in child protection issues, particularly with respect to the extent to which nurses should actively seek to detect cases of child abuse. An emphasis on identification and detection was not easily accepted by many nurses, and was perceived by some to be a change from their more traditional role of supporting families, as well as being potentially in conflict with some public health responsibilities. CONCLUSION: In spite of the perception of some nurses that there is a sharp divide between child protection work and public health interventions, many of the child protection roles identified by nurses, such as supporting families, parenting education and service development, are clearly within the ambit of contemporary notions of public health. Furthermore, it is clear that there is a role in child protection for a much wider group of nurses than health visitors.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Child,Child Abuse,Child Welfare,Community Health Nursing,Humans,Nurse's Role,Public Health Nursing,Scotland},
  annotation = {50 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{crisp_Global_2014,
  title = {Global {{Supply}} of {{Health Professionals}}},
  author = {Crisp, Nigel and Chen, Lincoln},
  date = {2014-03-06},
  journaltitle = {N Engl J Med},
  volume = {370},
  number = {10},
  pages = {950--957},
  issn = {0028-4793, 1533-4406},
  doi = {10.1056/NEJMra1111610},
  url = {http://www.nejm.org/doi/10.1056/NEJMra1111610},
  urldate = {2022-11-21},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Clinical Competence,{Education, Distance},{Education, Professional},Global Health,Health Occupations,Health Workforce,Nurses,Physicians},
  annotation = {152 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/HW2UAABI/NEJMra1111610.html}
}

@article{critchley_Cerebral_2000,
  title = {Cerebral {{Correlates}} of {{Autonomic Cardiovascular Arousal}}: {{A Functional Neuroimaging Investigation}} in {{Humans}}},
  author = {Critchley, H. D. and Corfield, D. R. and Chandler, M. P. and Mathias, C. J. and Dolan, R. J.},
  date = {2000},
  journaltitle = {J. Physiol.},
  eprint = {10673560},
  eprinttype = {pmid},
  issn = {00223751},
  doi = {10.1111/j.1469-7793.2000.t01-1-00259.x},
  abstract = {1. States of peripheral autonomic arousal accompany emotional behaviour, physical exercise and cognitive effort, and their central representation may influence decision making and the regulation of social and emotional behaviours. However, the cerebral functional neuroanatomy representing and mediating peripheral autonomic responses in humans is poorly understood. 2. Six healthy volunteer subjects underwent H215O positron emission tomography (PET) scanning while performing isometric exercise and mental arithmetic stressor tasks, and during corresponding control tasks. Mean arterial blood pressure (MAP) and heart rate (HR) were monitored during scanning. 3. Data were analysed using statistical parametric mapping (SPM99). Conjunction analyses were used to determine significant changes in regional cerebral blood flow (rCBF) during states of cardiovascular arousal common to both exercise and mental stressor tasks. 4. Exercise and mental stressor tasks, relative to their control tasks, were associated with significantly (P {$<$} 0.001) increased MAP and HR. Significant common activations (increased rCBF) were observed in cerebellar vermis, brainstem and right anterior cingulate. In both exercise and mental stress tasks, increased rCBF in cerebellar vermis, right anterior cingulate and right insula covaried with MAP; rCBF in pons, cerebellum and right insula covaried with HR. Cardiovascular arousal in both categorical and covariance analyses was associated with decreased rCBF in prefrontal and medial temporal regions. 5. Neural responses in discrete brain regions accompany peripheral cardiovascular arousal. We provide evidence for the involvement of areas previously implicated in cognitive and emotional behaviours in the representation of peripheral autonomic states, consistent with a functional organization that produces integrated cardiovascular response patterns in the service of volitional and emotional behaviours.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {758 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@software{crowdkit_webpage_documentation,
  title = {Crowd-{{Kit Documentation}}},
  shorttitle = {Crowd-{{Kit}}},
  author = {Toloka-AI},
  date = {2023},
  url = {https://toloka.ai/docs/crowd-kit},
  urldate = {2023-07-04},
  abstract = {Toloka combines cutting-edge technologies with the power of the crowd to deliver high-performing data in record time. Exceptional speed, quality and scalability.},
  organization = {{Toloka AI}}
}

@article{crum_Generalized_2006,
  title = {Generalized {{Overlap Measures}} for {{Evaluation}} and {{Validation}} in {{Medical Image Analysis}}},
  author = {Crum, W.R. and Camara, O. and Hill, D.L.G.},
  date = {2006-11},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {25},
  number = {11},
  pages = {1451--1461},
  issn = {0278-0062, 1558-254X},
  doi = {10.1109/TMI.2006.880587},
  url = {http://ieeexplore.ieee.org/document/1717643/},
  urldate = {2023-05-29},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Fuzzy sets,Hausdorff distance,Morphological operations,Registration,Segmentation,Validation},
  annotation = {625 citations (Semantic Scholar/DOI) [2023-05-28]}
}

@inproceedings{cui_Brain_2016,
  title = {Brain {{MRI Segmentation With Patch-Based CNN Approach}}},
  booktitle = {2016 35th {{Chin}}. {{Control Conf}}. {{CCC}}},
  author = {Cui, Z. and Yang, J. and Qiao, Y.},
  date = {2016-07},
  pages = {7026--7031},
  abstract = {Brain Magnetic Resonance Image (MRI) plays a non-substitutive role in clinical diagnosis. The symptom of many diseases corresponds to the structural variants of brain. Automatic structure segmentation in brain MRI is of great importance in modern medical research. Some methods were developed for automatic segmenting of brain MRI but failed to achieve desired accuracy. In this paper, we proposed a new patch-based approach for automatic segmentation of brain MRI using convolutional neural network (CNN). Each brain MRI acquired from a small portion of public dataset is firstly divided into patches. All of these patches are then used for training CNN, which is used for automatic segmentation of brain MRI. Experimental results showed that our approach achieved better segmentation accuracy compared with other deep learning methods.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,biomedical MRI,brain,diseases,image segmentation,l}
}

@article{dadashazar_Stratocumulus_2020,
  title = {Stratocumulus {{Cloud Clearings}}: {{Statistics From Satellites}}, {{Reanalysis Models}}, and {{Airborne Measurements}}},
  author = {Dadashazar, Hossein and Crosbie, Ewan and Majdi, Mohammad S. and Panahi, Milad and Moghaddam, Mohammad A. and Behrangi, Ali and Brunke, Michael and Zeng, Xubin and Jonsson, Haflidi H. and Sorooshian, Armin},
  date = {2020},
  journaltitle = {Atmospheric Chem. Phys.},
  issn = {16807324},
  doi = {10.5194/acp-20-4637-2020},
  abstract = {This study provides a detailed characterization of stratocumulus clearings off the US West Coast using remote sensing, reanalysis, and airborne in situ data. Ten years (2009 2018) of Geostationary Operational Environmental Satellite (GOES) imagery data are used to quantify the monthly frequency, growth rate of total area (GRArea), and dimensional characteristics of 306 total clearings. While there is interannual variability, the summer (winter) months experienced the most (least) clearing events, with the lowest cloud fractions being in close proximity to coastal topographical features along the central to northern coast of California, including especially just south of Cape Mendocino and Cape Blanco. From 09:00 to 18:00 (PST), the median length, width, and area of clearings increased from 680 to 1231, 193 to 443, and 67000 to 250000 km2, respectively. Machine learning was applied to identify the most influential factors governing the GRArea of clearings between 09:00 and 12:00 PST, which is the time frame of most rapid clearing expansion. The results from gradient-boosted regression tree (GBRT) modeling revealed that air temperature at 850 hPa (T850), specific humidity at 950 hPa (q950), sea surface temperature (SST), and anomaly in mean sea level pressure (MSLPanom) were probably most impactful in enhancing GRArea using two scoring schemes. Clearings have distinguishing features such as an enhanced Pacific high shifted more towards northern California, offshore air that is warm and dry, stronger coastal surface winds, enhanced lower-tropospheric static stability, and increased subsidence. Although clearings are associated obviously with reduced cloud fraction where they reside, the domain-averaged cloud albedo was actually slightly higher on clearing days as compared to non-clearing days. To validate speculated processes linking environmental parameters to clearing growth rates based on satellite and reanalysis data, airborne data from three case flights were examined. Measurements were compared on both sides of the clear cloudy border of clearings at multiple altitudes in the boundary layer and free troposphere, with results helping to support links suggested by this study s model simulations. More specifically, airborne data revealed the influence of the coastal low-level jet and extensive horizontal shear at cloud-relevant altitudes that promoted mixing between clear and cloudy air. Vertical profile data provide support for warm and dry air in the free troposphere, additionally promoting expansion of clearings. Airborne data revealed greater evidence of sea salt in clouds on clearing days, pointing to a possible role for, or simply the presence of, this aerosol type in clearing areas coincident with stronger coastal winds.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{dai_Good_2017,
  title = {Good {{Semi-Supervised Learning That Requires}} a {{Bad GAN}}},
  booktitle = {Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.},
  author = {Dai, Zihang and Yang, Zhilin and Yang, Fan and Cohen, William W. and Salakhutdinov, Ruslan},
  date = {2017},
  issn = {10495258},
  abstract = {Semi-supervised learning methods based on generative adversarial networks (GANs) obtained strong empirical results, but it is not clear 1) how the discriminator benefits from joint training with a generator, and 2) why good semi-supervised classification performance and a good generator cannot be obtained at the same time. Theoretically we show that given the discriminator objective, good semi-supervised learning indeed requires a bad generator, and propose the definition of a preferred generator. Empirically, we derive a novel formulation based on our analysis that substantially improves over feature matching GANs, obtaining state-of-the-art results on multiple benchmark datasets2.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{dalca_Unsupervised_2019,
  title = {Unsupervised {{Learning}} of {{Probabilistic Diffeomorphic Registration}} for {{Images}} and {{Surfaces}}},
  author = {Dalca, Adrian V. and Balakrishnan, Guha and Guttag, John and Sabuncu, Mert R.},
  date = {2019-10},
  journaltitle = {Med. Image Anal.},
  volume = {57},
  pages = {226--236},
  doi = {10.1016/j.media.2019.07.006},
  abstract = {Classical deformable registration techniques achieve impressive results and offer a rigorous theoretical treatment, but are computationally intensive since they solve an optimization problem for each image pair. Recently, learning-based methods have facilitated fast registration by learning spatial deformation functions. However, these approaches use restricted deformation models, require supervised labels, or do not guarantee a diffeomorphic (topology-preserving) registration. Furthermore, learning-based registration tools have not been derived from a probabilistic framework that can offer uncertainty estimates. In this paper, we build a connection between classical and learning-based methods. We present a probabilistic generative model and derive an unsupervised learning-based inference algorithm that uses insights from classical registration methods and makes use of recent developments in convolutional neural networks (CNNs). We demonstrate our method on a 3D brain registration task for both images and anatomical surfaces, and provide extensive empirical analyses of the algorithm. Our principled approach results in state of the art accuracy and very fast runtimes, while providing diffeomorphic guarantees. Our implementation is available online at http://voxelmorph.csail.mit.edu.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Convolutional neural networks,Diffeomorphic regis}
}

@article{dale_Cortical_1999,
  title = {Cortical {{Surface-Based Analysis}}. {{I}}. {{Segmentation}} and {{Surface Reconstruction}}},
  author = {Dale, A. M. and Fischl, B. and Sereno, M. I.},
  date = {1999-02},
  journaltitle = {Neuroimage},
  volume = {9},
  number = {2},
  pages = {179--194},
  doi = {10.1006/nimg.1998.0395},
  abstract = {Several properties of the cerebral cortex, including its columnar and laminar organization, as well as the topographic organization of cortical areas, can only be properly understood in the context of the intrinsic two-dimensional structure of the cortical surface. In order to study such cortical properties in humans, it is necessary to obtain an accurate and explicit representation of the cortical surface in individual subjects. Here we describe a set of automated procedures for obtaining accurate reconstructions of the cortical surface, which have been applied to data from more than 100 subjects, requiring little or no manual intervention. Automated routines for unfolding and flattening the cortical surface are described in a companion paper. These procedures allow for the routine use of cortical surface-based analysis and visualization methods in functional brain imaging.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {9033 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@online{dalmaijer_lowcosteyetribeeyetrackeranygoodresearch_2014,
  type = {preprint},
  ids = {dalmaijer_Lowcost_2014},
  title = {Is the {{Low-Cost Eyetribe Eye Tracker Any Good}} for {{Research}}?},
  author = {Dalmaijer, Edwin},
  date = {2014-11-04},
  eprinttype = {PeerJ PrePrints},
  doi = {10.7287/peerj.preprints.585v1},
  url = {https://peerj.com/preprints/585v1},
  urldate = {2023-05-08},
  abstract = {Eye-tracking technology is becoming increasingly cheaper, both on the hardware and on the software front. Currently, the EyeTribe tracker is the most inexpensive commercial eye tracker in the world, at a price of \$99. The low costs make it a potentially interesting resource for research, but no objective testing of its quality has been performed yet. Here the EyeTribe tracker is compared with an EyeLink 1000, a high-quality video eye tracker. Results indicate that the spatial precision and accuracy are good enough for fixation checking, point-of-regard analyses, and pupilometry. However, the low sampling rate renders the device unsuitable for testing high-accuracy saccade metrics. Additionally, open-source toolboxes for Matlab and Python, and a plug-in for OpenSesame are presented, which can be used to interface with the EyeTribe tracker.},
  langid = {english},
  pubstate = {preprint},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/RX23FBJL/Dalmaijer - 2014 - Is the low-cost EyeTribe eye tracker any good for .pdf}
}

@inproceedings{dalvi_Aggregating_2013,
  title = {Aggregating {{Crowdsourced Binary Ratings}}},
  booktitle = {Proc. 22nd {{Int}}. {{Conf}}. {{World Wide Web}}},
  author = {Dalvi, Nilesh and Dasgupta, Anirban and Kumar, Ravi and Rastogi, Vibhor},
  date = {2013-05-13},
  series = {{{WWW}} '13},
  pages = {285--294},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/2488388.2488414},
  abstract = {In this paper we analyze a crowdsourcing system consisting of a set of users and a set of binary choice questions. Each user has an unknown, fixed, reliability that determines the user's error rate in answering questions. The problem is to determine the truth values of the questions solely based on the user answers. Although this problem has been studied extensively, theoretical error bounds have been shown only for restricted settings: when the graph between users and questions is either random or complete. In this paper we consider a general setting of the problem where the user--question graph can be arbitrary. We obtain bounds on the error rate of our algorithm and show it is governed by the expansion of the graph. We demonstrate, using several synthetic and real datasets, that our algorithm outperforms the state of the art.},
  isbn = {978-1-4503-2035-1},
  keywords = {⛔ No INSPIRE recid found,crowdsourcing,mechanical turk,spectral methods},
  annotation = {192 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/FPBZ8WCE/Dalvi et al. - 2013 - Aggregating Crowdsourced Binary Ratings.pdf}
}

@article{daniel_Toman_2005,
  title = {Toman's {{Tuberculosis}}. {{Case Detection}}, {{Treatment}}, and {{Monitoring}}. {{Questions}} and {{Answers}}. {{Second Edition}}.},
  author = {Daniel, Thomas M.},
  date = {2005},
  journaltitle = {Am. J. Trop. Med. Hyg.},
  issn = {0002-9637},
  doi = {10.4269/ajtmh.2005.73.229},
  abstract = {2nd ed. Previous edition: Tuberculosis case-finding and chemotherapy : questions and answers / K. Toman. 1979. Annotation The second edition of this practical, authoritative reference book provides a rational basis for the diagnosis and management of tuberculosis. Written by a number of experts in the field, it remains faithful to Kurt Toman's original question-and-answer format, with subject matter grouped under the three headings Case Detection, Treatment, and Monitoring. It is a testament to the enduring nature of the first edition that so much material has been retained unchanged. At the same time, the new edition has had not only to address the huge resurgence of tuberculosis, the emergence of multi-drug-resistant bacilli, and the special needs of HIV-infected individuals with tuberculosis, but also to encompass significant scientific advances. These changes in the profile of the disease and in approaches to management have inevitably prompted many new questions and answers and given a different complexion to others. Toman's Tuberculosisremains essential reading for all who need to learn more about every aspect of tuberculosis - case-finding management and effective control strategies. It provides invaluable support to anyone in the front line of the battle against this disease, from program managers to policy-makers and from medical personnel to volunteer health workers. Now also available in Spanish through the Pan American Health Organization TUBERCULOSIS: Detecci\'on de casos tratamiento y vigilancia. Preguntas y respuestas.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{danziger_Extraneous_2011,
  title = {Extraneous {{Factors}} in {{Judicial Decisions}}},
  author = {Danziger, Shai and Levav, Jonathan and Avnaim-Pesso, Liora},
  date = {2011},
  journaltitle = {Proc. Natl. Acad. Sci. U. S. A.},
  eprint = {21482790},
  eprinttype = {pmid},
  issn = {00278424},
  doi = {10.1073/pnas.1018033108},
  abstract = {Are judicial rulings based solely on laws and facts? Legal formalism holds that judges apply legal reasons to the facts of a case in a rational, mechanical, and deliberative manner. In contrast, legal realists argue that the rational application of legal reasons does not sufficiently explain the decisions of judges and that psychological, political, and social factors influence judicial rulings. We test the common caricature of realism that justice is "what the judge ate for breakfast" in sequential parole decisions made by experienced judges.We record the judges' two daily food breaks, which result in segmenting the deliberations of the day into three distinct "decision sessions." We find that the percentage of favorable rulings drops gradually from {$\approx$}65\% to nearly zero within each decision session and returns abruptly to {$\approx$}65\% after a break. Our findings suggest that judicial rulings can be swayed by extraneous variables that should have no bearing on legal decisions.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Decisionmaking,Ego depletion,Expert decisionmaking,Legal realism,Mental depletion},
  annotation = {942 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{darapaneni_Pneumonia_2022,
  title = {Pneumonia {{Detection}} in {{Chest X-Rays Using Neural Networks}}},
  author = {Darapaneni, Narayana and Ranjan, Ashish and Bright, Dany and Trivedi, D. and Kumar, K. and Kumar, Vivek and Paduri, A.},
  date = {2022},
  journaltitle = {ArXiv},
  doi = {10.48550/arXiv.2204.03618},
  abstract = {The proposed CNN model (Convolutional Neural Network) for the classification of Chest X-ray images for Radiological Society of North America Pneumonia (RSNA) datasets is based on a non-complex CNN and the use of transfer learning algorithms like Xception, InceptionV3/V4, EfficientNetB7. : With the advancement in AI, deep learning techniques are widely used to design robust classification models in several areas such as medical diagnosis tasks in which it achieves good performance. In this paper, we have proposed the CNN model (Convolutional Neural Network) for the classification of Chest X-ray images for Radiological Society of North America Pneumonia (RSNA) datasets. The study also tries to achieve the same RSNA benchmark results using the limited computational resources by trying out various approaches to the methodologies that have been implemented in recent years. The proposed method is based on a non-complex CNN and the use of transfer learning algorithms like Xception, InceptionV3/V4, EfficientNetB7. Along with this, the study also tries to achieve the same RSNA benchmark results using the limited computational resources by trying out various approaches to the methodologies that have been implemented in recent years. The RSNA benchmark MAP score is 0.25, but using the Mask RCNN model on a stratified sample of 3017 along with image augmentation gave a MAP score of 0.15. Meanwhile, the YoloV3 without any hyperparameter tuning gave the MAP score of 0.32 but still, the loss keeps decreasing. Running the model for a greater number of iterations can give better results.},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {0 citations (Semantic Scholar/DOI) [2022-07-03]},
  file = {/Users/personal-macbook/Zotero/storage/ZQEBHDRW/Darapaneni et al. - 2022 - Pneumonia Detection in Chest X-Rays using Neural N.pdf}
}

@article{davenport_Artificial_2018,
  title = {Artificial {{Intelligence}} for the {{Real World}}},
  author = {Davenport, Thomas H. and Ronanki, Rajeev},
  date = {2018},
  journaltitle = {Harv. Bus. Rev.},
  issn = {00178012},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{davenport_Potential_2019,
  title = {The {{Potential}} for {{Artificial Intelligence}} in {{Healthcare}}},
  author = {Davenport, Thomas and Kalakota, Ravi},
  date = {2019},
  journaltitle = {Future Healthc. J.},
  issn = {2514-6645},
  doi = {10.7861/futurehosp.6-2-94},
  abstract = {The complexity and rise of data in healthcare means that artificial intelligence (AI) will increasingly be applied within the field. Several types of AI are already being employed by payers and providers of care, and life sciences companies. The key categories of applications involve diagnosis and treatment recommendations, patient engagement and adherence, and administrative activities. Although there are many instances in which AI can perform healthcare tasks as well or better than humans, implementation factors will prevent large-scale automation of healthcare professional jobs for a considerable period. Ethical issues in the application of AI to healthcare are also discussed.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{dawid_Maximum_1979,
  title = {Maximum {{Likelihood Estimation}} of {{Observer Error-Rates Using}} the {{EM Algorithm}}},
  author = {Dawid, A. P. and Skene, A. M.},
  date = {1979},
  journaltitle = {Applied Statistics},
  volume = {28},
  number = {1},
  eprint = {10.2307/2346806},
  eprinttype = {jstor},
  pages = {20},
  issn = {00359254},
  doi = {10.2307/2346806},
  url = {https://www.jstor.org/stable/10.2307/2346806?origin=crossref},
  urldate = {2022-12-29},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {1578 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/A9GXDUAR/Dawid and Skene - 1979 - Maximum Likelihood Estimation of Observer Error-Ra.pdf}
}

@article{deangel_Digital_2022,
  title = {Digital {{Health Tools}} for the {{Passive Monitoring}} of {{Depression}}: {{A Systematic Review}} of {{Methods}}},
  shorttitle = {Digital Health Tools for the Passive Monitoring of Depression},
  author = {De Angel, Valeria and Lewis, Serena and White, Katie and Oetzmann, Carolin and Leightley, Daniel and Oprea, Emanuela and Lavelle, Grace and Matcham, Faith and Pace, Alice and Mohr, David C. and Dobson, Richard and Hotopf, Matthew},
  date = {2022-01-11},
  journaltitle = {npj Digit. Med.},
  volume = {5},
  number = {1},
  pages = {1--14},
  publisher = {{Nature Publishing Group}},
  issn = {2398-6352},
  doi = {10.1038/s41746-021-00548-8},
  url = {https://www.nature.com/articles/s41746-021-00548-8},
  urldate = {2022-06-14},
  abstract = {The use of digital tools to measure physiological and behavioural variables of potential relevance to mental health is a growing field sitting at the intersection between computer science, engineering, and clinical science. We summarised the literature on remote measuring technologies, mapping methodological challenges and threats to reproducibility, and identified leading digital signals for depression. Medical and computer science databases were searched between January 2007 and November 2019. Published studies linking depression and objective behavioural data obtained from smartphone and wearable device sensors in adults with unipolar depression and healthy subjects were included. A descriptive approach was taken to synthesise study methodologies. We included 51 studies and found threats to reproducibility and transparency arising from failure to provide comprehensive descriptions of recruitment strategies, sample information, feature construction and the determination and handling of missing data. The literature is characterised by small sample sizes, short follow-up duration and great variability in the quality of reporting, limiting the interpretability of pooled results. Bivariate analyses show consistency in statistically significant associations between depression and digital features from sleep, physical activity, location, and phone use data. Machine learning models found the predictive value of aggregated features. Given the pitfalls in the combined literature, these results should be taken purely as a starting point for hypothesis generation. Since this research is ultimately aimed at informing clinical practice, we recommend improvements in reporting standards including consideration of generalisability and reproducibility, such as wider diversity of samples, thorough reporting methodology and the reporting of potential bias in studies with numerous features.},
  issue = {1},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Diagnostic markers,Human behaviour,Machine learning},
  annotation = {26 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/74VBFEZD/De Angel et al. - 2022 - Digital health tools for the passive monitoring of.pdf}
}

@incollection{delrue_Difficulties_2011,
  title = {Difficulties in the {{Interpretation}} of {{Chest Radiography}}},
  booktitle = {Comparative {{Interpretation}} of {{CT}} and {{Standard Radiography}} of the {{Chest}}},
  author = {Delrue, Louke and Gosselin, Robert and Ilsen, Bart and Van Landeghem, An and family=Mey, given=Johan, prefix=de, useprefix=true and Duyck, Philippe},
  editor = {Coche, Emmanuel E. and Ghaye, Benoit and family=Mey, given=Johan, prefix=de, useprefix=true and Duyck, Philippe},
  date = {2011},
  series = {Medical {{Radiology}}},
  pages = {27--49},
  publisher = {{Springer}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-540-79942-9_2},
  url = {https://doi.org/10.1007/978-3-540-79942-9_2},
  urldate = {2022-11-21},
  abstract = {Reading chest X-rays is a difficult and challenging task, and is still important despite the development of powerful imaging techniques such as computed tomography, high-resolution computed tomography, and magnetic resonance. For a correct reading and interpretation of chest X-rays, it is necessary to understand the techniques, their limitations, basic anatomy and physiology, and to have a systematic system of scrutiny. However, we have to keep in mind that interpretation is submitted to perceptual and cognitive limitations and errors. In this chapter, chest X-ray will be discussed from prescription to report in all its facets.},
  isbn = {978-3-540-79942-9},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Compute Radiography,Interstitial Lung Disease,Lung Field,Lung Nodule,Primary Ciliary Dyskinesia},
  file = {/Users/personal-macbook/Zotero/storage/7RJ55AYE/978-3-540-79942-9_2.html}
}

@inproceedings{demartini_Zencrowd_2012,
  title = {Zencrowd: {{Leveraging Probabilistic Reasoning}} and {{Crowdsourcing Techniques}} for {{Large-Scale Entity Linking}}},
  shorttitle = {Zencrowd},
  booktitle = {Proc. 21st {{Int}}. {{Conf}}. {{World Wide Web}}},
  author = {Demartini, Gianluca and Difallah, Djellel Eddine and Cudr\'e-Mauroux, Philippe},
  date = {2012-04-16},
  pages = {469--478},
  publisher = {{ACM}},
  location = {{Lyon France}},
  doi = {10.1145/2187836.2187900},
  url = {https://dl.acm.org/doi/10.1145/2187836.2187900},
  urldate = {2022-12-28},
  eventtitle = {{{WWW}} 2012: 21st {{World Wide Web Conference}} 2012},
  isbn = {978-1-4503-1229-5},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,crowdsourcing,entity linking,linked data,probabilistic reasoning},
  annotation = {453 citations (Semantic Scholar/DOI) [2022-12-28]},
  file = {/Users/personal-macbook/Zotero/storage/K392N5J7/Demartini et al. - 2012 - ZenCrowd Leveraging Probabilistic Reasoning and C.pdf}
}

@article{dembczynski_Label_2012,
  title = {On {{Label Dependence}} and {{Loss Minimization}} in {{Multi-Label Classification}}},
  author = {Dembczy\'nski, Krzysztof and Waegeman, Willem and Cheng, Weiwei and H\"ullermeier, Eyke},
  date = {2012-07},
  journaltitle = {Mach Learn},
  volume = {88},
  number = {1-2},
  pages = {5--45},
  issn = {0885-6125, 1573-0565},
  doi = {10.1007/s10994-012-5285-8},
  url = {http://link.springer.com/10.1007/s10994-012-5285-8},
  urldate = {2023-04-02},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Label dependence,Loss functions,Multi-label classification},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-04-04]},
  file = {/Users/personal-macbook/Zotero/storage/ZRN3ZD9B/Dembczyński et al. - 2012 - On label dependence and loss minimization in multi.pdf}
}

@incollection{demner-fushman_Annotation_2015,
  title = {Annotation of {{Chest Radiology Reports}} for {{Indexing}} and {{Retrieval}}},
  booktitle = {Multimodal {{Retrieval}} in the {{Medical Domain}}},
  author = {Demner-Fushman, Dina and Shooshan, Sonya E. and Rodriguez, Laritza and Antani, Sameer and Thoma, George R.},
  editor = {M\"uller, Henning and Jimenez del Toro, Oscar Alfonso and Hanbury, Allan and Langs, Georg and Foncubierta Rodriguez, Antonio},
  date = {2015},
  volume = {9059},
  pages = {99--111},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-24471-6_9},
  url = {http://link.springer.com/10.1007/978-3-319-24471-6_9},
  urldate = {2022-11-21},
  abstract = {Annotation of MEDLINE citations with controlled vocabulary terms improves the quality of retrieval results. Due to variety in descriptions of similar clinical phenomena and abundance of negation and uncertainty, annotation of clinical radiology reports for subsequent indexing and retrieval with a search engine is even more important. Provided with an opportunity to add about 4,000 radiology reports to collections indexed with NLM image retrieval engine Open-i, we needed to assure good retrieval quality. To accomplish this, we explored automatic and manual approaches to annotation, as well as developed a small controlled vocabulary of chest x-ray indexing terms and guidelines for manual annotation. Manual annotation captured the most salient findings in the reports and normalized the sparse distinct descriptions of similar findings to one controlled vocabulary term. This paper presents the vocabulary and the manual annotation process, as well as an evaluation of the automatic annotation of the reports.},
  isbn = {978-3-319-24470-9 978-3-319-24471-6},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/ZZMV3V54/Demner-Fushman et al. - 2015 - Annotation of Chest Radiology Reports for Indexing.pdf}
}

@article{demner-fushman_Preparing_2016,
  title = {Preparing a {{Collection}} of {{Radiology Examinations}} for {{Distribution}} and {{Retrieval}}},
  author = {Demner-Fushman, Dina and Kohli, Marc D. and Rosenman, Marc B. and Shooshan, Sonya E. and Rodriguez, Laritza and Antani, Sameer and Thoma, George R. and McDonald, Clement J.},
  date = {2016-03-01},
  journaltitle = {J. Am. Med. Inform. Assoc.},
  volume = {23},
  number = {2},
  pages = {304--310},
  issn = {1527-974X, 1067-5027},
  doi = {10.1093/jamia/ocv080},
  url = {https://academic.oup.com/jamia/article/23/2/304/2572395},
  urldate = {2023-01-07},
  abstract = {Abstract             Objective Clinical documents made available for secondary use play an increasingly important role in discovery of clinical knowledge, development of research methods, and education. An important step in facilitating secondary use of clinical document collections is easy access to descriptions and samples that represent the content of the collections. This paper presents an approach to developing a collection of radiology examinations, including both the images and radiologist narrative reports, and making them publicly available in a searchable database.             Materials and Methods The authors collected 3996 radiology reports from the Indiana Network for Patient Care and 8121 associated images from the hospitals' picture archiving systems. The images and reports were de-identified automatically and then the automatic de-identification was manually verified. The authors coded the key findings of the reports and empirically assessed the benefits of manual coding on retrieval.             Results The automatic de-identification of the narrative was aggressive and achieved 100\% precision at the cost of rendering a few findings uninterpretable. Automatic de-identification of images was not quite as perfect. Images for two of 3996 patients (0.05\%) showed protected health information. Manual encoding of findings improved retrieval precision.             Conclusion Stringent de-identification methods can remove all identifiers from text radiology reports. DICOM de-identification of images does not remove all identifying information and needs special attention to images scanned from film. Adding manual coding to the radiologist narrative reports significantly improved relevancy of the retrieved clinical documents. The de-identified Indiana chest X-ray collection is available for searching and downloading from the National Library of Medicine ( http://openi.nlm.nih.gov/ ).},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {385 citations (Semantic Scholar/DOI) [2023-01-06]},
  file = {/Users/personal-macbook/Zotero/storage/P6QVZEQV/Demner-Fushman et al. - 2016 - Preparing a collection of radiology examinations f.pdf}
}

@article{dempster_Maximum_1977,
  title = {Maximum {{Likelihood From Incomplete Data}} via the {{EM Algorithm}}},
  author = {Dempster, A. P. and Laird, N. M. and Rubin, D. B.},
  date = {1977},
  journaltitle = {J. R. Stat. Soc. Ser. B Methodol.},
  doi = {10.1111/j.2517-6161.1977.tb01600.x},
  abstract = {A broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. Theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. Many examples are sketched, including missing value situations, applications to grouped, censored or truncated data, finite mixture models, variance component estimation, hyperparameter estimation, iteratively reweighted least squares and factor analysis.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {9994 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{deng_ImageNet_2009,
  title = {{{ImageNet}}: {{A Large-Scale Hierarchical Image Database}}},
  shorttitle = {{{ImageNet}}},
  booktitle = {Conf. {{Comput}}. {{Vis}}. {{Pattern Recognit}}.},
  author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and {Kai Li} and {Li Fei-Fei}},
  date = {2009-06},
  pages = {248--255},
  publisher = {{IEEE}},
  location = {{Miami, FL}},
  doi = {10.1109/CVPR.2009.5206848},
  url = {https://ieeexplore.ieee.org/document/5206848/},
  urldate = {2022-12-20},
  eventtitle = {Computer {{Society Conference}} on {{Computer Vision}} and {{Pattern Recognition Workshops}}},
  isbn = {978-1-4244-3992-8},
  keywords = {⛔ No INSPIRE recid found,Explosions,Image databases,Image retrieval,Information retrieval,Internet,Large-scale systems,Multimedia databases,Ontologies,Robustness,Spine},
  annotation = {9995 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/RQB43NTP/Deng et al. - 2009 - ImageNet A Large-Scale Hierarchical Image Databas.pdf}
}

@article{denker_Transforming_1991,
  title = {Transforming {{Neural-Net Output Levels}} to {{Probability Distributions}}},
  author = {Denker, John S. and LeCun, Yann},
  date = {1991},
  journaltitle = {Adv. Neural Inf. Process. Syst. 3},
  abstract = {(1) The outputs of a typical multi-output classification network do not satisfy the axioms of probability; probabilities should be positive and sum to one. This problem can be solved by treating the trained network as a preprocessor that produces a feature vector that can be further processed, for instance by classical statistical estimation techniques. (2) We present a method for computing the first two moments ofthe probability distribution indicating the range of outputs that are consistent with the input and the training data. It is particularly useful to combine these two ideas: we implement the ideas of section 1 using Parzen windows, where the shape and relative size of each window is computed using the ideas of section 2. This allows us to make contact between important theoretical ideas (e.g. the ensemble formalism) and practical techniques (e.g. back-prop). Our results also shed new light on and generalize the well-known "soft max" scheme.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{deoni_Segmentation_2007,
  title = {Segmentation of {{Thalamic Nuclei Using}} a {{Modified K-Means Clustering Algorithm}} and {{High-Resolution Quantitative Magnetic Resonance Imaging}} at 1.5 {{T}}},
  author = {Deoni, Sean C. L. and Rutt, Brian K. and Parrent, Andrew G. and Peters, Terry M.},
  date = {2007-01},
  journaltitle = {Neuroimage},
  volume = {34},
  number = {1},
  pages = {117--126},
  doi = {10.1016/j.neuroimage.2006.09.016},
  abstract = {Patient outcome in minimally invasive stereotactic neurosurgical procedures depends on the ability to accurately locate the desired functional region within the deep brain while avoiding the surrounding anatomy. Due to the lack of sufficient contrast within this region in pre-operatively acquired MR images, electrophysiological exploration and histological atlases are currently required to define the surgical target within the thalamus in the treatment of many motor-control disorders. In this paper we introduce a method for segmenting the individual thalamic nuclei based on high-resolution quantitative magnetic resonance images, providing improved target visualization. The method was tested using whole-brain T1 and T2 data acquired from four healthy individuals. Accuracy of the segmentation results was assessed by comparing the center-of-mass coordinates of the segmented nuclei, with coordinates obtained from a classic histological atlas registered to these images. Strong agreement was found, with an average Euclidean distance difference of less than 4.5 mm averaged across all nuclei and all individuals. Reproducibility of the method, determined by calculating the percent similarity of segmentation results derived from data acquired from repeated scan sessions, was greater than 85\%. These results illustrate the ability to accurately and reliably segment the primary nuclei of the thalamus and suggest that the method may have utility in the study of individual nuclear regions in disease state as well as for planning deep-brain surgical procedures.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{descoteaux_Regularized_2007,
  title = {Regularized, {{Fast}}, and {{Robust Analytical Q-Ball Imaging}}},
  author = {Descoteaux, Maxime and Angelino, Elaine and Fitzgibbons, Shaun and Deriche, Rachid},
  date = {2007-09},
  journaltitle = {Magn. Reson. Med.},
  volume = {58},
  number = {3},
  pages = {497--510},
  doi = {10.1002/mrm.21277},
  abstract = {We propose a regularized, fast, and robust analytical solution for the Q-ball imaging (QBI) reconstruction of the orientation distribution function (ODF) together with its detailed validation and a discussion on its benefits over the state-of-the-art. Our analytical solution is achieved by modeling the raw high angular resolution diffusion imaging signal with a spherical harmonic basis that incorporates a regularization term based on the Laplace-Beltrami operator defined on the unit sphere. This leads to an elegant mathematical simplification of the Funk-Radon transform which approximates the ODF. We prove a new corollary of the Funk-Hecke theorem to obtain this simplification. Then, we show that the Laplace-Beltrami regularization is theoretically and practically better than Tikhonov regularization. At the cost of slightly reducing angular resolution, the Laplace-Beltrami regularization reduces ODF estimation errors and improves fiber detection while reducing angular error in the ODF maxima detected. Finally, a careful quantitative validation is performed against ground truth from synthetic data and against real data from a biological phantom and a human brain dataset. We show that our technique is also able to recover known fiber crossings in the human brain and provides the practical advantage of being up to 15 times faster than original numerical QBI method.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{devisetty_Bringing_2016,
  title = {Bringing {{Your Tools}} to {{CyVerse Discovery Environment Using Docker}}},
  author = {Devisetty, Upendra Kumar and Kennedy, Kathleen and Sarando, Paul and Merchant, Nirav and Lyons, Eric},
  date = {2016},
  journaltitle = {F1000Research},
  doi = {10.12688/f1000research.8935.1},
  abstract = {Docker has become a very popular container-based virtualization platform for software distribution that has revolutionized the way in which scientific software and software dependencies (software stacks) can be packaged, distributed, and deployed. Docker makes the complex and time-consuming installation procedures needed for scientific software a one-time process. Because it enables platform-independent installation, versioning of software environments, and easy redeployment and reproducibility, Docker is an ideal candidate for the deployment of identical software stacks on different compute environments such as XSEDE and Amazon AWS. CyVerse's Discovery Environment also uses Docker for integrating its powerful, community-recommended software tools into CyVerse's production environment for public use. This paper will help users bring their tools into CyVerse Discovery Environment (DE) which will not only allows users to integrate their tools with relative ease compared to the earlier method of tool deployment in DE but will also help users to share their apps with collaborators and release them for public use.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {35 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{dewan_Rigid_2016,
  title = {Rigid {{Scene Flow}} for {{3D LiDAR Scans}}},
  booktitle = {{{IEEE Int}}. {{Conf}}. {{Intell}}. {{Robots Syst}}.},
  author = {Dewan, Ayush and Caselitz, Tim and Tipaldi, Gian Diego and Burgard, Wolfram},
  date = {2016},
  issn = {21530866},
  doi = {10.1109/IROS.2016.7759282},
  abstract = {The perception of the dynamic aspects of the environment is a highly relevant precondition for the realization of autonomous robot system acting in the real world. In this paper, we propose a novel method for estimating dense rigid scene flow in 3D LiDAR scans. We formulate the problem as an energy minimization problem, where we assume local geometric constancy and incorporate regularization for smooth motion fields. Analyzing the dynamics at point level helps in inferring the fine-grained details of motion. We show results on multiple sequences of the KITTI odometry dataset, where we seamlessly estimate multiple motions pertaining to different dynamic objects. Furthermore, we test our approach on a dataset with pedestrians to show how our method adapts to a case with non-rigid motion. For comparison we use the ground truth from KITTI and show how our method outperforms different ICP-based methods.},
  isbn = {978-1-5090-3762-9},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{dice_Measures_1945,
  title = {Measures of the {{Amount}} of {{Ecologic Association Between Species}}},
  author = {Dice, Lee R.},
  date = {1945-07},
  journaltitle = {Ecology},
  volume = {26},
  number = {3},
  pages = {297--302},
  publisher = {{Wiley}},
  issn = {00129658},
  doi = {10.2307/1932409},
  url = {http://doi.wiley.com/10.2307/1932409},
  abstract = {The coefficient of association of Forbes indicates the amount of association be- tween two given species compared to the amount of association between them expected by chance. In order to provide a simple direct measure of the amount of association of one species with another the association index is proposed. If a is the number of random samples of a given series in which species A occurs and h is the number of samples in which another species B occurs together with A, then the association index B/A = h/a. Similarly, if b is the number of samples in which species B occurs, then the associa- tion index A/B = h/b. There is also proposed a coincidence index, 2h/(a + b), whose value is intermediate between the two reciprocal association indices. As a measure of the statistical reliability of the deviation shown by the samples of a given series from the amount of associa- tion expected by chance, the chi-square test may be used.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {9990 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{dill_Automated_2015,
  title = {Automated {{Methods}} for {{Hippocampus Segmentation}}: {{The Evolution}} and a {{Review}} of the {{State}} of the {{Art}}},
  author = {Dill, Vanderson and Franco, Alexandre Rosa and Pinho, M\'arcio Sarroglia},
  date = {2015-04},
  journaltitle = {Neuroinformatics},
  volume = {13},
  number = {2},
  pages = {133--150},
  doi = {10.1007/s12021-014-9243-4},
  abstract = {The segmentation of the hippocampus in Magnetic Resonance Imaging (MRI) has been an important procedure to diagnose and monitor several clinical situations. The precise delineation of the borders of this brain structure makes it possible to obtain a measure of the volume and estimate its shape, which can be used to diagnose some diseases, such as Alzheimer's disease, schizophrenia and epilepsy. As the manual segmentation procedure in three-dimensional images is highly time consuming and the reproducibility is low, automated methods introduce substantial gains. On the other hand, the implementation of those methods is a challenge because of the low contrast of this structure in relation to the neighboring areas of the brain. Within this context, this research presents a review of the evolution of automatized methods for the segmentation of the hippocampus in MRI. Many proposed methods for segmentation of the hippocampus have been published in leading journals in the medical image processing area. This paper describes these methods presenting the techniques used and quantitatively comparing the methods based on Dice Similarity Coefficient. Finally, we present an evaluation of those methods considering the degree of user intervention, computational cost, segmentation accuracy and feasibility of application in a clinical routine.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{dimitrovski_Hierarchical_2011,
  title = {Hierarchical {{Annotation}} of {{Medical Images}}},
  author = {Dimitrovski, Ivica and Kocev, Dragi and Loskovska, Suzana and D\v{z}eroski, Sa\v{s}o},
  date = {2011-10},
  journaltitle = {Pattern Recognition},
  volume = {44},
  number = {10-11},
  pages = {2436--2449},
  issn = {00313203},
  doi = {10.1016/j.patcog.2011.03.026},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0031320311001300},
  urldate = {2022-11-21},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {151 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/VFMAHUZK/Dimitrovski et al. - 2011 - Hierarchical annotation of medical images.pdf}
}

@article{dolz_3D_2018,
  title = {{{3D Fully Convolutional Networks}} for {{Subcortical Segmentation}} in {{Mri}}: {{A Large-Scale Study}}},
  shorttitle = {3d {{Fully Convolutional Networks}} for {{Subcortical Segmentation}} in {{Mri}}},
  author = {Dolz, Jose and Desrosiers, Christian and Ben Ayed, Ismail},
  date = {2018-04},
  journaltitle = {NeuroImage},
  volume = {170},
  pages = {456--470},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2017.04.039},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811917303324},
  urldate = {2022-12-29},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,3D CNN,Brain,Deep learning,Fully CNN,MRI segme},
  annotation = {311 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/QBIYA77G/Dolz et al. - 2018 - 3D fully convolutional networks for subcortical se.pdf}
}

@article{dolz_Segmentation_2015,
  title = {Segmentation {{Algorithms}} of {{Subcortical Brain Structures}} on {{MRI}} for {{Radiotherapy}} and {{Radiosurgery}}: {{A Survey}}},
  author = {Dolz, J. and Massoptier, L. and Vermandel, M.},
  date = {2015-08},
  journaltitle = {IRBM},
  volume = {36},
  number = {4},
  pages = {200--212},
  doi = {10.1016/j.irbm.2015.06.001},
  abstract = {This work covers the current state of the art with regard to approaches to segment subcortical brain structures. A huge range of diverse methods have been presented in the literature during the last decade to segment not only one or a constrained number of structures, but also a complete set of these subcortical regions. Special attention has been paid to atlas based segmentation methods, statistical models and deformable models for this purpose. More recently, the introduction of machine learning techniques, such as artificial neural networks or support vector machines, has helped the researchers to optimize the classification problem. These methods are presented in this work, and their advantages and drawbacks are further discussed. Although these methods have proved to perform well, their use is often limited to those situations where either there are no lesions in the brain or the presence of lesions does not highly vary the brain anatomy. Consequently, the development of segmentation algorithms that can deal with such lesions in the brain and still provide a good performance when segmenting subcortical structures is highly required in practice by some clinical applications, such as radiotherapy or radiosurgery.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{donahue_DeCAF_2014,
  title = {Decaf: {{A Deep Convolutional Activation Feature}} for {{Generic Visual Recognition}}},
  booktitle = {31st {{Int}}. {{Conf}}. {{Mach}}. {{Learn}}. {{ICML}} 2014},
  author = {Donahue, Jeff and Jia, Yangqing and Vinyals, Oriol and Hoffman, Judy and Zhang, Ning and Tzeng, Eric and Darrell, Trevor},
  date = {2014},
  abstract = {We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be re- purposed to novel generic tasks. Our generic tasks may differ significantly from the originally trained tasks and there may be insufficient labeled or unlabeled data to conventionally train or adapt a deep architecture to the new tasks. We investigate and visualize the semantic clustering of deep convolutional features with respect to a variety of such tasks, including scene recognition, domain adaptation, and fine-grained recognition challenges. We compare the efficacy of relying on various network levels to define a fixed feature, and report novel results that significantly outperform the state-of-the-art on several important vision challenges. We are releasing DeCAF, an open-source implementation of these deep convolutional activation features, along with all associated network parameters to enable vision researchers to be able to conduct experimenta-tion with deep representations across a range of visual concept learning paradigms.},
  isbn = {978-1-63439-397-3},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@incollection{dong_Unsupervised_2018a,
  ids = {dong_Unsupervised_2018},
  title = {Unsupervised {{Domain Adaptation}} for {{Automatic Estimation}} of {{Cardiothoracic Ratio}}},
  booktitle = {Medical {{Image Computing}} and {{Computer Assisted Intervention}} \textendash{} {{MICCAI}} 2018},
  author = {Dong, Nanqing and Kampffmeyer, Michael and Liang, Xiaodan and Wang, Zeya and Dai, Wei and Xing, Eric},
  editor = {Frangi, Alejandro F. and Schnabel, Julia A. and Davatzikos, Christos and Alberola-L\'opez, Carlos and Fichtinger, Gabor},
  date = {2018},
  volume = {11071},
  pages = {544--552},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-00934-2_61},
  url = {http://link.springer.com/10.1007/978-3-030-00934-2_61},
  urldate = {2023-05-08},
  isbn = {978-3-030-00933-5 978-3-030-00934-2},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/KUTXN9GQ/Dong et al. - 2018 - Unsupervised Domain Adaptation for Automatic Estim.pdf}
}

@inproceedings{donmez_Efficiently_2009,
  title = {Efficiently {{Learning}} the {{Accuracy}} of {{Labeling Sources}} for {{Selective Sampling}}},
  booktitle = {Proc. 15th {{ACM SIGKDD Int}}. {{Conf}}. {{Knowl}}. {{Discov}}. {{Data Min}}. - {{KDD}} 09},
  author = {Donmez, Pinar and Carbonell, Jaime G. and Schneider, Jeff},
  date = {2009},
  pages = {259},
  publisher = {{ACM Press}},
  location = {{Paris, France}},
  doi = {10.1145/1557019.1557053},
  url = {http://portal.acm.org/citation.cfm?doid=1557019.1557053},
  urldate = {2021-11-02},
  abstract = {Many scalable data mining tasks rely on active learning to provide the most useful accurately labeled instances. However, what if there are multiple labeling sources (`oracles' or `experts') with different but unknown reliabilities? With the recent advent of inexpensive and scalable online annotation tools, such as Amazon's Mechanical Turk, the labeling process has become more vulnerable to noise - and without prior knowledge of the accuracy of each individual labeler. This paper addresses exactly such a challenge: how to jointly learn the accuracy of labeling sources and obtain the most informative labels for the active learning task at hand minimizing total labeling effort. More specifically, we present IEThresh (Interval Estimate Threshold) as a strategy to intelligently select the expert(s) with the highest estimated labeling accuracy. IEThresh estimates a confidence interval for the reliability of each expert and filters out the one(s) whose estimated upper-bound confidence interval is below a threshold - which jointly optimizes expected accuracy (mean) and need to better estimate the expert's accuracy (variance). Our framework is flexible enough to work with a wide range of different noise levels and outperforms baselines such as asking all available experts and random expert selection. In particular, IEThresh achieves a given level of accuracy with less than half the queries issued by allexperts labeling and less than a third the queries required by random expert selection on datasets such as the UCI mushroom one. The results show that our method naturally balances exploration and exploitation as it gains knowledge of which experts to rely upon, and selects them with increasing frequency.},
  eventtitle = {The 15th {{ACM SIGKDD}} International Conference},
  isbn = {978-1-60558-495-9},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,active learning,estimation,labeler selection,noisy labelers},
  annotation = {262 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/DUMUFGWC/Donmez et al. - 2009 - Efficiently learning the accuracy of labeling sour.pdf}
}

@article{doshi-velez_Rigorous_2017,
  title = {Towards a {{Rigorous Science}} of {{Interpretable Machine Learning}}},
  author = {Doshi-Velez, Finale and Kim, Been},
  date = {2017-02},
  url = {http://arxiv.org/abs/1702.08608},
  abstract = {As machine learning systems become ubiquitous, there has been a surge of interest in interpretable machine learning: systems that provide explanation for their outputs. These explanations are often used to qualitatively assess other criteria such as safety or non-discrimination. However, despite the interest in interpretability, there is very little consensus on what interpretable machine learning is and how it should be measured. In this position paper, we first define interpretability and describe when interpretability is needed (and when it is not). Next, we suggest a taxonomy for rigorous evaluation and expose open questions towards a more rigorous science of interpretable machine learning.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@inproceedings{dosilovic_Explainable_2018,
  title = {Explainable {{Artificial Intelligence}}: {{A Survey}}},
  booktitle = {41st {{Int}}. {{Conv}}. {{Inf}}. {{Commun}}. {{Technol}}. {{Electron}}. {{Microelectron}}.},
  author = {Dosilovic, Filip Karlo and Brcic, Mario and Hlupic, Nikica},
  date = {2018},
  doi = {10.23919/MIPRO.2018.8400040},
  abstract = {In the last decade, with availability of large datasets and more computing power, machine learning systems have achieved (super)human performance in a wide variety of tasks. Examples of this rapid development can be seen in image recognition, speech analysis, strategic game planning and many more. The problem with many state-of-the-art models is a lack of transparency and interpretability. The lack of thereof is a major drawback in many applications, e.g. healthcare and finance, where rationale for model's decision is a requirement for trust. In the light of these issues, explainable artificial intelligence (XAI) has become an area of interest in research community. This paper summarizes recent developments in XAI in supervised learning, starts a discussion on its connection with artificial general intelligence, and gives proposals for further research directions.},
  isbn = {978-953-233-097-7},
  keywords = {\#nosource,⛔ No INSPIRE recid found,comprehensibility,explainability,explainable artificial intelligence,interpretability},
  annotation = {543 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{dou_Automatic_2016,
  title = {Automatic {{Detection}} of {{Cerebral Microbleeds From Mr Images}} via 3d {{Convolutional Neural Networks}}},
  author = {Dou, Qi and Chen, Hao and Yu, Lequan and Zhao, Lei and Qin, Jing and Wang, Defeng and Mok, Vincent C. T. and Shi, Lin and Heng, Pheng-Ann},
  date = {2016},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {35},
  number = {5},
  pages = {1182--1195},
  publisher = {{IEEE}},
  doi = {10.1109/TMI.2016.2528129},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {518 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{dou_Unsupervised_2018,
  title = {Unsupervised {{Cross-Modality Domain Adaptation}} of {{Convnets}} for {{Biomedical Image Segmentations With Adversarial Loss}}},
  booktitle = {{{IJCAI Int}}. {{Jt}}. {{Conf}}. {{Artif}}. {{Intell}}.},
  author = {Dou, Qi and Ouyang, Cheng and Chen, Cheng and Chen, Hao and Heng, Pheng Ann},
  date = {2018},
  issn = {10450823},
  doi = {10.24963/ijcai.2018/96},
  abstract = {Convolutional networks (ConvNets) have achieved great successes in various challenging vision tasks. However, the performance of ConvNets would degrade when encountering the domain shift. The domain adaptation is more significant while challenging in the field of biomedical image analysis, where cross-modality data have largely different distributions. Given that annotating the medical data is especially expensive, the supervised transfer learning approaches are not quite optimal. In this paper, we propose an unsupervised domain adaptation framework with adversarial learning for cross-modality biomedical image segmentations. Specifically, our model is based on a dilated fully convolutional network for pixel-wise prediction. Moreover, we build a plug-and-play domain adaptation module (DAM) to map the target input to features which are aligned with source domain feature space. A domain critic module (DCM) is set up for discriminating the feature space of both domains. We optimize the DAM and DCM via an adversarial loss without using any target domain label. Our proposed method is validated by adapting a ConvNet trained with MRI images to unpaired CT data for cardiac structures segmentations, and achieved very promising results.},
  isbn = {978-0-9992411-2-7},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{drozdzal_Importance_2016,
  title = {The {{Importance}} of {{Skip Connections}} in {{Biomedical Image Segmentation}}},
  booktitle = {Lect. {{Notes Comput}}. {{Sci}}.},
  author = {Drozdzal, Michal and Vorontsov, Eugene and Chartrand, Gabriel and Kadoury, Samuel and Pal, Chris},
  date = {2016-08},
  volume = {10008 LNCS},
  pages = {179--187},
  publisher = {{Springer Verlag}},
  doi = {10.1007/978-3-319-46976-8_19},
  url = {http://arxiv.org/abs/1608.04117},
  abstract = {In this paper, we study the influence of both long and short skip connections on Fully Convolutional Networks (FCN) for biomedical image segmentation. In standard FCNs, only long skip connections are used to skip features from the contracting path to the expanding path in order to recover spatial information lost during downsampling. We extend FCNs by adding short skip connections, that are similar to the ones introduced in residual networks, in order to build very deep FCNs (of hundreds of layers). A review of the gradient flow confirms that for a very deep FCN it is beneficial to have both long and short skip connections. Finally, we show that a very deep FCN can achieve near-to-state-of-the-art results on the EM dataset without any further post-processing.},
  isbn = {978-3-319-46975-1},
  keywords = {\#nosource,⛔ No INSPIRE recid found,FCN,ResNet,Semantic segmentation,Skip connections}
}

@online{du_Deep_2022,
  title = {Deep {{Learning}} on {{3D Point Clouds}}},
  author = {Du, Shuchen},
  date = {2022-01-05T01:47:57},
  url = {https://medium.com/mlearning-ai/deep-learning-on-3d-point-clouds-1c79d2fc3fd0},
  urldate = {2022-07-19},
  abstract = {Deep Learning without Pixels and Voxels},
  langid = {english},
  organization = {{MLearning.ai}},
  keywords = {⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/ZW8LNYLB/Du - 2022 - Deep Learning on 3D Point Clouds.pdf;/Users/personal-macbook/Zotero/storage/5GFWV3GP/deep-learning-on-3d-point-clouds-1c79d2fc3fd0.html}
}

@inproceedings{duan_Exploiting_2012,
  title = {Exploiting {{Web Images}} for {{Event Recognition}} in {{Consumer Videos}}: {{A Multiple Source Domain Adaptation Approach}}},
  booktitle = {Proc. {{IEEE Comput}}. {{Soc}}. {{Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}.},
  author = {Duan, Lixin and Xu, Dong and Chang, Shih Fu},
  date = {2012},
  issn = {10636919},
  doi = {10.1109/CVPR.2012.6247819},
  abstract = {Recent work has demonstrated the effectiveness of domain adaptation methods for computer vision applications. In this work, we propose a new multiple source domain adaptation method called Domain Selection Machine (DSM) for event recognition in consumer videos by leveraging a large number of loosely labeled web images from different sources (e.g., Flickr.com and Photosig.com), in which there are no labeled consumer videos. Specifically, we first train a set of SVM classifiers (referred to as source classifiers) by using the SIFT features of web images from different source domains. We propose a new parametric target decision function to effectively integrate the static SIFT features from web images/video keyframes and the spacetime (ST) features from consumer videos. In order to select the most relevant source domains, we further introduce a new data-dependent regularizer into the objective of Support Vector Regression (SVR) using the -insensitive loss, which enforces the target classifier shares similar decision values on the unlabeled consumer videos with the selected source classifiers. Moreover, we develop an alternating optimization algorithm to iteratively solve the target decision function and a domain selection vector which indicates the most relevant source domains. Extensive experiments on three real-world datasets demonstrate the effectiveness of our proposed method DSM over the state-of-the-art by a performance gain up to 46.41\%. \textcopyright{} 2012 IEEE.},
  isbn = {978-1-4673-1226-4},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {200 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{duan_Learning_2017,
  title = {Learning {{With Auxiliary Less-Noisy Labels}}},
  author = {Duan, Yunyan and Wu, Ou},
  date = {2017-07},
  journaltitle = {IEEE Trans. Neural Netw. Learning Syst.},
  volume = {28},
  number = {7},
  pages = {1716--1721},
  issn = {2162-237X, 2162-2388},
  doi = {10.1109/TNNLS.2016.2546956},
  url = {https://ieeexplore.ieee.org/document/7448430/},
  urldate = {2022-12-28},
  keywords = {⛔ No INSPIRE recid found,Crowdsourcing,Learning systems,Maximum likelihood approach,Maximum likelihood estimation,Noise measurement,noisy degrees,noisy labels,Probabilistic logic,soft constraints,Training,Training data},
  annotation = {19 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/N2VVZTC4/Duan and Wu - 2017 - Learning With Auxiliary Less-Noisy Labels.pdf}
}

@article{duan_Thalamus_2007,
  title = {Thalamus {{Segmentation From Diffusion Tensor Magnetic Resonance Imaging}}},
  author = {Duan, Ye and Li, Xiaoling and Xi, Yongjian},
  date = {2007},
  journaltitle = {Int. J. Biomed. Imaging},
  volume = {2007},
  pages = {90216},
  doi = {10.1155/2007/90216},
  abstract = {We propose a semi-automatic thalamus and thalamus nuclei segmentation algorithm from Diffusion Tensor Magnetic Resonance Imaging (DT-MRI) based on the mean-shift algorithm. Comparing with existing thalamus segmentation algorithms which are mainly based on K-means algorithm, our mean-shift based algorithm is more flexible and adaptive. It does not assume a Gaussian distribution or a fixed number of clusters. Furthermore, the single parameter in the mean-shift based algorithm supports hierarchical clustering naturally.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@dataset{duan_UCI_2017,
  title = {{{UCI Machine Learning Repository}}},
  shorttitle = {{{UCI}}},
  author = {Duan, Dheeru and Graff, Casey},
  date = {2017},
  location = {{Irvine, CA: University of California, School of Information and Computer Science}},
  url = {http://archive.ics.uci.edu/ml},
  urldate = {2023-04-06},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {University of California, Irvine, School of Information and Computer Sciences}
}

@inproceedings{dundar_Simplicity_2015,
  ids = {dundar15},
  title = {Simplicity of {{Kmeans Versus Deepness}} of {{Deep Learning}}: {{A Case}} of {{Unsupervised Feature Learning}} with {{Limited Data}}},
  shorttitle = {Simplicity of {{Kmeans Versus Deepness}} of {{Deep Learning}}},
  booktitle = {2015 {{IEEE}} 14th {{Int}}. {{Conf}}. {{Mach}}. {{Learn}}. {{Appl}}. {{ICMLA}}},
  author = {Dundar, Murat and Kou, Qiang and Zhang, Baichuan and He, Yicheng and Rajwa, Bartek},
  date = {2015-12},
  pages = {883--888},
  publisher = {{IEEE}},
  location = {{Miami, FL, USA}},
  doi = {10.1109/ICMLA.2015.78},
  url = {http://ieeexplore.ieee.org/document/7424433/},
  urldate = {2023-06-03},
  eventtitle = {2015 {{IEEE}} 14th {{International Conference}} on {{Machine Learning}} and {{Applications}} ({{ICMLA}})},
  isbn = {978-1-5090-0287-0},
  keywords = {⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/ID3FQSB2/Dundar et al. - 2015 - Simplicity of Kmeans Versus Deepness of Deep Learn.pdf}
}

@inproceedings{dusenberry_Analyzing_2020,
  title = {Analyzing the {{Role}} of {{Model Uncertainty}} for {{Electronic Health Records}}},
  booktitle = {{{ACM CHIL}} 2020 - {{Proc}}. 2020 {{ACM Conf}}. {{Health Inference Learn}}.},
  author = {Dusenberry, Michael W. and Tran, Dustin and Choi, Edward and Kemp, Jonas and Nixon, Jeremy and Jerfel, Ghassen and Heller, Katherine and Dai, Andrew M.},
  date = {2020},
  doi = {10.1145/3368555.3384457},
  abstract = {In medicine, both ethical and monetary costs of incorrect predictions can be significant, and the complexity of the problems often necessitates increasingly complex models. Recent work has shown that changing just the random seed is enough for otherwise well-tuned deep neural networks to vary in their individual predicted probabilities. In light of this, we investigate the role of model uncertainty methods in the medical domain. Using RNN ensembles and various Bayesian RNNs, we show that population-level metrics, such as AUC-PR, AUC-ROC, log-likelihood, and calibration error, do not capture model uncertainty. Meanwhile, the presence of significant variability in patient-specific predictions and optimal decisions motivates the need for capturing model uncertainty. Understanding the uncertainty for individual patients is an area with clear clinical impact, such as determining when a model decision is likely to be brittle. We further show that RNNs with only Bayesian embeddings can be a more efficient way to capture model uncertainty compared to ensembles, and we analyze how model uncertainty is impacted across individual input features and patient subgroups.},
  isbn = {978-1-4503-7046-2},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Bayesian deep learning,electronic health records,neural networks,uncertainty},
  annotation = {80 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{duyn_Highfield_2007,
  title = {High-{{Field MRI}} of {{Brain Cortical Substructure Based}} on {{Signal Phase}}},
  author = {Duyn, Jeff H. and family=Gelderen, given=Peter, prefix=van, useprefix=false and Li, Tie-Qiang and family=Zwart, given=Jacco A., prefix=de, useprefix=false and Koretsky, Alan P. and Fukunaga, Masaki},
  date = {2007-07},
  journaltitle = {Proc Natl Acad Sci U A},
  volume = {104},
  number = {28},
  pages = {11796--11801},
  doi = {10.1073/pnas.0610821104},
  abstract = {The ability to detect brain anatomy and pathophysiology with MRI is limited by the contrast-to-noise ratio (CNR), which depends on the contrast mechanism used and the spatial resolution. In this work, we show that in MRI of the human brain, large improvements in contrast to noise in high-resolution images are possible by exploiting the MRI signal phase at high magnetic field strength. Using gradient-echo MRI at 7.0 tesla and a multichannel detector, a nominal voxel size of 0.24 x 0.24 x 1.0 mm3 (58 nl) was achieved. At this resolution, a strong phase contrast was observed both between as well as within gray matter (GM) and white matter (WM). In gradient-echo phase images obtained on normal volunteers at this high resolution, the CNR between GM and WM ranged from 3:1 to 20:1 over the cortex. This CNR is an almost 10-fold improvement over conventional MRI techniques that do not use image phase, and it is an approximately 100-fold improvement when including the gains in resolution from high-field and multichannel detection. Within WM, phase contrast appeared to be associated with the major fiber bundles, whereas contrast within GM was suggestive of the underlying layer structure. The observed phase contrast is attributed to local variations in magnetic susceptibility, which, at least in part, appeared to originate from iron stores. The ability to detect cortical substructure from MRI phase contrast at high field is expected to greatly enhance the study of human brain anatomy in vivo.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {640 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{eaton-rosen_Safe_2018,
  title = {Towards {{Safe Deep Learning}}: {{Accurately Quantifying Biomarker Uncertainty}} in {{Neural Network Predictions}}},
  booktitle = {Lect. {{Notes Comput}}. {{Sci}}. {{Subser}}. {{Lect}}. {{Notes Artif}}. {{Intell}}. {{Lect}}. {{Notes Bioinforma}}.},
  author = {Eaton-Rosen, Zach and Bragman, Felix and Bisdas, Sotirios and Ourselin, S\'ebastien and Cardoso, M. Jorge},
  date = {2018},
  issn = {16113349},
  doi = {10.1007/978-3-030-00928-1_78},
  abstract = {Automated medical image segmentation, specifically using deep learning, has shown outstanding performance in semantic segmentation tasks. However, these methods rarely quantify their uncertainty, which may lead to errors in downstream analysis. In this work we propose to use Bayesian neural networks to quantify uncertainty within the domain of semantic segmentation. We also propose a method to convert voxel-wise segmentation uncertainty into volumetric uncertainty, and calibrate the accuracy and reliability of confidence intervals of derived measurements. When applied to a tumour volume estimation application, we demonstrate that by using such modelling of uncertainty, deep learning systems can be made to report volume estimates with well-calibrated error-bars, making them safer for clinical use. We also show that the uncertainty estimates extrapolate to unseen data, and that the confidence intervals are robust in the presence of artificial noise. This could be used to provide a form of quality control and quality assurance, and may permit further adoption of deep learning tools in the clinic.},
  isbn = {978-3-030-00927-4},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{eckhardt_Opportunities_2003,
  title = {Opportunities and {{Entrepreneurship}}},
  author = {Eckhardt, Jonathan T. and Shane, Scott A.},
  date = {2003},
  journaltitle = {J. Manag.},
  issn = {01492063},
  doi = {10.1016/S0149-2063(02)00225-8},
  abstract = {This article extends and elaborates the perspective on entrepreneurship articulated by Shane and Venkataraman (2000) and Venkataraman (1997) by explaining in more detail the role of opportunities in the entrepreneurial process. In particular, the article explains the importance of examining entrepreneurship through a disequilibrium framework that focuses on the characteristics and existence of entrepreneurial opportunities. In addition, the article describes several typologies of opportunities and their implications for understanding entrepreneurship. \textcopyright{} 2002 Elsevier Science Inc. All rights reserved.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{edelstein_Intrinsic_1986,
  title = {The {{Intrinsic Signal-to-Noise Ratio}} in {{Nmr Imaging}}},
  author = {Edelstein, W. A. and Glover, G. H. and Hardy, C. J. and Redington, R. W.},
  date = {1986-08},
  journaltitle = {Magn. Reson. Med.},
  volume = {3},
  number = {4},
  pages = {604--618},
  issn = {07403194, 15222594},
  doi = {10.1002/mrm.1910030413},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/mrm.1910030413},
  urldate = {2023-05-28},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {765 citations (Semantic Scholar/DOI) [2023-05-28]}
}

@inproceedings{el-fiky_MultiLabel_2021,
  title = {Multi-{{Label Transfer Learning}} for {{Identifying Lung Diseases Using Chest X-Rays}}},
  booktitle = {2021 {{Int}}. {{Conf}}. {{Electron}}. {{Eng}}. {{ICEEM}}},
  author = {El-Fiky, Azza and Shouman, Marwa Ahmed and Hamada, Salwa and El-Sayed, Ayman and Karar, Mohamed Esmail},
  date = {2021-07-03},
  pages = {1--6},
  publisher = {{IEEE}},
  location = {{Menouf, Egypt}},
  doi = {10.1109/ICEEM52022.2021.9480622},
  url = {https://ieeexplore.ieee.org/document/9480622/},
  urldate = {2022-12-15},
  eventtitle = {2021 {{International Conference}} on {{Electronic Engineering}} ({{ICEEM}})},
  isbn = {978-1-66541-842-3},
  keywords = {⛔ No INSPIRE recid found,Biomedical imaging,classification,Computer-aided diagnosis,Deep learning,Diagnostic radiography,Pulmonary diseases,Task analysis,Thorax diseases,Transfer learning,X-ray,X-ray imaging},
  annotation = {0 citations (Semantic Scholar/DOI) [2022-12-15]},
  file = {/Users/personal-macbook/Zotero/storage/4DJTBRUC/El-Fiky et al. - 2021 - Multi-Label Transfer Learning for Identifying Lung.pdf;/Users/personal-macbook/Zotero/storage/25T392HC/9480622.html}
}

@article{elias_Pilot_2013,
  title = {A {{Pilot Study}} of {{Focused Ultrasound Thalamotomy}} for {{Essential Tremor}}},
  author = {Elias, W. Jeffrey and Huss, Diane and Voss, Tiffini and Loomba, Johanna and Khaled, Mohamad and Zadicario, Eyal and Frysinger, Robert C. and Sperling, Scott A. and Wylie, Scott and Monteith, Stephen J. and Druzgal, Jason and Shah, Binit B. and Harrison, Madaline and Wintermark, Max},
  date = {2013-08-15},
  journaltitle = {N Engl J Med},
  volume = {369},
  number = {7},
  pages = {640--648},
  issn = {0028-4793, 1533-4406},
  doi = {10.1056/NEJMoa1300962},
  url = {http://www.nejm.org/doi/10.1056/NEJMoa1300962},
  urldate = {2023-05-08},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {670 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{elmore_Diagnostic_2015,
  title = {Diagnostic {{Concordance Among Pathologists Interpreting Breast Biopsy Specimens}}},
  author = {Elmore, Joann G. and Longton, Gary M. and Carney, Patricia A. and Geller, Berta M. and Onega, Tracy and Tosteson, Anna N. A. and Nelson, Heidi D. and Pepe, Margaret S. and Allison, Kimberly H. and Schnitt, Stuart J. and O'Malley, Frances P. and Weaver, Donald L.},
  date = {2015},
  journaltitle = {JAMA - J. Am. Med. Assoc.},
  eprint = {25781441},
  eprinttype = {pmid},
  issn = {15383598},
  doi = {10.1001/jama.2015.1405},
  abstract = {IMPORTANCE A breast pathology diagnosis provides the basis for clinical treatment and management decisions; however, its accuracy is inadequately understood. OBJECTIVES To quantify the magnitude of diagnostic disagreement among pathologists compared with a consensus panel reference diagnosis and to evaluate associated patient and pathologist characteristics. DESIGN, SETTING, AND PARTICIPANTS Study of pathologists who interpret breast biopsies in clinical practices in 8 US states. EXPOSURES Participants independently interpreted slides between November 2011 and May 2014 from test sets of 60 breast biopsies (240 total cases, 1 slide per case), including 23 cases of invasive breast cancer, 73 ductal carcinoma in situ (DCIS), 72 with atypical hyperplasia (atypia), and 72 benign cases without atypia. Participants were blinded to the interpretations of other study pathologists and consensus panel members. Among the 3 consensus panel members, unanimous agreement of their independent diagnoses was 75\%, and concordance with the consensus-derived reference diagnoses was 90.3\%. MAIN OUTCOMES AND MEASURES The proportions of diagnoses overinterpreted and underinterpreted relative to the consensus-derived reference diagnoses were assessed. RESULTS Sixty-five percent of invited, responding pathologists were eligible and consented to participate. Of these, 91\% (N = 115) completed the study, providing 6900 individual case diagnoses. Compared with the consensus-derived reference diagnosis, the overall concordance rate of diagnostic interpretations of participating pathologists was 75.3\%(95\% CI, 73.4\%-77.0\%; 5194 of 6900 interpretations). (Table Presented) Disagreement with the reference diagnosiswas statistically significantly higher among biopsies fromwomen with higher (n = 122) vs lower (n = 118) breast density on priormammograms (overall concordance rate, 73\%[95\%CI, 71\%-75\%]for higher vs 77\%[95\%CI, 75\%-80\%]for lower, P {$<$} .001), and among pathologistswhointerpreted lowerweekly case volumes (P {$<$} .001) orworked in smaller practices (P = .034) or nonacademic settings (P = .007). CONCLUSIONS AND RELEVANCE In this study of pathologists, in which diagnostic interpretation was based on a single breast biopsy slide, overall agreement between the individual pathologists' interpretations and the expert consensus-derived reference diagnoses was 75.3\%, with the highest level of concordance for invasive carcinoma and lower levels of concordance for DCIS and atypia. Further research is needed to understand the relationship of these findings with patient management.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {487 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{engelmann_Deep_2020a,
  ids = {engelmann_Deep_2020},
  title = {Into the {{Deep}} - {{AI}} and {{Total Pathology}}: {{Deep Medicine}}: {{How Artificial Intelligence Can Make Healthcare Human Again}}, by {{Eric Topol}}, {{New York}}: {{Basic Books}}, 2010, 400 {{Pp}}., \$17.99 ({{Paperback}}), {{ISBN}} 9781541644649.},
  shorttitle = {Into the {{Deep}} - {{AI}} and {{Total Pathology}}},
  author = {Engelmann, Lukas},
  date = {2020-10-01},
  journaltitle = {Science as Culture},
  volume = {29},
  number = {4},
  pages = {625--629},
  issn = {0950-5431, 1470-1189},
  doi = {10.1080/09505431.2020.1768232},
  url = {https://www.tandfonline.com/doi/full/10.1080/09505431.2020.1768232},
  urldate = {2023-05-08},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {6 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@thesis{engstrom_Adapting_2019,
  title = {Adapting and {{Interpreting Machine Learning Techniques}} in the {{Biomedical}} and {{Clinical Domains}}},
  author = {Engstrom, Collin J.},
  date = {2019},
  journaltitle = {Indo American Journal of Pharmaceutical Sciences},
  volume = {23},
  number = {3},
  institution = {{UNIVERSITY OF WISCONSIN\textendash MADISON 2019}},
  doi = {10.5281/zenodo.1477753},
  isbn = {6103544947},
  pagetotal = {6},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{eshghali_Machine_2023,
  title = {Machine {{Learning Based Integrated Scheduling}} and {{Rescheduling}} for {{Elective}} and {{Emergency Patients}} in the {{Operating Theatre}}},
  author = {Eshghali, Masoud and Kannan, Devika and Salmanzadeh-Meydani, Navid and Esmaieeli Sikaroudi, Amir Mohammad},
  date = {2023-01-19},
  journaltitle = {Ann Oper Res},
  issn = {0254-5330, 1572-9338},
  doi = {10.1007/s10479-023-05168-x},
  url = {https://link.springer.com/10.1007/s10479-023-05168-x},
  urldate = {2023-06-04},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {4 citations (Semantic Scholar/DOI) [2023-06-04]},
  file = {/Users/personal-macbook/Zotero/storage/IJRW9MTY/Eshghali et al. - 2023 - Machine learning based integrated scheduling and r.pdf}
}

@inproceedings{espinoza_Using_2011,
  title = {Using the {{Number}} of {{Pores}} on {{Fingerprint Images}} to {{Detect Spoofing Attacks}}},
  booktitle = {2011 {{Int}}. {{Conf}}. {{Hand-Based Biom}}. {{ICHB}} 2011 - {{Proc}}.},
  author = {Espinoza, Marcela and Champod, Christophe},
  date = {2011},
  doi = {10.1109/ICHB.2011.6094347},
  abstract = {Due to the growing use of biometric technologies in our modern society, spoofing attacks are becoming a serious concern. Many solutions have been proposed to detect the use of fake "fingerprints" on an acquisition device. In this paper, we propose to take advantage of intrinsic features of friction ridge skin: pores. The aim of this study is to investigate the potential of using pores to detect spoofing attacks. Results show that the use of pores is a promising approach. Four major observations were made: First, results confirmed that the reproduction of pores on fake " fingerprints" is possible. Second, the distribution of the total number of pores between fake and genuine fingerprints cannot be discriminated. Third, the difference in pore quantities between a query image and a reference image (genuine or fake) can be used as a discriminating factor in a linear discriminant analysis. In our sample, the observed error rates were as follows: 45.5\% of false positive (the fake passed the test) and 3.8\% of false negative (a genuine print has been rejected). Finally, the performance is improved by using the difference of pore quantity obtained between a distorted query fingerprint and a non-distorted reference fingerprint. By using this approach, the error rates improved to 21.2\% of false acceptation rate and 8.3\% of false rejection rate. ?? 2011 IEEE.},
  isbn = {978-1-4577-0490-1},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Biometrics,Fake fingerprints,Fingerprint recognition,Spoofing attacks}
}

@thesis{esteva_ARTIFICIAL_2018,
  title = {Artificial {{Inteligence}} in {{Healthcare}} and {{Medicine Enhancing}} the {{Expert}}},
  author = {Esteva, Andre},
  date = {2018},
  journaltitle = {Stanford},
  institution = {{STANFORD}},
  issue = {February},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{eugenioiglesias_Unified_2013,
  title = {A {{Unified Framework}} for {{Cross-Modality Multi-Atlas Segmentation}} of {{Brain Mri}}},
  author = {Eugenio Iglesias, Juan and Rory Sabuncu, Mert and Van Leemput, Koen},
  date = {2013-12},
  journaltitle = {Medical Image Analysis},
  volume = {17},
  number = {8},
  pages = {1181--1191},
  issn = {13618415},
  doi = {10.1016/j.media.2013.08.001},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S136184151300114X},
  urldate = {2023-01-27},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {7 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/CIH8MSUB/Eugenio Iglesias et al. - 2013 - A unified framework for cross-modality multi-atlas.pdf}
}

@article{faes_Automated_2019,
  title = {Automated {{Deep Learning Design}} for {{Medical Image Classification}} by {{Health-Care Professionals With No Coding Experience}}: {{A Feasibility Study}}},
  author = {Faes, Livia and Wagner, Siegfried K. and Fu, Dun Jack and Liu, Xiaoxuan and Korot, Edward and Ledsam, Joseph R. and Back, Trevor and Chopra, Reena and Pontikos, Nikolas and Kern, Christoph and Moraes, Gabriella and Schmid, Martin K. and Sim, Dawn and Balaskas, Konstantinos and Bachmann, Lucas M. and Denniston, Alastair K. and Keane, Pearse A.},
  date = {2019-09},
  journaltitle = {Lancet Digit. Health},
  volume = {1},
  number = {5},
  pages = {e232--e242},
  doi = {10.1016/S2589-7500(19)30108-6},
  abstract = {Summary Background Deep learning has the potential to transform health care; however, substantial expertise is required to train such models. We sought to evaluate the utility of automated deep learning software to develop medical image diagnostic classifiers by health-care professionals with no coding\textemdash and no deep learning\textemdash expertise. Methods We used five publicly available open-source datasets: retinal fundus images (MESSIDOR); optical coherence tomography (OCT) images (Guangzhou Medical University and Shiley Eye Institute, version 3); images of skin lesions (Human Against Machine [HAM] 10000), and both paediatric and adult chest x-ray (CXR) images (Guangzhou Medical University and Shiley Eye Institute, version 3 and the National Institute of Health [NIH] dataset, respectively) to separately feed into a neural architecture search framework, hosted through Google Cloud AutoML, that automatically developed a deep learning architecture to classify common diseases. Sensitivity (recall), specificity, and positive predictive value (precision) were used to evaluate the diagnostic properties of the models. The discriminative performance was assessed using the area under the precision recall curve (AUPRC). In the case of the deep learning model developed on a subset of the HAM10000 dataset, we did external validation using the Edinburgh Dermofit Library dataset. Findings Diagnostic properties and discriminative performance from internal validations were high in the binary classification tasks (sensitivity 73\dbend 3\textendash 97\dbend 0\%; specificity 67\textendash 100\%; AUPRC 0\dbend 87\textendash 1\dbend 00). In the multiple classification tasks, the diagnostic properties ranged from 38\% to 100\% for sensitivity and from 67\% to 100\% for specificity. The discriminative performance in terms of AUPRC ranged from 0\dbend 57 to 1\dbend 00 in the five automated deep learning models. In an external validation using the Edinburgh Dermofit Library dataset, the automated deep learning model showed an AUPRC of 0\dbend 47, with a sensitivity of 49\% and a positive predictive value of 52\%. Interpretation All models, except the automated deep learning model trained on the multilabel classification task of the NIH CXR14 dataset, showed comparable discriminative performance and diagnostic properties to state-of-the-art performing deep learning algorithms. The performance in the external validation study was low. The quality of the open-access datasets (including insufficient information about patient flow and demographics) and the absence of measurement for precision, such as confidence intervals, constituted the major limitations of this study. The availability of automated deep learning platforms provide an opportunity for the medical community to enhance their understanding in model development and evaluation. Although the derivation of classification models without requiring a deep understanding of the mathematical, statistical, and programming principles is attractive, comparable performance to expertly designed models is limited to more elementary classification tasks. Furthermore, care should be placed in adhering to ethical principles when using these automated models to avoid discrimination and causing harm. Future studies should compare several application programming interfaces on thoroughly curated datasets. Funding National Institute for Health Research and Moorfields Eye Charity.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {140 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{fama_Thalamic_2014,
  title = {Thalamic {{Volume Deficit Contributes}} to {{Procedural}} and {{Explicit Memory Impairment}} in {{Hiv Infection With Primary Alcoholism Comorbidity}}},
  author = {Fama, Rosemary and Rosenbloom, Margaret J. and Sassoon, Stephanie A. and Rohlfing, Torsten and Pfefferbaum, Adolf and Sullivan, Edith V.},
  date = {2014},
  journaltitle = {Brain Imaging Behav.},
  issn = {19317565},
  doi = {10.1007/s11682-013-9286-4},
  abstract = {\textcopyright{} 2014, Springer Science+Business Media New York. Component cognitive and motor processes contributing to diminished visuomotor procedural learning in HIV infection with comorbid chronic alcoholism (HIV+ALC) include problems with attention and explicit memory processes. The neural correlates associated with this constellation of cognitive and motor processes in HIV infection and alcoholism have yet to be delineated. Frontostriatal regions are affected in HIV infection, frontothalamocerebellar regions are affected in chronic alcoholism, and frontolimbic regions are likely affected in both; all three of these systems have the potential of contributing to both visuomotor procedural learning and explicit memory processes. Here, we examined the neural correlates of implicit memory, explicit memory, attention, and motor tests in 26 HIV+ALC (5 with comorbidity for nonalcohol drug abuse/dependence) and 19 age-range matched healthy control men. Parcellated brain volumes, including cortical, subcortical, and allocortical regions, as well as cortical sulci and ventricles, were derived using the SRI24 brain atlas. Results indicated that smaller thalamic volumes were associated with poorer performance on tests of explicit (immediate and delayed) and implicit (visuomotor procedural) memory in HIV+ALC. By contrast, smaller hippocampal volumes were associated with lower scores on explicit, but not implicit memory. Multiple regression analyses revealed that volumes of both the thalamus and the hippocampus were each unique independent predictors of explicit memory scores. This study provides evidence of a dissociation between implicit and explicit memory tasks in HIV+ALC, with selective relationships observed between hippocampal volume and explicit but not implicit memory, and highlights the relevance of the thalamus to mnemonic processes.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Explicit memory,Hippocampus,HIV infection-alcoholism comorbidity,Implicit memory,Thalamus,Visuomotor procedural learning}
}

@article{fama_Thalamic_2015,
  title = {Thalamic {{Structures}} and {{Associated Cognitive Functions}}: {{Relations With Age}} and {{Aging}}},
  shorttitle = {Thalamic {{Structures}} and {{Associated Cognitive Functions}}},
  author = {Fama, Rosemary and Sullivan, Edith V.},
  date = {2015-07},
  journaltitle = {Neuroscience \& Biobehavioral Reviews},
  volume = {54},
  pages = {29--37},
  issn = {01497634},
  doi = {10.1016/j.neubiorev.2015.03.008},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0149763415000822},
  urldate = {2023-05-12},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Aging,Attention,Connectivity,DTI,Executive fun,Executive functions,Memory,MRI,Thalamocortical,Thalamus},
  annotation = {171 citations (Semantic Scholar/DOI) [2023-05-12]},
  file = {/Users/personal-macbook/Zotero/storage/QTTFDULK/Fama and Sullivan - 2015 - Thalamic structures and associated cognitive funct.pdf}
}

@article{familoni_Sweat_2016,
  title = {Sweat {{Pore Reactivity}} as a {{Surrogate Measure}} of {{Sympathetic Nervous System Activity}} in {{Trauma-Exposed Individuals With}} and {{Without Posttraumatic Stress Disorder}}},
  author = {Familoni, Babajide O. and Gregor, Kristin L. and Dodson, Thomas S. and Krzywicki, Alan T. and Lowery, Bobby N. and Orr, Scott P. and Suvak, Michael K. and Rasmusson, Ann M.},
  date = {2016},
  journaltitle = {Psychophysiology},
  eprint = {27286885},
  eprinttype = {pmid},
  issn = {15405958},
  doi = {10.1111/psyp.12681},
  abstract = {Stress analysis by FLIR (forward-looking infrared) evaluation (SAFE) has been demonstrated to monitor sweat pore activation (SPA) as a novel surrogate measure of sympathetic nervous system (SNS) activity in a normal population. SNS responses to a series of 15 1-s, 82 dB, white noise bursts were measured by skin conductance (SC) and SAFE monitoring of SPA on the fingers (FiP) and face (FaP) in 10 participants with posttraumatic stress disorder (PTSD) and 16 trauma-exposed participants without PTSD (Mage = 48.92 {$\pm$} 12.00 years; 26.9\% female). Within participants, SC and FiP responses across trials were strongly correlated (r = .92, p {$<$} .001). Correlations between SC and FaP (r = .76, p = .001) and between FiP and FaP (r = .47, p = .005) were smaller. The habituation of SNS responses across the 15 trials was substantial (SC: d = -2.97; FiP: d = -2.34; FaP: d = -1.02). There was a strong correlation between habituation effects for SC and FiP (r = .76, p {$<$} .001), but not for SC and FaP (r = .15, p = .45) or FiP and FaP (r = .29, p = .16). Participants with PTSD showed larger SNS responses to the first loud noise than those without PTSD. PTSD reexperiencing symptoms assessed by the PTSD Checklist on the day of testing were associated with the SNS responses to the first loud noise measured by SC (d = 1.19) and FiP (d = .99), but not FaP (d = .10). This study confirms convergence of SAFE and SC as valid measures of SNS activity. SAFE FiP and SC responses were highly predictive of self-rated PTSD reexperiencing symptoms. SAFE may offer an attractive alternative for applications in PTSD and similar populations.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Loud noise test,PTSD,Skin conductance,Sweat pore,Sympathetic nervous system,Thermal imaging,Trauma}
}

@article{faridah_Fingerprint_2016,
  title = {Fingerprint {{Biometric Systems}}},
  author = {Faridah, Y. and Nasir, Haidawati and Kushsairy, A. K. and Safie, Sairul I. and Khan, Sheroz and Gunawan, Teddy S.},
  date = {2016},
  journaltitle = {Trends Bioinforma.},
  issn = {20772254},
  doi = {10.3923/tb.2016.52.58},
  abstract = {One of the popular and widely practiced biometric systems is fingerprint Fingerprint biometric systems are smaller in size, easy to use and has low power. It is available and deployed globally in law enforcement, such as immigration, banking sectors, forensics, health care and many more. This study reviewed fingerprint biometric systems and the methods used in each proposed system. Many studies have been done in the area of feature extraction and matching stages. The current techniques used in these stages are minutiae-based and euclidean distance-based. Application of the fingerprint biometric system in the industries has been accepted widely and used in the Europe and some developed country. Malaysia has also incorporated the use of this system in its administration for controlling the point of entry at the Kuala Lumpur International Airport. Generally, fingerprint biometric systems can be categorized into recognition, security, identification and control systems. Each system has their benefits and drawbacks that complemented each other.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Fingerprint,Fingerprint biometric system,Image,Pattern,Recognition,Technologies},
  annotation = {8 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{fei-fei_Knowledge_2006,
  title = {Knowledge {{Transfer}} in {{Learning}} to {{Recognize Visual Objects Classes}}},
  booktitle = {Int. {{Conf}}. {{Dev}}. {{Learn}}.},
  author = {Fei-Fei, Li},
  date = {2006},
  pages = {1--8},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{fei-fei_Oneshot_2006,
  title = {One-{{Shot Learning}} of {{Object Categories}}},
  author = {Fei-Fei, Li and Fergus, Rob and Perona, Pietro},
  date = {2006},
  journaltitle = {IEEE Trans. Pattern Anal. Mach. Intell.},
  eprint = {16566508},
  eprinttype = {pmid},
  issn = {01628828},
  doi = {10.1109/TPAMI.2006.79},
  abstract = {Learning visual models of object categories notoriously requires hundreds or thousands of training examples. We show that it is possible to learn much information about a category from just one, or a handful, of images. The key insight is that, rather than learning from scratch, one can take advantage of knowledge coming from previously learned categories, no matter how different these categories might be. We explore a Bayesian implementation of this idea. Object categories are represented by probabilistic models. Prior knowledge is represented as a probability density function on the parameters of these models. The posterior model for an object category is obtained by updating the prior in the light of one or more observations. We test a simple implementation of our algorithm on a database of 101 diverse object categories. We compare category models learned by an implementation of our Bayesian approach to models learned from by Maximum Likelihood (ML) and Maximum A Posteriori (MAP) methods. We find that on a database of more than 100 categories, the Bayesian approach produces informative models when the number of training examples is too small for other methods to operate successfully. \textcopyright{} 2006 IEEE.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Few images,Learning,Object categories,Priors,Recognition,Unsupervised,Variational inference}
}

@article{feldman_Leveraging_2003,
  title = {Leveraging {{Research}} and {{Development}}: {{Assessing}} the {{Impact}} of the {{U}}.{{S}}. {{Advanced Technology Program}}},
  author = {Feldman, Maryann P. and Kelley, Maryellen R.},
  date = {2003-03},
  journaltitle = {Small Bus. Econ.},
  volume = {20},
  number = {2},
  pages = {153--165},
  publisher = {{Kluwer Academic Publishers}},
  doi = {10.1023/A:1022264031993},
  abstract = {This paper examines the factors that affect a firm's chances of winning an award from the Advanced Technology Program (ATP) and the subsequent impact of the award on a firm's success in raising additional funds for its research and development (R\&D) activities. Analysis of data from a survey of 1998 ATP applicants shows that proposals with higher ratings by technical and business/economic experts have a greater chance of winning an award. Further, the projects and firms selected by ATP are more willing to share their research findings with other firms, and tend to be those that open up new pathways for innovation through combining technical areas or by forming new R\&D partnerships. Most of the non-winners have not proceeded with any aspect of the R\&D project proposed to ATP and, of those that have, most did so at a smaller scale. Furthermore, the ATP award has prestige value for the winning firms; the halo effect from the award increases the success of these firms in attracting additional funding from other sources. Our conclusion is that the ATP is leveraging activities that have a strong potential for broad-based economic benefit.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {79 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{fernando_Deep_2022,
  title = {Deep {{Learning}} for {{Medical Anomaly Detection}} \textendash{} {{A Survey}}},
  author = {Fernando, Tharindu and Gammulle, Harshala and Denman, S. and Sridharan, S. and Fookes, C.},
  date = {2022},
  journaltitle = {ACM Comput. Surv.},
  doi = {10.1145/3464423},
  abstract = {A coherent and systematic review of state-of-the-art techniques, comparing and contrasting their architectural differences as well as training algorithms and a comprehensive overview of deep model interpretation strategies that can be used to interpret model decisions are provided. Machine learning\textendash based medical anomaly detection is an important problem that has been extensively studied. Numerous approaches have been proposed across various medical application domains and we observe several similarities across these distinct applications. Despite this comparability, we observe a lack of structured organisation of these diverse research applications such that their advantages and limitations can be studied. The principal aim of this survey is to provide a thorough theoretical analysis of popular deep learning techniques in medical anomaly detection. In particular, we contribute a coherent and systematic review of state-of-the-art techniques, comparing and contrasting their architectural differences as well as training algorithms. Furthermore, we provide a comprehensive overview of deep model interpretation strategies that can be used to interpret model decisions. In addition, we outline the key limitations of existing deep medical anomaly detection techniques and propose key research directions for further investigation.},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {69 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/QH2XDWP3/Fernando et al. - 2022 - Deep Learning for Medical Anomaly Detection – A Su.pdf}
}

@online{fidon_dempstershaferapproachtrustworthyaiapplicationfetalbrainmrisegmentation_2022,
  title = {A {{Dempster-Shafer Approach}} to {{Trustworthy Ai With Application}} to {{Fetal Brain Mri Segmentation}}},
  author = {Fidon, Lucas and Aertsen, Michael and Kofler, Florian and Bink, Andrea and David, Anna L. and Deprest, Thomas and Emam, Doaa and Guffens, Fr\'ed\'eric and Jakab, Andr\'as and Kasprian, Gregor and Kienast, Patric and Melbourne, Andrew and Menze, Bjoern and Mufti, Nada and Pogledic, Ivana and Prayer, Daniela and Stuempflen, Marlene and Van Elslander, Esther and Ourselin, S\'ebastien and Deprest, Jan and Vercauteren, Tom},
  date = {2022},
  doi = {10.48550/ARXIV.2204.02779},
  url = {https://arxiv.org/abs/2204.02779},
  urldate = {2022-12-29},
  abstract = {Deep learning models for medical image segmentation can fail unexpectedly and spectacularly for pathological cases and images acquired at different centers than training images, with labeling errors that violate expert knowledge. Such errors undermine the trustworthiness of deep learning models for medical image segmentation. Mechanisms for detecting and correcting such failures are essential for safely translating this technology into clinics and are likely to be a requirement of future regulations on artificial intelligence (AI). In this work, we propose a trustworthy AI theoretical framework and a practical system that can augment any backbone AI system using a fallback method and a fail-safe mechanism based on Dempster-Shafer theory. Our approach relies on an actionable definition of trustworthy AI. Our method automatically discards the voxel-level labeling predicted by the backbone AI that violate expert knowledge and relies on a fallback for those voxels. We demonstrate the effectiveness of the proposed trustworthy AI approach on the largest reported annotated dataset of fetal MRI consisting of 540 manually annotated fetal brain 3D T2w MRIs from 13 centers. Our trustworthy AI method improves the robustness of a state-of-the-art backbone AI for fetal brain MRIs acquired across various centers and for fetuses with various brain abnormalities.},
  pubstate = {preprint},
  version = {3},
  keywords = {⛔ No INSPIRE recid found,Artificial Intelligence (cs.AI),Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Vision and Pattern Recognition (cs.CV),Electrical Engineering and Systems Science - Image and Video Processing,FOS: Computer and information sciences,{FOS: Electrical engineering, electronic engineering, information engineering},Image and Video Processing (eess.IV),Machine Learning (cs.LG)},
  annotation = {2 citations (Semantic Scholar/arXiv) [2023-05-08] 2 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/AMR394DH/Fidon et al. - 2022 - A Dempster-Shafer approach to trustworthy AI with .pdf;/Users/personal-macbook/Zotero/storage/DWGRZCNS/2204.html}
}

@article{fischl_freesurfer_2012,
  ids = {freesurfer_Fischl_2012,freesurfer_FreeSurfer_2012},
  title = {{{FreeSurfer}}},
  author = {Fischl, Bruce},
  date = {2012-08},
  journaltitle = {NeuroImage},
  volume = {62},
  number = {2},
  pages = {774--781},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2012.01.021},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811912000389},
  urldate = {2023-06-27},
  langid = {english},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found,Morphometry,MRI,Registration,Segmentation},
  annotation = {4189 citations (Semantic Scholar/DOI) [2023-06-27]},
  file = {/Users/personal-macbook/Zotero/storage/CEZ7BKUC/Fischl - 2012 - FreeSurfer.pdf}
}

@article{fischl_Whole_2002,
  title = {Whole {{Brain Segmentation}}: {{Automated Labeling}} of {{Neuroanatomical Structures}} in the {{Human Brain}}},
  author = {Fischl, Bruce and Salat, David H. and Busa, Evelina and Albert, Marilyn and Dieterich, Megan and Haselgrove, Christian and family=Kouwe, given=Andre, prefix=van der, useprefix=false and Killiany, Ron and Kennedy, David and Klaveness, Shuna and Montillo, Albert and Makris, Nikos and Rosen, Bruce and Dale, Anders M.},
  date = {2002-01},
  journaltitle = {Neuron},
  volume = {33},
  number = {3},
  pages = {341--355},
  doi = {10.1016/S0896-6273(02)00569-X},
  abstract = {We present a technique for automatically assigning a neuroanatomical label to each voxel in an MRI volume based on probabilistic information automatically estimated from a manually labeled training set. In contrast to existing segmentation procedures that only label a small number of tissue classes, the current method assigns one of 37 labels to each voxel, including left and right caudate, putamen, pallidum, thalamus, lateral ventricles, hippocampus, and amygdala. The classification technique employs a registration procedure that is robust to anatomical variability, including the ventricular enlargement typically associated with neurological diseases and aging. The technique is shown to be comparable in accuracy to manual labeling, and of sufficient sensitivity to robustly detect changes in the volume of noncortical structures that presage the onset of probable Alzheimer's disease.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@book{fisher_Operational_2000,
  title = {Operational {{Guidelines}} ({{Version}} 1.0) for {{Geological Fieldwork}} in {{Areas Endemic}} for {{Coccidioidomycosis}} ({{Valley Fever}})},
  author = {Fisher, Frederick S. and Bultman, Mark W. and Pappagianis, Demosthenes},
  date = {2000},
  publisher = {{US Geological Survey}},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{flengsrud_Essential_2019,
  title = {Essential {{Tremor}}},
  author = {Flengsrud, Karoline and Toft, Mathias and Dietrichs, Espen},
  date = {2019-05},
  journaltitle = {Tidsskr Laegeforen},
  volume = {139},
  number = {8},
  abstract = {Essential tremor affects almost 1 \% of the population and may be very debilitating. Much is still unclear with regard to its pathophysiology, environmental factors and genetic causes. The diagnosis of essential tremor most likely encompasses several different conditions. In this article we provide an overview of essential tremor, pharmacological and neurosurgical treatment, as well as a review of the proposals for new definitions for tremor in general, and for essential tremor in particular.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{fogel_Artificial_2018,
  title = {Artificial {{Intelligence Powers Digital Medicine}}},
  author = {Fogel, Alexander L. and Kvedar, Joseph C.},
  date = {2018},
  journaltitle = {Npj Digit. Med.},
  issn = {23986352},
  doi = {10.1038/s41746-017-0012-2},
  abstract = {Artificial intelligence (AI) has recently surpassed human performance in several domains, and there is great hope that in healthcare, AI may allow for better prevention, detection, diagnosis, and treatment of disease. While many fear that AI will disrupt jobs and the physician\textendash patient relationship, we believe that AI can eliminate many repetitive tasks to clear the way for human-to-human bonding and the application of emotional intelligence and judgment. We review several recent studies of AI applications in healthcare that provide a view of a future where healthcare delivery is a more unified, human experience.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {212 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@book{folio_Chest_2012,
  title = {Chest {{Imaging}}: {{An Algorithmic Approach}} to {{Learning}}},
  shorttitle = {Chest {{Imaging}}},
  author = {Folio, Les R.},
  date = {2012-02-02},
  publisher = {{Springer Science \& Business Media}},
  abstract = {The chest X-ray (CXR) or chest radiograph remains the most commonly ordered imaging study in medicine, yet paradoxically is often the most complex to learn, recall, and master effective and accurate interpretation. The chest radiograph includes all thoracic anatomy and provides a high yield, given the low cost and single source. This guide presents a structured lexicon for use by readers to reproducibly describe radiographic abnormalities of the chest detected on plain film CXRs. The lexicon is designed to provide readers with clinically significant differentiation of abnormalities detected. The content is structured to relate specific combinations of distinct radiographic findings to classes/groupings of pathological etiologies of those findings. Recognizing the individual findings and identifying their combination or lack of combination with other individual findings allows readers to create effective differential diagnoses that can then be further evaluated using other imaging procedures and/or non-radiographic clinical information. The book includes hundreds of images, including radiographs, CTs, graphics, and analogous models to help teach otherwise complex processes and radiographic principles.},
  isbn = {978-1-4614-1317-2},
  langid = {english},
  pagetotal = {162},
  keywords = {⛔ No INSPIRE recid found,Medical / Allied Health Services / Imaging Technologies,Medical / Biochemistry,Medical / Clinical Medicine,Medical / Diagnostic Imaging / General},
  file = {/Users/personal-macbook/Zotero/storage/2A8LMVEL/scholar_lookup.html}
}

@article{freedman_Hunting_2019,
  title = {Hunting for {{New Drugs With AI}}},
  author = {Freedman, David H.},
  date = {2019},
  journaltitle = {Nature},
  eprint = {31853074},
  eprinttype = {pmid},
  issn = {14764687},
  doi = {10.1038/d41586-019-03846-0},
  abstract = {The pharmaceutical industry is in a drug-discovery slump. How much can AI help? [Figure not available: see fulltext.].},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Computer science,Health care},
  annotation = {37 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{freedman_Relationship_1994,
  title = {The {{Relationship}} of {{Sweat Gland Count}} to {{Electrodermal Activity}}},
  author = {Freedman, L. W. and Scerbo, A. S. and Dawson, M. E. and Raine, A. and McClure, W. O. and Venables, P. H.},
  date = {1994-03},
  journaltitle = {Psychophysiology},
  volume = {31},
  number = {2},
  pages = {196--200},
  doi = {10.1111/j.1469-8986.1994.tb01040.x},
  abstract = {This study assessed whether greater skin conductance activity at the distal versus medial site (Scerbo, Freedman, Raine, Dawson, \& Venables, 1992) is attributable to a greater number of active (open) sweat glands at the distal site. The number of sweat glands was measured using the Palmar Sweat Index (PSI). Twenty-four subjects were exposed to 10 auditory stimuli. Electrodes were placed on the fore and middle fingers of each hand, using distal sites on one hand and medial sites on the other. The PSI was measured at the medial and distal phalanges adjacent to the electrode placement sites. The distal site contained more open and total sweat glands. Open gland count had the strongest correlations with skin conductance. Multivariate analyses of covariance revealed that site effects for nonspecific and orienting response frequency and trials to habituation were associated with site differences in open glands. Skin conductance measures and the PSI reveal greater electrodermal activity at the distal site. In addition, the number of open glands may be a useful measure related to electrodermal response frequency when polygraph measurement is unavailable.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{frenay_Classification_2014,
  title = {Classification in the {{Presence}} of {{Label Noise}}: {{A Survey}}},
  author = {Fr\'enay, Beno\^it and Verleysen, Michel},
  date = {2014},
  journaltitle = {IEEE Trans. Neural Netw. Learn. Syst.},
  eprint = {24808033},
  eprinttype = {pmid},
  issn = {21622388},
  doi = {10.1109/TNNLS.2013.2292894},
  abstract = {Label noise is an important issue in classification, with many potential negative consequences. For example, the accuracy of predictions may decrease, whereas the complexity of inferred models and the number of necessary training samples may increase. Many works in the literature have been devoted to the study of label noise and the development of techniques to deal with label noise. However, the field lacks a comprehensive survey on the different types of label noise, their consequences and the algorithms that consider label noise. This paper proposes to fill this gap. First, the definitions and sources of label noise are considered and a taxonomy of the types of label noise is proposed. Second, the potential consequences of label noise are discussed. Third, label noise-robust, label noise cleansing, and label noise-tolerant algorithms are reviewed. For each category of approaches, a short discussion is proposed to help the practitioner to choose the most suitable technique in its own particular field of application. Eventually, the design of experiments is also discussed, what may interest the researchers who would like to test their own algorithms. In this paper, label noise consists of mislabeled instances: no additional information is assumed to be available like e.g., confidences on labels. \textcopyright{} 2012 IEEE.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Class noise,classification,label noise,mislabeling,robust methods,survey.},
  annotation = {1281 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{french_Selfensembling_2018,
  title = {Self-{{Ensembling}} for {{Visual Domain Adaptation}}},
  booktitle = {6th {{Int}}. {{Conf}}. {{Learn}}. {{Represent}}. {{ICLR}} 2018 - {{Conf}}. {{Track Proc}}.},
  author = {French, Geoff and Mackiewicz, Michal and Fisher, Mark},
  date = {2018},
  abstract = {This paper explores the use of self-ensembling for visual domain adaptation problems. Our technique is derived from the mean teacher variant (Tarvainen \& Valpola (2017)) of temporal ensembling (Laine \& Aila (2017)), a technique that achieved state of the art results in the area of semi-supervised learning. We introduce a number of modifications to their approach for challenging domain adaptation scenarios and evaluate its effectiveness. Our approach achieves state of the art results in a variety of benchmarks, including our winning entry in the VISDA-2017 visual domain adaptation challenge. In small image benchmarks, our algorithm not only outperforms prior art, but can also achieve accuracy that is close to that of a classifier trained in a supervised fashion.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{frisoni_Clinical_2010,
  title = {The {{Clinical Use}} of {{Structural MRI}} in {{Alzheimer Disease}}},
  author = {Frisoni, Giovanni B. and Fox, Nick C. and Jr, Clifford R. Jack and Scheltens, Philip and Thompson, Paul M.},
  date = {2010-02},
  journaltitle = {Nat. Rev. Neurol.},
  volume = {6},
  number = {2},
  pages = {67--77},
  doi = {10.1038/nrneurol.2009.215},
  abstract = {Structural imaging based on magnetic resonance is an integral part of the clinical assessment of patients with suspected Alzheimer dementia. Prospective data on the natural history of change in structural markers from preclinical to overt stages of Alzheimer disease are radically changing how the disease is conceptualized, and will influence its future diagnosis and treatment. Atrophy of medial temporal structures is now considered to be a valid diagnostic marker at the mild cognitive impairment stage. Structural imaging is also included in diagnostic criteria for the most prevalent non-Alzheimer dementias, reflecting its value in differential diagnosis. In addition, rates of whole-brain and hippocampal atrophy are sensitive markers of neurodegeneration, and are increasingly used as outcome measures in trials of potentially disease-modifying therapies. Large multicenter studies are currently investigating the value of other imaging and nonimaging markers as adjuncts to clinical assessment in diagnosis and monitoring of progression. The utility of structural imaging and other markers will be increased by standardization of acquisition and analysis methods, and by development of robust algorithms for automated assessment.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{frohler_Exploring_,
  title = {Exploring {{Uncertainty}} in {{Image Segmentation Ensembles}}},
  author = {Fr\"ohler, B. and M\"oller, T. and Weissenb\"ock, J. and Hege, H.-C. and Kastner, J. and Heinzl, C.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@online{frosst_distillingneuralnetworksoftdecisiontree_2017,
  title = {Distilling a {{Neural Network Into}} a {{Soft Decision Tree}}},
  author = {Frosst, Nicholas and Hinton, Geoffrey},
  date = {2017},
  doi = {10.48550/ARXIV.1711.09784},
  url = {https://arxiv.org/abs/1711.09784},
  urldate = {2022-12-28},
  abstract = {Deep neural networks have proved to be a very effective way to perform classification tasks. They excel when the input data is high dimensional, the relationship between the input and the output is complicated, and the number of labeled training examples is large. But it is hard to explain why a learned network makes a particular classification decision on a particular test case. This is due to their reliance on distributed hierarchical representations. If we could take the knowledge acquired by the neural net and express the same knowledge in a model that relies on hierarchical decisions instead, explaining a particular decision would be much easier. We describe a way of using a trained neural net to create a type of soft decision tree that generalizes better than one learned directly from the training data.},
  pubstate = {preprint},
  version = {1},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found,Artificial Intelligence (cs.AI),Computer Science - Artificial Intelligence,Computer Science - Machine Learning,FOS: Computer and information sciences,Machine Learning (cs.LG),Machine Learning (stat.ML),Statistics - Machine Learning},
  annotation = {478 citations (Semantic Scholar/arXiv) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/UUHAHL3Z/Frosst and Hinton - 2017 - Distilling a Neural Network Into a Soft Decision T.pdf}
}

@inproceedings{gal_Dropout_2016a,
  ids = {gal_Dropout_2016},
  title = {Dropout as a {{Bayesian Approximation}}: {{Representing Model Uncertainty}} in {{Deep Learning}}},
  shorttitle = {Dropout as a {{Bayesian Approximation}}},
  booktitle = {Proc. 33rd {{Int}}. {{Conf}}. {{Mach}}. {{Learn}}.},
  author = {Gal, Yarin and Ghahramani, Zoubin},
  date = {2016-06-11},
  pages = {1050--1059},
  publisher = {{PMLR}},
  issn = {1938-7228},
  url = {https://proceedings.mlr.press/v48/gal16.html},
  urldate = {2023-05-03},
  abstract = {Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs \textendash{} extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout's uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout's uncertainty in deep reinforcement learning.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/UT64AFW7/Gal and Ghahramani - 2016 - Dropout as a Bayesian Approximation Representing .pdf}
}

@thesis{gal_Uncertainty_2016,
  title = {Uncertainty in {{Deep Learning}}},
  author = {Gal, Yarin},
  date = {2016},
  institution = {{University of Cambridge}},
  abstract = {Deep learning has attracted tremendous attention from researchers in various fields ofinformation engineering such as AI, computer vision, and language processing [Kalch-brenner and Blunsom, 2013; Krizhevsky et al., 2012; Mnih et al., 2013], but also frommore traditional sciences such as physics, biology, and manufacturing [Anjos et al., 2015;Baldi et al., 2014; Bergmann et al., 2014]. Neural networks, image processing toolssuch as convolutional neural networks, sequence processing models such as recurrentneural networks, and regularisation tools such as dropout, are used extensively. However,fields such as physics, biology, and manufacturing are ones in which representing modeluncertainty is of crucial importance [Ghahramani, 2015; Krzywinski and Altman, 2013].With the recent shift in many of these fields towards the use of Bayesian uncertainty[Herzog and Ostwald, 2013; Nuzzo, 2014; Trafimow and Marks, 2015], new needs arisefrom deep learning.In this work we develop tools to obtain practical uncertainty estimates in deeplearning, casting recent deep learning tools as Bayesian models without changing eitherthe models or the optimisation. In the first part of this thesis we develop the theoryfor such tools, providing applications and illustrative examples. We tie approximateinference in Bayesian models to dropout and other stochastic regularisation techniques,and assess the approximations empirically. We give example applications arising fromthis connection between modern deep learning and Bayesian modelling such as activelearning of image data and data-efficient deep reinforcement learning. We furtherdemonstrate the tools' practicality through a survey of recent applications making use ofthe suggested techniques in language applications, medical diagnostics, bioinformatics,image processing, and autonomous driving. In the second part of the thesis we explorethe insights stemming from the link between Bayesian modelling and deep learning, andits theoretical implications. We discuss what determines model uncertainty properties,analyse the approximate inference analytically in the linear case, and theoreticallyexamine various priors such as spike and slab priors.},
  pagetotal = {174},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{ganin_Domainadversarial_2017,
  title = {Domain-{{Adversarial Training}} of {{Neural Networks}}},
  author = {Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, Fran\c{c}ois and Marchand, Mario and Lempitsky, Victor},
  date = {2017},
  journaltitle = {Adv. Comput. Vis. Pattern Recognit.},
  issn = {21916594},
  doi = {10.1007/978-3-319-58347-1_10},
  abstract = {We introduce a representation learning approach for domain adaptation, in which data at training and test time come from similar but different distributions. Our approach is directly inspired by the theory on domain adaptation suggesting that, for effective domain transfer to be achieved, predictions must be made based on features that cannot discriminate between the training (source) and test (target) domains. The approach implements this idea in the context of neural network architectures that are trained on labeled data from the source domain and unlabeled data from the target domain (no labeled target-domain data is necessary). As the training progresses, the approach promotes the emergence of features that are (i) discriminative for the main learning task on the source domain and (ii) indiscriminate with respect to the shift between the domains. We show that this adaptation behavior can be achieved in almost any feed-forward model by augmenting it with few standard layers and a new Gradient Reversal Layer. The resulting augmented architecture can be trained using standard backpropagation, and can thus be implemented with little effort using any of the deep learning packages. We demonstrate the success of our approach for image classification, where state-of-the-art domain adaptation performance on standard benchmarks is achieved. We also validate the approach for descriptor learning task in the context of person re-identification application.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Deep learning,Domain adaptation,Image classification,Neural network,Person re-identification,Representation learning,Sentiment analysis,Synthetic data},
  annotation = {5728 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{ganin_Unsupervised_2015,
  title = {Unsupervised {{Domain Adaptation}} by {{Backpropagation}}},
  booktitle = {32nd {{Int}}. {{Conf}}. {{Mach}}. {{Learn}}.},
  author = {Ganin, Yaroslav and Lempitsky, Victor},
  date = {2015},
  abstract = {Top-performing deep architectures are trained on massive amounts of labeled data. In the absence of labeled data for a certain task, domain adaptation often provides an attractive option given that labeled data of similar nature but from a different domain (e.g. synthetic images) are available. Here, we propose a new approach to domain adaptation in deep architectures that can be trained on large amount of labeled data from the source domain and large amount of unlabeled data from the target domain (no labeled target-domain data is necessary). As the training progresses, the approach promotes the emergence of "deep" features that are (i) discriminative for the main learning task on the source domain and (ii) invariant with respect to the shift between the domains. We show that this adaptation behaviour can be achieved in almost any feed-forward model by augmenting it with few standard layers and a simple new gradient reversal layer. The resulting augmented architecture can be trained using standard back-propagation. Overall, the approach can be implemented with little effort using any of the deep-learning packages. The method performs very well in a series of image classification experiments, achieving adaptation effect in the presence of big domain shifts and outperforming previous state-of-the-art on Office datasets.},
  isbn = {978-1-5108-1058-7},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{gao_Computer_2018,
  title = {Computer {{Vision}} in {{Healthcare Applications}}},
  author = {Gao, Junfeng and Yang, Yong and Lin, Pan and Park, Dong Sun},
  date = {2018-03},
  journaltitle = {J Heal. Eng},
  volume = {2018},
  pages = {5157020},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@inproceedings{gao_Multiatlas_2014,
  title = {Multi-{{Atlas Propagation}} via a {{Manifold Graph}} on a {{Database}} of {{Both Labeled}} and {{Unlabeled Images}}},
  booktitle = {Med. {{Imaging}} 2014 {{Comput}}.-{{Aided Diagn}}.},
  author = {Gao, Qinquan and Tong, Tong and Rueckert, Daniel and {PJ}},
  date = {2014-03},
  volume = {9035},
  pages = {90350A},
  publisher = {{International Society for Optics and Photonics}},
  abstract = {We present a framework for multi-atlas based segmentation in situations where we have a small number of segmented atlas images, but a large database of unlabeled images is also available. The novelty lies in the application of graph-based registration on a manifold to the problem of multi-atlas registration. The approach is to place all the images in a learned manifold space and construct a graph connecting near neighbors. Atlases are selected for any new image to be segmented based on the shortest path length along the manifold graph. A multi-scale non-rigid registration takes place via each of the nodes on the graph. The expectation is that by registering via similar images, the likelihood of misregistrations is reduced. Having registered multiple atlases via the graph, patch-based voxel weighted voting takes place to provide the final segmentation. We apply this approach to a set of T2 MRI images of the prostate, which is a notoriously difficult segmentation task. On a set of 25 atlas images and 85 images overall, we see that registration via the manifold graph improves the Dice coefficient from 0:82\$\textbackslash pm\$0:05 to 0:86\$\textbackslash pm\$0:03 and the average symmetrical boundary distance from 2:89\$\textbackslash pm\$0:62mm to 2:47\$\textbackslash pm\$0:51mm. This is a modest but potentially useful improvement in a difficult set of images. It is expected that our approach will provide similar improvement to any multi-atlas segmentation task where a large number of unsegmented images are available.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,labeled and unlabeled im,multi-atlas segmentation}
}

@article{gao_PostProcessing_2020,
  ids = {gao_Postprocessing_2020},
  title = {A {{Post-Processing Scheme}} for the {{Performance Improvement}} of {{Vehicle Detection}} in {{Wide-Area Aerial Imagery}}},
  author = {Gao, Xin},
  date = {2020-04},
  journaltitle = {SIViP},
  volume = {14},
  number = {3},
  pages = {625--633},
  issn = {1863-1703, 1863-1711},
  doi = {10.1007/s11760-019-01592-4},
  url = {http://link.springer.com/10.1007/s11760-019-01592-4},
  urldate = {2023-05-08},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Aerial imagery,Deep learning,Overlap,Post-processing,Segmentation,Vehicle detection},
  annotation = {1 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{gao_Rapamycin_2013,
  ids = {gao13},
  title = {Rapamycin {{Inhibition}} of {{Mtorc1 Reverses Lithium-Induced Proliferation}} of {{Renal Collecting Duct Cells}}},
  author = {Gao, Yang and Romero-Aleshire, Melissa J. and Cai, Qi and Price, Theodore J. and Brooks, Heddwen L.},
  date = {2013-10-15},
  journaltitle = {American Journal of Physiology-Renal Physiology},
  volume = {305},
  number = {8},
  pages = {F1201-F1208},
  issn = {1931-857X, 1522-1466},
  doi = {10.1152/ajprenal.00153.2013},
  url = {https://www.physiology.org/doi/10.1152/ajprenal.00153.2013},
  urldate = {2023-06-03},
  abstract = {Nephrogenic diabetes insipidus (NDI) is the most common renal side effect in patients undergoing lithium therapy for bipolar affective disorders. Approximately 2 million US patients take lithium of whom {$\sim$}50\% will have altered renal function and develop NDI ( 2 , 37 ). Lithium-induced NDI is a defect in the urinary concentrating mechanism. Lithium therapy also leads to proliferation and abundant renal cysts (microcysts), commonly in the collecting ducts of the cortico-medullary region. The mTOR pathway integrates nutrient and mitogen signals to control cell proliferation and cell growth (size) via the mTOR Complex 1 (mTORC1). To address our hypothesis that mTOR activation may be responsible for lithium-induced proliferation of collecting ducts, we fed mice lithium chronically and assessed mTORC1 signaling in the renal medulla. We demonstrate that mTOR signaling is activated in the renal collecting ducts of lithium-treated mice; lithium increased the phosphorylation of rS6 (Ser240/Ser244), p-TSC2 (Thr1462), and p-mTOR (Ser2448). Consistent with our hypothesis, treatment with rapamycin, an allosteric inhibitor of mTOR, reversed lithium-induced proliferation of medullary collecting duct cells and reduced levels of p-rS6 and p-mTOR. Medullary levels of p-GSK3{$\beta$} were increased in the renal medullas of lithium-treated mice and remained elevated following rapamycin treatment. However, mTOR inhibition did not improve lithium-induced NDI and did not restore the expression of collecting duct proteins aquaporin-2 or UT-A1.},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {20 citations (Semantic Scholar/DOI) [2023-06-02]}
}

@article{gao_Reflective_2022,
  title = {Reflective {{Noise Filtering}} of {{Large-Scale Point Cloud Using Transformer}}},
  author = {Gao, Rui and Li, Mengyu and Yang, Seung-Jun and Cho, Kyungeun},
  date = {2022-01-26},
  journaltitle = {Remote Sensing},
  volume = {14},
  number = {3},
  pages = {577},
  issn = {2072-4292},
  doi = {10.3390/rs14030577},
  url = {https://www.mdpi.com/2072-4292/14/3/577},
  urldate = {2022-07-15},
  abstract = {Point clouds acquired with LiDAR are widely adopted in various fields, such as three-dimensional (3D) reconstruction, autonomous driving, and robotics. However, the high-density point cloud of large scenes captured with Lidar usually contains a large number of virtual points generated by the specular reflections of reflective materials, such as glass. When applying such large-scale high-density point clouds, reflection noise may have a significant impact on 3D reconstruction and other related techniques. In this study, we propose a method that uses deep learning and multi-position sensor comparison method to remove noise due to reflections from high-density point clouds in large scenes. The proposed method converts large-scale high-density point clouds into a range image and subsequently uses a deep learning method and multi-position sensor comparison method for noise detection. This alleviates the limitation of the deep learning networks, specifically their inability to handle large-scale high-density point clouds. The experimental results show that the proposed algorithm can effectively detect and remove noise due to reflection.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {2 citations (Semantic Scholar/DOI) [2022-07-18]},
  file = {/Users/personal-macbook/Zotero/storage/9JD66J3D/Gao et al. - 2022 - Reflective Noise Filtering of Large-Scale Point Cl.pdf}
}

@article{garbuio_Artificial_2019,
  title = {Artificial {{Intelligence}} as a {{Growth Engine}} for {{Health Care Startups}}: {{Emerging Business Models}}},
  shorttitle = {Artificial {{Intelligence}} as a {{Growth Engine}} for {{Health Care Startups}}},
  author = {Garbuio, Massimo and Lin, Nidthida},
  date = {2019-02},
  journaltitle = {California Management Review},
  volume = {61},
  number = {2},
  pages = {59--83},
  issn = {0008-1256, 2162-8564},
  doi = {10.1177/0008125618811931},
  url = {http://journals.sagepub.com/doi/10.1177/0008125618811931},
  urldate = {2023-05-10},
  abstract = {The future of health care may change dramatically as entrepreneurs offer solutions that change how we prevent, diagnose, and cure health conditions, using artificial intelligence (AI). This article provides a timely and critical analysis of AI-driven health care startups and identifies emerging business model archetypes that entrepreneurs from around the world are using to bring AI solutions to the marketplace. It identifies areas of value creation for the application of AI in health care and proposes an approach to designing business models for AI health care startups.},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Artificial intelligence,Business models,Disruptive technology,Entrepreneurship,Health care,Innovation},
  annotation = {105 citations (Semantic Scholar/DOI) [2023-05-09]}
}

@thesis{garcia_Noise_2016,
  title = {Noise {{Detection}} in {{Classification problemsLu\'is}}},
  author = {Garcia, Paulo Faina},
  date = {2016},
  institution = {{Institute of Mathematical and Computer Sciences - ICMC-USP}},
  url = {https://www.capes.gov.br/images/stories/download/pct/2017/Teses-Premiadas/Ciencia-da-Computacao-Luis-Paulo-Faina-Garcia.PDF},
  abstract = {In many areas of knowledge, considerable amounts of time have been spent to compre-hend and to treat noisy data, one of the most common problems regarding informationcollection, transmission and storage. These noisy data, when used for training MachineLearning techniques, lead to increased complexity in the induced classification models,higher processing time and reduced predictive power. Treating them in a preprocessingstep may improve the data quality and the comprehension of the problem. This The-sis aims to investigate the use of data complexity measures capable to characterize thepresence of noise in datasets, to develop new efficient noise filtering techniques in such sub-samples of problems of noise identification compared to the state of art and to recommendthe most properly suited techniques or ensembles for a specific dataset by meta-learning.Both artificial and real problem datasets were used in the experimental part of this work.They were obtained from public data repositories and a cooperation project. The evalu-ation was made through the analysis of the effect of artificially generated noise and alsoby the feedback of a domain expert. The reported experimental results show that theinvestigated proposals are promising.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Classification Problems,Machine Learning,Meta-learning.,Noise Detection}
}

@article{ge_Improving_2020,
  title = {Improving {{Multi-Label Chest X-Ray Disease Diagnosis}} by {{Exploiting Disease}} and {{Health Labels Dependencies}}},
  author = {Ge, Zongyuan and Mahapatra, Dwarikanath and Chang, Xiaojun and Chen, Zetao and Chi, Lianhua and Lu, Huimin},
  date = {2020-06-01},
  journaltitle = {Multimed Tools Appl},
  volume = {79},
  number = {21},
  pages = {14889--14902},
  issn = {1573-7721},
  doi = {10.1007/s11042-019-08260-2},
  url = {https://doi.org/10.1007/s11042-019-08260-2},
  urldate = {2022-06-23},
  abstract = {The widely used ChestX-ray14 dataset addresses an important medical image classification problem and has the following caveats: 1) many lung pathologies are visually similar, 2) a variant of multiple diseases including lung cancer, tuberculosis, and pneumonia are present in a single scan at the same time, i.e. multiple labels. Existing literature uses state-of-the-art deep learning models being transfer learned where output neurons of the networks are trained for individual diseases to cater for multiple disease labels in each image. However, most of them don't consider the label relationship explicitly between present and absent classes. In this work we have proposed a pair of novel error functions that can be employed for any deep learning model, Multi-label Softmax Loss (MSML) and Correlation Loss (CorLoss), to specifically address the properties of multiple labels and visually similar data. Moreover, we provide a fine-grained perspective into this problem and use bilinear pooling as an encoding scheme to increase discrimination of the model. The experiments are conducted on the ChestX-ray14 dataset. We first report improvements using our proposed loss with various backbone networks. After that, we extend our experiments to prove the rich disparity being learned by the model with our proposed losses, which can be fused with other models to improve the overall performances.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Chest X-Ray disease recognition,Deep convolutional neural network,Model fusion,Multi-label learning},
  annotation = {22 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/LY7DQA6Z/Ge et al. - 2020 - Improving multi-label chest X-ray disease diagnosi.pdf}
}

@inproceedings{geifman_Selective_2017,
  title = {Selective {{Classification}} for {{Deep Neural Networks}}},
  booktitle = {Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.},
  author = {Geifman, Yonatan and El-Yaniv, Ran},
  date = {2017},
  issn = {10495258},
  abstract = {Selective classification techniques (also known as reject option) have not yet been considered in the context of deep neural networks (DNNs). These techniques can potentially significantly improve DNNs prediction performance by trading-off coverage. In this paper we propose a method to construct a selective classifier given a trained neural network. Our method allows a user to set a desired risk level. At test time, the classifier rejects instances as needed, to grant the desired risk (with high probability). Empirical results over CIFAR and ImageNet convincingly demonstrate the viability of our method, which opens up possibilities to operate DNNs in mission-critical applications. For example, using our method an unprecedented 2\% error in top-5 ImageNet classification can be guaranteed with probability 99.9\%, and almost 60\% test coverage.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{gerig_Nonlinear_1992,
  title = {Nonlinear {{Anisotropic Filtering}} of {{MRI Data}}},
  author = {Gerig, Guido and Kbler, Olaf and Kikinis, Ron and Jolesz, Ferenc A.},
  date = {1992},
  journaltitle = {IEEE Trans. Med. Imaging},
  issn = {1558254X},
  doi = {10.1109/42.141646},
  abstract = {Despite significant improvements in image quality over the past several years, the full exploitation of magnetic resonance image (MRI) data is often limited by low signal-to-noise ratio (SNR) or contrast-to-noise ratio (CNR). In implementing new MR techniques, the criteria of acquisition speed and image quality are usually paramount. To decrease noise during the acquisition either time averaging over repeated measurements or enlarging voxel volume may be employed. However, these methods either substantially increase the overall acquisition time or scan a spatial volume in only coarse intervals. In contrast to acquisition-based noise reduction methods we propose a postprocess based on anisotropic diffusion. Extensions of this new technique support 3-D and multi-echo MRI, incorporating higher spatial and spectral dimensions. The procedure overcomes the major drawbacks of conventional filter methods, namely the blurring of object boundaries and the suppression of fine structural details. The simplicity of the filter algorithm enables an efficient implementation even on small workstations. We demonstrate the efficient noise reduction and sharpening of object boundaries by applying this image processing technique to 2-D and 3-D spin echo and gradient echo MR data. The potential advantages for MRI, diagnosis and computerized analysis are discussed in detail. \textcopyright{} 1992 IEEE},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{geuze_MRbased_2005,
  title = {{{MR-based}} in {{Vivo Hippocampal Volumetrics}}: 1. {{Review}} of {{Methodologies Currently Employed}}},
  author = {Geuze, E. and Vermetten, E. and Bremner, J. D.},
  date = {2005-02},
  journaltitle = {Mol. Psychiatry},
  volume = {10},
  number = {2},
  pages = {147--159},
  doi = {10.1038/sj.mp.4001580},
  abstract = {The advance of neuroimaging techniques has resulted in a burgeoning of studies reporting abnormalities in brain structure and function in a number of neuropsychiatric disorders. Measurement of hippocampal volume has developed as a useful tool in the study of neuropsychiatric disorders. We reviewed the literature and selected all English-language, human subject, data-driven papers on hippocampal volumetry, yielding a database of 423 records. From this database, the methodology of all original manual tracing protocols were studied. These protocols differed in a number of important factors for accurate hippocampal volume determination including magnetic field strength, the number of slices assessed and the thickness of slices, hippocampal orientation correction, volumetric correction, software used, inter-rater reliability, and anatomical boundaries of the hippocampus. The findings are discussed in relation to optimizing determination of hippocampal volume.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{ghafoorian_Location_2017,
  title = {Location {{Sensitive Deep Convolutional Neural Networks}} for {{Segmentation}} of {{White Matter Hyperintensities}}},
  author = {Ghafoorian, Mohsen and Karssemeijer, Nico and Heskes, Tom and Uden, Inge W. M. Van and Sanchez, Clara I. and Litjens, Geert and Leeuw, Frank Erik De and Ginneken, Bram Van and Marchiori, Elena and Platel, Bram},
  date = {2017},
  journaltitle = {Sci. Rep.},
  volume = {7},
  number = {1},
  issn = {20452322},
  doi = {10.1038/s41598-017-05300-5},
  abstract = {The anatomical location of imaging features is of crucial importance for accurate diagnosis in many medical tasks. Convolutional neural networks (CNN) have had huge successes in computer vision, but they lack the natural ability to incorporate the anatomical location in their decision making process, hindering success in some medical image analysis tasks. In this paper, to integrate the anatomical location information into the network, we propose several deep CNN architectures that consider multi-scale patches or take explicit location features while training. We apply and compare the proposed architectures for segmentation of white matter hyperintensities in brain MR images on a large dataset. As a result, we observe that the CNNs that incorporate location information substantially outperform a conventional segmentation method with handcrafted features as well as CNNs that do not integrate location information. On a test set of 50 scans, the best configuration of our networks obtained a Dice score of 0.792, compared to 0.805 for an independent human observer. Performance levels of the machine and the independent human observer were not statistically significantly different (p-value = 0.06).},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{ghafoorian_Transfer_2017,
  title = {Transfer {{Learning}} for {{Domain Adaptation}} in {{MRI}}: {{Application}} in {{Brain Lesion Segmentation}}},
  booktitle = {Med. {{Image Comput}}. {{Comput}}. {{Assist}}. {{Interv}}. - {{MICCAI}} 2017},
  author = {Ghafoorian, Mohsen and Mehrtash, Alireza and Kapur, Tina and Karssemeijer, Nico and Marchiori, Elena and Pesteie, Mehran and Guttmann, Charles R. G. and family=Leeuw, given=Frank-Erik, prefix=de, useprefix=false and Tempany, Clare M. and family=Ginneken, given=Bram, prefix=van, useprefix=false and Fedorov, Andriy and Abolmaesumi, Purang and Platel, Bram and Wells, William M.},
  date = {2017},
  pages = {516--524},
  publisher = {{Springer International Publishing}},
  abstract = {Magnetic Resonance Imaging (MRI) is widely used in routine clinical diagnosis and treatment. However, variations in MRI acquisition protocols result in different appearances of normal and diseased tissue in the images. Convolutional neural networks (CNNs), which have shown to be successful in many medical image analysis tasks, are typically sensitive to the variations in imaging protocols. Therefore, in many cases, networks trained on data acquired with one MRI protocol, do not perform satisfactorily on data acquired with different protocols. This limits the use of models trained with large annotated legacy datasets on a new dataset with a different domain which is often a recurring situation in clinical settings. In this study, we aim to answer the following central questions regarding domain adaptation in medical image analysis: Given a fitted legacy model, (1) How much data from the new domain is required for a decent adaptation of the original network?; and, (2) What portion of the pre-trained model parameters should be retrained given a certain number of the new domain training samples? To address these questions, we conducted extensive experiments in white matter hyperintensity segmentation task. We trained a CNN on legacy MR images of brain and evaluated the performance of the domain-adapted network on the same task with images from a different domain. We then compared the performance of the model to the surrogate scenarios where either the same trained network is used or a new network is trained from scratch on the new dataset. The domain-adapted network tuned only by two training examples achieved a Dice score of 0.63 substantially outperforming a similar network trained on the same set of examples from scratch.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{ghahramani_Multitask_2021,
  title = {Multi-{{Task Deep Learning-Based Survival Analysis}} on the {{Prognosis}} of {{Late AMD Using}} the {{Longitudinal Data}} in {{AREDS}}},
  author = {Ghahramani, Gregory and Brendel, Matthew and Lin, Mingquan and Chen, Qingyu and Keenan, Tiarnan and Chen, Kun and Chew, Emily and Lu, Zhiyong and Peng, Yifan and Wang, Fei},
  date = {2021-09-03},
  pages = {2021.08.26.21262548},
  doi = {10.1101/2021.08.26.21262548},
  url = {https://www.medrxiv.org/content/10.1101/2021.08.26.21262548v1},
  urldate = {2022-04-28},
  abstract = {Age-related macular degeneration (AMD) is the leading cause of vision loss. Some patients experience vision loss over a delayed timeframe, others at a rapid pace. Physicians analyze time-of-visit fundus photographs to predict patient risk of developing late-AMD, the most severe form of AMD. Our study hypothesizes that 1) incorporating historical data improves predictive strength of developing late-AMD and 2) state-of-the-art deep-learning techniques extract more predictive image features than clinicians do. We incorporate longitudinal data from the Age-Related Eye Disease Studies and deep-learning extracted image features in survival settings to predict development of late-AMD. To extract image features, we used multi-task learning frameworks to train convolutional neural networks. Our findings show 1) incorporating longitudinal data improves prediction of late-AMD for clinical standard features, but only the current visit is informative when using complex features and 2) ``deep-features'' are more informative than clinician derived features. We make codes publicly available at https://github.com/bionlplab/AMD\_prognosis\_amia2021.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/274A7HZN/Ghahramani et al. - 2021 - Multi-task deep learning-based survival analysis o.pdf;/Users/personal-macbook/Zotero/storage/W8PMELZE/2021.08.26.21262548v1.html}
}

@article{ghahramani_Personal_2019,
  title = {Personal {{CO2 Bubble}}: {{Context-Dependent Variations}} and {{Wearable Sensors Usability}}},
  shorttitle = {Personal {{Co2 Bubble}}},
  author = {Ghahramani, Ali and Pantelic, Jovan and Vannucci, Matthew and Pistore, Lorenza and Liu, Shichao and Gilligan, Brian and Alyasin, Soheila and Arens, Edward and Kampshire, Kevin and Sternberg, Esther},
  date = {2019-03},
  journaltitle = {Journal of Building Engineering},
  volume = {22},
  pages = {295--304},
  issn = {23527102},
  doi = {10.1016/j.jobe.2018.11.015},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2352710218310969},
  urldate = {2023-05-12},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,CO 2 exposure,Inhalation zone CO 2 concentration,Occupant behavior,Personal indoor air quality,Ubiquitous sensing,Wearable CO 2 sensor},
  annotation = {21 citations (Semantic Scholar/DOI) [2023-05-12]},
  file = {/Users/personal-macbook/Zotero/storage/2BMNRBBT/Ghahramani et al. - 2019 - Personal CO2 bubble Context-dependent variations .pdf}
}

@article{ghesu_Quantifying_2021,
  title = {Quantifying and {{Leveraging Predictive Uncertainty}} for {{Medical Image Assessment}}},
  author = {Ghesu, Florin C. and Georgescu, Bogdan and Mansoor, Awais and Yoo, Youngjin and Gibson, Eli and Vishwanath, R. S. and Balachandran, Abishek and Balter, James M. and Cao, Yue and Singh, Ramandeep and Digumarthy, Subba R. and Kalra, Mannudeep K. and Grbic, Sasa and Comaniciu, Dorin},
  date = {2021-02-01},
  journaltitle = {Medical Image Analysis},
  volume = {68},
  pages = {101855},
  issn = {1361-8415},
  doi = {10.1016/j.media.2020.101855},
  url = {https://www.sciencedirect.com/science/article/pii/S136184152030219X},
  urldate = {2022-06-14},
  abstract = {The interpretation of medical images is a challenging task, often complicated by the presence of artifacts, occlusions, limited contrast and more. Most notable is the case of chest radiography, where there is a high inter-rater variability in the detection and classification of abnormalities. This is largely due to inconclusive evidence in the data or subjective definitions of disease appearance. An additional example is the classification of anatomical views based on 2D Ultrasound images. Often, the anatomical context captured in a frame is not sufficient to recognize the underlying anatomy. Current machine learning solutions for these problems are typically limited to providing probabilistic predictions, relying on the capacity of underlying models to adapt to limited information and the high degree of label noise. In practice, however, this leads to overconfident systems with poor generalization on unseen data. To account for this, we propose a system that learns not only the probabilistic estimate for classification, but also an explicit uncertainty measure which captures the confidence of the system in the predicted output. We argue that this approach is essential to account for the inherent ambiguity characteristic of medical images from different radiologic exams including computed radiography, ultrasonography and magnetic resonance imaging. In our experiments we demonstrate that sample rejection based on the predicted uncertainty can significantly improve the ROC-AUC for various tasks, e.g., by 8\% to 0.91 with an expected rejection rate of under 25\% for the classification of different abnormalities in chest radiographs. In addition, we show that using uncertainty-driven bootstrapping to filter the training data, one can achieve a significant increase in robustness and accuracy. Finally, we present a multi-reader study showing that the predictive uncertainty is indicative of reader errors.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Belief estimation,Building user trust,Classification uncertainty,Predictive uncertainty quantification,Sample rejection,Theory of evidence},
  file = {/Users/personal-macbook/Zotero/storage/8FH7I5LB/Ghesu et al. - 2021 - Quantifying and leveraging predictive uncertainty .pdf}
}

@inproceedings{ghosh_Who_2011,
  title = {Who {{Moderates}} the {{Moderators}}?: {{Crowdsourcing Abuse Detection}} in {{User-Generated Content}}},
  shorttitle = {Who {{Moderates}} the {{Moderators}}?},
  booktitle = {Proc. 12th {{ACM Conf}}. {{Electron}}. {{Commer}}.},
  author = {Ghosh, Arpita and Kale, Satyen and McAfee, Preston},
  date = {2011},
  pages = {167},
  publisher = {{ACM Press}},
  location = {{San Jose, California, USA}},
  doi = {10.1145/1993574.1993599},
  url = {http://portal.acm.org/citation.cfm?doid=1993574.1993599},
  urldate = {2022-12-20},
  eventtitle = {Proceedings of the 12th {{ACM Conference}} on {{Electronic Commerce}}},
  isbn = {978-1-4503-0261-6},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {166 citations (Semantic Scholar/DOI) [2022-12-20]},
  file = {/Users/personal-macbook/Zotero/storage/9Z9PUQEF/Ghosh et al. - 2011 - Who moderates the moderators crowdsourcing abuse .pdf;/Users/personal-macbook/Zotero/storage/Z7Z3IJFS/1993574.html}
}

@article{gichoya_AI_2022,
  title = {{{AI Recognition}} of {{Patient Race}} in {{Medical Imaging}}: {{A Modelling Study}}},
  shorttitle = {Ai {{Recognition}} of {{Patient Race}} in {{Medical Imaging}}},
  author = {Gichoya, Judy Wawira and Banerjee, Imon and Bhimireddy, Ananth Reddy and Burns, John L and Celi, Leo Anthony and Chen, Li-Ching and Correa, Ramon and Dullerud, Natalie and Ghassemi, Marzyeh and Huang, Shih-Cheng and Kuo, Po-Chih and Lungren, Matthew P and Palmer, Lyle J and Price, Brandon J and Purkayastha, Saptarshi and Pyrros, Ayis T and Oakden-Rayner, Lauren and Okechukwu, Chima and Seyyed-Kalantari, Laleh and Trivedi, Hari and Wang, Ryan and Zaiman, Zachary and Zhang, Haoran},
  date = {2022-06-01},
  journaltitle = {The Lancet Digital Health},
  volume = {4},
  number = {6},
  pages = {e406-e414},
  issn = {2589-7500},
  doi = {10.1016/S2589-7500(22)00063-2},
  url = {https://www.sciencedirect.com/science/article/pii/S2589750022000632},
  urldate = {2022-11-18},
  abstract = {Background Previous studies in medical imaging have shown disparate abilities of artificial intelligence (AI) to detect a person's race, yet there is no known correlation for race on medical imaging that would be obvious to human experts when interpreting the images. We aimed to conduct a comprehensive evaluation of the ability of AI to recognise a patient's racial identity from medical images. Methods Using private (Emory CXR, Emory Chest CT, Emory Cervical Spine, and Emory Mammogram) and public (MIMIC-CXR, CheXpert, National Lung Cancer Screening Trial, RSNA Pulmonary Embolism CT, and Digital Hand Atlas) datasets, we evaluated, first, performance quantification of deep learning models in detecting race from medical images, including the ability of these models to generalise to external environments and across multiple imaging modalities. Second, we assessed possible confounding of anatomic and phenotypic population features by assessing the ability of these hypothesised confounders to detect race in isolation using regression models, and by re-evaluating the deep learning models by testing them on datasets stratified by these hypothesised confounding variables. Last, by exploring the effect of image corruptions on model performance, we investigated the underlying mechanism by which AI models can recognise race. Findings In our study, we show that standard AI deep learning models can be trained to predict race from medical images with high performance across multiple imaging modalities, which was sustained under external validation conditions (x-ray imaging [area under the receiver operating characteristics curve (AUC) range 0{$\cdot$}91\textendash 0{$\cdot$}99], CT chest imaging [0{$\cdot$}87\textendash 0{$\cdot$}96], and mammography [0{$\cdot$}81]). We also showed that this detection is not due to proxies or imaging-related surrogate covariates for race (eg, performance of possible confounders: body-mass index [AUC 0{$\cdot$}55], disease distribution [0{$\cdot$}61], and breast density [0{$\cdot$}61]). Finally, we provide evidence to show that the ability of AI deep learning models persisted over all anatomical regions and frequency spectrums of the images, suggesting the efforts to control this behaviour when it is undesirable will be challenging and demand further study. Interpretation The results from our study emphasise that the ability of AI deep learning models to predict self-reported race is itself not the issue of importance. However, our finding that AI can accurately predict self-reported race, even from corrupted, cropped, and noised medical images, often when clinical experts cannot, creates an enormous risk for all model deployments in medical imaging. Funding National Institute of Biomedical Imaging and Bioengineering, MIDRC grant of National Institutes of Health, US National Science Foundation, National Library of Medicine of the National Institutes of Health, and Taiwan Ministry of Science and Technology},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {33 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/CJ6SZ5PX/Gichoya et al. - 2022 - AI recognition of patient race in medical imaging.pdf;/Users/personal-macbook/Zotero/storage/5373VEY7/S2589750022000632.html}
}

@report{gill_Improving_2017,
  title = {Improving {{Diagnostic Pathways}} for {{Patients With Suspected Lung Cancer}}: {{Final Report}}},
  author = {Gill, B},
  date = {2017},
  institution = {{ACE Lung Cancer Pathway Cluster}},
  url = {https://www.macmillan.org.uk/_images/ACE-Lung-Pathways-final-report-v1_tcm9-310170.pdf},
  urldate = {2019-01-14},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{gilman_Karen_2001,
  title = {Karen {{Horney}}, {{M}}.{{D}}., 1885-1952},
  author = {Gilman, S. L.},
  date = {2001-08},
  journaltitle = {Am J Psychiatry},
  volume = {158},
  number = {8},
  eprint = {11481151},
  eprinttype = {pmid},
  pages = {1205},
  issn = {0002-953X},
  doi = {10.1176/appi.ajp.158.8.1205},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Berlin,Feminism,{History, 20th Century},New York City,Psychoanalysis},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{girshick_RegionBased_2016,
  title = {Region-{{Based Convolutional Networks}} for {{Accurate Object Detection}} and {{Segmentation}}},
  author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
  date = {2016-01-01},
  journaltitle = {IEEE Trans. Pattern Anal. Mach. Intell.},
  volume = {38},
  number = {1},
  pages = {142--158},
  issn = {0162-8828, 2160-9292},
  doi = {10.1109/TPAMI.2015.2437384},
  url = {http://ieeexplore.ieee.org/document/7112511/},
  urldate = {2023-01-11},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {1753 citations (Semantic Scholar/DOI) [2023-01-11]},
  file = {/Users/personal-macbook/Zotero/storage/ME6C27RL/Girshick et al. - 2015 - Region-based convolutional networks for accurate o.pdf;/Users/personal-macbook/Zotero/storage/PV8YYS7Y/7112511.html}
}

@article{glaister_Thalamus_2017,
  title = {Thalamus {{Segmentation Using Multi-Modal Feature Classification}}: {{Validation}} and {{Pilot Study}} of an {{Age-Matched Cohort}}},
  shorttitle = {Thalamus {{Segmentation Using Multi-Modal Feature Classification}}},
  author = {Glaister, Jeffrey and Carass, Aaron and NessAiver, Tziona and Stough, Joshua V. and Saidha, Shiv and Calabresi, Peter A. and Prince, Jerry L.},
  date = {2017-09},
  journaltitle = {NeuroImage},
  volume = {158},
  pages = {430--440},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2017.06.047},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811917305189},
  urldate = {2023-05-28},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Diffusion MRI,Magnetic resonance imaging,Thalamu,Thalamus segmentation},
  annotation = {22 citations (Semantic Scholar/DOI) [2023-05-28]},
  file = {/Users/personal-macbook/Zotero/storage/5JCZGZVN/Glaister et al. - 2017 - Thalamus segmentation using multi-modal feature cl.pdf}
}

@inproceedings{glaister_thalamusparcellationusingmultimodalfeatureclassificationthalamicnucleipriors_2016,
  ids = {glaister_Thalamus_2016},
  title = {Thalamus {{Parcellation Using Multi-Modal Feature Classification}} and {{Thalamic Nuclei Priors}}},
  author = {Glaister, Jeffrey and Carass, Aaron and Stough, Joshua V. and Calabresi, Peter A. and Prince, Jerry L.},
  editor = {Styner, Martin A. and Angelini, Elsa D.},
  date = {2016-03-21},
  pages = {97843J},
  location = {{San Diego, California, United States}},
  doi = {10.1117/12.2216987},
  url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2216987},
  urldate = {2023-05-28},
  eventtitle = {{{SPIE Medical Imaging}}},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Diffusion MRI,machine learning,magnetic resonanc},
  annotation = {14 citations (Semantic Scholar/DOI) [2023-05-28]},
  file = {/Users/personal-macbook/Zotero/storage/8YJ58V8Y/Glaister et al. - 2016 - Thalamus parcellation using multi-modal feature cl.pdf}
}

@article{glikson_Human_2020,
  title = {Human {{Trust}} in {{Artificial Intelligence}}: {{Review}} of {{Empirical Research}}},
  author = {Glikson, Ella and Woolley, Anita Williams},
  date = {2020},
  journaltitle = {Acad. Manag. Ann.},
  issn = {1941-6520},
  doi = {10.5465/annals.2018.0057},
  abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein-protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-{$\alpha$}-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD {$\leq$} 2.0 \AA{} for the interface backbone atoms) increased from 21\% with default Glide SP settings to 58\% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63\% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40\% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {327 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{glockner_Irrational_2016,
  title = {The {{Irrational Hungry Judge Effect Revisited}}: {{Simulations Reveal That}} the {{Magnitude}} of the {{Effect Is Overestimated}}},
  author = {Gl\"ockner, Andreas},
  date = {2016},
  journaltitle = {Judgm. Decis. Mak.},
  issn = {19302975},
  doi = {10.1017/S1930297500004812},
  abstract = {Danziger, Levav and Avnaim-Pesso (2011) analyzed legal rulings of Israeli parole boards concerning the effect of serial order in which cases are presented within ruling sessions. They found that the probability of a favorable decision drops from about 65\% to almost 0\% from the first ruling to the last ruling within each session and that the rate of favorable rulings returns to 65\% in a session following a food break. The authors argue that these findings provide support for extraneous factors influencing judicial decisions and cautiously speculate that the effect might be driven by mental depletion. A simulation shows that the observed influence of order can be alternatively explained by a statistical artifact resulting from favorable rulings taking longer than unfavorable ones. An effect of similar magnitude would be produced by a (hypothetical) rational judge who plans ahead minimally and ends a session instead of starting cases that he or she assumes will take longer directly before the break. One methodological detail further increased the magnitude of the artifact and generates it even without assuming any foresight concerning the upcoming case. Implications for this article are discussed and the increased application of simulations to identify nonobvious rational explanations is recommended.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Decision making,Legal realism,Mental depletion,Methods,Rationality}
}

@article{gohagan_Prostate_2000,
  ids = {gohagan_prostatelungcolorectalovarianplcocancerscreeningtrialnationalcancerinstitutehistoryorganizationstatus_2000a},
  title = {The {{Prostate}}, {{Lung}}, {{Colorectal}} and {{Ovarian}} ({{PLCO}}) {{Cancer Screening Trial}} of the {{National Cancer Institute}}: {{History}}, Organization, and Status},
  shorttitle = {The {{Prostate}}, {{Lung}}, {{Colorectal}} and {{Ovarian}} ({{PLCO}}) {{Cancer Screening Trial}} of the {{National Cancer Institute}}},
  author = {Gohagan, John K. and Prorok, Philip C. and Hayes, Richard B. and Kramer, Barnett-S.},
  date = {2000-12},
  journaltitle = {Controlled Clinical Trials},
  volume = {21},
  number = {6},
  pages = {251S-272S},
  issn = {01972456},
  doi = {10.1016/S0197-2456(00)00097-0},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0197245600000970},
  urldate = {2023-06-18},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {497 citations (Semantic Scholar/DOI) [2023-06-17]}
}

@inproceedings{goldberger_Efficient_2003,
  title = {An {{Efficient Image Similarity Measure Based}} on {{Approximations}} of {{KL-divergence Between Two Gaussian Mixtures}}},
  booktitle = {Proc. {{IEEE Int}}. {{Conf}}. {{Comput}}. {{Vis}}.},
  author = {Goldberger, Jacob and Gordon, Shiri and Greenspan, Hayit},
  date = {2003},
  doi = {10.1109/iccv.2003.1238387},
  abstract = {In this work we present two new methods for approximating the Kullback-Liebler (KL) divergence between two mixtures of Gaussians. The first method is based on matching between the Gaussian elements of the two Gaussian mixture densities. The second method is based on the unscented transform. The proposed methods are utilized for image retrieval tasks. Continuous probabilistic image modeling based on mixtures of Gaussians together with KL measure for image similarity, can be used for image retrieval tasks with remarkable performance. The efficiency and the performance of the KL approximation methods proposed are demonstrated on both simulated data and real image data sets. The experimental results indicate that our proposed approximations outperform previously suggested methods.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {470 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{gondara_Medical_2016,
  title = {Medical {{Image Denoising Using Convolutional Denoising Autoencoders}}},
  author = {Gondara, Lovedeep},
  date = {2016-08},
  abstract = {Image denoising is an important pre-processing step in medical image analysis. Different algorithms have been proposed in past three decades with varying denoising performances. More recently, having outperformed all conventional methods, deep learning based models have shown a great promise. These methods are however limited for requirement of large training sample size and high computational costs. In this paper we show that using small sample size, denoising autoencoders constructed using convolutional layers can be used for efficient denoising of medical images. Heterogeneous images can be combined to boost sample size for increased denoising performance. Simplest of networks can reconstruct images with corruption levels so high that noise and signal are not differentiable to human eye.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@inproceedings{gong_Geodesic_2012,
  title = {Geodesic {{Flow Kernel}} for {{Unsupervised Domain Adaptation}}},
  booktitle = {Proc. {{IEEE Comput}}. {{Soc}}. {{Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}.},
  author = {Gong, Boqing and Shi, Yuan and Sha, Fei and Grauman, Kristen},
  date = {2012},
  issn = {10636919},
  doi = {10.1109/CVPR.2012.6247911},
  abstract = {In real-world applications of visual recognition, many factors such as pose, illumination, or image quality can cause a significant mismatch between the source domain on which classifiers are trained and the target domain to which those classifiers are applied. As such, the classifiers often perform poorly on the target domain. Domain adaptation techniques aim to correct the mismatch. Existing approaches have concentrated on learning feature representations that are invariant across domains, and they often do not directly exploit low-dimensional structures that are intrinsic to many vision datasets. In this paper, we propose a new kernel-based method that takes advantage of such structures. Our geodesic flow kernel models domain shift by integrating an infinite number of subspaces that characterize changes in geometric and statistical properties from the source to the target domain. Our approach is computationally advantageous, automatically inferring important algorithmic parameters without requiring extensive cross-validation or labeled data from either domain. We also introduce a metric that reliably measures the adaptability between a pair of source and target domains. For a given target domain and several source domains, the metric can be used to automatically select the optimal source domain to adapt and avoid less desirable ones. Empirical studies on standard datasets demonstrate the advantages of our approach over competing methods. \textcopyright{} 2012 IEEE.},
  isbn = {978-1-4673-1226-4},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {2050 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@book{goodfellow_Deep_2016,
  title = {Deep {{Learning}}},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  date = {2016-11},
  publisher = {{MIT Press}},
  abstract = {An introduction to a broad range of topics in deep learning, covering mathematical and conceptual background, deep learning techniques used in industry, and research perspectives.``Written by three experts in the field, Deep Learning is the only comprehensive book on the subject.''\textemdash Elon Musk, cochair of OpenAI; cofounder and CEO of Tesla and SpaceXDeep learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning. The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and videogames. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models. Deep Learning can be used by undergraduate or graduate students planning careers in either industry or research, and by software engineers who want to begin using deep learning in their products or platforms. A website offers supplementary material for both readers and instructors.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{goodfellow_Explaining_2015,
  title = {Explaining and {{Harnessing Adversarial Examples}}},
  booktitle = {3rd {{Int}}. {{Conf}}. {{Learn}}. {{Represent}}. {{ICLR}} 2015 - {{Conf}}. {{Track Proc}}.},
  author = {Goodfellow, Ian J. and Shlens, Jonathon and Szegedy, Christian},
  date = {2015},
  abstract = {Several machine learning models, including neural networks, consistently misclassify adversarial examples\textemdash inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that the perturbed input results in the model outputting an incorrect answer with high confidence. Early attempts at explaining this phenomenon focused on nonlinearity and overfitting. We argue instead that the primary cause of neural networks' vulnerability to adversarial perturbation is their linear nature. This explanation is supported by new quantitative results while giving the first explanation of the most intriguing fact about them: their generalization across architectures and training sets. Moreover, this view yields a simple and fast method of generating adversarial examples. Using this approach to provide examples for adversarial training, we reduce the test set error of a maxout network on the MNIST dataset.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@inproceedings{goodfellow_Generative_2014,
  title = {Generative {{Adversarial Nets}}},
  booktitle = {Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.},
  author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  date = {2014},
  issn = {10495258},
  abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to \textsuperscript{1}/{$<$}inf{$>$}2{$<$}/inf{$>$} everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@inproceedings{gortler_Neo_2022,
  title = {Neo: {{Generalizing Confusion Matrix Visualization}} to {{Hierarchical}} and {{Multi-Output Labels}}},
  shorttitle = {Neo},
  booktitle = {{{CHI Conf}}. {{Hum}}. {{Factors Comput}}. {{Syst}}.},
  author = {G\"ortler, Jochen and Hohman, Fred and Moritz, Dominik and Wongsuphasawat, Kanit and Ren, Donghao and Nair, Rahul and Kirchner, Marc and Patel, Kayur},
  date = {2022-04-29},
  pages = {1--13},
  publisher = {{ACM}},
  location = {{New Orleans LA USA}},
  doi = {10.1145/3491102.3501823},
  url = {https://dl.acm.org/doi/10.1145/3491102.3501823},
  urldate = {2023-02-28},
  eventtitle = {{{CHI}} '22: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9157-3},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {10 citations (Semantic Scholar/DOI) [2023-02-28]},
  file = {/Users/personal-macbook/Zotero/storage/YK9PQ5S4/Görtler et al. - 2022 - Neo Generalizing Confusion Matrix Visualization t.pdf}
}

@article{goyal_Clinical_2020,
  title = {Clinical {{Characteristics}} of {{Covid-19}} in {{New York City}}},
  author = {Goyal, Parag and Choi, Justin J. and Pinheiro, Laura C. and Schenck, Edward J. and Chen, Ruijun and Jabri, Assem and Satlin, Michael J. and Campion, Thomas R. and Nahid, Musarrat and Ringel, Joanna B. and Hoffman, Katherine L. and Alshak, Mark N. and Li, Han A. and Wehmeyer, Graham T. and Rajan, Mangala and Reshetnyak, Evgeniya and Hupert, Nathaniel and Horn, Evelyn M. and Martinez, Fernando J. and Gulick, Roy M. and Safford, Monika M.},
  date = {2020},
  journaltitle = {N. Engl. J. Med.},
  eprint = {32302078},
  eprinttype = {pmid},
  issn = {0028-4793},
  doi = {10.1056/nejmc2010419},
  abstract = {Covid-19 in New York City In this series of 393 consecutive patients admitted with Covid-19 to two New York City hospitals from March 3 to March 27, a third of patients received invasive mechanical...},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {1773 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{graham_HoVerNet_2018,
  title = {{{HoVer-Net}}: {{Simultaneous Segmentation}} and {{Classification}} of {{Nuclei}} in {{Multi-Tissue Histology Images}}},
  author = {Graham, Simon and Vu, Quoc Dang and Raza, Shan E. Ahmed and Azam, Ayesha and Tsang, Yee Wah and Kwak, Jin Tae and Rajpoot, Nasir},
  date = {2018-12},
  abstract = {Nuclear segmentation and classification within Haematoxylin \& Eosin stained histology images is a fundamental prerequisite in the digital pathology work-flow. The development of automated methods for nuclear segmentation and classification enables the quantitative analysis of tens of thousands of nuclei within a whole-slide pathology image, opening up possibilities of further analysis of large-scale nuclear morphometry. However, automated nuclear segmentation and classification is faced with a major challenge in that there are several different types of nuclei, some of them exhibiting large intra-class variability such as the tumour cells. Additionally, some of the nuclei are often clustered together. To address these challenges, we present a novel convolutional neural network for simultaneous nuclear segmentation and classification that leverages the instance-rich information encoded within the vertical and horizontal distances of nuclear pixels to their centres of mass. These distances are then utilised to separate clustered nuclei, resulting in an accurate segmentation, particularly in areas with overlapping instances. Then for each segmented instance, the network predicts the type of nucleus via a devoted up-sampling branch. We demonstrate state-of-the-art performance compared to other methods on multiple independent multi-tissue histology image datasets. As part of this work, we introduce a new dataset of Haematoxylin \& Eosin stained colorectal adenocarcinoma image tiles, containing 24,319 exhaustively annotated nuclei with associated class labels.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found,Computational pathology,Deep learning,Nuclear cl}
}

@article{gray_logistic_2021,
  ids = {gray_logisticregressionveilimprecisedata_2021a},
  title = {Logistic {{Regression Through}} the {{Veil}} of {{Imprecise Data}}},
  author = {Gray, Nicholas and Ferson, Scott},
  date = {2021},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.2106.00492},
  url = {https://arxiv.org/abs/2106.00492},
  urldate = {2023-05-18},
  abstract = {Logistic regression is an important statistical tool for assessing the probability of an outcome based upon some predictive variables. Standard methods can only deal with precisely known data, however many datasets have uncertainties which traditional methods either reduce to a single point or completely disregarded. In this paper we show that it is possible to include these uncertainties by considering an imprecise logistic regression model using the set of possible models that can be obtained from values from within the intervals. This has the advantage of clearly expressing the epistemic uncertainty removed by traditional methods.},
  version = {2},
  keywords = {\#nosource,FOS: Computer and information sciences,Machine Learning (stat.ML),Methodology (stat.ME)},
  annotation = {0 citations (Semantic Scholar/arXiv) [2023-05-17]}
}

@article{greenberg_Cerebral_2009,
  title = {Cerebral {{Microbleeds}}: {{A Guide}} to {{Detection}} and {{Interpretation}}},
  author = {Greenberg, Steven M. and Vernooij, Meike W. and Cordonnier, Charlotte and Viswanathan, Anand and Salman, Rustam Al-Shahi and Warach, Steven and Launer, Lenore J. and Buchem, Mark A. Van and Breteler, Monique Mb and Group, Microbleed Study},
  date = {2009-02},
  journaltitle = {Lancet Neurol.},
  volume = {8},
  number = {2},
  pages = {165--174},
  doi = {10.1016/S1474-4422(09)70013-4},
  abstract = {Cerebral microbleeds (CMBs) are increasingly recognised neuroimaging findings in individuals with cerebrovascular disease and dementia, and in normal ageing. There has been substantial progress in the understanding of CMBs in recent years, particularly in the development of newer MRI methods for the detection of CMBs and the application of these techniques to population-based samples of elderly people. In this Review, we focus on these recent developments and their effects on two main questions: how CMBs are detected, and how CMBs should be interpreted. The number of CMBs detected depends on MRI characteristics, such as pulse sequence, sequence parameters, spatial resolution, magnetic field strength, and image post-processing, emphasising the importance of taking into account MRI technique in the interpretation of study results. Recent investigations with sensitive MRI techniques have indicated a high prevalence of CMBs in community-dwelling elderly people. We propose a procedural guide for identification of CMBs and suggest possible future approaches for elucidating the role of these common lesions as markers for, and contributors to, small-vessel brain disease.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {1419 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@book{greenspan_UNSURE_2019,
  title = {{{UNSURE Proceeding MIT Book}} of {{All Articles Published}} 2019},
  editor = {Greenspan, Hayit and Tanno, Ryutaro and Erdt, Marius and Arbel, Tal and Baumgartner, Christian and Dalca, Adrian and Sudre, Carole H. and Wells, William M. and Drechsler, Klaus and Linguraru, Marius George and Laura, Cristina Oyarzun and Shekhar, Raj and Wesarg, Stefan and Ballester, Miguel \'Angel Gonz\'alez},
  date = {2019},
  publisher = {{Springer, Cham}},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{gringel_Optimized_2009,
  title = {Optimized {{High-Resolution Mapping}} of {{Magnetization Transfer}} ({{Mt}}) at 3 {{Tesla}} for {{Direct Visualization}} of {{Substructures}} of the {{Human Thalamus}} in {{Clinically Feasible Measurement Time}}},
  author = {Gringel, Tabea and Schulz-Schaeffer, Walter and Elolf, Erck and Fr\"olich, Andreas and Dechent, Peter and Helms, Gunther},
  date = {2009-06},
  journaltitle = {J. Magn. Reson. Imaging},
  volume = {29},
  number = {6},
  pages = {1285--1292},
  doi = {10.1002/jmri.21756},
  abstract = {PURPOSE: To optimize contrast-to-noise and spatial resolution of a FLASH-based magnetization transfer (MT) protocol for visualization of substructures in human thalamus. MATERIALS AND METHODS: Healthy adults were examined at 3 Tesla with a three-dimensional (3D) spoiled gradient-echo sequence. The signal-to-noise ratio (SNR) was increased by averaging eight bipolar echo acquisitions (mean echo time = 12.3 ms; bandwidth = 370 Hz/pixel). Three isotropic datasets with different weighting (proton density: flip angle/repetition time = 7 degrees /30 ms; T(1): 20 degrees /30 ms and MT: 10 degrees /48 ms, Gaussian MT prepulse) yielded maps of T(1), signal amplitude, MT ratio and MT saturation for comparison to MP-RAGE images. Measuring time was 23 min using partial k-space acquisition. First, the SNR of MT saturation maps in thalamus was optimized by means of the excitation flip angle. Then, noise and partial volume effects were traded off by means of the resolution. Finally, the contrast within the thalamus and to adjacent structures was compared between different maps. RESULTS: The optimized MT saturation maps at 0.95 mm isotropic resolution provided the highest contrast. It was most prominent between structures of high axonal content (internal medullary lamina, ventral nuclei) and those containing predominantly neuronal somata (pulvinar, mediodorsal thalamus, geniculate bodies). CONCLUSION: Semiquantitative MT saturation maps provide an enhanced intra-thalamic contrast. The borders and nuclear groups of the thalamus are reliably delineated; individual assignment of singular nuclei seems feasible.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{guan_Clinical_2020,
  title = {Clinical {{Characteristics}} of {{Coronavirus Disease}} 2019 in {{China}}},
  author = {Guan, W. and Ni, Z. and Hu, Yu and Liang, W. and Ou, C. and He, J. and Liu, L. and Shan, H. and Lei, C. and Hui, D. S. C. and Du, B. and Li, L. and Zeng, G. and Yuen, K. Y. and Chen, R. and Tang, C. and Wang, T. and Chen, P. and Xiang, J. and Li, S. and Wang, Jin Lin and Liang, Z. and Peng, Y. and Wei, L. and Liu, Y. and Hu, Ya Hua and Peng, P. and Wang, Jian Ming and Liu, J. and Chen, Z. and Li, G. and Zheng, Z. and Qiu, S. and Luo, J. and Ye, C. and Zhu, S. and Zhong, N.},
  date = {2020},
  journaltitle = {N. Engl. J. Med.},
  eprint = {32109013},
  eprinttype = {pmid},
  issn = {15334406},
  doi = {10.1056/NEJMoa2002032},
  abstract = {BACKGROUND Since December 2019, when coronavirus disease 2019 (Covid-19) emerged in Wuhan city and rapidly spread throughout China, data have been needed on the clinical characteristics of the affected patients. METHODS We extracted data regarding 1099 patients with laboratory-confirmed Covid-19 from 552 hospitals in 30 provinces, autonomous regions, and municipalities in mainland China through January 29, 2020. The primary composite end point was admission to an intensive care unit (ICU), the use of mechanical ventilation, or death. RESULTS The median age of the patients was 47 years; 41.9\% of the patients were female. The primary composite end point occurred in 67 patients (6.1\%), including 5.0\% who were admitted to the ICU, 2.3\% who underwent invasive mechanical ventilation, and 1.4\% who died. Only 1.9\% of the patients had a history of direct contact with wildlife. Among nonresidents of Wuhan, 72.3\% had contact with residents of Wuhan, including 31.3\% who had visited the city. The most common symptoms were fever (43.8\% on admission and 88.7\% during hospitalization) and cough (67.8\%). Diarrhea was uncommon (3.8\%). The median incubation period was 4 days (interquartile range, 2 to 7). On admission, ground-glass opacity was the most common radiologic finding on chest computed tomography (CT) (56.4\%). No radiographic or CT abnormality was found in 157 of 877 patients (17.9\%) with nonsevere disease and in 5 of 173 patients (2.9\%) with severe disease. Lymphocytopenia was present in 83.2\% of the patients on admission. CONCLUSIONS During the first 2 months of the current outbreak, Covid-19 spread rapidly throughout China and caused varying degrees of illness. Patients often presented without fever, and many did not have abnormal radiologic findings.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {9986 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@online{guan_Diagnose_2018,
  title = {Diagnose {{Like}} a {{Radiologist}}: {{Attention Guided Convolutional Neural Network}} for {{Thorax Disease Classification}}},
  shorttitle = {Diagnose like a {{Radiologist}}},
  author = {Guan, Qingji and Huang, Yaping and Zhong, Zhun and Zheng, Zhedong and Zheng, Liang and Yang, Yi},
  date = {2018},
  doi = {10.48550/arXiv.1801.09927},
  url = {https://arxiv.org/abs/1801.09927},
  urldate = {2022-11-21},
  abstract = {This paper considers the task of thorax disease classification on chest X-ray images. Existing methods generally use the global image as input for network learning. Such a strategy is limited in two aspects. 1) A thorax disease usually happens in (small) localized areas which are disease specific. Training CNNs using global image may be affected by the (excessive) irrelevant noisy areas. 2) Due to the poor alignment of some CXR images, the existence of irregular borders hinders the network performance. In this paper, we address the above problems by proposing a three-branch attention guided convolution neural network (AG-CNN). AG-CNN 1) learns from disease-specific regions to avoid noise and improve alignment, 2) also integrates a global branch to compensate the lost discriminative cues by local branch. Specifically, we first learn a global CNN branch using global images. Then, guided by the attention heat map generated from the global branch, we inference a mask to crop a discriminative region from the global image. The local region is used for training a local CNN branch. Lastly, we concatenate the last pooling layers of both the global and local branches for fine-tuning the fusion branch. The Comprehensive experiment is conducted on the ChestX-ray14 dataset. We first report a strong global baseline producing an average AUC of 0.841 with ResNet-50 as backbone. After combining the local cues with the global information, AG-CNN improves the average AUC to 0.868. While DenseNet-121 is used, the average AUC achieves 0.871, which is a new state of the art in the community.},
  pubstate = {preprint},
  version = {1},
  keywords = {⛔ No INSPIRE recid found,Computer Science - Computer Vision and Pattern Recognition,Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences},
  annotation = {214 citations (Semantic Scholar/arXiv) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/AXD7I5YX/Guan et al. - 2018 - Diagnose like a Radiologist Attention Guided Conv.pdf;/Users/personal-macbook/Zotero/storage/IJTI5NRX/1801.html}
}

@article{gudbjartsson_Rician_1995,
  title = {The {{Rician Distribution}} of {{Noisy Mri Data}}},
  author = {Gudbjartsson, H\'aKon and Patz, Samuel},
  date = {1995-12},
  journaltitle = {Magn. Reson. Med.},
  volume = {34},
  number = {6},
  eprint = {8598820},
  eprinttype = {pmid},
  pages = {910--914},
  issn = {15222594},
  doi = {10.1002/mrm.1910340618},
  url = {https://pubmed.ncbi.nlm.nih.gov/8598820 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2254141/},
  abstract = {The image intensity in magnetic resonance magnitude images in the presence of noise is shown to be governed by a Rician distribution. Low signal intensities (SNR {$<$} 2) are therefore biased due to the noise. it is shown how the underlying noise can be estimated from the images and a simple correction scheme is provided to reduce the bias. the noise characteristics in phase images are also studied and shown to be very different from those of the magnitude images. Common to both, however, is that the noise distributions are nearly Gaussian for SNR larger than two. Copyright \textcopyright{} 1995 Wiley-Liss, Inc., A Wiley Company},
  keywords = {*Image Processing,\#nosource,⛔ No INSPIRE recid found,Computer-Assisted/statistics \&,Gaussian,noise,Rayleigh,Rician}
}

@article{gudbjartsson_Rician_1996,
  title = {The {{Rician Distribution}} of {{Noisy MRI Data}} ({{Vol}} 34, {{Pg}} 910, 1995)},
  author = {Gudbjartsson, H. and Patz, S.},
  date = {1996},
  journaltitle = {Magn. Reson. Med.},
  volume = {36},
  number = {2},
  pages = {332},
  abstract = {The image intensity in magnetic resonance magnitude images in the presence of noise is shown to be governed by a Rician distribution. Low signal intensities (SNR {$<$} 2) are therefore biased due to the noise. It is shown how the underlying noise can be estimated from the images and a simple correction scheme is provided to reduce the bias. The noise characteristics in phase images are also studied and shown to be very different from those of the magnitude images. Common to both, however, is that the noise distributions are nearly Gaussian for SNR larger than two.},
  isbn = {0740-3194},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found,Gaussian,noise,Rayleigh,Rician}
}

@online{guendel_MultiTask_2019,
  title = {Multi-{{Task Learning}} for {{Chest X-Ray Abnormality Classification}} on {{Noisy Labels}}},
  author = {Guendel, Sebastian and Ghesu, Florin C. and Grbic, Sasa and Gibson, Eli and Georgescu, Bogdan and Maier, Andreas and Comaniciu, Dorin},
  date = {2019-05-15},
  eprint = {1905.06362},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1905.06362},
  url = {http://arxiv.org/abs/1905.06362},
  urldate = {2022-11-21},
  abstract = {Chest X-ray (CXR) is the most common X-ray examination performed in daily clinical practice for the diagnosis of various heart and lung abnormalities. The large amount of data to be read and reported, with 100+ studies per day for a single radiologist, poses a challenge in maintaining consistently high interpretation accuracy. In this work, we propose a method for the classification of different abnormalities based on CXR scans of the human body. The system is based on a novel multi-task deep learning architecture that in addition to the abnormality classification, supports the segmentation of the lungs and heart and classification of regions where the abnormality is located. We demonstrate that by training these tasks concurrently, one can increase the classification performance of the model. Experiments were performed on an extensive collection of 297,541 chest X-ray images from 86,876 patients, leading to a state-of-the-art performance level of 0.883 AUC on average for 12 different abnormalities. We also conducted a detailed performance analysis and compared the accuracy of our system with 3 board-certified radiologists. In this context, we highlight the high level of label noise inherent to this problem. On a reduced subset containing only cases with high confidence reference labels based on the consensus of the 3 radiologists, our system reached an average AUC of 0.945.},
  pubstate = {preprint},
  keywords = {⛔ No INSPIRE recid found,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  annotation = {19 citations (Semantic Scholar/arXiv) [2022-11-21]},
  file = {/Users/personal-macbook/Zotero/storage/JY9WBRYP/Guendel et al. - 2019 - Multi-task Learning for Chest X-ray Abnormality Cl.pdf;/Users/personal-macbook/Zotero/storage/SX6HBWGH/1905.html}
}

@article{gui_Fast_2018,
  title = {Fast {{Supervised Discrete Hashing}}},
  author = {Gui, Jie and Liu, Tongliang and Sun, Zhenan and Tao, Dacheng and Tan, Tieniu},
  date = {2018-02},
  journaltitle = {IEEE Trans. Pattern Anal. Mach. Intell.},
  volume = {40},
  number = {2},
  pages = {490--496},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2017.2678475},
  abstract = {Learning-based hashing algorithms are ``hot topics'' because they can greatly increase the scale at which existing methods operate. In this paper, we propose a new learning-based hashing method called ``fast supervised discrete hashing'' (FSDH) based on ``supervised discrete hashing'' (SDH). Regressing the training examples (or hash code) to the corresponding class labels is widely used in ordinary least squares regression. Rather than adopting this method, FSDH uses a very simple yet effective regression of the class labels of training examples to the corresponding hash code to accelerate the algorithm. To the best of our knowledge, this strategy has not previously been used for hashing. Traditional SDH decomposes the optimization into three sub-problems, with the most critical sub-problem - discrete optimization for binary hash codes - solved using iterative discrete cyclic coordinate descent (DCC), which is time-consuming. However, FSDH has a closed-form solution and only requires a single rather than iterative hash code-solving step, which is highly efficient. Furthermore, FSDH is usually faster than SDH for solving the projection matrix for least squares regression, making FSDH generally faster than SDH. For example, our results show that FSDH is about 12-times faster than SDH when the number of hashing bits is 128 on the CIFAR-10 data base, and FSDH is about 151-times faster than FastHash when the number of hashing bits is 64 on the MNIST data-base. Our experimental results show that FSDH is not only fast, but also outperforms other comparative methods.},
  eventtitle = {{{IEEE Transactions}} on {{Pattern Analysis}} and {{Machine Intelligence}}},
  keywords = {⛔ No INSPIRE recid found,Algorithm design and analysis,Binary codes,Closed-form solutions,Fast supervised discrete hashing,learning-based hashing,least squares regression,Linear programming,Optimization,supervised discrete hashing,Synchronous digital hierarchy,Training},
  annotation = {195 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/G24NZ2XH/Gui et al. - 2018 - Fast Supervised Discrete Hashing.pdf}
}

@article{gui_Supervised_2018,
  title = {Supervised {{Discrete Hashing With Relaxation}}},
  author = {Gui, Jie and Liu, Tongliang and Sun, Zhenan and Tao, Dacheng and Tan, Tieniu},
  date = {2018-03},
  journaltitle = {IEEE Trans. Neural Netw. Learning Syst.},
  volume = {29},
  number = {3},
  pages = {608--617},
  issn = {2162-237X, 2162-2388},
  doi = {10.1109/TNNLS.2016.2636870},
  url = {http://ieeexplore.ieee.org/document/7801881/},
  urldate = {2022-12-28},
  keywords = {⛔ No INSPIRE recid found,Data-dependent hashing,Kernel,Learning systems,least squares regression,Linear programming,Optimization,Quantization (signal),supervised discrete hashing (SDH),supervised discrete hashing with relaxation (SDHR),Synchronous digital hierarchy,Training},
  annotation = {57 citations (Semantic Scholar/DOI) [2022-12-28]},
  file = {/Users/personal-macbook/Zotero/storage/9CFNTGC4/Supervised Discrete Hashing With Relaxation.pdf;/Users/personal-macbook/Zotero/storage/GVENKQE3/Gui et al. - 2018 - Supervised Discrete Hashing With Relaxation.pdf;/Users/personal-macbook/Zotero/storage/56HZGZXJ/7801881.html}
}

@article{guler_DensePose_2018,
  title = {{{DensePose}}: {{Dense Human Pose Estimation}} in the {{Wild}}},
  author = {G\"uler, R\i za Alp and Neverova, Natalia and Kokkinos, Iasonas},
  date = {2018-02},
  abstract = {In this work, we establish dense correspondences between RGB image and a surface-based representation of the human body, a task we refer to as dense human pose estimation. We first gather dense correspondences for 50K persons appearing in the COCO dataset by introducing an efficient annotation pipeline. We then use our dataset to train CNN-based systems that deliver dense correspondence 'in the wild', namely in the presence of background, occlusions and scale variations. We improve our training set's effectiveness by training an 'inpainting' network that can fill in missing groundtruth values and report clear improvements with respect to the best results that would be achievable in the past. We experiment with fully-convolutional networks and region-based models and observe a superiority of the latter; we further improve accuracy through cascading, obtaining a system that delivers highly0accurate results in real time. Supplementary materials and videos are provided on the project page http://densepose.org},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{gulshan_Development_2016,
  title = {Development and {{Validation}} of a {{Deep Learning Algorithm}} for {{Detection}} of {{Diabetic Retinopathy}} in {{Retinal Fundus Photographs}}},
  author = {Gulshan, Varun and Peng, Lily and Coram, Marc and Stumpe, Martin C. and Wu, Derek and Narayanaswamy, Arunachalam and Venugopalan, Subhashini and Widner, Kasumi and Madams, Tom and Cuadros, Jorge and Kim, Ramasamy and Raman, Rajiv and Nelson, Philip C. and Mega, Jessica L. and Webster, Dale R.},
  date = {2016},
  journaltitle = {JAMA - J. Am. Med. Assoc.},
  eprint = {27898976},
  eprinttype = {pmid},
  issn = {15383598},
  doi = {10.1001/jama.2016.17216},
  abstract = {IMPORTANCE Deep learning is a family of computational methods that allow an algorithm to program itself by learning from a large set of examples that demonstrate the desired behavior, removing the need to specify rules explicitly. Application of these methods to medical imaging requires further assessment and validation. OBJECTIVE To apply deep learning to create an algorithm for automated detection of diabetic retinopathy and diabetic macular edema in retinal fundus photographs. DESIGN AND SETTING A specific type of neural network optimized for image classification called a deep convolutional neural network was trained using a retrospective development data set of 128 175 retinal images, which were graded 3 to 7 times for diabetic retinopathy, diabetic macular edema, and image gradability by a panel of 54 US licensed ophthalmologists and ophthalmology senior residents between May and December 2015. The resultant algorithm was validated in January and February 2016 using 2 separate data sets, both graded by at least 7 US board-certified ophthalmologists with high intragrader consistency. EXPOSURE Deep learning-trained algorithm. MAIN OUTCOMES AND MEASURES The sensitivity and specificity of the algorithm for detecting referable diabetic retinopathy (RDR), defined as moderate and worse diabetic retinopathy, referable diabetic macular edema, or both, were generated based on the reference standard of the majority decision of the ophthalmologist panel. The algorithm was evaluated at 2 operating points selected from the development set, one selected for high specificity and another for high sensitivity. RESULTS The EyePACS-1 data set consisted of 9963 images from 4997 patients (mean age, 54.4 years; 62.2\%women; prevalence ofRDR, 683/8878 fully gradable images [7.8\%]); the Messidor-2 data set had 1748 images from 874 patients (mean age, 57.6 years; 42.6\%women; prevalence ofRDR, 254/1745 fully gradable images [14.6\%]). For detectingRDR, the algorithm had an area under the receiver operating curve of0.991 (95\%CI,0.988-0.993) for EyePACS-1 and 0.990(95\%CI,0.986-0.995) forMessidor-2. Using the first operating cut point with high specificity, for EyePACS-1, the sensitivitywas90.3\%(95\%CI, 87.5\%-92.7\%) and the specificity was 98.1\%(95\%CI, 97.8\%-98.5\%). ForMessidor-2, the sensitivitywas 87.0\%(95\%CI, 81.1\%-91.0\%)and the specificitywas 98.5\%(95\%CI, 97.7\%-99.1\%). Using a second operating point with high sensitivity in the development set, for EyePACS-1 the sensitivitywas 97.5\%and specificitywas 93.4\%and forMessidor-2 the sensitivitywas 96.1\%and specificitywas 93.9\%. CONCLUSIONS AND RELEVANCE In this evaluation of retinal fundus photographs from adults with diabetes, an algorithm based on deep machine learning had high sensitivity and specificity for detecting referable diabetic retinopathy. Further research is necessary to determine the feasibility of applying this algorithm in the clinical setting and to determine whether use of the algorithm could lead to improved care and outcomes compared with current ophthalmologic assessment.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {4458 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{guo_CNNRNN_2018,
  title = {{{CNN-RNN}}: {{A Large-Scale Hierarchical Image Classification Framework}}},
  shorttitle = {Cnn-{{Rnn}}},
  author = {Guo, Yanming and Liu, Yu and Bakker, Erwin M. and Guo, Yuanhao and Lew, Michael S.},
  date = {2018-04},
  journaltitle = {Multimed Tools Appl},
  volume = {77},
  number = {8},
  pages = {10251--10271},
  issn = {1380-7501, 1573-7721},
  doi = {10.1007/s11042-017-5443-x},
  url = {http://link.springer.com/10.1007/s11042-017-5443-x},
  urldate = {2022-11-21},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/ESFMAV5Q/Guo et al. - 2018 - CNN-RNN a large-scale hierarchical image classifi.pdf}
}

@article{guo_Deep_2016,
  title = {Deep {{Learning}} for {{Visual Understanding}}: {{A Review}}},
  author = {Guo, Yanming and Liu, Yu and Oerlemans, Ard and Lao, Songyang and Wu, Song and Lew, Michael S.},
  date = {2016-04},
  journaltitle = {Neurocomputing},
  volume = {187},
  pages = {27--48},
  publisher = {{Elsevier B.V.}},
  issn = {18728286},
  doi = {10.1016/j.neucom.2015.09.116},
  abstract = {Deep learning algorithms are a subset of the machine learning algorithms, which aim at discovering multiple levels of distributed representations. Recently, numerous deep learning algorithms have been proposed to solve traditional artificial intelligence problems. This work aims to review the state-of-the-art in deep learning algorithms in computer vision by highlighting the contributions and challenges from over 210 recent research papers. It first gives an overview of various deep learning approaches and their recent developments, and then briefly describes their applications in diverse vision tasks, such as image classification, object detection, image retrieval, semantic segmentation and human pose estimation. Finally, the paper summarizes the future trends and challenges in designing and training deep neural networks.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Appl,Applications,Challenges,Computer vision,Deep learning,Developments,Trends},
  annotation = {1603 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{guo_Deep_2020,
  ids = {guo_Deep_2019},
  title = {Deep {{Learning}} for 3d {{Point Clouds}}: {{A Survey}}},
  shorttitle = {Deep Learning for 3d Point Clouds},
  author = {Guo, Yulan and Wang, Hanyun and Hu, Qingyong and Liu, Hao and Liu, Li and Bennamoun, Mohammed},
  date = {2020},
  journaltitle = {IEEE Trans. Pattern Anal. Mach. Intell.},
  volume = {43},
  number = {12},
  pages = {4338--4364},
  publisher = {{IEEE}},
  doi = {10.1109/TPAMI.2020.3005434},
  keywords = {⛔ No INSPIRE recid found,3D data,Deep learning,instance segmentation,Laser radar,object detection,Object detection,object tracking,part segmentation,point clouds,scene flow,semantic segmentation,Sensors,shape classification,shape retrieval,Solid modeling,Task analysis,Three-dimensional displays},
  annotation = {791 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/8RT7HJG3/Guo et al. - 2019 - Deep Learning for 3D Point Clouds A Survey.pdf;/Users/personal-macbook/Zotero/storage/JMN3J2SN/9127813.html}
}

@article{guo_PCT_2021,
  title = {{{PCT}}: {{Point Cloud Transformer}}},
  author = {Guo, Meng-Hao and Cai, Jun-Xiong and Liu, Zheng-Ning and Liu, Zheng-Ning and Mu, Tai-Jiang and Martin, Ralph R. and Hu, Shi-Min},
  date = {2021},
  journaltitle = {Comput. Vis. Media},
  eprint = {null},
  eprinttype = {pmid},
  doi = {10.1007/s41095-021-0229-5},
  abstract = {The irregular domain and lack of ordering make it challenging to design deep neural networks for point cloud processing. This paper presents a novel framework named Point Cloud Transformer (PCT) for point cloud learning. PCT is based on Transformer, which achieves huge success in natural language processing and displays great potential in image processing. It is inherently permutation invariant for processing a sequence of points, making it well-suited for point cloud learning. To better capture local context within the point cloud, we enhance input embedding with the support of farthest point sampling and nearest neighbor search. Extensive experiments demonstrate that the PCT achieves the state-of-the-art performance on shape classification, part segmentation, semantic segmentation, and normal estimation tasks.},
  pmcid = {null},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {221 citations (Semantic Scholar/DOI) [2022-07-18]},
  file = {/Users/personal-macbook/Zotero/storage/9ND7UW3T/Guo et al. - 2021 - PCT Point cloud transformer.pdf}
}

@article{guo_Uncertainty_2020,
  title = {Uncertainty {{Characterization}} for {{Predictive Analytics With Clinical Time Series Data}}},
  author = {Guo, Yang and Liu, Zhengyuan and Ramasamy, Savitha and Krishnaswamy, Pavitra},
  date = {2020-02},
  url = {https://oar.a-star.edu.sg/jspui/handle/123456789/3744},
  abstract = {This research was supported by grant funding from A*STAR, Singapore (SSF A1818g0044 and IAF H19/01/a0/023).},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found,Bayesian LSTM,Time Series,Uncertainty Quanti cation}
}

@article{gupta_Characterizing_2010,
  title = {Characterizing {{Exhaled Airflow From Breathing}} and {{Talking}}},
  author = {Gupta, Jitendra K. and Lin, Chao Hsin and Chen, Qingyan},
  date = {2010},
  journaltitle = {Indoor Air},
  issn = {09056947},
  doi = {10.1111/j.1600-0668.2009.00623.x},
  abstract = {The exhaled air of infected humans is one of the prime sources of contagious viruses. The exhaled air comes from respiratory events such as the coughing, sneezing, breathing and talking. Accurate information on the thermo-fluid characteristics of the exhaled airflow can be important for prediction of infectious disease transmission. The present study developed a source model to provide the thermo-fluid conditions of the exhaled air from the breathing and talking processes. The source model is a set of equations obtained from the measurements of the flow rate, flow direction, and area of mouth/nose opening with human subjects. It was found that the exhaled flow rate over time can be represented as a sinusoidal function for breathing and a constant for talking. The flow rates can be calculated by physiological parameters of a subject. The direction of the exhalation jet did not vary much between subjects and the area of mouth/nose opening could be regarded as a constant. Though the mouth/nose opening size varied among subjects, they were not correlated with the physiological parameters of the subjects. If combined with appropriate virus and droplet distribution information, the model can be used to describe the disease source due to breathing and talking. Practical Implications Accurate prediction of airborne disease transmission, and the infection prone zones, can aid in identifying and implementing the control strategies. With the recent advancements, Computational Fluid Dynamics (CFD) has become a powerful tool in predicting the disease transmission. Accurate prediction of the transmission by these CFD simulations requires information on sources and sinks of infectious viruses and models for dispersion of these viruses. The exhaled air of an infected human is one of the prime sources of disease viruses. In the present study, measurements of the flow were conducted on human subjects to develop models for the flow boundary conditions for the exhalation and inhalation during breathing and talking. \textcopyright{} 2009 John Wiley \& Sons A/S.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Airborne infection,Airflow,Opening area,Source model,Visualization},
  annotation = {349 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{gupta_Convolutional_2017,
  ids = {gupta17},
  title = {Convolutional {{Neural Networks}} for {{False Positive Reduction}} of {{Automatically Detected Cilia}} in {{Low Magnification TEM Images}}},
  booktitle = {Image {{Anal}}.},
  author = {Gupta, Anindya and Suveer, Amit and Lindblad, Joakim and Dragomir, Anca and Sintorn, Ida-Maria and Sladoje, Nata\v{s}a},
  editor = {Sharma, Puneet and Bianchi, Filippo Maria},
  date = {2017},
  volume = {10269},
  pages = {407--418},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-59126-1_34},
  url = {https://link.springer.com/10.1007/978-3-319-59126-1_34},
  urldate = {2023-06-03},
  isbn = {978-3-319-59125-4 978-3-319-59126-1},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{haacke_Susceptibility_2004,
  title = {Susceptibility {{Weighted Imaging}} ({{SWI}})},
  author = {Haacke, E. Mark and Xu, Yingbiao and Cheng, Yu-Chung N. and Reichenbach, Jurgen R.},
  date = {2004-09},
  journaltitle = {Magn. Reson. Med.},
  volume = {52},
  number = {3},
  pages = {612--618},
  issn = {0740-3194, 1522-2594},
  doi = {10.1002/mrm.20198},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/mrm.20198},
  urldate = {2023-05-28},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Artery/vein separation,Imaging iron,Magnetic susceptibility,Phase imaging,Water/fat separation},
  annotation = {1491 citations (Semantic Scholar/DOI) [2023-05-28]},
  file = {/Users/personal-macbook/Zotero/storage/WKCXUM9A/Haacke et al. - 2004 - Susceptibility weighted imaging (SWI).pdf}
}

@article{habli_Artificial_2020,
  title = {Artificial {{Intelligence}} in {{Health Care}}: {{Accountability}} and {{Safety}}},
  author = {Habli, Ibrahim and Lawton, Tom and Porter, Zoe},
  date = {2020},
  journaltitle = {Bull. World Health Organ.},
  issn = {15640604},
  doi = {10.2471/BLT.19.237487},
  abstract = {The prospect of patient harm caused by the decisions made by an artificial intelligence-based clinical tool is something to which current practices of accountability and safety worldwide have not yet adjusted. We focus on two aspects of clinical artificial intelligence used for decision-making: moral accountability for harm to patients; and safety assurance to protect patients against such harm. Artificial intelligence-based tools are challenging the standard clinical practices of assigning blame and assuring safety. Human clinicians and safety engineers have weaker control over the decisions reached by artificial intelligence systems and less knowledge and understanding of precisely how the artificial intelligence systems reach their decisions. We illustrate this analysis by applying it to an example of an artificial intelligence-based system developed for use in the treatment of sepsis. The paper ends with practical suggestions for ways forward to mitigate these concerns. We argue for a need to include artificial intelligence developers and systems safety engineers in our assessments of moral accountability for patient harm. Meanwhile, none of the actors in the model robustly fulfil the traditional conditions of moral accountability for the decisions of an artificial intelligence system. We should therefore update our conceptions of moral accountability in this context. We also need to move from a static to a dynamic model of assurance, accepting that considerations of safety are not fully resolvable during the design of the artificial intelligence system before the system has been deployed.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {50 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{haenlein_Brief_2019,
  title = {A {{Brief History}} of {{Artificial Intelligence}}: {{On}} the {{Past}}, {{Present}}, and {{Future}} of {{Artificial Intelligence}}},
  shorttitle = {A {{Brief History}} of {{Artificial Intelligence}}},
  author = {Haenlein, Michael and Kaplan, Andreas},
  date = {2019-08},
  journaltitle = {California Management Review},
  volume = {61},
  number = {4},
  pages = {5--14},
  issn = {0008-1256, 2162-8564},
  doi = {10.1177/0008125619864925},
  url = {http://journals.sagepub.com/doi/10.1177/0008125619864925},
  urldate = {2023-05-08},
  abstract = {This introduction to this special issue discusses artificial intelligence (AI), commonly defined as ``a system's ability to interpret external data correctly, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation.'' It summarizes seven articles published in this special issue that present a wide variety of perspectives on AI, authored by several of the world's leading experts and specialists in AI. It concludes by offering a comprehensive outlook on the future of AI, drawing on micro-, meso-, and macro-perspectives.},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Artificial intelligence,Big data,Machine-blearning,Regulation,Strategy},
  annotation = {542 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{haghighi_AUTOMATIC_2018,
  title = {Automatic {{Renal Segmentation}} in {{Dce-Mri Using Convolutional Neural Networks}}},
  author = {Haghighi, Marzieh and Warfield, Simon K. and Kurugol, Sila},
  date = {2018-04},
  journaltitle = {Proc. IEEE Int. Symp. Biomed. Imaging},
  volume = {2018},
  pages = {1534--1537},
  abstract = {Kidney function evaluation using dynamic contrast-enhanced MRI (DCE-MRI) images could help in diagnosis and treatment of kidney diseases of children. Automatic segmentation of renal parenchyma is an important step in this process. In this paper, we propose a time and memory efficient fully automated segmentation method which achieves high segmentation accuracy with running time in the order of seconds in both normal kidneys and kidneys with hydronephrosis. The proposed method is based on a cascaded application of two 3D convolutional neural networks that employs spatial and temporal information at the same time in order to learn the tasks of localization and segmentation of kidneys, respectively. Segmentation performance is evaluated on both normal and abnormal kidneys with varying levels of hydronephrosis. We achieved a mean dice coefficient of 91.4 and 83.6 for normal and abnormal kidneys of pediatric patients, respectively.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found,CNN,DCE-MRI,Fully-automated,Kidney segmentation}
}

@article{hale_Comparison_2015,
  ids = {_Comparison_},
  title = {Comparison of {{Functional Thalamic Segmentation From Seed-Based Analysis}} and {{Ica}}},
  author = {Hale, Joanne R. and Mayhew, Stephen D. and Mullinger, Karen J. and Wilson, Rebecca S. and Arvanitis, Theodoros N. and Francis, Susan T. and Bagshaw, Andrew P.},
  date = {2015-07},
  journaltitle = {NeuroImage},
  volume = {114},
  pages = {448--465},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2015.04.027},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811915003171},
  urldate = {2023-05-08},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Functional connectivity,ICA,Resting state,Thala},
  annotation = {38 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/K4SB2XKN/Hale et al. - 2015 - Comparison of functional thalamic segmentation fro.pdf}
}

@article{hamet_Artificial_2017,
  title = {Artificial {{Intelligence}} in {{Medicine}}},
  author = {Hamet, Pavel and Tremblay, Johanne},
  date = {2017-04},
  journaltitle = {Metabolism},
  volume = {69},
  pages = {S36-S40},
  issn = {00260495},
  doi = {10.1016/j.metabol.2017.01.011},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S002604951730015X},
  urldate = {2023-05-09},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Artificial intelligence,Avatars,Future of medicine,Robots},
  annotation = {543 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{han_Point2node_2020,
  title = {Point2node: {{Correlation Learning}} of {{Dynamic-Node}} for {{Point Cloud Feature Modeling}}},
  shorttitle = {Point2node},
  booktitle = {Proc. {{AAAI Conf}}. {{Artif}}. {{Intell}}.},
  author = {Han, Wenkai and Wen, Chenglu and Wang, Cheng and Li, Xin and Li, Qing},
  date = {2020},
  volume = {34},
  number = {07},
  pages = {10925--10932},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/4BW5TGE7/Han et al. - 2020 - Point2node Correlation learning of dynamic-node f.pdf;/Users/personal-macbook/Zotero/storage/VMGCI57E/6725.html}
}

@article{han_Progressive_2018,
  title = {Progressive {{Stochastic Learning}} for {{Noisy Labels}}},
  author = {Han, Bo and Tsang, Ivor W. and Chen, Ling and Yu, Celina P. and Fung, Sai-Fu},
  date = {2018-10},
  journaltitle = {IEEE Trans. Neural Netw. Learning Syst.},
  volume = {29},
  number = {10},
  pages = {5136--5148},
  issn = {2162-237X, 2162-2388},
  doi = {10.1109/TNNLS.2018.2792062},
  url = {https://ieeexplore.ieee.org/document/8281022/},
  urldate = {2022-12-28},
  keywords = {⛔ No INSPIRE recid found,Convergence,Crowdsourcing,curriculum learning (CL),effectiveness,Noise measurement,noisy labels,Progressive stochastic learning (POSTAL),robustness,Robustness,screening losses,stochastic gradient descent (SGD),Stochastic processes,Task analysis},
  annotation = {26 citations (Semantic Scholar/DOI) [2022-12-28]},
  file = {/Users/personal-macbook/Zotero/storage/2MMFBWK5/Han et al. - 2018 - Progressive Stochastic Learning for Noisy Labels.pdf;/Users/personal-macbook/Zotero/storage/DZTJPJIR/8281022.html}
}

@article{haralick_Image_1987,
  title = {Image {{Analysis Using Mathematical Morphology}}},
  author = {Haralick, R. M. and Sternberg, S. R. and Zhuang, X.},
  date = {1987-04},
  journaltitle = {IEEE Trans. Pattern Anal. Mach. Intell.},
  volume = {9},
  number = {4},
  pages = {532--550},
  doi = {10.1109/TPAMI.1987.4767941},
  abstract = {For the purposes of object or defect identification required in industrial vision applications, the operations of mathematical morphology are more useful than the convolution operations employed in signal processing because the morphological operators relate directly to shape. The tutorial provided in this paper reviews both binary morphology and gray scale morphology, covering the operations of dilation, erosion, opening, and closing and their relations. Examples are given for each morphological concept and explanations are given for many of their interrelationships.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {2574 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{harding_Variation_1998,
  title = {Variation in {{Hippocampal Neuron Number With Age}} and {{Brain Volume}}},
  author = {Harding, A. J. and Halliday, G. M. and Kril, J. J.},
  date = {1998-12},
  journaltitle = {Cereb. Cortex},
  volume = {8},
  number = {8},
  pages = {710--718},
  doi = {10.1093/cercor/8.8.710},
  abstract = {Hippocampal size and neuron number are reduced in a number of conditions, including temporal lobe epilepsy and Alzheimer's disease. Furthermore, a decrease with advancing age has also been suggested. The present study examined the entire hippocampal formation of 12 subjects aged from 46 to 85 years and free from neurological disease. The volume of seven subregions (CA1, CA2-3, CA4, dentate gyrus, subiculum, presubiculum and white matter) was determined and the number of neurons estimated in each of these grey matter subregions using the optical dissector technique. There was a significant relationship between CA1 neuron number and cerebrum volume. Multivariate analysis showed the greater contribution to the variance in CA1 neuron number was made by cerebrum volume (69\%) rather than age (2\%) or sex (1\%). The findings of this study show that, in neurologically normal individuals, brain size is a major determinant of the number of CA1 neurons.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@incollection{harvey_Standardised_2019,
  title = {A {{Standardised Approach}} for {{Preparing Imaging Data}} for {{Machine Learning Tasks}} in {{Radiology}}},
  booktitle = {Artificial {{Intelligence}} in {{Medical Imaging}}: {{Opportunities}}, {{Applications}} and {{Risks}}},
  author = {Harvey, Hugh and Glocker, Ben},
  editor = {Ranschaert, Erik R. and Morozov, Sergey and Algra, Paul R.},
  date = {2019},
  pages = {61--72},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-94878-2_6},
  url = {https://doi.org/10.1007/978-3-319-94878-2_6},
  urldate = {2022-11-21},
  abstract = {Medical imaging data is now extremely abundant due to over two decades of digitisation of imaging protocols and data storage formats. However, clean, well-curated data, that is amenable to machine learning, is relatively scarce, and AI developers are paradoxically data starved. Imaging and clinical data is also heterogeneous, often unstructured and unlabelled, whereas current supervised and semi-supervised machine learning techniques rely on homogeneous and carefully annotated data. While imaging biobanks contain small volumes of well-curated data, it is the leveraging of `big data' from the front-line of healthcare that is the focus of many machine learning developers hoping to train and validate computer vision algorithms. The quest for sufficiently large volumes of clean data that can be used for training, validation and testing involves several hurdles, namely ethics and consent, security, the assessment of data quality, ground truth data labelling, bias reduction, reusability and generalisability. In this chapter we propose a new medical imaging data readiness (MIDaR) scale. The MIDaR scale is designed to objectively clarify data quality for both researchers seeking imaging data and clinical providers aiming to share their data. It is hoped that the MIDaR scale will be used globally during collaborative academic and business conversations, so that everyone can more easily understand and quickly appraise the relevant stages of data readiness for machine learning in relation to their AI development projects. We believe that the MIDaR scale could become essential in the design, planning and management of AI medical imaging projects, and significantly increase chances of success.},
  isbn = {978-3-319-94878-2},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Data readiness,Machine learning,Medical imaging,MIDaR scale}
}

@article{hashai_Gradually_2004,
  title = {Gradually {{Internationalizing}} `{{Born Global}}'firms: {{An Oxymoron}}?},
  author = {Hashai, Niron and Almor, Tamar},
  date = {2004},
  journaltitle = {Int. Bus. Rev.},
  volume = {13},
  number = {4},
  pages = {465--483},
  publisher = {{Elsevier}},
  doi = {10.1016/j.ibusrev.2004.04.004},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {245 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{havaei_Brain_2017,
  title = {Brain {{Tumor Segmentation With Deep Neural Networks}}},
  author = {Havaei, Mohammad and Davy, Axel and Warde-Farley, David and Biard, Antoine and Courville, Aaron and Bengio, Yoshua and Pal, Chris and Jodoin, Pierre-Marc and Larochelle, Hugo},
  date = {2017-01},
  journaltitle = {Med. Image Anal.},
  volume = {35},
  pages = {18--31},
  doi = {10.1016/j.media.2016.05.004},
  abstract = {In this paper, we present a fully automatic brain tumor segmentation method based on Deep Neural Networks (DNNs). The proposed networks are tailored to glioblastomas (both low and high grade) pictured in MR images. By their very nature, these tumors can appear anywhere in the brain and have almost any kind of shape, size, and contrast. These reasons motivate our exploration of a machine learning solution that exploits a flexible, high capacity DNN while being extremely efficient. Here, we give a description of different model choices that we've found to be necessary for obtaining competitive performance. We explore in particular different architectures based on Convolutional Neural Networks (CNN), i.e. DNNs specifically adapted to image data. We present a novel CNN architecture which differs from those traditionally used in computer vision. Our CNN exploits both local features as well as more global contextual features simultaneously. Also, different from most traditional uses of CNNs, our networks use a final layer that is a convolutional implementation of a fully connected layer which allows a 40 fold speed up. We also describe a 2-phase training procedure that allows us to tackle difficulties related to the imbalance of tumor labels. Finally, we explore a cascade architecture in which the output of a basic CNN is treated as an additional source of information for a subsequent CNN. Results reported on the 2013 BRATS test data-set reveal that our architecture improves over the currently published state-of-the-art while being over 30 times faster.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Brain tumor segmentation,Cascaded convolutional n},
  annotation = {2345 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@book{haykin_Neural_2009,
  ids = {haykin09,haykin_neuralnetworkslearningmachines_2009},
  title = {Neural {{Networks}} and {{Learning Machines}}},
  author = {Haykin, Simon S.},
  date = {2009},
  edition = {3},
  publisher = {{Prentice Hall}},
  location = {{New York}},
  isbn = {978-0-13-147139-9},
  langid = {english},
  pagetotal = {906},
  keywords = {⛔ No INSPIRE recid found,Adaptive filters,Neural networks (Computer science)},
  annotation = {OCLC: ocn237325326},
  file = {/Users/personal-macbook/Zotero/storage/VYT7YHKS/Haykin and Haykin - 2009 - Neural networks and learning machines.pdf}
}

@inproceedings{he_Deep_2016,
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  booktitle = {2016 {{IEEE Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}. {{CVPR}}},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  date = {2016-06},
  pages = {770--778},
  publisher = {{IEEE}},
  location = {{Las Vegas, NV, USA}},
  doi = {10.1109/CVPR.2016.90},
  url = {https://doi.org/10.1109/CVPR.2016.90},
  urldate = {2023-05-28},
  eventtitle = {2016 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-4673-8851-1},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Complexity theory,Computer Science - Computer Vision and Pattern Recognition,Degradation,Fructooligosaccharides,Fructosyltransferase,Image recognition,Image segmentation,Neural networks,Oligofructosides,Sweetener,Training,Visualization},
  file = {/Users/personal-macbook/Zotero/storage/85G23G8A/He et al. - 2016 - Deep Residual Learning for Image Recognition.pdf;/Users/personal-macbook/Zotero/storage/FSANRUSU/He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf;/Users/personal-macbook/Zotero/storage/2YKYE7YU/7780459.html;/Users/personal-macbook/Zotero/storage/SXPYFL43/He et al. - 2015 - Deep Residual Learning for Image Recognition.html}
}

@inproceedings{he_Hippocampus_2013,
  title = {Hippocampus {{Segmentation Techniques}}: {{A Survey}}},
  booktitle = {Adv. {{Mater}}. {{Res}}.},
  author = {He, Bing Song and Zhang, Xue Ping and Shi, Yong Gang},
  date = {2013},
  volume = {760},
  pages = {2086--2090},
  publisher = {{Trans Tech Publ}},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{he_MultiLabel_2020,
  title = {Multi-{{Label Classification}} by {{Exploiting Data-Driven Pair-Wise Label Dependence}}},
  author = {He, Tao and Zhang, Lei and Guo, Jixiang and Yi, Zhang},
  date = {2020},
  journaltitle = {Int. J. Intell. Syst.},
  volume = {35},
  number = {9},
  pages = {1375--1396},
  issn = {1098-111X},
  doi = {10.1002/int.22257},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/int.22257},
  urldate = {2022-06-23},
  abstract = {Exploiting label dependence is a widely used approach to boost classification performance for multilabel classification problems. However, most of the traditional label dependence methods have high time complexity, especially when combined with deep neural networks (DNNs). Thus they usually can not be efficiently applied in large-scale data sets. Recent advances in large-scale multilabel classification widely developed pair-wise ranking and structure-driven methods, but label dependence was little exploited. In most of the structure-driven methods, binary relevance (BR) with multiple binary cross-entropy (BCE) loss functions, a simple but effective method, is still the prior solution incorporation with DNNs in large-scale data sets. In this paper, we propose a novel loss function called label dependent cross-entropy (LDCE), which directly introduces label dependence to BCE loss function by data-driven conditional probability. Combined with deep convolutional neural networks (DCNNs), LDCE introduces no extra parameters and induces very little extra computational complexity. Moreover, we develop its tiny variant with sparse label dependence and its learnable version for automatic learning pair-wise label dependence. Within the BR scheme, LDCE outperforms BCE on seven widely used benchmark datasets. We also perform two large-scale multilabel image classification tasks (VOC 2007 and ChestX-ray14) with DCNNs, and LDCE outperforms BCE and achieves comparable results to the state-of-the-art.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,cross-entropy,data-driven,deep neural networks,label dependent,multi-label classification,pair-wise label dependence},
  file = {/Users/personal-macbook/Zotero/storage/UJV6TJ2H/He et al. - 2020 - Multilabel classification by exploiting data-drive.pdf;/Users/personal-macbook/Zotero/storage/KBTSKJXP/int.html}
}

@article{heath_Prediction_2019,
  title = {Prediction {{Machines}}: {{The Simple Economics}} of {{Artificial Intelligence}}},
  author = {Heath, Donald R.},
  date = {2019},
  journaltitle = {J. Inf. Technol. Case Appl. Res.},
  issn = {1522-8053},
  doi = {10.1080/15228053.2019.1673511},
  abstract = {The idea of artificial intelligence\textendash job-killing robots, self-driving cars, and self-managing organizations\textendash captures the imagination, evoking a combination of wonder and dread for those of us who will have to deal with the consequences. But what if it's not quite so complicated? The real job of artificial intelligence, argue these three eminent economists, is to lower the cost of prediction. And once you start talking about costs, you can use some well-established economics to cut through the hype. The constant challenge for all managers is to make decisions under uncertainty. And AI contributes by making knowing what's coming in the future cheaper and more certain. But decision making has another component: judgment, which is firmly in the realm of humans, not machines. Making prediction cheaper means that we can make more predictions more accurately and assess them with our better (human) judgment. Once managers can separate tasks into components of prediction and judgment, we can begin to understand how to optimize the interface between humans and machines. More than just an account of AI's powerful capabilities, Prediction Machines shows managers how they can most effectively leverage AI, disrupting business as usual only where required, and provides businesses with a toolkit to navigate the coming wave of challenges and opportunities.\textendash{} Intro; Contents; Acknowledgments; Ch. 1: Introduction; Ch. 2: Cheap Changes Everything; Part 1: Prediction; Ch. 3: Prediction Machine Magic; Ch. 4: Why It's Called Intelligence; Ch. 5: Data Is the New Oil; Ch. 6: The New Division of Labor; Part 2: Decision Making; Ch. 7: Unpacking Decisions; Ch. 8: The Value of Judgment; Ch. 9: Predicting Judgment; Ch. 10: Taming Complexity; Ch. 11: Fully Automated Decision Making; Part 3: Tools; Ch. 12: Deconstructing Work Flows; Ch. 13: Decomposing Decisions; Ch. 14: Job Redesign; Part 4: Strategy; Ch. 15: AI in the C-Suite. Ch. 16: When AI Transforms Your BusinessCh. 17: Your Learning Strategy; Ch. 18: Managing AI Risk; Part 5: Society; Ch. 19: Beyond Business; Notes; Index; About the Authors.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{heckemann_Automatic_2006,
  title = {Automatic {{Anatomical Brain MRI Segmentation Combining Label Propagation}} and {{Decision Fusion}}},
  author = {Heckemann, Rolf A. and Hajnal, Joseph V. and Aljabar, Paul and Rueckert, Daniel and Hammers, Alexander},
  date = {2006-10},
  journaltitle = {Neuroimage},
  volume = {33},
  number = {1},
  pages = {115--126},
  doi = {10.1016/j.neuroimage.2006.05.061},
  abstract = {Regions in three-dimensional magnetic resonance (MR) brain images can be classified using protocols for manually segmenting and labeling structures. For large cohorts, time and expertise requirements make this approach impractical. To achieve automation, an individual segmentation can be propagated to another individual using an anatomical correspondence estimate relating the atlas image to the target image. The accuracy of the resulting target labeling has been limited but can potentially be improved by combining multiple segmentations using decision fusion. We studied segmentation propagation and decision fusion on 30 normal brain MR images, which had been manually segmented into 67 structures. Correspondence estimates were established by nonrigid registration using free-form deformations. Both direct label propagation and an indirect approach were tested. Individual propagations showed an average similarity index (SI) of 0.754+/-0.016 against manual segmentations. Decision fusion using 29 input segmentations increased SI to 0.836+/-0.009. For indirect propagation of a single source via 27 intermediate images, SI was 0.779+/-0.013. We also studied the effect of the decision fusion procedure using a numerical simulation with synthetic input data. The results helped to formulate a model that predicts the quality improvement of fused brain segmentations based on the number of individual propagated segmentations combined. We demonstrate a practicable procedure that exceeds the accuracy of previous automatic methods and can compete with manual delineations.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {936 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{heiberg_Design_2010,
  title = {Design and {{Validation}} of {{Segment}}\textendash Freely {{Available Software}} for {{Cardiovascular Image Analysis}}},
  author = {Heiberg, Einar and Sj\"ogren, Jane and Ugander, Martin and Carlsson, Marcus and Engblom, Henrik and Arheden, H\aa kan},
  date = {2010-01},
  journaltitle = {BMC Med. Imaging},
  volume = {10},
  pages = {1},
  abstract = {BACKGROUND: Commercially available software for cardiovascular image analysis often has limited functionality and frequently lacks the careful validation that is required for clinical studies. We have already implemented a cardiovascular image analysis software package and released it as freeware for the research community. However, it was distributed as a stand-alone application and other researchers could not extend it by writing their own custom image analysis algorithms. We believe that the work required to make a clinically applicable prototype can be reduced by making the software extensible, so that researchers can develop their own modules or improvements. Such an initiative might then serve as a bridge between image analysis research and cardiovascular research. The aim of this article is therefore to present the design and validation of a cardiovascular image analysis software package (Segment) and to announce its release in a source code format. RESULTS: Segment can be used for image analysis in magnetic resonance imaging (MRI), computed tomography (CT), single photon emission computed tomography (SPECT) and positron emission tomography (PET). Some of its main features include loading of DICOM images from all major scanner vendors, simultaneous display of multiple image stacks and plane intersections, automated segmentation of the left ventricle, quantification of MRI flow, tools for manual and general object segmentation, quantitative regional wall motion analysis, myocardial viability analysis and image fusion tools. Here we present an overview of the validation results and validation procedures for the functionality of the software. We describe a technique to ensure continued accuracy and validity of the software by implementing and using a test script that tests the functionality of the software and validates the output. The software has been made freely available for research purposes in a source code format on the project home page http://segment.heiberg.se. CONCLUSIONS: Segment is a well-validated comprehensive software package for cardiovascular image analysis. It is freely available for research purposes provided that relevant original research publications related to the software are cited.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{heinze-deml_Conditional_2017,
  title = {Conditional {{Variance Penalties}} and {{Domain Shift Robustness}}},
  author = {Heinze-Deml, Christina and Meinshausen, Nicolai},
  date = {2017-10},
  url = {https://arxiv.org/abs/1710.11469},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found},
  annotation = {4 citations (Semantic Scholar/arXiv) [2023-05-08]}
}

@inproceedings{heller_Imperfect_2018,
  title = {Imperfect {{Segmentation Labels}}: {{How Much Do They Matter}}?},
  booktitle = {Intravasc. {{Imaging Comput}}. {{Assist}}. {{Stenting Large-Scale Annot}}. {{Biomed}}. {{Data Expert Label Synth}}.},
  author = {Heller, Nicholas and Dean, Joshua and Papanikolopoulos, Nikolaos},
  date = {2018},
  pages = {112--120},
  publisher = {{Springer International Publishing}},
  doi = {10.1007/978-3-030-01364-6_13},
  abstract = {Labeled datasets for semantic segmentation are imperfect, especially in medical imaging where borders are often subtle or ill-defined. Little work has been done to analyze the effect that label errors have on the performance of segmentation methodologies. Here we present a large-scale study of model performance in the presence of varying types and degrees of error in training data. We trained U-Net, SegNet, and FCN32 several times for liver segmentation with 10 different modes of ground-truth perturbation. Our results show that for each architecture, performance steadily declines with boundary-localized errors, however, U-Net was significantly more robust to jagged boundary errors than the other architectures. We also found that each architecture was very robust to non-boundary-localized errors, suggesting that boundary-localized errors are fundamentally different and more challenging problem than random label errors in a classification setting.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {27 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{hendrickson_Atomic_1975,
  title = {Atomic {{Models}} for the {{Polypeptide Backbones}} of {{Myohemerythrin}} and {{Hemerythrin}}},
  author = {Hendrickson, W. A. and Ward, K. B.},
  date = {1975-10-27},
  journaltitle = {Biochem Biophys Res Commun},
  volume = {66},
  number = {4},
  eprint = {5},
  eprinttype = {pmid},
  pages = {1349--1356},
  issn = {1090-2104},
  doi = {10.1016/0006-291x(75)90508-2},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Animals,Cnidaria,Computers,Hemerythrin,Metalloproteins,{Models, Molecular},Muscle Proteins,Protein Conformation,Species Specificity},
  annotation = {42 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@online{hendrycks_baselinedetectingmisclassifiedoutofdistributionexamplesneuralnetworks_2016,
  ids = {gimpel_Baseline_2017,hendrycks_Baseline_2016,hendrycks_Baseline_2018},
  title = {A {{Baseline}} for {{Detecting Misclassified}} and {{Out-of-Distribution Examples}} in {{Neural Networks}}},
  author = {Hendrycks, Dan and Gimpel, Kevin},
  date = {2016},
  doi = {10.48550/ARXIV.1610.02136},
  url = {https://arxiv.org/abs/1610.02136},
  urldate = {2023-05-08},
  abstract = {We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks.},
  pubstate = {preprint},
  version = {3},
  keywords = {⛔ No INSPIRE recid found,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,Machine Learning (cs.LG),Neural and Evolutionary Computing (cs.NE)},
  annotation = {1892 citations (Semantic Scholar/arXiv) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/RJQITMU9/Hendrycks and Gimpel - 2018 - A Baseline for Detecting Misclassified and Out-of-.pdf;/Users/personal-macbook/Zotero/storage/K8RV3WNH/1610.html}
}

@inproceedings{heo_UncertaintyAware_2018,
  title = {Uncertainty-{{Aware Attention}} for {{Reliable Interpretation}} and {{Prediction}}},
  booktitle = {Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.},
  author = {Heo, Jay and Lee, Hae Beom and Kim, Saehoon and Lee, Juho and Kim, Kwang Joon and Yang, Eunho and Hwang, Sung Ju},
  date = {2018},
  issn = {10495258},
  abstract = {Attention mechanism is effective in both focusing the deep learning models on relevant features and interpreting them. However, attentions may be unreliable since the networks that generate them are often trained in a weakly-supervised manner. To overcome this limitation, we introduce the notion of input-dependent uncertainty to the attention mechanism, such that it generates attention for each feature with varying degrees of noise based on the given input, to learn larger variance on instances it is uncertain about. We learn this Uncertainty-aware Attention (UA) mechanism using variational inference, and validate it on various risk prediction tasks from electronic health records on which our model significantly outperforms existing attention models. The analysis of the learned attentions shows that our model generates attentions that comply with clinicians' interpretation, and provide richer interpretation via learned variance. Further evaluation of both the accuracy of the uncertainty calibration and the prediction performance with ``I don't know'' decision show that UA yields networks with high reliability as well.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{hernandez-gonzalez_Note_2019,
  title = {A {{Note}} on the {{Behavior}} of {{Majority Voting}} in {{Multi-Class Domains With Biased Annotators}}},
  author = {Hernandez-Gonzalez, Jeronimo and Inza, Inaki and Lozano, Jose A.},
  date = {2019-01-01},
  journaltitle = {IEEE Trans. Knowl. Data Eng.},
  volume = {31},
  number = {1},
  pages = {195--200},
  issn = {1041-4347, 1558-2191, 2326-3865},
  doi = {10.1109/TKDE.2018.2845400},
  url = {https://ieeexplore.ieee.org/document/8375733/},
  urldate = {2022-12-20},
  keywords = {⛔ No INSPIRE recid found,Aggregates,biased annotations,Labeling,learning from crowds,Multi-class learning,Noise measurement,Robustness,Standards,Training},
  annotation = {7 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/G5ZC6X2F/Hernandez-Gonzalez et al. - 2019 - A Note on the Behavior of Majority Voting in Multi.pdf}
}

@inproceedings{heusel_GANs_2017,
  title = {{{GANs Trained}} by a {{Two Time-Scale Update Rule Converge}} to a {{Local Nash Equilibrium}}},
  booktitle = {Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.},
  author = {Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  date = {2017},
  issn = {10495258},
  abstract = {Generative Adversarial Networks (GANs) excel at creating realistic images with complex models for which maximum likelihood is infeasible. However, the convergence of GAN training has still not been proved. We propose a two time-scale update rule (TTUR) for training GANs with stochastic gradient descent on arbitrary GAN loss functions. TTUR has an individual learning rate for both the discriminator and the generator. Using the theory of stochastic approximation, we prove that the TTUR converges under mild assumptions to a stationary local Nash equilibrium. The convergence carries over to the popular Adam optimization, for which we prove that it follows the dynamics of a heavy ball with friction and thus prefers flat minima in the objective landscape. For the evaluation of the performance of GANs at image generation, we introduce the 'Fr\'echet Inception Distance" (FID) which captures the similarity of generated images to real ones better than the Inception Score. In experiments, TTUR improves learning for DCGANs and Improved Wasserstein GANs (WGAN-GP) outperforming conventional GAN training on CelebA, CIFAR-10, SVHN, LSUN Bedrooms, and the One Billion Word Benchmark.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@online{hinton_Improving_2012,
  ids = {hinton_Improving_2012a},
  title = {Improving {{Neural Networks}} by {{Preventing Co-Adaptation}} of {{Feature Detectors}}},
  author = {Hinton, Geoffrey E. and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan R.},
  date = {2012-07-03},
  eprint = {1207.0580},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1207.0580},
  urldate = {2022-05-16},
  abstract = {When a large feedforward neural network is trained on a small training set, it typically performs poorly on held-out test data. This "overfitting" is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorially large variety of internal contexts in which it must operate. Random "dropout" gives big improvements on many benchmark tasks and sets new records for speech and object recognition.},
  pubstate = {preprint},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  annotation = {6879 citations (Semantic Scholar/arXiv) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/VKKT3I4Y/Hinton et al. - 2012 - Improving neural networks by preventing co-adaptat.pdf;/Users/personal-macbook/Zotero/storage/I25GV9AF/Hinton et al. - 2012 - Improving neural networks by preventing co-adaptat.html}
}

@article{hinton_Training_2002,
  title = {Training {{Products}} of {{Experts}} by {{Minimizing Contrastive Divergence}}},
  author = {Hinton, Geoffrey E.},
  date = {2002-08},
  journaltitle = {Neural Comput.},
  volume = {14},
  number = {8},
  pages = {1771--1800},
  doi = {10.1162/089976602760128018},
  abstract = {It is possible to combine multiple latent-variable models of the same data by multiplying their probability distributions together and then renormalizing. This way of combining individual ``expert'' models makes it hard to generate samples from the combined model but easy to infer the values of the latent variables of each expert, because the combination rule ensures that the latent variables of different experts are conditionally independent when given the data. A product of experts (PoE) is therefore an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary. Training a PoE by maximizing the likelihood of the data is difficult because it is hard even to approximate the derivatives of the renormalization term in the combination rule. Fortunately, a PoE can be trained using a different objective function called ``contrastive divergence'' whose derivatives with regard to the parameters can be approximated accurately and efficiently. Examples are presented of contrastive divergence learning using several types of expert on several types of data.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{hird_Noise_2009,
  title = {Noise {{Reduction}} of {{NDVI Time Series}}: {{An Empirical Comparison}} of {{Selected Techniques}}},
  author = {Hird, Jennifer N. and McDermid, Gregory J.},
  date = {2009},
  journaltitle = {Remote Sens. Environ.},
  issn = {00344257},
  doi = {10.1016/j.rse.2008.09.003},
  abstract = {Satellite-derived NDVI time series are fundamental to the remote sensing of vegetation phenology, but their application is hindered by prevalent noise resulting chiefly from varying atmospheric conditions and sun-sensor-surface viewing geometries. A model-based empirical comparison of six selected NDVI time series noise-reduction techniques revealed the general superiority of the double logistic and asymmetric Gaussian function-fitting methods over four alternative filtering techniques. However, further analysis demonstrated the strong influence of noise level, strength, and bias, and the extraction of phenological variables on technique performance. Users are strongly cautioned to consider both their ultimate objectives and the nature of the noise present in an NDVI data set when selecting an approach to noise reduction, particularly when deriving phenological variables. \textcopyright{} 2008 Elsevier Inc. All rights reserved.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,MODIS,NDVI time series,Noise reduction,Vegetation phenology}
}

@article{hiroyoshidatakehikosegawa_Visualization_2002,
  title = {Visualization of {{Wall Turbulence Under Artificial Disturbance}} by {{Piezo Actuator Array}}},
  author = {Hiro Yoshida Takehiko Segawa, Peiwen Li, Yasuo Kawaguchi},
  date = {2002},
  journaltitle = {J. Turbul.},
  volume = {3},
  abstract = {A possibility of turbulent flow control by an actuator array was experimentally examined. A turbulent channel flow of water at Re=7500 in a rectangle channel (cross section: 500 mm x 40 mm) was used to clarify the optimum driving condition of the actuator array. Using a particle image velocimetry (PIV) system, we could visualize the low-speed fluid element penetrating into the outer layer from the inner layer. Six actuators are installed on the wall and aligned in spanwise direction. Each actuator element can be independently oscillated vertically at 100 mm amplitude. The mean spacing of streak-like structures existing in the vicinity of the wall are known to be in the order of 100 times the viscous length scale, 100n/ u. Suitable size of the actuator was determined to have half size of the mean spacing of low-speed streaks near the wall. Driving frequency was changed to find the condition of interactions between low-speed streaks and structures generated by actuators. In such a project, observation of instantaneous velocity distribution gives essential information and PIV is the only method usable to this purpose. The present PIV system allows to detect instantaneous velocity as well as vorticity concentrated near the wall in the interval of less than 0.1sec. As a result of analyzing spatial velocity distribution in x-z plane near the wall by PIV, the regularity of the velocity distribution in y + =50 observed in plane channel flow becomes indistinct for the frequency (fa) of actuator more than 12.5 Hz},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{hoang_Interobserver_2018,
  title = {Interobserver {{Variability}} of {{Sonographic Features Used}} in the {{American College}} of {{Radiology Thyroid Imaging Reporting}} and {{Data System}}},
  author = {Hoang, Jenny K. and Middleton, William D. and Farjat, Alfredo E. and Teefey, Sharlene A. and Abinanti, Nicole and Boschini, Fernando J. and Bronner, Abraham J. and Dahiya, Nirvikar and Hertzberg, Barbara S. and Newman, Justin R. and Scanga, Daniel and Vogler, Robert C. and Tessler, Franklin N.},
  date = {2018-07},
  journaltitle = {AJR Am J Roentgenol},
  volume = {211},
  number = {1},
  eprint = {29702015},
  eprinttype = {pmid},
  pages = {162--167},
  issn = {1546-3141},
  doi = {10.2214/AJR.17.19192},
  abstract = {OBJECTIVE: The purpose of this study was to assess interobserver variability in assigning features in the American College of Radiology Thyroid Imaging Reporting and Data System (ACR TI-RADS) lexicon and in making recommendations for thyroid nodule biopsy. MATERIALS AND METHODS: The study cohort comprised 100 nodules in 92 patients who underwent fine-needle aspiration with definitive cytologic results (Bethesda category II or VI) or diagnostic lobectomy between April 2009 and May 2010. Eight board-certified radiologists evaluated the nodules according to the five feature categories that constitute ACR TI-RADS and gave a biopsy recommendation based on their own practice. Variability in feature assignment and biopsy recommendation was assessed with the Fleiss kappa statistic. RESULTS: Agreement in interpretation was fair to moderate for all features except shape ({$\kappa$} = 0.61) and macrocalcifications ({$\kappa$} = 0.73), which had substantial agreement. The features with the poorest agreement were margin and other types of echogenic foci, which had kappa values ranging from 0.25 to 0.39, indicating fair agreement. Interobserver agreement regarding biopsy recommendation was fair ({$\kappa$} = 0.22) based on radiologists' current practice. Applying ACR TI-RADS resulted in moderate agreement ({$\kappa$} = 0.51). CONCLUSION: Variability in interpreting thyroid nodule sonographic features was highest for margin and all types of echogenic foci, except for macrocalcifications. Because radiologists' interpretations of these features change the level of suspicion of thyroid malignancy, the results of this study suggest a need for further education. Despite the variability in assigning features, adoption of ACR TI-RADS improves agreement for recommending biopsy.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Adult,Aged,{Aged, 80 and over},{Biopsy, Fine-Needle},Female,Humans,interobserver agreement,interobserver variability,Male,Middle Aged,Observer Variation,{Societies, Medical},thyroid malignancy,Thyroid Neoplasms,Thyroid Nodule,thyroid ultrasound,TI-RADS,Ultrasonography,United States},
  annotation = {77 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/H8XLG9QP/Hoang et al. - 2018 - Interobserver Variability of Sonographic Features .pdf;/Users/personal-macbook/Zotero/storage/7FIRF7CX/Hoang et al. - 2018 - Interobserver Variability of Sonographic Features .html}
}

@article{hochreiter_Feature_1999,
  title = {Feature {{Extraction Through LOCOCODE}}},
  author = {Hochreiter, S. and Schmidhuber, J.},
  date = {1999-04},
  journaltitle = {Neural Comput.},
  volume = {11},
  number = {3},
  pages = {679--714},
  doi = {10.1162/089976699300016629},
  abstract = {Low-complexity coding and decoding (LOCOCODE) is a novel approach to sensory coding and unsupervised learning. Unlike previous methods, it explicitly takes into account the information-theoretic complexity of the code generator. It computes lococodes that convey information about the input data and can be computed and decoded by low-complexity mappings. We implement LOCOCODE by training autoassociators with flat minimum search, a recent, general method for discovering low-complexity neural nets. It turns out that this approach can unmix an unknown number of independent data sources by extracting a minimal number of low-complexity features necessary for representing the data. Experiments show that unlike codes obtained with standard autoencoders, lococodes are based on feature detectors, never unstructured, usually sparse, and sometimes factorial or local (depending on statistical properties of the data). Although LOCOCODE is not explicitly designed to enforce sparse or factorial codes, it extracts optimal codes for difficult versions of the ``bars'' benchmark problem, whereas independent component analysis (ICA) and principal component analysis (PCA) do not. It produces familiar, biologically plausible feature detectors when applied to real-world images and codes with fewer bits per pixel than ICA and PCA. Unlike ICA, it does not need to know the number of independent sources. As a preprocessor for a vowel recognition benchmark problem, it sets the stage for excellent classification performance. Our results reveal an interesting, previously ignored connection between two important fields: regularizer research and ICA-related research. They may represent a first step toward unification of regularization and unsupervised learning.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {87 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{hoeting_Bayesian_1999,
  title = {Bayesian {{Model Averaging}}: {{A Tutorial}} ({{With Comments}} by {{M}}. {{Clyde}}, {{David Draper}} and {{E}}. {{I}}. {{George}}, and a {{Rejoinder}} by the {{Authors}}},
  shorttitle = {Bayesian {{Model Averaging}}},
  author = {Hoeting, Jennifer A. and Madigan, David and Raftery, Adrian E. and Volinsky, Chris T.},
  date = {1999-11-01},
  journaltitle = {Statist. Sci.},
  volume = {14},
  number = {4},
  issn = {0883-4237},
  doi = {10.1214/ss/1009212519},
  url = {https://projecteuclid.org/journals/statistical-science/volume-14/issue-4/Bayesian-model-averaging--a-tutorial-with-comments-by-M/10.1214/ss/1009212519.full},
  urldate = {2023-05-03},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {3287 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/PP9QHG5T/Hoeting et al. - 1999 - Bayesian model averaging a tutorial (with comment.pdf}
}

@inproceedings{hoffman_CyCADA_2018,
  title = {{{CyCADA}}: {{Cycle-Consistent Adversarial Domain Adaptation}}},
  booktitle = {35th {{Int}}. {{Conf}}. {{Mach}}. {{Learn}}. {{ICML}} 2018},
  author = {Hoffman, Judy and Tzeng, Eric and Park, Taesung and Zhu, Jun Yan and Isola, Phillip and Saenko, Kate and Efros, Alexei A. and Darrell, Trevor},
  date = {2018},
  abstract = {Domain adaptation is critical for success in new, unseen environments. Adversarial adaptation models have shown tremendous progress towards adapting to new environments by focusing either on discovering domain invariant representations or by mapping between unpaired image domains. While feature space methods are difficult to interpret and sometimes fail to capture pixel-level and low-level domain shifts, image space methods sometimes fail to incorporate high level semantic knowledge relevant for the end task. We propose a model which adapts between domains using both generative image space alignment and latent representation space alignment. Our approach, Cycle-Consistent Adversarial Domain Adaptation (CyCADA), guides transfer between domains according to a specific discriminatively trained task and avoids divergence by enforcing consistency of the relevant semantics before and after adaptation. We evaluate our method on a variety of visual recognition and prediction settings, including digit classification and semantic segmentation of road scenes, advancing state-of-the-art performance for unsupervised adaptation from synthetic to real world driving domains.},
  isbn = {978-1-5108-6796-3},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{hogan_MRIbased_2004,
  title = {{{MRI-based High-Dimensional Hippocampal Mapping}} in {{Mesial Temporal Lobe Epilepsy}}},
  author = {Hogan, R. Edward and Wang, Lei and Bertrand, Mary E. and Willmore, L. James and Bucholz, Richard D. and Nassif, A. Sami and Csernansky, John G.},
  date = {2004-08},
  journaltitle = {Brain},
  volume = {127},
  pages = {1731--1740},
  abstract = {MRI-based evaluation of the hippocampus is important in the assessment and treatment of patients with mesial temporal lobe epilepsy (MTLE). Using MRI-based large-deformation high-dimensional mapping (HDM-LD), which allows structural evaluation of regions of the hippocampus, we document the HDM-LD-defined pattern of hippocampal deformation in MTLE patients compared with matched controls. In 30 subjects with MTLE and confirmed medial temporal lobe sclerosis (MTS), we performed measurements of intracranial area, brain parenchymal volume and deformation-based hippocampal segmentations, and then grouped patients into right and left MTS groups (resulting in 15 subjects in each group). Using HDM-LD techniques, we compared the right and left MTS groups with a group of 15 matched controls. Analysis included both the MTS and contralateral hippocampi, and covariance for changes in brain parenchymal volume. Final results were interpreted using a segmentation showing normal hippocampal surface subfield anatomy. Comparing the MTS groups with controls, after covarying with brain parenchymal volume, the MTS hippocampi showed significant volume loss (P {$<$} 0.0001), contralateral hippocampi showed no significant volume loss. HDM-LD techniques showed significant shape changes, with marked inward deviation in the Sommer sector of the MTS hippocampi. In the contralateral hippocampi, the inferior surface of the hippocampal body showed inward deformation in the medial aspect of the subiculum, with minimal involvement of the Sommer sector. HDM-LD shows involvement of subregions of the hippocampus which are consistent with MTS histopathology. Contralateral hippocampi show different HDM-LD changes, suggesting that the underlying disease process in the contralateral hippocampi is different from MTS.},
  issue = {Pt 8},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{hoi_SemiSupervised_,
  title = {Semi-{{Supervised SVM Batch Mode Active Learning}} for {{Image Retrieval}}},
  author = {Hoi, Steven C. H. and Jin, Rong},
  doi = {10.1109/CVPR.2008.4587350},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{holland_Efficient_2010,
  title = {Efficient {{Correction}} of {{Inhomogeneous Static Magnetic Field-Induced Distortion}} in {{Echo Planar Imaging}}},
  author = {Holland, Dominic and Kuperman, Joshua M. and Dale, Anders M.},
  date = {2010-03},
  journaltitle = {Neuroimage},
  volume = {50},
  number = {1},
  pages = {175--183},
  doi = {10.1016/j.neuroimage.2009.11.044},
  abstract = {Single-shot Echo Planar Imaging (EPI) is one of the most efficient magnetic resonance imaging (MRI) acquisition schemes, producing relatively high-definition images in 100 ms or less. These qualities make it desirable for Diffusion Tensor Imaging (DTI), functional MRI (fMRI), and Dynamic Susceptibility Contrast MRI (DSC-MRI). However, EPI suffers from severe spatial and intensity distortion due to B(0) field inhomogeneity induced by magnetic susceptibility variations. Anatomically accurate, undistorted images are essential for relating DTI and fMRI images with anatomical MRI scans, and for spatial registration with other modalities. We present here a fast, robust, and accurate procedure for correcting EPI images from such spatial and intensity distortions. The method involves acquisition of scans with opposite phase encoding polarities, resulting in opposite spatial distortion patterns, and alignment of the resulting images using a fast nonlinear registration procedure. We show that this method, requiring minimal additional scan time, provides superior accuracy relative to the more commonly used, and more time consuming, field mapping approach. This method is also highly computationally efficient, allowing for direct ``real-time'' implementation on the MRI scanner. We further demonstrate that the proposed method can be used to recover dropouts in gradient echo (BOLD and DSC-MRI) EPI images.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {405 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{hong_Learning_2016,
  title = {Learning {{Transferrable Knowledge}} for {{Semantic Segmentation With Deep Convolutional Neural Network}}},
  booktitle = {2016 {{IEEE Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}. {{CVPR}}},
  author = {Hong, S. and Oh, J. and Lee, H. and Han, B.},
  date = {2016-06},
  pages = {3204--3212},
  abstract = {We propose a novel weakly-supervised semantic segmentation algorithm based on Deep Convolutional Neural Network (DCNN). Contrary to existing weakly-supervised approaches, our algorithm exploits auxiliary segmentation annotations available for different categories to guide segmentations on images with only image-level class labels. To make segmentation knowledge transferrable across categories, we design a decoupled encoder-decoder architecture with attention model. In this architecture, the model generates spatial highlights of each category presented in images using an attention model, and subsequently performs binary segmentation for each highlighted region using decoder. Combining attention model, the decoder trained with segmentation annotations in different categories boosts accuracy of weakly-supervised semantic segmentation. The proposed algorithm demonstrates substantially improved performance compared to the state-of-theart weakly-supervised techniques in PASCAL VOC 2012 dataset when our model is trained with the annotations in 60 exclusive categories in Microsoft COCO dataset.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,image segmentation,learning (artificial intelligen}
}

@article{hongzhiwang_MultiAtlas_2013,
  ids = {wang_MultiAtlas_2013},
  title = {Multi-{{Atlas Segmentation With Joint Label Fusion}}},
  author = {{Hongzhi Wang} and Suh, J. W. and Das, S. R. and Pluta, J. B. and Craige, C. and Yushkevich, P. A.},
  date = {2013-03},
  journaltitle = {IEEE Trans. Pattern Anal. Mach. Intell.},
  volume = {35},
  number = {3},
  pages = {611--623},
  issn = {0162-8828, 2160-9292},
  doi = {10.1109/TPAMI.2012.143},
  url = {http://ieeexplore.ieee.org/document/6226425/},
  urldate = {2023-05-08},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {753 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/3AHKFJZJ/Hongzhi Wang et al. - 2013 - Multi-Atlas Segmentation with Joint Label Fusion.pdf}
}

@article{hosny_Artificial_2018,
  title = {Artificial {{Intelligence}} in {{Radiology}}},
  author = {Hosny, Ahmed and Parmar, Chintan and Quackenbush, John and Schwartz, Lawrence H. and Aerts, Hugo J. W. L.},
  date = {2018},
  journaltitle = {Nat. Rev. Cancer},
  eprint = {29777175},
  eprinttype = {pmid},
  issn = {14741768},
  doi = {10.1038/s41568-018-0016-5},
  abstract = {Artificial intelligence (AI) algorithms, particularly deep learning, have demonstrated remarkable progress in image-recognition tasks. Methods ranging from convolutional neural networks to variational autoencoders have found myriad applications in the medical image analysis field, propelling it forward at a rapid pace. Historically, in radiology practice, trained physicians visually assessed medical images for the detection, characterization and monitoring of diseases. AI methods excel at automatically recognizing complex patterns in imaging data and providing quantitative, rather than qualitative, assessments of radiographic characteristics. In this Opinion article, we establish a general understanding of AI methods, particularly those pertaining to image-based tasks. We explore how these methods could impact multiple facets of radiology, with a general focus on applications in oncology, and demonstrate ways in which these methods are advancing the field. Finally, we discuss the challenges facing clinical implementation and provide our perspective on how the domain could be advanced.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Cancer imaging,Cancer screening,Machine learning,Medical imaging},
  annotation = {1223 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{hou_FewShot_2019,
  title = {Few-{{Shot Sequence Labeling With Label Dependency Transfer}} and {{Pair-Wise Embedding}}},
  author = {Hou, Yutai and Zhou, Zhihan and Liu, Yijia and Wang, Ning and Che, Wanxiang and Liu, Han and Liu, Ting},
  date = {2019},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.1906.08711},
  url = {https://arxiv.org/abs/1906.08711},
  urldate = {2022-11-21},
  abstract = {While few-shot classification has been widely explored with similarity based methods, few-shot sequence labeling poses a unique challenge as it also calls for modeling the label dependencies. To consider both the item similarity and label dependency, we propose to leverage the conditional random fields (CRFs) in few-shot sequence labeling. It calculates emission score with similarity based methods and obtains transition score with a specially designed transfer mechanism. When applying CRF in the few-shot scenarios, the discrepancy of label sets among different domains makes it hard to use the label dependency learned in prior domains. To tackle this, we introduce the dependency transfer mechanism that transfers abstract label transition patterns. In addition, the similarity methods rely on the high quality sample representation, which is challenging for sequence labeling, because sense of a word is different when measuring its similarity to words in different sentences. To remedy this, we take advantage of recent contextual embedding technique, and further propose a pair-wise embedder. It provides additional certainty for word sense by embedding query and support sentence pairwisely. Experimental results on slot tagging and named entity recognition show that our model significantly outperforms the strongest few-shot learning baseline by 11.76 (21.2\%) and 12.18 (97.7\%) F1 scores respectively in the one-shot setting.},
  version = {3},
  keywords = {⛔ No INSPIRE recid found,Computation and Language (cs.CL),FOS: Computer and information sciences,Machine Learning (cs.LG)},
  annotation = {12 citations (Semantic Scholar/arXiv) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/8HTUKGZ6/Hou et al. - 2019 - Few-shot sequence labeling with label dependency t.pdf;/Users/personal-macbook/Zotero/storage/2JSDJIFM/1906.html;/Users/personal-macbook/Zotero/storage/N7KGD229/forum.html}
}

@article{hoult_Sensitivity_1979,
  title = {The {{Sensitivity}} of the {{Zeugmatographic Experiment Involving Human Samples}}},
  author = {Hoult, D.I and Lauterbur, Paul C},
  date = {1979-05},
  journaltitle = {Journal of Magnetic Resonance (1969)},
  volume = {34},
  number = {2},
  pages = {425--433},
  issn = {00222364},
  doi = {10.1016/0022-2364(79)90019-2},
  url = {https://linkinghub.elsevier.com/retrieve/pii/0022236479900192},
  urldate = {2023-05-28},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {761 citations (Semantic Scholar/DOI) [2023-05-28]}
}

@inproceedings{hovy_MACE_2013,
  title = {Learning {{Whom}} to {{Trust}} with {{MACE}}},
  author = {Hovy, Dirk and Berg-Kirkpatrick, Taylor and Vaswani, Ashish and Hovy, E.},
  date = {2013-06-01},
  url = {https://www.semanticscholar.org/paper/Learning-Whom-to-Trust-with-MACE-Hovy-Berg-Kirkpatrick/624a5c97be5d3ec63d48c34db25726008e5d92a4},
  urldate = {2023-06-30},
  abstract = {Non-expert annotation services like Amazon's Mechanical Turk (AMT) are cheap and fast ways to evaluate systems and provide categorical annotations for training data. Unfortunately, some annotators choose bad labels in order to maximize their pay. Manual identification is tedious, so we experiment with an item-response model. It learns in an unsupervised fashion to a) identify which annotators are trustworthy and b) predict the correct underlying labels. We match performance of more complex state-of-the-art systems and perform well even under adversarial conditions. We show considerable improvements over standard baselines, both for predicted label accuracy and trustworthiness estimates. The latter can be further improved by introducing a prior on model parameters and using Variational Bayes inference. Additionally, we can achieve even higher accuracy by focusing on the instances our model is most confident in (trading in some recall), and by incorporating annotated control instances. Our system, MACE (Multi-Annotator Competence Estimation), is available for download 1 .},
  eventtitle = {North {{American Chapter}} of the {{Association}} for {{Computational Linguistics}}},
  keywords = {⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/YK5FICX4/Hovy et al. - 2013 - Learning Whom to Trust with MACE.pdf}
}

@article{hu_Combination_2018,
  title = {Combination of {{Near-Infrared}} and {{Thermal Imaging Techniques}} for the {{Remote}} and {{Simultaneous Measurements}} of {{Breathing}} and {{Heart Rates Under Sleep Situation}}},
  author = {Hu, Menghan and Zhai, Guangtao and Li, Duo and Fan, Yezhao and Duan, Huiyu and Zhu, Wenhan and Yang, Xiaokang},
  editor = {Yang, You},
  date = {2018-01-05},
  journaltitle = {PLoS ONE},
  volume = {13},
  number = {1},
  pages = {e0190466},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0190466},
  url = {https://dx.plos.org/10.1371/journal.pone.0190466},
  urldate = {2023-05-08},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {56 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/HP8SKTSL/Hu et al. - 2018 - Combination of near-infrared and thermal imaging t.pdf}
}

@inproceedings{hu_Supervised_2019,
  title = {Supervised {{Uncertainty Quantification}} for {{Segmentation With Multiple Annotations}}},
  booktitle = {Med. {{Image Comput}}. {{Comput}}. {{Assist}}. {{Interv}}. \textendash{} {{MICCAI}} 2019},
  author = {Hu, Shi and Worrall, Daniel and Knegt, Stefan and Veeling, Bas and Huisman, Henkjan and Welling, Max},
  date = {2019},
  pages = {137--145},
  publisher = {{Springer International Publishing}},
  doi = {10.1007/978-3-030-32245-8_16},
  abstract = {The accurate estimation of predictive uncertainty carries importance in medical scenarios such as lung node segmentation. Unfortunately, most existing works on predictive uncertainty do not return calibrated uncertainty estimates, which could be used in practice. In this work we exploit multi-grader annotation variability as a source of `groundtruth' aleatoric uncertainty, which can be treated as a target in a supervised learning problem. We combine this groundtruth uncertainty with a Probabilistic U-Net and test on the LIDC-IDRI lung nodule CT dataset and MICCAI2012 prostate MRI dataset. We find that we are able to improve predictive uncertainty estimates. We also find that we can improve sample accuracy and sample diversity. In real-world applications, our method could inform doctors about the confidence of the segmentation results.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{huang_Densely_2017,
  title = {Densely {{Connected Convolutional Networks}}},
  booktitle = {Proc. - 30th {{IEEE Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}. {{CVPR}} 2017},
  author = {Huang, Gao and Liu, Zhuang and Maaten, Laurens Van Der and Weinberger, Kilian Q.},
  date = {2017},
  doi = {10.1109/CVPR.2017.243},
  abstract = {Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections - one between each layer and its subsequent layer - our network has L(L2+1) direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less computation to achieve high performance. Code and pre-trained models are available at https://github.com/liuzhuang13/DenseNet.},
  isbn = {978-1-5386-0457-1},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {9992 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{huang_Fast_1979,
  title = {A {{Fast Two-Dimensional Median Filtering Algorithm}}},
  author = {Huang, T. and Yang, G. and Tang, G.},
  date = {1979-02},
  journaltitle = {IEEE Trans. Acoust., Speech, Signal Process.},
  volume = {27},
  number = {1},
  pages = {13--18},
  issn = {0096-3518},
  doi = {10.1109/TASSP.1979.1163188},
  url = {http://ieeexplore.ieee.org/document/1163188/},
  urldate = {2023-05-08},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {1301 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{huang_Nonrigid_2014,
  title = {Non-{{Rigid Registration Using Gradient}} of {{Self-Similarity Response}}},
  author = {Huang, James L. and Rodriguez, Jeffrey J.},
  date = {2014},
  journaltitle = {Image Vis. Comput.},
  issn = {02628856},
  doi = {10.1016/j.imavis.2014.06.005},
  abstract = {Locally affine transformation with globally elastic interpolation is a common strategy for non-rigid registration. Current techniques improve the registration accuracy by only processing the sub-images that contain well-defined structures quantified by Moran's spatial correlation. As an indicator, Moran's metric successfully excludes noisy structures that result in misleading global optimum in terms of similarity. However, some well-defined structures with intensity only varying in one direction may also cause mis-registration. In this paper, we propose a new metric based on the response of a similarity function to quantify the ability of being correctly registered for each sub-image. Using receiver operating characteristic analysis, we show that the proposed metric more accurately reflects such ability than Moran's metric. Incorporating the proposed metric into a hierarchical non-rigid registration scheme, we show that registration accuracy is improved relative to Moran's metric. \textcopyright{} 2014 Elsevier B.V. All rights reserved.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Hierarchical elastic registration,Locally affine transformation,Non-rigid registration}
}

@article{hullermeier_Flexible_2022,
  title = {A {{Flexible Class}} of {{Dependence-Aware Multi-Label Loss Functions}}},
  author = {H\"ullermeier, Eyke and Wever, Marcel and Loza Mencia, Eneldo and F\"urnkranz, Johannes and Rapp, Michael},
  date = {2022-02},
  journaltitle = {Mach Learn},
  volume = {111},
  number = {2},
  pages = {713--737},
  issn = {0885-6125, 1573-0565},
  doi = {10.1007/s10994-021-06107-2},
  url = {https://link.springer.com/10.1007/s10994-021-06107-2},
  urldate = {2022-11-21},
  abstract = {The idea to exploit label dependencies for better prediction is at the core of methods for multi-label classification (MLC), and performance improvements are normally explained in this way. Surprisingly, however, there is no established methodology that allows to analyze the dependence-awareness of MLC algorithms. With that goal in mind, we introduce a class of loss functions that are able to capture the important aspect of label dependence. To this end, we leverage the mathematical framework of non-additive measures and integrals. Roughly speaking, a non-additive measure allows for modeling the importance of correct predictions of label subsets (instead of single labels), and thereby their impact on the overall evaluation, in a flexible way. The well-known Hamming and subset 0/1 losses are rather extreme special cases of this function class, which give full importance to single label sets or the entire label set, respectively. We present concrete instantiations of this class, which appear to be especially appealing from a modeling perspective. The assessment of multi-label classifiers in terms of these losses is illustrated in an empirical study, clearly showing their aptness at capturing label dependencies. Finally, while not being the main goal of this study, we also show some preliminary results on the minimization of this parametrized family of losses.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Analysis,Label dependence,Loss function,Multi-label classification,Non-additive measures},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/YSWSCAN9/Hüllermeier et al. - 2022 - A flexible class of dependence-aware multi-label l.pdf}
}

@inproceedings{hult_Greylevel_2003,
  title = {Grey-{{Level Morphology Combined With}} an {{Artificial Neural Networks Approach}} for {{Multimodal Segmentation}} of the {{Hippocampus}}},
  booktitle = {Image {{Anal}}. {{Process}}. 2003 {{Proc}}. 12th {{Int}}. {{Conf}}. {{On}}},
  author = {Hult, Roger},
  date = {2003},
  pages = {277--282},
  publisher = {{IEEE}},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{humphreys_UMLS_1993a,
  ids = {humphreys_UMLS_1993},
  title = {The {{UMLS Project}}: {{Making}} the {{Conceptual Connection Between Users}} and the {{Information They Need}}.},
  shorttitle = {The {{UMLS}} Project},
  author = {Humphreys, B L and Lindberg, D A},
  date = {1993-04},
  journaltitle = {Bull Med Libr Assoc},
  volume = {81},
  number = {2},
  eprint = {8472002},
  eprinttype = {pmid},
  pages = {170--177},
  issn = {0025-7338},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC225759/},
  urldate = {2022-12-15},
  abstract = {Conceptual connections between users and information sources depend on an accurate representation of the content of available information sources, an accurate representation of specific user information needs, and the ability to match the two. Establishing such connections is a principal function of medical librarians. The goal of the National Library of Medicine's Unified Medical Language System (UMLS) project is to facilitate the development of conceptual connections between users and relevant machine-readable information. The UMLS model involves a combination of three centrally developed Knowledge Sources (a Metathesaurus, a Semantic Network, and an Information Sources Map) and a variety of smart interface programs that make use of these Knowledge Sources to help users in different environments find machine-readable information relevant to their particular practice or research problems. The third experimental edition of the UMLS Knowledge Sources was issued in the fall of 1992. Current priorities for the UMLS project include developing applications that make use of the Knowledge Sources and using feedback from these applications to guide ongoing enhancement and expansion of the Knowledge Sources. Medical librarians are involved heavily in the direction of the UMLS project, in the development of the Knowledge Sources, and in their experimental application. The involvement of librarians in reviewing, testing, and providing feedback on UMLS products will increase the likelihood that the UMLS project will achieve its goal of improving access to machine-readable biomedical information.},
  pmcid = {PMC225759},
  keywords = {⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/PUNAYMRJ/Humphreys and Lindberg - 1993 - The UMLS project making the conceptual connection.pdf}
}

@article{hunsaker_Evaluating_2008,
  title = {Evaluating the {{Temporal Context}} of {{Episodic Memory}}: {{The Role}} of {{CA3}} and {{CA1}}},
  author = {Hunsaker, Michael R. and Lee, Bart and Kesner, Raymond P.},
  date = {2008-04},
  journaltitle = {Behav. Brain Res.},
  volume = {188},
  number = {2},
  pages = {310--315},
  doi = {10.1016/j.bbr.2007.11.015},
  abstract = {It has been suggested that the hippocampus mediates episodic memory processing involving snapshot memory and temporal sequence learning. To test this theory, rats learned trial-unique sequences of spatial locations along a runway box and were tested on recall by removing one of the locations in the sequence and making the rat choose the correct location to be rewarded. Once animals were able to reliably perform this episodic memory task, they received lesions to either CA3 or CA1. Animals with lesions to either CA3 or CA1 had difficulty with episodic memory processing, although CA1 lesioned animals had a much greater deficit. However, when animals were trained on a non-episodic version of the same task, hippocampal lesions had no effect. These results suggest that CA3 and CA1 both contribute to episodic memory processing since lesions to CA3 or CA1 result in an inability to process spatial information episodically, whereas they have no effect on non-episodic information processing.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {98 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{hunter_MM_2004,
  title = {{{MM Algorithms}} for {{Generalized Bradley-Terry Models}}},
  author = {Hunter, David R.},
  date = {2004-02-01},
  journaltitle = {Ann. Statist.},
  volume = {32},
  number = {1},
  issn = {0090-5364},
  doi = {10.1214/aos/1079120141},
  url = {https://projecteuclid.org/journals/annals-of-statistics/volume-32/issue-1/MM-algorithms-for-generalized-Bradley-Terry-models/10.1214/aos/1079120141.full},
  urldate = {2022-12-28},
  keywords = {⛔ No INSPIRE recid found,62F07,65D15,Bradley-Terry model,Luce's choice axiom,maximum likelihood estimation,MM algorithm,Newton-Raphson,Plackett-Luce model},
  annotation = {477 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/43HJLVTR/Hunter - 2004 - Mm Algorithms for Generalized Bradley-Terry Models.pdf}
}

@article{hwang_Development_2019,
  title = {Development and {{Validation}} of a {{Deep Learning-Based Automated Detection Algorithm}} for {{Major Thoracic Diseases}} on {{Chest Radiographs}}},
  author = {Hwang, Eui Jin and Park, Sunggyun and Jin, Kwang Nam and Kim, Jung Im and Choi, So Young and Lee, Jong Hyuk and Goo, Jin Mo and Aum, Jaehong and Yim, Jae Joon and Cohen, Julien G. and Ferretti, Gilbert R. and Park, Chang Min},
  date = {2019},
  journaltitle = {JAMA Netw. Open},
  eprint = {30901052},
  eprinttype = {pmid},
  issn = {25743805},
  doi = {10.1001/jamanetworkopen.2019.1095},
  abstract = {Importance: Interpretation of chest radiographs is a challenging task prone to errors, requiring expert readers. An automated system that can accurately classify chest radiographs may help streamline the clinical workflow. Objectives: To develop a deep learning-based algorithm that can classify normal and abnormal results from chest radiographs with major thoracic diseases including pulmonary malignant neoplasm, active tuberculosis, pneumonia, and pneumothorax and to validate the algorithm's performance using independent data sets. Design, Setting, and Participants: This diagnostic study developed a deep learning-based algorithm using single-center data collected between November 1, 2016, and January 31, 2017. The algorithm was externally validated with multicenter data collected between May 1 and July 31, 2018. A total of 54 221 chest radiographs with normal findings from 47 917 individuals (21 556 men and 26 361 women; mean [SD] age, 51 [16] years) and 35 613 chest radiographs with abnormal findings from 14 102 individuals (8373 men and 5729 women; mean [SD] age, 62 [15] years) were used to develop the algorithm. A total of 486 chest radiographs with normal results and 529 with abnormal results (1 from each participant; 628 men and 387 women; mean [SD] age, 53 [18] years) from 5 institutions were used for external validation. Fifteen physicians, including nonradiology physicians, board-certified radiologists, and thoracic radiologists, participated in observer performance testing. Data were analyzed in August 2018. Exposures: Deep learning-based algorithm. Main Outcomes and Measures: Image-wise classification performances measured by area under the receiver operating characteristic curve; lesion-wise localization performances measured by area under the alternative free-response receiver operating characteristic curve. Results: The algorithm demonstrated a median (range) area under the curve of 0.979 (0.973-1.000) for image-wise classification and 0.972 (0.923-0.985) for lesion-wise localization; the algorithm demonstrated significantly higher performance than all 3 physician groups in both image-wise classification (0.983 vs 0.814-0.932; all P {$<$} .005) and lesion-wise localization (0.985 vs 0.781-0.907; all P {$<$} .001). Significant improvements in both image-wise classification (0.814-0.932 to 0.904-0.958; all P {$<$} .005) and lesion-wise localization (0.781-0.907 to 0.873-0.938; all P {$<$} .001) were observed in all 3 physician groups with assistance of the algorithm. Conclusions and Relevance: The algorithm consistently outperformed physicians, including thoracic radiologists, in the discrimination of chest radiographs with major thoracic diseases, demonstrating its potential to improve the quality and efficiency of clinical practice.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {219 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{hwang_Novel_2016,
  title = {A {{Novel Approach}} for {{Tuberculosis Screening Based}} on {{Deep Convolutional Neural Networks}}},
  author = {Hwang, Sangheum and Kim, Hyo-Eun and Jeong, Jihoon and Kim, Hee-Jin},
  editor = {Tourassi, Georgia D. and Armato, Samuel G.},
  date = {2016-03-24},
  pages = {97852W},
  location = {{San Diego, California, United States}},
  doi = {10.1117/12.2216198},
  url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2216198},
  urldate = {2023-05-08},
  eventtitle = {{{SPIE Medical Imaging}}},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Deep convolutional neural,Tuberculosis screening},
  annotation = {160 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{iglesias_Computational_2015,
  title = {A {{Computational Atlas}} of the {{Hippocampal Formation Using Ex Vivo}}, {{Ultra-High Resolution Mri}}: {{Application}} to {{Adaptive Segmentation}} of in {{Vivo Mri}}},
  shorttitle = {A {{Computational Atlas}} of the {{Hippocampal Formation Using Ex Vivo}}, {{Ultra-High Resolution Mri}}},
  author = {Iglesias, Juan Eugenio and Augustinack, Jean C. and Nguyen, Khoa and Player, Christopher M. and Player, Allison and Wright, Michelle and Roy, Nicole and Frosch, Matthew P. and McKee, Ann C. and Wald, Lawrence L. and Fischl, Bruce and Van Leemput, Koen},
  date = {2015-07},
  journaltitle = {NeuroImage},
  volume = {115},
  pages = {117--137},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2015.04.042},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811915003420},
  urldate = {2022-12-29},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {780 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/I9IG2FHQ/Iglesias et al. - 2015 - A computational atlas of the hippocampal formation.pdf}
}

@article{iglesias_Probabilistic_2018,
  title = {A {{Probabilistic Atlas}} of the {{Human Thalamic Nuclei Combining Ex Vivo Mri}} and {{Histology}}},
  author = {Iglesias, Juan Eugenio and Insausti, Ricardo and Lerma-Usabiaga, Garikoitz and Bocchetta, Martina and Van Leemput, Koen and Greve, Douglas N. and Van Der Kouwe, Andre and Fischl, Bruce and Caballero-Gaudes, C\'esar and Paz-Alonso, Pedro M.},
  date = {2018-12},
  journaltitle = {NeuroImage},
  volume = {183},
  pages = {314--326},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2018.08.012},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811918307109},
  urldate = {2023-05-08},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Atlasing,Bayesian inference,Ex-vivo MRI,Histolo,Histology,Segmentation,Thalamus},
  annotation = {248 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/CXSRBXVW/Iglesias et al. - 2018 - A probabilistic atlas of the human thalamic nuclei.pdf}
}

@article{iglesias_Robust_2009,
  title = {Robust {{Initial Detection}} of {{Landmarks}} in {{Film-Screen Mammograms Using Multiple FFDM Atlases}}},
  author = {Iglesias, Juan Eugenio and Karssemeijer, Nico},
  date = {2009-11},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {28},
  number = {11},
  pages = {1815--1824},
  doi = {10.1109/TMI.2009.2025036},
  abstract = {Automated analysis of mammograms requires robust methods for pectoralis segmentation and nipple detection. Locating the nipple is especially important in multiview computer aided detection systems, in which findings are matched across images using the nipple-to-finding distance. Segmenting the pectoralis is a key preprocessing step to avoid false positives when detecting masses due to the similarity of the texture of mammographic parenchyma and the pectoral muscle. A multiatlas algorithm capable of providing very robust initial estimates of the nipple position and pectoral region in digitized mammograms is presented here. Ten full-field digital mammograms, which are easily annotated attributed to their excellent contrast, are robustly registered to the target digitized film-screen mammogram. The annotations are then propagated and fused into a final nipple position and pectoralis segmentation. Compared to other nipple detection methods in the literature, the system proposed here has the advantages that it is more robust and can provide a reliable estimate when the nipple is located outside the image. Our results show that the change in the correlation between nipple-to-finding distances in craniocaudal and mediolateral oblique views is not significant when the detected nipple positions replace the manual annotations. Moreover, the pectoralis segmentation is acceptable and can be used as initialization for a more complex algorithm to optimize the outline locally. A novel aspect of the method is that it is also capable of detecting and segmenting the pectoralis in craniocaudal views.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{iglesias_Robust_2011,
  title = {Robust {{Brain Extraction Across Datasets}} and {{Comparison With Publicly Available Methods}}},
  author = {Iglesias, Juan Eugenio and Liu, Cheng-Yi and Thompson, Paul M. and Tu, Zhuowen},
  date = {2011-09},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {30},
  number = {9},
  pages = {1617--1634},
  doi = {10.1109/TMI.2011.2138152},
  abstract = {Automatic whole-brain extraction from magnetic resonance images (MRI), also known as skull stripping, is a key component in most neuroimage pipelines. As the first element in the chain, its robustness is critical for the overall performance of the system. Many skull stripping methods have been proposed, but the problem is not considered to be completely solved yet. Many systems in the literature have good performance on certain datasets (mostly the datasets they were trained/tuned on), but fail to produce satisfactory results when the acquisition conditions or study populations are different. In this paper we introduce a robust, learning-based brain extraction system (ROBEX). The method combines a discriminative and a generative model to achieve the final result. The discriminative model is a Random Forest classifier trained to detect the brain boundary; the generative model is a point distribution model that ensures that the result is plausible. When a new image is presented to the system, the generative model is explored to find the contour with highest likelihood according to the discriminative model. Because the target shape is in general not perfectly represented by the generative model, the contour is refined using graph cuts to obtain the final segmentation. Both models were trained using 92 scans from a proprietary dataset but they achieve a high degree of robustness on a variety of other datasets. ROBEX was compared with six other popular, publicly available methods (BET, BSE, FreeSurfer, AFNI, BridgeBurner, and GCUT) on three publicly available datasets (IBSR, LPBA40, and OASIS, 137 scans in total) that include a wide range of acquisition hardware and a highly variable population (different age groups, healthy/diseased). The results show that ROBEX provides significantly improved performance measures for almost every method/dataset combination.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{iglovikov_Paediatric_2018,
  title = {Paediatric {{Bone Age Assessment Using Deep Convolutional Neural Networks}}},
  booktitle = {Lect. {{Notes Comput}}. {{Sci}}. {{Subser}}. {{Lect}}. {{Notes Artif}}. {{Intell}}. {{Lect}}. {{Notes Bioinforma}}.},
  author = {Iglovikov, Vladimir I. and Rakhlin, Alexander and Kalinin, Alexandr A. and Shvets, Alexey A.},
  date = {2018},
  volume = {11045 LNCS},
  pages = {300--308},
  publisher = {{Springer Verlag}},
  issn = {16113349},
  doi = {10.1007/978-3-030-00889-5_34},
  abstract = {Skeletal bone age assessment is a common clinical practice to diagnose endocrine and metabolic disorders in child development. In this paper, we describe a deep learning approach to the problem of bone age assessment using data from the 2017 Pediatric Bone Age Challenge organized by the Radiological Society of North America. This dataset consists of 12,600 radiological images. Each radiograph in the dataset is an image of a left hand labeled with bone age and sex of a patient. Our approach introduces a comprehensive preprocessing protocol based on the positive mining technique. We use images of whole hands as well as specific hand parts for both training and prediction. This allows us to measure the importance of specific hand bones for automated bone age analysis. We further evaluate the performance of the suggested methods in the context of skeletal development stages. Our approach outperforms other common methods for bone age assessment.},
  isbn = {978-3-030-00888-8},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Computer vision,Computer-aided diagnosis (CAD),Deep learning,Image recognition,Medical imaging}
}

@inproceedings{ioffe_Batch_2015,
  ids = {Ioffe2015BatchNA,ioffe_Batch_2015a},
  title = {Batch {{Normalization}}: {{Accelerating Deep Network Training}} by {{Reducing Internal Covariate Shift}}},
  shorttitle = {Batch {{Normalization}}},
  booktitle = {Proc. 32nd {{Int}}. {{Conf}}. {{Int}}. {{Conf}}. {{Mach}}. {{Learn}}. - {{Vol}}. 37},
  author = {Ioffe, Sergey and Szegedy, Christian},
  date = {2015-07-06},
  series = {{{ICML}}'15},
  pages = {448--456},
  publisher = {{JMLR.org}},
  location = {{Lille, France}},
  abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82\% top-5 test error, exceeding the accuracy of human raters.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found,Cobalt complex,Computer Science - Machine Learning,Fluorescence,FOS: Computer and information sciences,Machine Learning (cs.LG),Protonation,Redox-active},
  file = {/Users/personal-macbook/Zotero/storage/T9Z6XBFZ/Ioffe and Szegedy - 2015 - Batch Normalization Accelerating Deep Network Tra.pdf;/Users/personal-macbook/Zotero/storage/9QVKI74I/Ioffe and Szegedy - 2015 - Batch Normalization Accelerating Deep Network Tra.html}
}

@article{irfan_Valley_2012,
  title = {Valley {{Fever}} on the {{Rise}} in {{U}}.{{S}}. {{Southwest}}, {{With Links}} to {{Climate Change}}},
  author = {Irfan, Climatewire Umair},
  date = {2012-09},
  journaltitle = {Sci. Am.},
  abstract = {Heat waves exacerbated by climate change may be helping kick up the dust responsible for the fungal disease in humans},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@inproceedings{irvin_CheXpert_2019,
  ids = {irvin_Chexpert_2019},
  title = {{{CheXpert}}: {{A Large Chest Radiograph Dataset With Uncertainty Labels}} and {{Expert Comparison}}},
  shorttitle = {{{CheXpert}}},
  booktitle = {Proc. {{AAAI Conf}}. {{Artif}}. {{Intell}}.},
  author = {Irvin, Jeremy and Rajpurkar, Pranav and Ko, Michael and Yu, Yifan and Ciurea-Ilcus, Silviana and Chute, Chris and Marklund, Henrik and Haghgoo, Behzad and Ball, Robyn and Shpanskaya, Katie and Seekins, Jayne and Mong, David A. and Halabi, Safwan S. and Sandberg, Jesse K. and Jones, Ricky and Larson, David B. and Langlotz, Curtis P. and Patel, Bhavik N. and Lungren, Matthew P. and Ng, Andrew Y.},
  date = {2019-07-17},
  volume = {33},
  pages = {590--597},
  doi = {10.1609/aaai.v33i01.3301590},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/3834},
  urldate = {2022-11-21},
  abstract = {Large, labeled datasets have driven deep learning methods to achieve expert-level performance on a variety of medical imaging tasks. We present CheXpert, a large dataset that contains 224,316 chest radiographs of 65,240 patients. We design a labeler to automatically detect the presence of 14 observations in radiology reports, capturing uncertainties inherent in radiograph interpretation. We investigate different approaches to using the uncertainty labels for training convolutional neural networks that output the probability of these observations given the available frontal and lateral radiographs. On a validation set of 200 chest radiographic studies which were manually annotated by 3 board-certified radiologists, we find that different uncertainty approaches are useful for different pathologies. We then evaluate our best model on a test set composed of 500 chest radiographic studies annotated by a consensus of 5 board-certified radiologists, and compare the performance of our model to that of 3 additional radiologists in the detection of 5 selected pathologies. On Cardiomegaly, Edema, and Pleural Effusion, the model ROC and PR curves lie above all 3 radiologist operating points. We release the dataset to the public as a standard benchmark to evaluate performance of chest radiograph interpretation models.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found},
  annotation = {1353 citations (Semantic Scholar/DOI) [2023-05-08] 543 citations (Crossref) [2022-11-20]},
  file = {/Users/personal-macbook/Zotero/storage/8P3ARSSD/Irvin et al. - 2019 - CheXpert A Large Chest Radiograph Dataset with Un.pdf}
}

@article{isgum_Multiatlasbased_2009,
  title = {Multi-{{Atlas-Based Segmentation With Local Decision Fusion}}\textendash Application to {{Cardiac}} and {{Aortic Segmentation}} in {{CT Scans}}},
  author = {Isgum, Ivana and Staring, Marius and Rutten, Annemarieke and Prokop, Mathias and Viergever, Max A. and family=Ginneken, given=Bram, prefix=van, useprefix=false},
  date = {2009-07},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {28},
  number = {7},
  pages = {1000--1010},
  doi = {10.1109/TMI.2008.2011480},
  abstract = {A novel atlas-based segmentation approach based on the combination of multiple registrations is presented. Multiple atlases are registered to a target image. To obtain a segmentation of the target, labels of the atlas images are propagated to it. The propagated labels are combined by spatially varying decision fusion weights. These weights are derived from local assessment of the registration success. Furthermore, an atlas selection procedure is proposed that is equivalent to sequential forward selection from statistical pattern recognition theory. The proposed method is compared to three existing atlas-based segmentation approaches, namely 1) single atlas-based segmentation, 2) average-shape atlas-based segmentation, and 3) multi-atlas-based segmentation with averaging as decision fusion. These methods were tested on the segmentation of the heart and the aorta in computed tomography scans of the thorax. The results show that the proposed method outperforms other methods and yields results very close to those of an independent human observer. Moreover, the additional atlas selection step led to a faster segmentation at a comparable performance.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@online{islam_Abnormality_2017,
  title = {Abnormality {{Detection}} and {{Localization}} in {{Chest X-Rays}} Using {{Deep Convolutional Neural Networks}}},
  author = {Islam, Mohammad Tariqul and Aowal, Md Abdul and Minhaz, Ahmed Tahseen and Ashraf, Khalid},
  date = {2017},
  doi = {10.48550/ARXIV.1705.09850},
  url = {https://arxiv.org/abs/1705.09850},
  urldate = {2023-05-18},
  abstract = {Chest X-Rays (CXRs) are widely used for diagnosing abnormalities in the heart and lung area. Automatically detecting these abnormalities with high accuracy could greatly enhance real world diagnosis processes. Lack of standard publicly available dataset and benchmark studies, however, makes it difficult to compare various detection methods. In order to overcome these difficulties, we have used a publicly available Indiana CXR, JSRT and Shenzhen dataset and studied the performance of known deep convolutional network (DCN) architectures on different abnormalities. We find that the same DCN architecture doesn't perform well across all abnormalities. Shallow features or earlier layers consistently provide higher detection accuracy compared to deep features. We have also found ensemble models to improve classification significantly compared to single model. Combining these insight, we report the highest accuracy on chest X-Ray abnormality detection on these datasets. We find that for cardiomegaly detection, the deep learning method improves the accuracy by a staggering 17 percentage point compared to rule based methods. We applied the techniques to the problem of tuberculosis detection on a different dataset and achieved the highest accuracy. Our localization experiments using these trained classifiers show that for spatially spread out abnormalities like cardiomegaly and pulmonary edema, the network can localize the abnormalities successfully most of the time. One remarkable result of the cardiomegaly localization is that the heart and its surrounding region is most responsible for cardiomegaly detection, in contrast to the rule based models where the ratio of heart and lung area is used as the measure. We believe that through deep learning based classification and localization, we will discover many more interesting features in medical image diagnosis that are not considered traditionally.},
  pubstate = {preprint},
  version = {3},
  keywords = {⛔ No INSPIRE recid found,Computer Science - Computer Vision and Pattern Recognition,Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences},
  annotation = {151 citations (Semantic Scholar/arXiv) [2023-05-18]},
  file = {/Users/personal-macbook/Zotero/storage/3NNAEK5T/Tariqul Islam et al. - 2017 - Abnormality Detection and Localization in Chest X-.pdf;/Users/personal-macbook/Zotero/storage/KEZBV8MN/1705.html}
}

@inproceedings{isola_Imagetoimage_2017,
  title = {Image-to-{{Image Translation With Conditional Adversarial Networks}}},
  booktitle = {Proc. - 30th {{IEEE Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}. {{CVPR}} 2017},
  author = {Isola, Phillip and Zhu, Jun Yan and Zhou, Tinghui and Efros, Alexei A.},
  date = {2017},
  doi = {10.1109/CVPR.2017.632},
  abstract = {We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. Moreover, since the release of the pix2pix software associated with this paper, hundreds of twitter users have posted their own artistic experiments using our system. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without hand-engineering our loss functions either.},
  isbn = {978-1-5386-0457-1},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {9995 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{iwaszczuk_Matching_2011,
  title = {Matching of {{3D Building Models With IR Images}} for {{Texture Extraction}}},
  booktitle = {2011 {{Jt}}. {{Urban Remote Sens}}. {{Event JURSE}} 2011 - {{Proc}}.},
  author = {Iwaszczuk, Dorota and Hoegner, Ludwig and Stilla, Uwe},
  date = {2011},
  pages = {25--28},
  doi = {10.1109/JURSE.2011.5764710},
  abstract = {Thermal inspections of buildings contribute to detection of damaged and weak spots in the building hull. 3D spatial reference for this purpose can be achieved combining infrared images with 3D building models via texture mapping. Using terrestrial image sequences from a camera mounted in a mobile platform frontal faces can be captured, while airborne image sequences can be taken for roofs and inner yards. However, according to different geometry of acquisition, two different methods for matching of terrestrial and airborne images are required. In this paper we present a concept for texturing of an existing 3D building model with complementary terrestrial and airborne IR image sequences. First we present a method for matching of terrestrial image sequences based on relative orientation of the point cloud. Second, we introduce a method for matching of airborne images including system calibration and best texture selection. Further, the combination of the terrestrial and airborne data in one 3D building model is introduced. \textcopyright{} 2011 IEEE.},
  isbn = {978-1-4244-8657-1},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {29 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{jaderberg_Spatial_2015,
  title = {Spatial {{Transformer Networks}}},
  booktitle = {Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.},
  author = {Jaderberg, Max and Simonyan, Karen and Zisserman, Andrew and {kavukcuoglu}, koray},
  editor = {Cortes, C. and Lawrence, N. and Lee, D. and Sugiyama, M. and Garnett, R.},
  date = {2015},
  volume = {28},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2015/file/33ceb07bf4eeb3da587e268d663aba1a-Paper.pdf},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/WFRPSJMX/Jaderberg et al. - 2015 - Spatial Transformer Networks.pdf}
}

@article{jaeger_Automatic_2014,
  title = {Automatic {{Tuberculosis Screening Using Chest Radiographs}}},
  author = {Jaeger, Stefan and Karargyris, Alexandros and Candemir, Sema and Folio, Les and Siegelman, Jenifer and Callaghan, Fiona and Xue, Zhiyun and Palaniappan, Kannappan and Singh, Rahul K. and Antani, Sameer and Thoma, George and Wang, Yi-Xiang and Lu, Pu-Xuan and McDonald, Clement J.},
  date = {2014-02},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {33},
  number = {2},
  pages = {233--245},
  doi = {10.1109/TMI.2013.2284099},
  abstract = {Tuberculosis is a major health threat in many regions of the world. Opportunistic infections in immunocompromised HIV/AIDS patients and multi-drug-resistant bacterial strains have exacerbated the problem, while diagnosing tuberculosis still remains a challenge. When left undiagnosed and thus untreated, mortality rates of patients with tuberculosis are high. Standard diagnostics still rely on methods developed in the last century. They are slow and often unreliable. In an effort to reduce the burden of the disease, this paper presents our automated approach for detecting tuberculosis in conventional posteroanterior chest radiographs. We first extract the lung region using a graph cut segmentation method. For this lung region, we compute a set of texture and shape features, which enable the X-rays to be classified as normal or abnormal using a binary classifier. We measure the performance of our system on two datasets: a set collected by the tuberculosis control program of our local county's health department in the United States, and a set collected by Shenzhen Hospital, China. The proposed computer-aided diagnostic system for TB screening, which is ready for field deployment, achieves a performance that approaches the performance of human experts. We achieve an area under the ROC curve (AUC) of 87\% (78.3\% accuracy) for the first set, and an AUC of 90\% (84\% accuracy) for the second set. For the first set, we compare our system performance with the performance of radiologists. When trying not to miss any positive cases, radiologists achieve an accuracy of about 82\% on this set, and their false positive rate is about half of our system's rate.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {422 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{jaeger_Two_2014,
  title = {Two {{Public Chest X-Ray Datasets}} for {{Computer-Aided Screening}} of {{Pulmonary Diseases}}},
  author = {Jaeger, Stefan and Candemir, Sema and Antani, Sameer and W\'ang, Y\`i-Xi\'ang J. and Lu, Pu-Xuan and Thoma, George},
  date = {2014-12},
  journaltitle = {Quant Imaging Med Surg},
  volume = {4},
  number = {6},
  eprint = {25525580},
  eprinttype = {pmid},
  pages = {475--477},
  issn = {2223-4292},
  doi = {10.3978/j.issn.2223-4292.2014.11.20},
  abstract = {The U.S. National Library of Medicine has made two datasets of postero-anterior (PA) chest radiographs available to foster research in computer-aided diagnosis of pulmonary diseases with a special focus on pulmonary tuberculosis (TB). The radiographs were acquired from the Department of Health and Human Services, Montgomery County, Maryland, USA and Shenzhen No. 3 People's Hospital in China. Both datasets contain normal and abnormal chest X-rays with manifestations of TB and include associated radiologist readings.},
  langid = {english},
  pmcid = {PMC4256233},
  keywords = {⛔ No INSPIRE recid found,automatic screening,chest X-rays,computer-aided diagnosis,medical imaging,Tuberculosis (TB)},
  annotation = {531 citations (Semantic Scholar/DOI) [2023-01-06]},
  file = {/Users/personal-macbook/Zotero/storage/6D7EGGZW/PMC4256233.html}
}

@article{jain_Introduction_2004,
  title = {An {{Introduction}} to {{Biometric Recognition}}},
  author = {Jain, Anil K. and Ross, Arun and Prabhakar, Salil},
  date = {2004},
  journaltitle = {IEEE Trans. Circuits Syst. Video Technol.},
  issn = {10518215},
  doi = {10.1109/TCSVT.2003.818349},
  abstract = {A wide variety of systems requires reliable personal recognition schemes to either confirm or determine the identity of an individual requesting their services. The purpose of such schemes is to ensure that the rendered services are accessed only by a legitimate user and no one else. Examples of such applications include secure access to buildings, computer systems, laptops, cellular phones, and ATMs. In the absence of robust personal recognition schemes, these systems are vulnerable to the wiles of an impostor. Biometric recognition or, simply, biometrics refers to the automatic recognition of individuals based on their physiological and/or behavioral characteristics. By using biometrics, it is possible to confirm or establish an individual's identity based on "who she is," rather than by "what she possesses" (e.g., an ID card) or "what she remembers" (e.g., a password). In this paper, we give a brief overview of the field of biometrics and summarize some of its advantages, disadvantages, strengths, limitations, and related privacy concerns.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Biometrics,Identification,Multimodal biometrics,Recognition,Verification},
  annotation = {4979 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{jain_Pores_2007,
  title = {Pores and {{Ridges}}: {{High-Resolution Fingerprint Matching Using Level}} 3 {{Features}}},
  author = {Jain, Anil K. and Chen, Yi and Demirkus, Meltem},
  date = {2007},
  journaltitle = {IEEE Trans. Pattern Anal. Mach. Intell.},
  eprint = {17108380},
  eprinttype = {pmid},
  issn = {01628828},
  doi = {10.1109/TPAMI.2007.250596},
  abstract = {Fingerprint friction ridge details are generally described in a hierarchical order at three different levels, namely, level 1 (pattern), level 2 (minutia points), and level 3 (pores and ridge contours). Although latent print examiners frequently take advantage of level 3 features to assist in identification, automated fingerprint identification systems (AFIS) currently rely only on level 1 and level 2 features. In fact, the Federal Bureau of Investigation's (FBI) standard of fingerprint resolution for AFIS is 500 pixels per inch (ppi), which is inadequate for capturing level 3 features, such as pores. With the advances in fingerprint sensing technology, many sensors are now equipped with dual resolution (500 ppi/1,000 ppi) scanning capability. However, increasing the scan resolution alone does not necessarily provide any performance improvement in fingerprint matching, unless an extended feature set is utilized. As a result, a systematic study to determine how much performance gain one can achieve by introducing level 3 features in AFIS is highly desired. We propose a hierarchical matching system that utilizes features at all the three levels extracted from 1,000 ppi fingerprint scans. Level 3 features, including pores and ridge contours, are automatically extracted using Gabor filters and wavelet transform and are locally matched using the iterative closest point (ICP) algorithm. Our experiments show that level 3 features carry significant discriminatory information. There is a relative reduction of 20 percent in the equal error rate (EER) of the matching system when level 3 features are employed in combination with level 1 and 2 features. This significant performance gain is consistently observed across various quality fingerprint images. \textcopyright{} 2007 IEEE.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Extended feature set,Fingerprint recognition,Hierarchical matching,High-resolution fingerprints,Level 3 features,Minutia,Pores,Ridge contours}
}

@inproceedings{jain_visualchexbertaddressingdiscrepancyradiologyreportlabelsimagelabels_2021,
  ids = {jain_VisualCheXbert_2021},
  title = {{{VisualCheXbert}}: {{Addressing}} the {{Discrepancy Between Radiology Report Labels}} and {{Image Labels}}},
  shorttitle = {{{VisualCheXbert}}},
  booktitle = {Proc. {{Conf}}. {{Health Inference Learn}}.},
  author = {Jain, Saahil and Smit, Akshay and Truong, Steven Qh and Nguyen, Chanh Dt and Huynh, Minh-Thanh and Jain, Mudit and Young, Victoria A. and Ng, Andrew Y. and Lungren, Matthew P. and Rajpurkar, Pranav},
  date = {2021-04-08},
  pages = {105--115},
  publisher = {{ACM}},
  location = {{Virtual Event USA}},
  doi = {10.1145/3450439.3451862},
  url = {https://dl.acm.org/doi/10.1145/3450439.3451862},
  urldate = {2023-05-10},
  eventtitle = {{{ACM CHIL}} '21: {{ACM Conference}} on {{Health}}, {{Inference}}, and {{Learning}}},
  isbn = {978-1-4503-8359-2},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {1 citations (Semantic Scholar/DOI) [2023-05-09]},
  file = {/Users/personal-macbook/Zotero/storage/IDQWC49Y/Jain et al. - 2021 - VisualCheXbert addressing the discrepancy between.pdf}
}

@article{jaiswal_Identifying_2019,
  title = {Identifying {{Pneumonia}} in {{Chest X-Rays}}: {{A Deep Learning Approach}}},
  shorttitle = {Identifying {{Pneumonia}} in {{Chest X-Rays}}},
  author = {Jaiswal, Amit Kumar and Tiwari, Prayag and Kumar, Sachin and Gupta, Deepak and Khanna, Ashish and Rodrigues, Joel J. P. C.},
  date = {2019-10-01},
  journaltitle = {Measurement},
  volume = {145},
  pages = {511--518},
  issn = {0263-2241},
  doi = {10.1016/j.measurement.2019.05.076},
  url = {https://www.sciencedirect.com/science/article/pii/S0263224119305202},
  urldate = {2022-11-21},
  abstract = {The rich collection of annotated datasets piloted the robustness of deep learning techniques to effectuate the implementation of diverse medical imaging tasks. Over 15\% of deaths include children under age five are caused by pneumonia globally. In this study, we describe our deep learning based approach for the identification and localization of pneumonia in Chest X-rays (CXRs) images. Researchers usually employ CXRs for the diagnostic imaging study. Several factors such as positioning of the patient and depth of inspiration can change the appearance of the chest X-ray, complicating interpretation further. Our identification model (https://github.com/amitkumarj441/identify\_pneumonia) is based on Mask-RCNN, a deep neural network which incorporates global and local features for pixel-wise segmentation. Our approach achieves robustness through critical modifications of the training process and a novel post-processing step which merges bounding boxes from multiple models. The proposed identification model achieves better performances evaluated on chest radiograph dataset which depict potential pneumonia causes.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Chest X-ray,Medical imaging,Object detection,Segmentation},
  annotation = {245 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/4858FPBT/Jaiswal et al. - 2019 - Identifying pneumonia in chest X-rays A deep lear.pdf;/Users/personal-macbook/Zotero/storage/J3B6U284/S0263224119305202.html}
}

@article{jakab_Generation_2012,
  title = {Generation of {{Individualized Thalamus Target Maps}} by {{Using Statistical Shape Models}} and {{Thalamocortical Tractography}}},
  author = {Jakab, Andr\'as and Blanc, R. and Ber\'enyi, E. L. and Sz\'ekely, G.},
  date = {2012-12},
  journaltitle = {Am. J. Neuroradiol.},
  volume = {33},
  number = {11},
  eprint = {22700756},
  eprinttype = {pmid},
  pages = {2110--2116},
  publisher = {{American Journal of Neuroradiology}},
  issn = {01956108},
  doi = {10.3174/ajnr.A3140},
  abstract = {BACKGROUND AND PURPOSE: Neurosurgical interventions of the thalamus rely on transferring stereotactic coordinates from an atlas onto the patient's MR brain images. We propose a prototype application for performing thalamus target map individualization by fusing patient-specific thalamus geometric information and diffusion tensor tractography. MATERIALS AND METHODS: Previously, our workgroup developed a thalamus atlas by fusing anatomic information from 7 histologically processed thalami. Thalamocortical connectivity maps were generated from DTI scans of 40 subjects by using a previously described procedure and were mapped to a standard neuroimaging space. These data were merged into a statistical shape model describing the morphologic variability of the thalamic outline, nuclei, and connectivity landmarks. This model was used to deform the atlas to individual images. Postmortem MR imaging scans were used to quantify the accuracy of nuclei predictions. RESULTS: Reliable tractography-based markers were located in the ventral lateral thalamus, with the somatosensory connections coinciding with the VPLa and VPLp nuclei; and motor/premotor connections, with the VLpv and VLa nuclei. Prediction accuracy of thalamus outlines was higher with the SSM approach than the ACPC alignment of data (0.56 mm versus 1.24; Dice overlap: 0.87 versus 0.7); for individual nuclei: 0.65 mm, Dice: 0.63 (SSM); 1.24 mm, Dice: 0.4 (ACPC). CONCLUSIONS: Previous studies have already applied DTI to the thalamus. As a further step in this direction, we demonstrate a hybrid approach by using statistical shape models, which have the potential to cope with intersubject variations in individual thalamus geometry.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {68 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@thesis{jean_MACHINE_2019,
  title = {Machine {{Learning}} for a {{Sustainable World Adissertation}}},
  author = {Jean, Neal},
  date = {2019},
  journaltitle = {Stanford},
  institution = {{STANFORD}},
  issue = {December},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{jeffreyj.rodriguezsrspmalladi_Image_2020,
  title = {Image {{Denoising Using Superpixel-Based PCA}}},
  author = {Jeffrey J. Rodriguez SRSP Malladi, Sundaresh Ram},
  date = {2020},
  journaltitle = {IEEE Trans. Multimed.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@inproceedings{jha_Clustering_2010,
  title = {A {{Clustering Algorithm}} for {{Liver Lesion Segmentation}} of {{Diffusion-Weighted Mr Images}}},
  booktitle = {2010 {{IEEE Southwest Symp}}. {{Image Anal}}. {{Interpret}}. {{SSIAI}}},
  author = {Jha, Abhinav K. and Rodriguez, Jeffrey J. and Stephen, Renu M. and Stopeck, Alison T.},
  date = {2010-05},
  pages = {93--96},
  publisher = {{IEEE}},
  location = {{Austin, TX}},
  doi = {10.1109/SSIAI.2010.5483911},
  url = {http://ieeexplore.ieee.org/document/5483911/},
  urldate = {2022-12-29},
  eventtitle = {2010 {{IEEE Southwest Symposium}} on {{Image Analysis}} \& {{Interpretation}} ({{SSIAI}})},
  isbn = {978-1-4244-7801-9 978-1-4244-7802-6},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {26 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/2IH8NSK5/Jha et al. - 2010 - A clustering algorithm for liver lesion segmentati.pdf}
}

@article{ji_Dynamic_2016,
  title = {Dynamic {{Thalamus Parcellation From Resting-State Fmri Data}}},
  author = {Ji, Bing and Li, Zhihao and Li, Kaiming and Li, Longchuan and Langley, Jason and Shen, Hui and Nie, Shengdong and Zhang, Renjie and Hu, Xiaoping},
  date = {2016-03},
  journaltitle = {Hum. Brain Mapp.},
  volume = {37},
  number = {3},
  pages = {954--967},
  doi = {10.1002/hbm.23079},
  abstract = {The thalamus is a relay center between various subcortical brain areas and the cerebral cortex with delineation of its constituent nuclei being of particular interest in many applications. While previous studies have demonstrated efficacy of connectivity-based thalamus segmentation, they used approaches that do not consider the dynamic nature of thalamo-cortical interactions. In this study, we explicitly exploited the dynamic variation of thalamo-cortical connections to identify different states of functional connectivity and performed state-specific thalamus parcellation. With normalized spectral clustering successively applied in temporal and spatial domains, nine thalamo-cortical connectivity states were identified and the dynamic thalamus parcellation revealed finer thalamic structures with improved atlas correspondence. The present results extend our understanding of thalamo-cortical connectivity and provide a more comprehensive view of the thalamo-cortical interaction.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,dynamic parcellation,functional connectivity,nor},
  annotation = {44 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{jia_Newborn_2010,
  title = {Newborn {{Footprint Recognition Using Subspace Learning Methods}}},
  booktitle = {Adv. {{Intell}}. {{Comput}}. {{Theor}}. {{Appl}}.},
  author = {Jia, Wei and Gui, Jie and Hu, Rong-Xiang and Lei, Ying-Ke and Xiao, Xue-Yang},
  editor = {Huang, De-Shuang and Zhao, Zhongming and Bevilacqua, Vitoantonio and Figueroa, Juan Carlos},
  date = {2010},
  pages = {447--453},
  publisher = {{Springer Berlin Heidelberg}},
  location = {{Berlin, Heidelberg}},
  abstract = {In this paper, we propose a novel online newborn personal authentication system based on footprint recognition. Compared with traditional offline footprinting scheme, the proposed system can capture digital footprint images with high quality. We also develop a preprocessing method for orientation and scale normalization. In this way, a coordinate system is defined to align the images and a region of interest (ROI) is cropped. In recognition stage, several representative subspace learning methods such as PCA, LDA are exploited for recognition. A newborn footprint database is established to examine the performance of the proposed system, and the promising experimental results demonstrate the effectiveness of proposed system.},
  isbn = {978-3-642-14922-1},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{jia_Newborn_2010a,
  title = {``{{Newborn Footprint Recognition Using Subspace Learning Methods}},'' in {{Proc}}},
  author = {Jia, W. and Gui, J. and Hu, R.-X. and Lei, Y.-K. and Xiao, X.-Y.},
  date = {2010},
  journaltitle = {Int. Conf. Intell. Comput},
  pages = {447--453},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@inproceedings{jia_Prostate_2017,
  title = {Prostate {{Segmentation}} in {{MR Images Using Ensemble Deep Convolutional Neural Networks}}},
  booktitle = {Proc. - {{Int}}. {{Symp}}. {{Biomed}}. {{Imaging}}},
  author = {Jia, Haozhe and Xia, Yong and Cai, Weidong and Fulham, Michael and Feng, David Dagan},
  date = {2017-06},
  pages = {762--765},
  publisher = {{IEEE Computer Society}},
  issn = {19458452},
  doi = {10.1109/ISBI.2017.7950630},
  abstract = {The automated segmentation of the prostate gland from MR images is increasingly used for clinical diagnosis. Since deep learning demonstrates superior performance in computer vision applications, we propose a coarse-to-fine segmentation strategy using ensemble deep convolutional neural networks (DCNNs) to address prostate segmentation in MR images. First, we use registration-based coarse segmentation on pre-processed prostate MR images to define the potential boundary region. We then train four DCNNs as voxel-based classifiers and classify the voxel in the potential region is a prostate voxel when at least three DCNNs made that decision. Finally, we use boundary refinement to eliminate the outliers and smooth the boundary. We evaluated our approach on the MICCAI PROMIS12 challenge dataset and our experimental results verify the effectiveness of the proposed algorithms.},
  isbn = {978-1-5090-1171-1},
  keywords = {\#nosource,⛔ No INSPIRE recid found,deep convolutional neural network,Deep convolutional neural network,Index Terms-MR prostate segmentation,MR prostate segmentation,voxel classification,Voxel classification}
}

@article{jiang_Class_2019,
  title = {Class {{Specific Attribute Weighted Naive Bayes}}},
  author = {Jiang, Liangxiao and Zhang, Lungan and Yu, Liangjun and Wang, Dianhong},
  date = {2019-04},
  journaltitle = {Pattern Recognition},
  volume = {88},
  pages = {321--330},
  issn = {00313203},
  doi = {10.1016/j.patcog.2018.11.032},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0031320318304205},
  urldate = {2022-12-28},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Attribute weighting,Naive Bayes,Weight optimization},
  annotation = {124 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/YJKD7TY3/Jiang et al. - 2019 - Class-Specific Attribute Weighted Naive Bayes.pdf}
}

@inproceedings{jiang_Tumoraware_2018,
  title = {Tumor-{{Aware}}, {{Adversarial Domain Adaptation From CT}} to {{MRI}} for {{Lung Cancer Segmentation}}},
  booktitle = {Lect. {{Notes Comput}}. {{Sci}}. {{Subser}}. {{Lect}}. {{Notes Artif}}. {{Intell}}. {{Lect}}. {{Notes Bioinforma}}.},
  author = {Jiang, Jue and Hu, Yu Chi and Tyagi, Neelam and Zhang, Pengpeng and Rimner, Andreas and Mageras, Gig S. and Deasy, Joseph O. and Veeraraghavan, Harini},
  date = {2018},
  issn = {16113349},
  doi = {10.1007/978-3-030-00934-2_86},
  abstract = {We present an adversarial domain adaptation based deep learning approach for automatic tumor segmentation from T2-weighted MRI. Our approach is composed of two steps: (i) a tumor-aware unsupervised cross-domain adaptation (CT to MRI), followed by (ii) semi-supervised tumor segmentation using Unet trained with synthesized and limited number of original MRIs. We introduced a novel target specific loss, called tumor-aware loss, for unsupervised cross-domain adaptation that helps to preserve tumors on synthesized MRIs produced from CT images. In comparison, state-of-the art adversarial networks trained without our tumor-aware loss produced MRIs with ill-preserved or missing tumors. All networks were trained using labeled CT images from 377 patients with non-small cell lung cancer obtained from the Cancer Imaging Archive and unlabeled T2w MRIs from a completely unrelated cohort of 6 patients with pre-treatment and 36 on-treatment scans. Next, we combined 6 labeled pre-treatment MRI scans with the synthesized MRIs to boost tumor segmentation accuracy through semi-supervised learning. Semi-supervised training of cycle-GAN produced a segmentation accuracy of 0.66 computed using Dice Score Coefficient (DSC). Our method trained with only synthesized MRIs produced an accuracy of 0.74 while the same method trained in semi-supervised setting produced the best accuracy of 0.80 on test. Our results show that tumor-aware adversarial domain adaptation helps to achieve reasonably accurate cancer segmentation from limited MRI data by leveraging large CT datasets.},
  isbn = {978-3-030-00933-5},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{jiang_Wrapper_2019,
  title = {Wrapper {{Framework}} for {{Test-Cost-Sensitive Feature Selection}}},
  author = {Jiang, Liangxiao and Kong, Ganggang and Li, Chaoqun},
  date = {2019},
  journaltitle = {IEEE Trans. Syst. Man Cybern, Syst.},
  pages = {1--10},
  issn = {2168-2216, 2168-2232},
  doi = {10.1109/TSMC.2019.2904662},
  url = {https://ieeexplore.ieee.org/document/8674538/},
  urldate = {2022-12-28},
  keywords = {⛔ No INSPIRE recid found,Classification accuracy,Data mining,decision making,Feature extraction,feature selection,Geology,Medical diagnosis,Optimization,Support vector machines,test cost,test-cost-sensitive learning,Training},
  annotation = {26 citations (Semantic Scholar/DOI) [2022-12-28]},
  file = {/Users/personal-macbook/Zotero/storage/B6RPR3XF/Jiang et al. - 2021 - Wrapper Framework for Test-Cost-Sensitive Feature .pdf;/Users/personal-macbook/Zotero/storage/86DL4QKT/8674538.html}
}

@article{jin_Augmenting_2019,
  title = {Augmenting {{Monte Carlo Dropout Classification Models With Unsupervised Learning Tasks}} for {{Detecting}} and {{Diagnosing Out-of-Distribution Faults}}},
  author = {Jin, Baihong and Tan, Yingshui and Chen, Yuxin and Sangiovanni-Vincentelli, Alberto},
  date = {2019-09},
  url = {http://arxiv.org/abs/1909.04202},
  abstract = {The Monte Carlo dropout method has proved to be a scalable and easy-to-use approach for estimating the uncertainty of deep neural network predictions. This approach was recently applied to Fault Detection and Di-agnosis (FDD) applications to improve the classification performance on incipient faults. In this paper, we propose a novel approach of augmenting the classification model with an additional unsupervised learning task. We justify our choice of algorithm design via an information-theoretical analysis. Our experimental results on three datasets from diverse application domains show that the proposed method leads to improved fault detection and diagnosis performance, especially on out-of-distribution examples including both incipient and unknown faults.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found},
  annotation = {5 citations (Semantic Scholar/arXiv) [2023-05-08]}
}

@inproceedings{jin_Leveraging_2018,
  title = {Leveraging {{Label Category Relationships}} in {{Multi-Class Crowdsourcing}}},
  booktitle = {Adv. {{Knowl}}. {{Discov}}. {{Data Min}}.},
  author = {Jin, Yuan and Du, Lan and Zhu, Ye and Carman, Mark},
  date = {2018},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {128--140},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-93037-4_11},
  abstract = {Current quality control methods for crowdsourcing largely account for variations in worker responses to items by interactions between item difficulty and worker expertise. Few have taken into account the semantic relationships that can exist between the response label categories. When the number of the label categories is large, these relationships are naturally indicative of how crowd-workers respond to items, with expert workers tending to respond with more semantically related categories to the categories of true labels, and with difficult items tending to see greater spread in the responded labels. Based on these observations, we propose a new statistical model which contains a latent real-valued matrix for capturing the relatedness of response categories alongside variables for worker expertise, item difficulty and item true labels. The model can be easily extended to incorporate prior knowledge about the semantic relationships between response labels in the form of a hierarchy over them. Experiments show that compared with numerous state-of-the-art baselines, our model (both with and without the prior knowledge) yields superior true label prediction performance on four new crowdsourcing datasets featuring large sets of label categories.},
  isbn = {978-3-319-93037-4},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {5 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/NTW53G5J/Jin et al. - 2018 - Leveraging Label Category Relationships in Multi-c.pdf}
}

@inproceedings{johansson_Learning_2016,
  title = {Learning {{Representations}} for {{Counterfactual Inference}}},
  booktitle = {33rd {{Int}}. {{Conf}}. {{Mach}}. {{Learn}}. {{ICML}} 2016},
  author = {Johansson, Fredrik D. and Shalit, Uri and Sontag, David},
  date = {2016},
  abstract = {Observational studies are rising in importance due to the widespread accumulation of data in fields such as healthcare, education, employment and ecology. We consider the task of answering counterfactual questions such as, "Would this patient have lower blood sugar had she received a different medication?". We propose a new algorithmic framework for counterfactual inference which brings together ideas from domain adaptation and representation learning. In addition to a theoretical justification, we perform an empirical comparison with previous approaches to causal inference from observational data. Our deep learning algorithm significantly outperforms the previous state-of-the-art.},
  isbn = {978-1-5108-2900-8},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{johns_Restoring_2003,
  title = {Restoring {{Balance}} to {{Industry-Academia Relationships}} in an {{Era}} of {{Institutional Financial Conflicts}} of {{Interest}}: {{Promoting Research While Maintaining Trust}}},
  author = {Johns, Michael M. E. and Barnes, Mark and Florencio, Patrik S.},
  date = {2003-02},
  journaltitle = {JAMA},
  volume = {289},
  number = {6},
  pages = {741--746},
  doi = {10.1001/jama.289.6.741},
  abstract = {Economic partnerships between industry and academia accelerate medical innovation and enhance patient access to medical advances, but such partnerships have sometimes eroded public trust in the research enterprise. There is particular risk for conflict of interest when economic partnerships extend beyond a university's corporate interests to involve institutional decision makers. Institutions and institutional decision makers should fully disclose industry-related financial interests and relationships. Without legitimate justification for such interests, individuals should divest themselves from these interests or recuse themselves from responsibility for research oversight. Management of institutional partnerships also might entail the physical separation of certain facilities, the placement of restrictions on information shared between investment and research staffs, and provision of oversight by independent review panels made up of persons who have expertise in intellectual property, finance, and research, but who are not financially or otherwise dependent on the institution. Through these means, it is possible to restore balance to industry-academia relationships, thereby promoting progress while maintaining public trust in research.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Biomedical and Behavioral Research}
}

@article{johnson_MIMICCXR_2019,
  title = {{{MIMIC-CXR}}, a {{De-Identified Publicly Available Database}} of {{Chest Radiographs With Free-Text Reports}}},
  author = {Johnson, Alistair E. W. and Pollard, Tom J. and Berkowitz, Seth J. and Greenbaum, Nathaniel R. and Lungren, Matthew P. and Deng, Chih-ying and Mark, Roger G. and Horng, Steven},
  date = {2019-12-12},
  journaltitle = {Sci Data},
  volume = {6},
  number = {1},
  pages = {317},
  issn = {2052-4463},
  doi = {10.1038/s41597-019-0322-0},
  url = {https://www.nature.com/articles/s41597-019-0322-0},
  urldate = {2023-01-07},
  abstract = {Abstract             Chest radiography is an extremely powerful imaging modality, allowing for a detailed inspection of a patient's chest, but requires specialized training for proper interpretation. With the advent of high performance general purpose computer vision algorithms, the accurate automated analysis of chest radiographs is becoming increasingly of interest to researchers. Here we describe MIMIC-CXR, a large dataset of 227,835 imaging studies for 65,379 patients presenting to the Beth Israel Deaconess Medical Center Emergency Department between 2011\textendash 2016. Each imaging study can contain one or more images, usually a frontal view and a lateral view. A total of 377,110 images are available in the dataset. Studies are made available with a semi-structured free-text radiology report that describes the radiological findings of the images, written by a practicing radiologist contemporaneously during routine clinical care. All images and reports have been de-identified to protect patient privacy. The dataset is made freely available to facilitate and encourage a wide range of research in computer vision, natural language processing, and clinical data mining.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {369 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/9A7C64JM/Johnson et al. - 2019 - MIMIC-CXR, a de-identified publicly available data.pdf;/Users/personal-macbook/Zotero/storage/HEIQXR2X/s41597-019-0322-0.html}
}

@inproceedings{johnson_Perceptual_2016,
  title = {Perceptual {{Losses}} for {{Real-Time Style Transfer}} and {{Super-Resolution}}},
  booktitle = {Lect. {{Notes Comput}}. {{Sci}}. {{Subser}}. {{Lect}}. {{Notes Artif}}. {{Intell}}. {{Lect}}. {{Notes Bioinforma}}.},
  author = {Johnson, Justin and Alahi, Alexandre and Fei-Fei, Li},
  date = {2016},
  issn = {16113349},
  doi = {10.1007/978-3-319-46475-6_43},
  abstract = {We consider image transformation problems, where an input image is transformed into an output image. Recent methods for such problems typically train feed-forward convolutional neural networks using a per-pixel loss between the output and ground-truth images. Parallel work has shown that high-quality images can be generated by defining and optimizing perceptual loss functions based on high-level features extracted from pretrained networks. We combine the benefits of both approaches, and propose the use of perceptual loss functions for training feed-forward networks for image transformation tasks. We show results on image style transfer, where a feed-forward network is trained to solve the optimization problem proposed by Gatys et al. in real-time. Compared to the optimization-based method, our network gives similar qualitative results but is three orders of magnitude faster. We also experiment with single-image super-resolution, where replacing a per-pixel loss with a perceptual loss gives visually pleasing results.},
  isbn = {978-3-319-46474-9},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Deep learning,Style transfer,Super-resolution}
}

@article{jonasson_Level_2007,
  title = {A {{Level Set Method}} for {{Segmentation}} of the {{Thalamus}} and {{Its Nuclei}} in {{Dt-Mri}}},
  author = {Jonasson, Lisa and Hagmann, Patric and Pollo, Claudio and Bresson, Xavier and Richero Wilson, Cecilia and Meuli, Reto and Thiran, Jean-Philippe},
  date = {2007-02},
  journaltitle = {Signal Processing},
  volume = {87},
  number = {2},
  pages = {309--321},
  issn = {01651684},
  doi = {10.1016/j.sigpro.2005.12.017},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0165168406001733},
  urldate = {2023-05-08},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Brain gray matter segmentation,Coupled level sets},
  annotation = {75 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/DB4NMUVQ/Jonasson et al. - 2007 - A level set method for segmentation of the thalamu.pdf}
}

@article{jorgecardoso_STEPS_2013,
  title = {{{STEPS}}: {{Similarity}} and {{Truth Estimation}} for {{Propagated Segmentations}} and {{Its Application}} to {{Hippocampal Segmentation}} and {{Brain Parcelation}}},
  shorttitle = {{{STEPS}}},
  author = {Jorge Cardoso, M. and Leung, Kelvin and Modat, Marc and Keihaninejad, Shiva and Cash, David and Barnes, Josephine and Fox, Nick C. and Ourselin, Sebastien},
  date = {2013-08},
  journaltitle = {Medical Image Analysis},
  volume = {17},
  number = {6},
  pages = {671--684},
  issn = {13618415},
  doi = {10.1016/j.media.2013.02.006},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1361841513000200},
  urldate = {2023-01-27},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {249 citations (Semantic Scholar/DOI) [2023-01-26]},
  file = {/Users/personal-macbook/Zotero/storage/MBVRYKZH/Jorge Cardoso et al. - 2013 - STEPS Similarity and Truth Estimation for Propaga.pdf}
}

@article{jr_Prediction_1999,
  title = {Prediction of {{AD With MRI-based Hippocampal Volume}} in {{Mild Cognitive Impairment}}},
  author = {Jr, C. R. Jack and Petersen, R. C. and Xu, Y. C. and O'Brien, P. C. and Smith, G. E. and Ivnik, R. J. and Boeve, B. F. and Waring, S. C. and Tangalos, E. G. and Kokmen, E.},
  date = {1999-04},
  journaltitle = {Neurology},
  volume = {52},
  number = {7},
  pages = {1397--1403},
  abstract = {OBJECTIVE: To test the hypothesis that MRI-based measurements of hippocampal volume are related to the risk of future conversion to Alzheimer's disease (AD) in older patients with a mild cognitive impairment (MCI). BACKGROUND: Patients who develop AD pass through a transitional state, which can be characterized as MCI. In some patients, however, MCI is a more benign condition, which may not progress to AD or may do so slowly. PATIENTS: Eighty consecutive patients who met criteria for the diagnosis of MCI were recruited from the Mayo Clinic Alzheimer's Disease Center/Alzheimer's Disease Patient Registry. METHODS: At entry into the study, each patient received an MRI examination of the head, from which the volumes of both hippocampi were measured. Patients were followed longitudinally with approximately annual clinical/cognitive assessments. The primary endpoint was the crossover of individual MCI patients to the clinical diagnosis of AD during longitudinal clinical follow-up. RESULTS: During the period of longitudinal observation, which averaged 32.6 months, 27 of the 80 MCI patients became demented. Hippocampal atrophy at baseline was associated with crossover from MCI to AD (relative risk [RR], 0.69, p = 0.015). When hippocampal volume was entered into bivariate models-using age, postmenopausal estrogen replacement, standard neuropsychological tests, apolipoprotein E (APOE) genotype, history of ischemic heart disease, and hypertension-the RRs were not substantially different from that found univariately, and the associations between hippocampal volume and crossover remained significant. CONCLUSION: In older patients with MCI, hippocampal atrophy determined by premorbid MRI-based volume measurements is predictive of subsequent conversion to AD.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@inproceedings{ju_3D_2005,
  title = {{{3D Thermography Imaging Standardization Technique}} for {{Inflammation Diagnosis}}},
  booktitle = {Infrared {{Compon}}. {{Their Appl}}.},
  author = {Ju, Xiangyang and Nebel, Jean-Christophe and Siebert, J. Paul},
  editor = {Gong, Haimei and Cai, Yi and Chatard, Jean-Pierre},
  date = {2005-01},
  volume = {5640},
  pages = {266},
  publisher = {{SPIE}},
  issn = {0277786X},
  doi = {10.1117/12.577055},
  url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.577055},
  abstract = {We develop a 3D thermography imaging standardization technique to allow quantitative data analysis. Medical Digital Infrared Thermal Imaging is very sensitive and reliable mean of graphically mapping and display skin surface temperature. It allows doctors to visualise in colour and quantify temperature changes in skin surface. The spectrum of colours indicates both hot and cold responses which may co-exist if the pain associate with an inflammatory focus excites an increase in sympathetic activity. However, due to thermograph provides only qualitative diagnosis information, it has not gained acceptance in the medical and veterinary communities as a necessary or effective tool in inflammation and tumor detection. Here, our technique is based on the combination of visual 3D imaging technique and thermal imaging technique, which maps the 2D thermography images on to 3D anatomical model. Then we rectify the 3D thermogram into a view independent thermogram and conform it a standard shape template. The combination of these imaging facilities allows the generation of combined 3D and thermal data from which thermal signatures can be quantified.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,3D imaging,Inflammation,Thermogram Standardization,Thermography},
  annotation = {52 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{ju_Improving_2022,
  title = {Improving {{Medical Images Classification With Label Noise Using Dual-Uncertainty Estimation}}},
  author = {Ju, Lie and Wang, Xin and Wang, Lin and Mahapatra, Dwarikanath and Zhao, Xin and Zhou, Quan and Liu, Tongliang and Ge, Zongyuan},
  date = {2022-06},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {41},
  number = {6},
  pages = {1533--1546},
  issn = {1558-254X},
  doi = {10.1109/TMI.2022.3141425},
  abstract = {Deep neural networks are known to be data-driven and label noise can have a marked impact on model performance. Recent studies have shown great robustness to classic image recognition even under a high noisy rate. In medical applications, learning from datasets with label noise is more challenging since medical imaging datasets tend to have instance-dependent noise (IDN) and suffer from high observer variability. In this paper, we systematically discuss the two common types of label noise in medical images - disagreement label noise from inconsistency expert opinions and single-target label noise from biased aggregation of individual annotations. We then propose an uncertainty estimation-based framework to handle these two label noise amid the medical image classification task. We design a dual-uncertainty estimation approach to measure the {$<$}bold{$>$}disagreement label noise{$<$}/bold{$>$} and {$<$}bold{$>$}single-target label noise{$<$}/bold{$>$} via improved Direct Uncertainty Prediction and Monte-Carlo-Dropout. A boosting-based curriculum training procedure is later introduced for robust learning. We demonstrate the effectiveness of our method by conducting extensive experiments on three different diseases with synthesized and real-world label noise: skin lesions, prostate cancer, and retinal diseases. We also release a large re-engineered database that consists of annotations from more than ten ophthalmologists with an unbiased golden standard dataset for evaluation and benchmarking. The dataset is available at {$<$}uri{$>$}https://mmai.group/peoples/julie/{$<$}/uri{$>$}.},
  eventtitle = {{{IEEE Transactions}} on {{Medical Imaging}}},
  keywords = {⛔ No INSPIRE recid found,Diseases,Estimation,Label noise,Medical diagnostic imaging,Medical services,Noise measurement,prostate cancer,retinal diseases,skin lesions,Training,Uncertainty,uncertainty estimation},
  annotation = {25 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/SN9IA57R/Ju et al. - 2022 - Improving Medical Images Classification With Label.pdf}
}

@article{jungo_Uncertaintydriven_2018,
  title = {Uncertainty-{{Driven Sanity Check}}: {{Application}} to {{Postoperative Brain Tumor Cavity Segmentation}}},
  author = {Jungo, Alain and Meier, Raphael and Ermis, Ekin and Herrmann, Evelyn and Reyes, Mauricio and Reyes, Mauricio},
  date = {2018-06},
  journaltitle = {arXiv},
  abstract = {Uncertainty estimates of modern neuronal networks provide additional information next to the computed predictions and are thus expected to improve the understanding of the underlying model. Reliable uncertainties are particularly interesting for safety-critical computer-assisted applications in medicine, e.g., neurosurgical interventions and radiotherapy planning. We propose an uncertainty-driven sanity check for the identification of segmentation results that need particular expert review. Our method uses a fully-convolutional neural network and computes uncertainty estimates by the principle of Monte Carlo dropout. We evaluate the performance of the proposed method on a clinical dataset with 30 postoperative brain tumor images. The method can segment the highly inhomogeneous resection cavities accurately (Dice coefficients 0.792 {$\pm$} 0.154). Furthermore, the proposed sanity check is able to detect the worst segmentation and three out of the four outliers. The results highlight the potential of using the additional information from the model's parameter uncertainty to validate the segmentation performance of a deep learning model.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{kahneman_Pupil_1966,
  title = {Pupil {{Diameter}} and {{Load}} on {{Memory}}},
  author = {Kahneman, Daniel and Beatty, Jackson},
  date = {1966},
  journaltitle = {Science},
  eprint = {5924930},
  eprinttype = {pmid},
  issn = {00368075},
  doi = {10.1126/science.154.3756.1583},
  abstract = {During a short-term memory task, pupil diameter is a measure of the amount of material which is under active processing at any time. The pupil dilates as the material is presented and constricts during report. The rate of change of these functions is related to task difficulty.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{kalis_10_2018,
  entrysubtype = {magazine},
  title = {10 {{Promising AI Applications}} in {{Health Care}}},
  author = {Kalis, Brian and Collier, Matt and Fu, Richard},
  date = {2018-05-10T15:00:31Z},
  journaltitle = {Harvard Business Review},
  issn = {0017-8012},
  url = {https://hbr.org/2018/05/10-promising-ai-applications-in-health-care},
  urldate = {2023-05-08},
  abstract = {There's a lot of excitement right now about how artificial intelligence (AI) is going to change health care. Indeed, many AI technologies are cropping up to help people streamline administrative and clinical health care processes. Accenture investigated the value of 10 promising AI applications and found that they could create up to \$150 billion in annual savings for U.S. health care by 2026. They found AI currently creates the most value in helping frontline clinicians be more productive and in making back-end processes more efficient\textemdash but not yet in making clinical decisions or improving clinical outcomes. These applications range from robot-assisted surgery and virtual nursing assistants to fraud detection and cybersecurity.},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found,Healthcare sector,Operations and supply chain management,Personal productivity,Strategy,Technology and analytics},
  file = {/Users/personal-macbook/Zotero/storage/B3I9DX7K/10-promising-ai-applications-in-health-care.html}
}

@inproceedings{kamar_Identifying_2015,
  title = {Identifying and {{Accounting}} for {{Task-Dependent Bias}} in {{Crowdsourcing}}},
  booktitle = {Proc. {{AAAI Conf}}. {{Hum}}. {{Comput}}. {{Crowdsourcing}}},
  author = {Kamar, Ece and Kapoor, Ashish and Horvitz, Eric},
  date = {2015-09-23},
  volume = {3},
  pages = {92--101},
  doi = {10.1609/hcomp.v3i1.13238},
  url = {https://ojs.aaai.org/index.php/HCOMP/article/view/13238},
  urldate = {2022-12-28},
  abstract = {Models for aggregating contributions by crowd workers have been shown to be challenged by the rise of task-specific biases or errors. Task-dependent errors in assessment may shift the majority opinion of even large numbers of workers to an incorrect answer. We introduce and evaluate probabilistic models that can detect and correct task-dependent bias automatically. First, we show how to build and use probabilistic graphical models for jointly modeling task features, workers' biases, worker contributions and ground truth answers of tasks so that task-dependent bias can be corrected. Second, we show how the approach can perform a type of transfer learning among workers to address the issue of annotation sparsity. We evaluate the models with varying complexity on a large data set collected from a citizen science project and show that the models are effective at correcting the task-dependent worker bias. Finally, we investigate the use of active learning to guide the acquisition of expert assessments to enable automatic detection and correction of worker bias.},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {73 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/TSJTT878/Kamar et al. - 2015 - Identifying and Accounting for Task-Dependent Bias.pdf}
}

@article{kamnitsas_Efficient_2017,
  title = {Efficient {{Multi-Scale 3D CNN With Fully Connected CRF}} for {{Accurate Brain Lesion Segmentation}}},
  author = {Kamnitsas, Konstantinos and Ledig, Christian and Newcombe, Virginia F. J. and Simpson, Joanna P. and Kane, Andrew D. and Menon, David K. and Rueckert, Daniel and Glocker, Ben},
  date = {2017-02},
  journaltitle = {Med. Image Anal.},
  volume = {36},
  pages = {61--78},
  doi = {10.1016/j.media.2016.10.004},
  abstract = {We propose a dual pathway, 11-layers deep, three-dimensional Convolutional Neural Network for the challenging task of brain lesion segmentation. The devised architecture is the result of an in-depth analysis of the limitations of current networks proposed for similar applications. To overcome the computational burden of processing 3D medical scans, we have devised an efficient and effective dense training scheme which joins the processing of adjacent image patches into one pass through the network while automatically adapting to the inherent class imbalance present in the data. Further, we analyze the development of deeper, thus more discriminative 3D CNNs. In order to incorporate both local and larger contextual information, we employ a dual pathway architecture that processes the input images at multiple scales simultaneously. For post-processing of the network's soft segmentation, we use a 3D fully connected Conditional Random Field which effectively removes false positives. Our pipeline is extensively evaluated on three challenging tasks of lesion segmentation in multi-channel MRI patient data with traumatic brain injuries, brain tumours, and ischemic stroke. We improve on the state-of-the-art for all three applications, with top ranking performance on the public benchmarks BRATS 2015 and ISLES 2015. Our method is computationally efficient, which allows its adoption in a variety of research and clinical settings. The source code of our implementation is made publicly available.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,3D convolutional neural network,Brain lesions,De},
  annotation = {2470 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{kamnitsas_Unsupervised_2017,
  title = {Unsupervised {{Domain Adaptation}} in {{Brain Lesion Segmentation With Adversarial Networks}}},
  booktitle = {Lect. {{Notes Comput}}. {{Sci}}. {{Subser}}. {{Lect}}. {{Notes Artif}}. {{Intell}}. {{Lect}}. {{Notes Bioinforma}}.},
  author = {Kamnitsas, Konstantinos and Baumgartner, Christian and Ledig, Christian and Newcombe, Virginia and Simpson, Joanna and Kane, Andrew and Menon, David and Nori, Aditya and Criminisi, Antonio and Rueckert, Daniel and Glocker, Ben},
  date = {2017},
  issn = {16113349},
  doi = {10.1007/978-3-319-59050-9_47},
  abstract = {Significant advances have been made towards building accurate automatic segmentation systems for a variety of biomedical applications using machine learning. However, the performance of these systems often degrades when they are applied on new data that differ from the training data, for example, due to variations in imaging protocols. Manually annotating new data for each test domain is not a feasible solution. In this work we investigate unsupervised domain adaptation using adversarial neural networks to train a segmentation method which is more robust to differences in the input data, and which does not require any annotations on the test domain. Specifically, we derive domain-invariant features by learning to counter an adversarial network, which attempts to classify the domain of the input data by observing the activations of the segmentation network. Furthermore, we propose a multi-connected domain discriminator for improved adversarial training. Our system is evaluated using two MR databases of subjects with traumatic brain injuries, acquired using different scanners and imaging protocols. Using our unsupervised approach, we obtain segmentation accuracies which are close to the upper bound of supervised domain adaptation.},
  isbn = {978-3-319-59049-3},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{kang_LabelAssemble_2021,
  title = {Label-{{Assemble}}: {{Leveraging Multiple Datasets With Partial Labels}}},
  shorttitle = {Label-{{Assemble}}},
  author = {Kang, Mintong and Lu, Yongyi and Yuille, A. and Zhou, Zongwei},
  date = {2021},
  abstract = {This paper introduces a new dynamic adapter to encode different visual tasks, which addresses the challenges of incomparable, heterogeneous, or even conflicting labeling protocols, and employs pseudo-labeling and consistency constraints to harness data with missing labels and to mitigate the domain gap across datasets. The success of deep learning relies heavily on large and diverse datasets with extensive labels, but we often only have access to several small datasets associated with partial labels. In this paper, we start a new initiative, ``LabelAssemble'', that aims to unleash the full potential of partially labeled data from an assembly of public datasets. Technically, we introduce a new dynamic adapter to encode different visual tasks, which addresses the challenges of incomparable, heterogeneous, or even conflicting labeling protocols. We also employ pseudo-labeling and consistency constraints to harness data with missing labels and to mitigate the domain gap across datasets. From rigorous evaluations on three natural imaging and six medical imaging tasks, we discover that learning from ``negative examples'' facilitates both classification and segmentation of classes of interest. This sheds new light on the computer-aided diagnosis of rare diseases and emerging pandemics, wherein ``positive examples'' are hard to collect, yet ``negative examples'' are relatively easier to assemble. Apart from exceeding prior arts in the ChestXray benchmark, our model is particularly strong in identifying diseases of minority classes, yielding over 3-point improvement on average. Remarkably, when using existing partial labels, our model performance is on-par with that using full labels, eliminating the need for an additional 40\% of annotation costs. Code will be made available at https://github.com/MrGiovanni/LabelAssemble.},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/JK7NNU4P/Kang et al. - 2021 - Label-Assemble Leveraging Multiple Datasets with .pdf}
}

@article{kaplan_Siri_2019,
  title = {Siri, {{Siri}}, in {{My Hand}}: {{Who}}'s the {{Fairest}} in the {{Land}}? {{On}} the {{Interpretations}}, {{Illustrations}}, and {{Implications}} of {{Artificial Intelligence}}},
  author = {Kaplan, Andreas and Haenlein, Michael},
  date = {2019},
  journaltitle = {Bus. Horiz.},
  issn = {00076813},
  doi = {10.1016/j.bushor.2018.08.004},
  abstract = {Artificial intelligence (AI)\textemdash defined as a system's ability to correctly interpret external data, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation\textemdash is a topic in nearly every boardroom and at many dinner tables. Yet, despite this prominence, AI is still a surprisingly fuzzy concept and a lot of questions surrounding it are still open. In this article, we analyze how AI is different from related concepts, such as the Internet of Things and big data, and suggest that AI is not one monolithic term but instead needs to be seen in a more nuanced way. This can either be achieved by looking at AI through the lens of evolutionary stages (artificial narrow intelligence, artificial general intelligence, and artificial super intelligence) or by focusing on different types of AI systems (analytical AI, human-inspired AI, and humanized AI). Based on this classification, we show the potential and risk of AI using a series of case studies regarding universities, corporations, and governments. Finally, we present a framework that helps organizations think about the internal and external implications of AI, which we label the Three C Model of Confidence, Change, and Control.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Artificial intelligence,Big data,Deep learning,Expert systems,Internet of Things,Machine learning}
}

@article{karger_Budget_2014,
  title = {Budget {{Optimal Task Allocation}} for {{Reliable Crowdsourcing Systems}}},
  author = {Karger, David R. and Oh, Sewoong and Shah, Devavrat},
  date = {2014-02},
  journaltitle = {Operations Research},
  volume = {62},
  number = {1},
  pages = {1--24},
  issn = {0030-364X, 1526-5463},
  doi = {10.1287/opre.2013.1235},
  url = {http://pubsonline.informs.org/doi/10.1287/opre.2013.1235},
  urldate = {2022-12-20},
  abstract = {Crowdsourcing systems, in which numerous tasks are electronically distributed to numerous ``information pieceworkers,'' have emerged as an effective paradigm for human-powered solving of large-scale problems in domains such as image classification, data entry, optical character recognition, recommendation, and proofreading. Because these low-paid workers can be unreliable, nearly all such systems must devise schemes to increase confidence in their answers, typically by assigning each task multiple times and combining the answers in an appropriate manner, e.g., majority voting.             In this paper, we consider a general model of such crowdsourcing tasks and pose the problem of minimizing the total price (i.e., number of task assignments) that must be paid to achieve a target overall reliability. We give a new algorithm for deciding which tasks to assign to which workers and for inferring correct answers from the workers' answers. We show that our algorithm, inspired by belief propagation and low-rank matrix approximation, significantly outperforms majority voting and, in fact, is optimal through comparison to an oracle that knows the reliability of every worker. Further, we compare our approach with a more general class of algorithms that can dynamically assign tasks. By adaptively deciding which questions to ask to the next set of arriving workers, one might hope to reduce uncertainty more efficiently. We show that, perhaps surprisingly, the minimum price necessary to achieve a target reliability scales in the same manner under both adaptive and nonadaptive scenarios. Hence, our nonadaptive approach is order optimal under both scenarios. This strongly relies on the fact that workers are fleeting and cannot be exploited. Therefore, architecturally, our results suggest that building a reliable worker-reputation system is essential to fully harnessing the potential of adaptive designs.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {362 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/6KVBJMLR/Karger et al. - 2014 - Budget-Optimal Task Allocation for Reliable Crowds.pdf}
}

@inproceedings{karger_Efficient_2013,
  title = {Efficient {{Crowdsourcing}} for {{Multi-Class Labeling}}},
  booktitle = {Proc. {{ACM SIGMETRICS}}},
  author = {Karger, David R. and Oh, Sewoong and Shah, Devavrat},
  date = {2013},
  series = {{{SIGMETRICS}} '13},
  pages = {81--92},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/2465529.2465761},
  url = {https://doi.org/10.1145/2465529.2465761},
  abstract = {Crowdsourcing systems like Amazon's Mechanical Turk have emerged as an effective large-scale human-powered platform for performing tasks in domains such as image classification, data entry, recommendation, and proofreading. Since workers are low-paid (a few cents per task) and tasks performed are monotonous, the answers obtained are noisy and hence unreliable. To obtain reliable estimates, it is essential to utilize appropriate inference algorithms (e.g. Majority voting) coupled with structured redundancy through task assignment. Our goal is to obtain the best possible trade-off between reliability and redundancy. In this paper, we consider a general probabilistic model for noisy observations for crowd-sourcing systems and pose the problem of minimizing the total price (i.e. redundancy) that must be paid to achieve a target overall reliability. Concretely, we show that it is possible to obtain an answer to each task correctly with probability 1-{$\epsilon$} as long as the redundancy per task is O((K/q) log (K/{$\epsilon$})), where each task can have any of the \$K\$ distinct answers equally likely, q is the crowd-quality parameter that is defined through a probabilistic model. Further, effectively this is the best possible redundancy-accuracy trade-off any system design can achieve. Such a single-parameter crisp characterization of the (order-)optimal trade-off between redundancy and reliability has various useful operational consequences. Further, we analyze the robustness of our approach in the presence of adversarial workers and provide a bound on their influence on the redundancy-accuracy trade-off.Unlike recent prior work [GKM11, KOS11, KOS11], our result applies to non-binary (i.e. K\&gt;2) tasks. In effect, we utilize algorithms for binary tasks (with inhomogeneous error model unlike that in [GKM11, KOS11, KOS11]) as key subroutine to obtain answers for K-ary tasks. Technically, the algorithm is based on low-rank approximation of weighted adjacency matrix for a random regular bipartite graph, weighted according to the answers provided by the workers.},
  eventtitle = {International {{Conference}} on {{Measurement}} and {{Modeling}} of {{Computer Systems}}},
  isbn = {978-1-4503-1900-3},
  venue = {Pittsburgh, PA, USA},
  keywords = {⛔ No INSPIRE recid found,crowdsourcing,human computation,low-rank matrix,random graphs},
  annotation = {157 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/ARX7Y5KF/Karger et al. - 2013 - Efficient Crowdsourcing for Multi-Class Labeling.pdf}
}

@article{karimi_Deep_2020,
  ids = {karimi_Deep_2020a},
  title = {Deep {{Learning With Noisy Labels}}: {{Exploring Techniques}} and {{Remedies}} in {{Medical Image Analysis}}},
  shorttitle = {Deep Learning with Noisy Labels},
  author = {Karimi, D. and Dou, Haoran and Warfield, S. and Gholipour, A.},
  date = {2020},
  journaltitle = {Med. Image Anal},
  doi = {10.1016/j.media.2020.101759},
  abstract = {Semantic Scholar extracted view of "Deep learning with noisy labels: exploring techniques and remedies in medical image analysis" by D. Karimi et al.},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {269 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/E47IBTEZ/Karimi et al. - 2020 - Deep learning with noisy labels exploring techniq.pdf}
}

@online{karimi_deeplearningbasedmethodprostatesegmentationt2weightedmagneticresonanceimaging_2019,
  ids = {karimi_Deep_2019},
  title = {A {{Deep Learning-Based Method}} for {{Prostate Segmentation}} in {{T2-Weighted Magnetic Resonance Imaging}}},
  author = {Karimi, Davood and Samei, Golnoosh and Shao, Yanan and Salcudean, Septimiu},
  date = {2019},
  doi = {10.48550/ARXIV.1901.09462},
  url = {https://arxiv.org/abs/1901.09462},
  urldate = {2023-05-08},
  abstract = {We propose a novel automatic method for accurate segmentation of the prostate in T2-weighted magnetic resonance imaging (MRI). Our method is based on convolutional neural networks (CNNs). Because of the large variability in the shape, size, and appearance of the prostate and the scarcity of annotated training data, we suggest training two separate CNNs. A global CNN will determine a prostate bounding box, which is then resampled and sent to a local CNN for accurate delineation of the prostate boundary. This way, the local CNN can effectively learn to segment the fine details that distinguish the prostate from the surrounding tissue using the small amount of available training data. To fully exploit the training data, we synthesize additional data by deforming the training images and segmentations using a learned shape model. We apply the proposed method on the PROMISE12 challenge dataset and achieve state of the art results. Our proposed method generates accurate, smooth, and artifact-free segmentations. On the test images, we achieve an average Dice score of 90.6 with a small standard deviation of 2.2, which is superior to all previous methods. Our two-step segmentation approach and data augmentation strategy may be highly effective in segmentation of other organs from small amounts of annotated medical images.},
  pubstate = {preprint},
  version = {2},
  keywords = {⛔ No INSPIRE recid found,FOS: Computer and information sciences,{FOS: Electrical engineering, electronic engineering, information engineering},Image and Video Processing (eess.IV),Machine Learning (cs.LG),Machine Learning (stat.ML)},
  annotation = {8 citations (Semantic Scholar/arXiv) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/5HE9F6QD/Karimi et al. - 2019 - A Deep Learning-Based Method for Prostate Segmenta.pdf}
}

@article{karimi_Reducing_2019,
  title = {Reducing the {{Hausdorff Distance}} in {{Medical Image Segmentation With Convolutional Neural Networks}}},
  author = {Karimi, Davood and Salcudean, Septimiu E.},
  date = {2019},
  journaltitle = {IEEE Trans. Med. Imaging},
  issn = {0278-0062},
  doi = {10.1109/tmi.2019.2930068},
  abstract = {The Hausdorff Distance (HD) is widely used in evaluating medical image segmentation methods. However, existing segmentation methods do not attempt to reduce HD directly. In this paper, we present novel loss functions for training convolutional neural network (CNN)-based segmentation methods with the goal of reducing HD directly. We propose three methods to estimate HD from the segmentation probability map produced by a CNN. One method makes use of the distance transform of the segmentation boundary. Another method is based on applying morphological erosion on the difference between the true and estimated segmentation maps. The third method works by applying circular/spherical convolution kernels of different radii on the segmentation probability maps. Based on these three methods for estimating HD, we suggest three loss functions that can be used for training to reduce HD. We use these loss functions to train CNNs for segmentation of the prostate, liver, and pancreas in ultrasound, magnetic resonance, and computed tomography images and compare the results with commonly-used loss functions. Our results show that the proposed loss functions can lead to approximately 18-45 \% reduction in HD without degrading other segmentation performance criteria such as the Dice similarity coefficient. The proposed loss functions can be used for training medical image segmentation methods in order to reduce the large segmentation errors.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@book{kastor_Mergers_2009,
  title = {Mergers of {{Teaching Hospitals}} in {{Boston}}, {{New York}}, and {{Northern California}}},
  author = {Kastor, John A.},
  date = {2009-12},
  publisher = {{University of Michigan Press}},
  abstract = {If a teaching hospital loses funding, what is the next option? Mergers of Teaching Hospitals in Boston, New York, and Northern California investigates the recent mergers of six of the nation's most respected teaching hospitals. The author explains the reasons why these institutions decided to change their governance and the factors that have allowed two of them to continue to operate while forcing the third to dissolve after only 23 months of operation. The case studies contained within this book rely on an impressive amount of research. Notably, instead of citing only published articles and books, the author includes information from numerous, extensive personal interviews with key participants in the various mergers. With this research the author not only presents to the reader a picture of why these mergers came about, but also investigates how the organizations have fared since joining together. The mergers are analyzed and compared in order to identify various methods of merger formation as well as ways in which other newly formed hospitals might accomplish a variety of important goals. Offering a spectacular account of some of the mergers that occurred in the health care field at the close of the twentieth century, these stories provide insight into academia's relationship with teaching hospitals and the challenges involved in bringing prestigious and powerful medical institutions together. The institutions discussed are Partners, the corporation which includes the Massachusetts General Hospital and the Brigham and Women's Hospital, New York-Presbyterian Hospital, the union of the New York and Presbyterian hospitals in New York City, and the UCSF Stanford, the merged teaching hospitals of the University of California, San Francisco and Stanford. This book will particularly appeal to professionals and academics interested in medicine, business, and organizational studies. John Kastor is Professor of Medicine at the University of Maryland School of Medicine. From 1984 to 1997, he was Theodore E. Woodward Professor of Medicine and Chairman of the Department of Medicine at Maryland and Chief of the Medical Service at the University of Maryland Hospital. Dr. Kastor is also the author of Arrhythmias.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{kaur_Survey_2016a,
  ids = {kaur_Survey_2016},
  title = {A {{Survey}} on {{Techniques}} for {{Brain Tumor Segmentation From Mri}}},
  author = {Kaur, Harsimranjot and Sharma, Dr. Reecha},
  date = {2016-05},
  journaltitle = {IOSR},
  volume = {11},
  number = {05},
  pages = {01--05},
  issn = {22788735, 22782834},
  doi = {10.9790/2834-1105010105},
  url = {http://www.iosrjournals.org/iosr-jece/papers/Vol.%2011%20Issue%205/Version-1/A1105010105.pdf},
  urldate = {2023-05-08},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {8 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/5C5VFXX3/Kaur and Sharma - 2016 - A Survey on Techniques for Brain Tumor Segmentatio.pdf}
}

@article{kaushal_Wiring_2019,
  title = {Wiring {{Minds}}},
  author = {Kaushal, Amit and Altman, Russ B.},
  date = {2019},
  journaltitle = {Nature},
  eprint = {31853071},
  eprinttype = {pmid},
  issn = {14764687},
  doi = {10.1038/d41586-019-03849-x},
  abstract = {Successfully applying AI to biomedicine requires innovators trained in contrasting cultures. [Figure not available: see fulltext.].},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Computer science,Health care}
}

@article{kawaguchi_Experimental_2002,
  title = {Experimental {{Study}} on {{Drag-Reducing Channel Flow With Surfactant Additives-Spatial Structure}} of {{Turbulence Investigated}} by {{PIV System}}},
  author = {Kawaguchi, Yasuo and Segawa, Takehiko and Feng, Ziping and Li, Peiwen},
  date = {2002-10},
  journaltitle = {Int. J. Heat Fluid Flow},
  volume = {23},
  number = {5},
  pages = {700--709},
  publisher = {{Elsevier}},
  issn = {0142727X},
  doi = {10.1016/S0142-727X(02)00166-2},
  abstract = {The turbulent frictional drag of water can be reduced dramatically by adding small amounts of drag-reducing materials, such as polymers or surfactants. As a percentage drag reduction of 80\% can easily be achieved, this technique is thought to be the most practical method of reducing turbulent frictional drag. In this work, a double pulse particle image velocimetry (PIV) system was used to clarify the spatial velocity distribution of surfactant solution flow in a two-dimensional channel. A type of cationic surfactant cetyltrimethyl ammonium chloride (C16H33N(CH3)3Cl) mixed with the same weight of counter-ion material NaSal (HOC6H4COONa) was used as a drag-reducing additive to water at a mass concentration of 40 ppm. Instantaneous velocity distribution taken by PIV was examined to clarify the effect of surfactant. It was found that the instantaneous velocity distribution taken in water flow exhibits penetration from the low-speed fluid region into the high-speed region, which is one of the important events of turbulence energy production and turbulent mixing. Although this structure is commonly observed in water flow, it was not found in drag-reducing flow under the same Reynolds number. The strong vorticity fluctuation near the wall also disappeared and the integral length scale in streamwise direction of turbulent fluctuation had a smaller value in surfactant solution flow. \textcopyright{} 2002 Elsevier Science Inc. All rights reserved.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Channel flow,Drag reduction,PIV,Spatial structure,Surfactant,Turbulence},
  annotation = {99 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{kawamura_Studies_1975,
  title = {Studies on Low Volume Priming Heart Lung Bypass},
  author = {Kawamura, M},
  date = {1975-03-01},
  journaltitle = {Hokkaido Igaku Zasshi},
  volume = {50},
  number = {2},
  eprint = {292},
  eprinttype = {pmid},
  pages = {137--167},
  issn = {0367-6102},
  abstract = {This report concerns the feasibility of low volume priming extracorporeal circulation. Through this study, the bubble oxygenator with Zuhdi's heat exchange was used. Moderate hypothermia with surface cooling and hemodilution perfusion with 5 per cent D/W was evaluated in 32 mongrel dogs and 16 clinical open heart cases. The results obtained here were as follow: 1) Body temperature reduction by surface cooling before bypass provided more even cooling than did core cooling by low flow partial bypass alone. 2) In regard to cardiac loading on returning the whole perfusate of the circuit to patient, approximately 20 ml/kg of 5 per cent D/W was feasible as a priming solution. 3) To reduce the blood visicosity, hemodilution technique with 5 per cent D/W was superior, and hemodilution effect during postoperative periods was temporaly. 4) The excess lactate volume postulated by Huckabee was a available index to evaluate metabolic acidosis during the extracorporeal circulation. 5) With aid of surface cooling, the acid-base balance during perfusion was kept to lesser extent than that of core cooling only. 6) This study indicated that the low priming perfusion in conjunction with surface cooling hypothermia was a reliable technique for the open heart operation and may be applied in more prolonged perfusion.},
  langid = {jpn},
  keywords = {⛔ No INSPIRE recid found,Acid-Base Equilibrium,Adolescent,Adult,Animals,Binding Sites,Blood Cell Count,Blood Viscosity,Blood Volume,Body Temperature,Child,{Child, Preschool},Cobalt,Dogs,Electrolytes,Extracorporeal Circulation,Female,Heart-Lung Machine,Hematocrit,Hemoglobins,Humans,Hydrogen-Ion Concentration,{Hypothermia, Induced},Iron,Lactates,Ligands,Male,Mathematics,Oxygen,Oxyhemoglobins,Perfusion,Protein Binding,Spectrum Analysis},
  file = {/Users/personal-macbook/Zotero/storage/F6D6HQZ3/292.html}
}

@article{kayalibay_CNNbased_2017,
  title = {{{CNN-based Segmentation}} of {{Medical Imaging Data}}},
  author = {Kayalibay, Baris and Jensen, Grady and family=Smagt, given=Patrick, prefix=van der, useprefix=false},
  date = {2017-01},
  abstract = {Convolutional neural networks have been applied to a wide variety of computer vision tasks. Recent advances in semantic segmentation have enabled their application to medical image segmentation. While most CNNs use two-dimensional kernels, recent CNN-based publications on medical image segmentation featured three-dimensional kernels, allowing full access to the three-dimensional structure of medical images. Though closely related to semantic segmentation, medical image segmentation includes specific challenges that need to be addressed, such as the scarcity of labelled data, the high class imbalance found in the ground truth and the high memory demand of three-dimensional images. In this work, a CNN-based method with three-dimensional filters is demonstrated and applied to hand and brain MRI. Two modifications to an existing CNN architecture are discussed, along with methods on addressing the aforementioned challenges. While most of the existing literature on medical image segmentation focuses on soft tissue and the major organs, this work is validated on data both from the central nervous system as well as the bones of the hand.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{kendall_Bayesian_2017,
  title = {Bayesian {{SegNet}}: {{Model Uncertainty}} in {{Deep Convolutional Encoder-Decoder Architectures}} for {{Scene Understanding}}},
  shorttitle = {Bayesian {{SegNet}}},
  author = {Kendall, Alex and Badrinarayanan, Vijay and Cipolla, R.},
  date = {2017},
  journaltitle = {BMVC},
  doi = {10.5244/C.31.57},
  abstract = {A practical system which is able to predict pixel-wise class labels with a measure of model uncertainty, and shows that modelling uncertainty improves segmentation performance by 2-3\% across a number of state of the art architectures such as SegNet, FCN and Dilation Network, with no additional parametrisation. We present a deep learning framework for probabilistic pixel-wise semantic segmentation, which we term Bayesian SegNet. Semantic segmentation is an important tool for visual scene understanding and a meaningful measure of uncertainty is essential for decision making. Our contribution is a practical system which is able to predict pixel-wise class labels with a measure of model uncertainty. We achieve this by Monte Carlo sampling with dropout at test time to generate a posterior distribution of pixel class labels. In addition, we show that modelling uncertainty improves segmentation performance by 2-3\% across a number of state of the art architectures such as SegNet, FCN and Dilation Network, with no additional parametrisation. We also observe a significant improvement in performance for smaller datasets where modelling uncertainty is more effective. We benchmark Bayesian SegNet on the indoor SUN Scene Understanding and outdoor CamVid driving scenes datasets.},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {903 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/5T4NV5BV/Kendall et al. - 2017 - Bayesian SegNet Model Uncertainty in Deep Convolu.pdf}
}

@inproceedings{kendall_What_2017,
  title = {What {{Uncertainties Do We Need}} in {{Bayesian Deep Learning}} for {{Computer Vision}}?},
  booktitle = {Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.},
  author = {Kendall, Alex and Gal, Yarin},
  date = {2017},
  issn = {10495258},
  abstract = {There are two major types of uncertainty one can model. Aleatoric uncertainty captures noise inherent in the observations. On the other hand, epistemic uncertainty accounts for uncertainty in the model - uncertainty which can be explained away given enough data. Traditionally it has been difficult to model epistemic uncertainty in computer vision, but with new Bayesian deep learning tools this is now possible. We study the benefits of modeling epistemic vs. aleatoric uncertainty in Bayesian deep learning models for vision tasks. For this we present a Bayesian deep learning framework combining input-dependent aleatoric uncertainty together with epistemic uncertainty. We study models under the framework with per-pixel semantic segmentation and depth regression tasks. Further, our explicit uncertainty formulation leads to new loss functions for these tasks, which can be interpreted as learned attenuation. This makes the loss more robust to noisy data, also giving new state-of-the-art results on segmentation and depth regression benchmarks.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{keramidas_TND_2012,
  ids = {keramidas_Tnd_2012},
  title = {{{$T$ND}}: {{A Thyroid Nodule Detection System}} for {{Analysis}} of {{Ultrasound Images}} and {{Videos}}},
  shorttitle = {{{$T$ND}}},
  author = {Keramidas, Eystratios G. and Maroulis, Dimitris and Iakovidis, Dimitris K.},
  date = {2012-06-01},
  journaltitle = {J Med Syst},
  volume = {36},
  number = {3},
  pages = {1271--1281},
  issn = {1573-689X},
  doi = {10.1007/s10916-010-9588-7},
  url = {https://doi.org/10.1007/s10916-010-9588-7},
  urldate = {2022-05-16},
  abstract = {In this paper, we present a computer-aided-diagnosis (CAD) system prototype, named TND (Thyroid Nodule Detector), for the detection of nodular tissue in ultrasound (US) thyroid images and videos acquired during thyroid US examinations. The proposed system incorporates an original methodology that involves a novel algorithm for automatic definition of the boundaries of the thyroid gland, and a novel approach for the extraction of noise resilient image features effectively representing the textural and the echogenic properties of the thyroid tissue. Through extensive experimental evaluation on real thyroid US data, its accuracy in thyroid nodule detection has been estimated to exceed 95\%. These results attest to the feasibility of the clinical application of TND, for the provision of a second more objective opinion to the radiologists by exploiting image evidences.},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Computer-aided-diagnosis,Nodule,Thyroid,Ultrasound},
  file = {/Users/personal-macbook/Zotero/storage/B3AWNDJJ/Keramidas et al. - 2012 - ΤND A Thyroid Nodule Detection System for Analysi.pdf}
}

@software{keras_2023,
  ids = {chollet_Deep_2017},
  title = {Keras: {{Deep Learning}} for Humans},
  shorttitle = {Keras},
  date = {2023-05-28T21:23:57Z},
  origdate = {2015-03-28T00:35:42Z},
  url = {https://github.com/keras-team/keras},
  urldate = {2023-05-28},
  abstract = {Deep Learning for humans},
  organization = {{Keras}},
  keywords = {\#nosource,⛔ No INSPIRE recid found,data-science,deep-learning,machine-learning,neural-networks,python,tensorflow}
}

@article{kesner_Analysis_2013,
  title = {An {{Analysis}} of the {{Dentate Gyrus Function}}},
  author = {Kesner, Raymond P.},
  date = {2013-10},
  journaltitle = {Behav. Brain Res.},
  volume = {254},
  pages = {1--7},
  doi = {10.1016/j.bbr.2013.01.012},
  abstract = {In this review article the emphasis will be on the role of the DG (dorsal and ventral) in supporting memory based on the operation of specific processes. Based on the development of computational models of dorsal dentate gyrus (dDG) and behavioral evidence based on dysfunction of dDG, this review will show that the dDG mediates mnemonic processing of spatial information. The processes subserved by dDG include (a) the operation of conjunctive encoding of multiple sensory inputs, implying an integration of sensory inputs to determine a spatial representation, and (b) pattern separation of spatial (especially metric) information, involving the reduction of interference between similar spatial locations (c) pattern separation of context (d) importance of context in object recognition, and (e) temporal integration and remote memory and spatial pattern separation based in part on neurogenesis. In addition the ventral dentate gyrus (vDG) mediates mnemonic processing of odor information as indicated by odor pattern separation.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Conjunctive encoding,Context,Dorsal and ventral},
  annotation = {120 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{khosla_Novel_2011,
  title = {Novel {{Dataset}} for {{Fine-Grained Image Categorization}}: {{Stanford Dogs}}},
  shorttitle = {Novel {{Dataset}} for {{Fine-Grained Image Categorization}}},
  booktitle = {Proc {{CVPR Workshop Fine-Grained Vis}}. {{Categ}}. {{FGVC}}},
  author = {Khosla, Aditya and Jayadevaprakash, Nityananda and Yao, Bangpeng and Li, Fei-Fei},
  date = {2011},
  volume = {2},
  number = {1},
  publisher = {{Citeseer}},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/TRMY3BWS/Khosla et al. - 2011 - Novel Dataset for Fine-Grained Image Categorizatio.pdf}
}

@article{kim_Diffusion_2016,
  title = {Diffusion {{Tensor Imaging-Based Thalamic Segmentation}} in {{Deep Brain Stimulation}} for {{Chronic Pain Conditions}}},
  author = {Kim, Won and Chivukula, Srinivas and Hauptman, Jason and Pouratian, Nader},
  date = {2016-08},
  journaltitle = {Ster. Funct Neurosurg},
  volume = {94},
  number = {4},
  pages = {225--234},
  doi = {10.1159/000448079},
  abstract = {BACKGROUND/AIMS: Thalamic deep brain stimulation (DBS) for the treatment of medically refractory pain has largely been abandoned on account of its inconsistent and oftentimes poor efficacy. Our aim here was to use diffusion tensor imaging (DTI)-based segmentation to assess the internal thalamic nuclei of patients who have undergone thalamic DBS for intractable pain and retrospectively correlate lead position with clinical outcome. METHODS: DTI-based segmentation was performed on 5 patients who underwent sensory thalamus DBS for chronic pain. Postoperative computed tomography images obtained for electrode placement were fused with preoperative magnetic resonance images that had undergone DTI-based thalamic segmentation. Sensory thalamus maps of 4 patients were analyzed for lead positioning and interpatient variability. RESULTS: Four patients who experienced significant pain relief following DBS demonstrated contact positions within the DTI-determined sensory thalamus or in its vicinity, whereas 1 patient who did not respond to stimulation did not. Only 4 voxels (2\%) within the sensory thalamus were mutually shared among patients; 108 voxels (58\%) were uniquely represented. CONCLUSIONS: DTI-based segmentation of the thalamus can be used to confirm thalamic lead placement relative to the sensory thalamus and may serve as a useful tool to guide thalamic DBS electrode implantation in the future.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {17 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{kim_MultiLabel_2020,
  title = {Multi-{{Label Na\"ive Bayes Classification Considering Label Dependence}}},
  author = {Kim, Hae-Cheon and Park, Jin-Hyeong and Kim, Dae-Won and Lee, Jaesung},
  date = {2020-08-01},
  journaltitle = {Pattern Recognition Letters},
  volume = {136},
  pages = {279--285},
  issn = {0167-8655},
  doi = {10.1016/j.patrec.2020.06.021},
  url = {https://www.sciencedirect.com/science/article/pii/S0167865520302397},
  urldate = {2022-06-23},
  abstract = {Multilabel classification is the task of assigning relevant labels to an instance, and it has received considerable attention in recent years. This task can be performed by extending a single-label classifier, such as the na\"ive Bayes classifier, to utilize the useful relations among labels for achieving better multilabel classification accuracy. However, the conventional multilabel na\"ive Bayes classifier treats each label independently and hence neglects the relations among labels, resulting in degenerated accuracy. We propose a new multilabel na\"ive Bayes classifier that considers the relations or dependence among labels. Experimental results show that the proposed method outperforms conventional multilabel classifiers.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Label dependence,Multilabel classifier,Na\"ive Bayes classification},
  file = {/Users/personal-macbook/Zotero/storage/M9A57KRC/Kim et al. - 2020 - Multilabel naïve Bayes classification considering .pdf;/Users/personal-macbook/Zotero/storage/26CA8UCZ/S0167865520302397.html}
}

@article{kim_Simulationbased_2017,
  title = {Simulation-{{Based Machine Shop Operations Scheduling System}} for {{Energy Cost Reduction}}},
  author = {Kim, Sojung and Meng, Chao and Son, Young Jun},
  date = {2017},
  journaltitle = {Simul. Model. Pract. Theory},
  issn = {1569190X},
  doi = {10.1016/j.simpat.2017.05.007},
  abstract = {Owing to the ever increasing requirements in sustainability, manufacturing firms are trying to reduce their energy consumption and cost. In this paper, we propose a simulation-based machine shop operations scheduling system for minimizing the energy cost without sacrificing the productivity. The proposed system consists of two major functions: (1) real-time energy consumption monitoring (through power meters, a database server, and mobile applications) and (2) simulation-based machine shop operations scheduling (through a machine shop operations simulator). First, the real-time energy consumption monitoring function is developed to collect energy consumption data and provide real-time energy consumption status monitoring/electrical load abnormality warnings. Second, the simulation-based machine shop operations scheduling function is devised to estimate the energy consumptions and cost of CNC machines. In addition, an additive regression algorithm is developed to formulate energy consumption models for each individual machine as simulation inputs. The proposed system is implemented at a manufacturing company located in Tucson, Arizona state of USA. The experiment results reveal the effectiveness of the proposed system in achieving energy cost savings without sacrificing the productivity under various scenarios of machine shop operations.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,CNC machine,Energy reduction,Real-time monitoring,Simulation-based scheduling}
}

@inproceedings{kim_Vehicle_2017,
  title = {Vehicle {{Type Classification Using Bagging}} and {{Convolutional Neural Network}} on {{Multi View Surveillance Image}}},
  author = {Kim, Pyong-Kun and Lim, Kil-Taek},
  date = {2017},
  pages = {41--46},
  url = {https://openaccess.thecvf.com/content_cvpr_2017_workshops/w9/html/Kim_Vehicle_Type_Classification_CVPR_2017_paper.html},
  urldate = {2023-01-11},
  eventtitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition Workshops}}},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/NXHKXTU2/Kim and Lim - 2017 - Vehicle Type Classification Using Bagging and Conv.pdf;/Users/personal-macbook/Zotero/storage/W2D3KK8T/Kim_Vehicle_Type_Classification_CVPR_2017_paper.html}
}

@online{kingma_Adam_2014,
  ids = {kingma15,kingma_adammethodstochasticoptimization_2015},
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  shorttitle = {Adam},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  date = {2014},
  eprint = {1412.6980},
  eprinttype = {arxiv},
  eprintclass = {cs.LG},
  doi = {10.48550/ARXIV.1412.6980},
  url = {https://arxiv.org/abs/1412.6980},
  urldate = {2023-01-11},
  abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  pubstate = {preprint},
  version = {9},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found,bone density,Computer Science - Machine Learning,FOS: Computer and information sciences,grafted maxillary sinuses,logistic regression,Machine Learning (cs.LG),prognostic factors,Tilted implants},
  annotation = {9989 citations (Semantic Scholar/arXiv) [2023-05-08] 1673 citations (INSPIRE 2023/5/8) 1673 citations w/o self (INSPIRE 2023/5/8)},
  file = {/Users/personal-macbook/Zotero/storage/4XVJEXIA/Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf;/Users/personal-macbook/Zotero/storage/B69QEWPK/1412.html;/Users/personal-macbook/Zotero/storage/JU2FJGM6/search.html}
}

@inproceedings{kingma_Variational_2015,
  title = {Variational {{Dropout}} and the {{Local Reparameterization Trick}}},
  booktitle = {Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.},
  author = {Kingma, Diederik P. and Salimans, Tim and Welling, Max},
  date = {2015},
  issn = {10495258},
  abstract = {We investigate a local reparameterizaton technique for greatly reducing the variance of stochastic gradients for variational Bayesian inference (SGVB) of a posterior over model parameters, while retaining parallelizability. This local reparameterization translates uncertainty about global parameters into local noise that is independent across datapoints in the minibatch. Such parameterizations can be trivially parallelized and have variance that is inversely proportional to the minibatch size, generally leading to much faster convergence. Additionally, we explore a connection with dropout: Gaussian dropout objectives correspond to SGVB with local reparameterization, a scale-invariant prior and proportionally fixed posterior variance. Our method allows inference of more flexibly parameterized posteriors; specifically, we propose variational dropout, a generalization of Gaussian dropout where the dropout rates are learned, often leading to better models. The method is demonstrated through several experiments.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{Kingma:2013hel,
  title = {Auto-{{Encoding Variational Bayes}}},
  author = {Kingma, Diederik P. and Welling, Max},
  date = {2014-05-01},
  journaltitle = {arXiv:1312.6114 [stat.ML]},
  eprint = {1312.6114},
  eprinttype = {arxiv},
  eprintclass = {stat.ML},
  doi = {10.48550/arXiv.1312.6114},
  url = {http://arxiv.org/abs/1312.6114},
  urldate = {2022-06-21},
  abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  annotation = {9995 citations (Semantic Scholar/arXiv) [2023-05-08] 280 citations (INSPIRE 2023/5/8) 278 citations w/o self (INSPIRE 2023/5/8)},
  file = {/Users/personal-macbook/Zotero/storage/TR93D4ME/Kingma and Welling - 2014 - Auto-Encoding Variational Bayes.pdf;/Users/personal-macbook/Zotero/storage/TFJC5TBA/Kingma and Welling - 2014 - Auto-Encoding Variational Bayes.html}
}

@article{kintz_Chapter_2000,
  title = {Chapter 13 {{Unconventional Samples}} and {{Alternative Matrices}}},
  author = {Kintz, Pascal and Samyn, Nele},
  date = {2000},
  journaltitle = {Handb. Anal. Sep.},
  issn = {15677192},
  doi = {10.1016/S1567-7192(00)80068-6},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {7 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{kleesiek_Deep_2016,
  title = {Deep {{MRI Brain Extraction}}: {{A 3D Convolutional Neural Network}} for {{Skull Stripping}}},
  author = {Kleesiek, Jens and Urban, Gregor and Hubert, Alexander and Schwarz, Daniel and Maier-Hein, Klaus and Bendszus, Martin and Biller, Armin},
  date = {2016-04},
  journaltitle = {Neuroimage},
  volume = {129},
  pages = {460--469},
  doi = {10.1016/j.neuroimage.2016.01.024},
  abstract = {Brain extraction from magnetic resonance imaging (MRI) is crucial for many neuroimaging workflows. Current methods demonstrate good results on non-enhanced T1-weighted images, but struggle when confronted with other modalities and pathologically altered tissue. In this paper we present a 3D convolutional deep learning architecture to address these shortcomings. In contrast to existing methods, we are not limited to non-enhanced T1w images. When trained appropriately, our approach handles an arbitrary number of modalities including contrast-enhanced scans. Its applicability to MRI data, comprising four channels: non-enhanced and contrast-enhanced T1w, T2w and FLAIR contrasts, is demonstrated on a challenging clinical data set containing brain tumors (N=53), where our approach significantly outperforms six commonly used tools with a mean Dice score of 95.19. Further, the proposed method at least matches state-of-the-art performance as demonstrated on three publicly available data sets: IBSR, LPBA40 and OASIS, totaling N=135 volumes. For the IBSR (96.32) and LPBA40 (96.96) data set the convolutional neuronal network (CNN) obtains the highest average Dice scores, albeit not being significantly different from the second best performing method. For the OASIS data the second best Dice (95.02) results are achieved, with no statistical difference in comparison to the best performing tool. For all data sets the highest average specificity measures are evaluated, whereas the sensitivity displays about average results. Adjusting the cut-off threshold for generating the binary masks from the CNN's probability output can be used to increase the sensitivity of the method. Of course, this comes at the cost of a decreased specificity and has to be decided application specific. Using an optimized GPU implementation predictions can be achieved in less than one minute. The proposed method may prove useful for large-scale studies and clinical trials.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Brain extraction,Brain mask,Convolutional networ},
  annotation = {395 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{klein_Mindboggle_2005,
  title = {Mindboggle: {{Automated Brain Labeling With Multiple Atlases}}},
  author = {Klein, Arno and Mensh, Brett and Ghosh, Satrajit and Tourville, Jason and Hirsch, Joy},
  date = {2005-10},
  journaltitle = {BMC Med. Imaging},
  volume = {5},
  pages = {7},
  abstract = {BACKGROUND: To make inferences about brain structures or activity across multiple individuals, one first needs to determine the structural correspondences across their image data. We have recently developed Mindboggle as a fully automated, feature-matching approach to assign anatomical labels to cortical structures and activity in human brain MRI data. Label assignment is based on structural correspondences between labeled atlases and unlabeled image data, where an atlas consists of a set of labels manually assigned to a single brain image. In the present work, we study the influence of using variable numbers of individual atlases to nonlinearly label human brain image data. METHODS: Each brain image voxel of each of 20 human subjects is assigned a label by each of the remaining 19 atlases using Mindboggle. The most common label is selected and is given a confidence rating based on the number of atlases that assigned that label. The automatically assigned labels for each subject brain are compared with the manual labels for that subject (its atlas). Unlike recent approaches that transform subject data to a labeled, probabilistic atlas space (constructed from a database of atlases), Mindboggle labels a subject by each atlas in a database independently. RESULTS: When Mindboggle labels a human subject's brain image with at least four atlases, the resulting label agreement with coregistered manual labels is significantly higher than when only a single atlas is used. Different numbers of atlases provide significantly higher label agreements for individual brain regions. CONCLUSION: Increasing the number of reference brains used to automatically label a human subject brain improves labeling accuracy with respect to manually assigned labels. Mindboggle software can provide confidence measures for labels based on probabilistic assignment of labels and could be applied to large databases of brain images.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@report{kleinberg_NBER_2017,
  title = {{{NBER WORKING PAPER SERIES HUMAN DECISIONS AND MACHINE PREDICTIONS Human Decisions}} and {{Machine Predictions}}},
  author = {Kleinberg, Jon and Lakkaraju, Himabindu and Leskovec, Jure and Ludwig, Jens and Mullainathan, Sendhil and Abrams, David and Alsdorf, Matt and Cohen, Molly and Crohn, Alexander and Cusick, Gretchen Ruth and Dierks, Tim and Donohue, John and Dupont, Mark and Egan, Meg and Glazer, Elizabeth and Gottschall, Joan and Hess, Nathan and Kane, Karen and Kellam, Leslie and Lascala-Gruenewald, Angela and Loeffler, Charles and Milgram, Anne and Raphael, Lauren and Rohlfs, Chris and Rosenbaum, Dan and Salo, Terry and Shleifer, Andrei and Sojourner, Aaron and Sowerby, James and Sunstein, Cass and Sviridoff, Michele and Turner, Emily and Wasilewski, John},
  date = {2017},
  url = {http://www.nber.org/papers/w23180},
  abstract = {We examine how machine learning can be used to improve and understand human decision-making. In particular, we focus on a decision that has important policy consequences. Millions of times each year, judges must decide where defendants will await trial-at home or in jail. By law, this decision hinges on the judge's prediction of what the defendant would do if released. This is a promising machine learning application because it is a concrete prediction task for which there is a large volume of data available. Yet comparing the algorithm to the judge proves complicated. First, the data are themselves generated by prior judge decisions. We only observe crime outcomes for released defendants, not for those judges detained. This makes it hard to evaluate counterfactual decision rules based on algorithmic predictions. Second, judges may have a broader set of preferences than the single variable that the algorithm focuses on; for instance, judges may care about racial inequities or about specific crimes (such as violent crimes) rather than just overall crime risk. We deal with these problems using different econometric strategies, such as quasi-random assignment of cases to judges. Even accounting for these concerns, our results suggest potentially large welfare gains: a policy simulation shows crime can be reduced by up to 24.8\% with no change in jailing rates, or jail populations can be reduced by 42.0\%with no increase in crime rates. Moreover, we see reductions in all categories of crime, including violent ones. Importantly, such gains can be had while also significantly reducing the percentage of African-Americans and Hispanics in jail. We find similar results in a national dataset as well. In addition, by focusing the algorithm on predicting judges' decisions, rather than defendant behavior, we gain some insight into decision-making: a key problem appears to be that judges to respond to 'noise' as if it were signal. These results suggest that while machine learning can be valuable, realizing this value requires integrating these tools into an economic framework: being clear about the link between predictions and decisions; specifying the scope of payoff functions; and constructing unbiased decision counterfactuals.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{kleindessner_Crowdsourcing_2018,
  title = {Crowdsourcing {{With Arbitrary Adversaries}}},
  booktitle = {Proc. 35th {{Int}}. {{Conf}}. {{Mach}}. {{Learn}}.},
  author = {Kleindessner, Matthaeus and Awasthi, Pranjal},
  date = {2018-07-10},
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {80},
  pages = {2708--2717},
  publisher = {{PMLR}},
  url = {https://proceedings.mlr.press/v80/kleindessner18a.html},
  abstract = {Most existing works on crowdsourcing assume that the workers follow the Dawid-Skene model, or the one-coin model as its special case, where every worker makes mistakes independently of other workers and with the same error probability for every task. We study a significant extension of this restricted model. We allow almost half of the workers to deviate from the one-coin model and for those workers, their probabilities of making an error to be task-dependent and to be arbitrarily correlated. In other words, we allow for arbitrary adversaries, for which not only error probabilities can be high, but which can also perfectly collude. In this adversarial scenario, we design an efficient algorithm to consistently estimate the workers' error probabilities.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  keywords = {⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/NX5GERRE/Kleindessner and Awasthi - 2018 - Crowdsourcing with Arbitrary Adversaries.pdf;/Users/personal-macbook/Zotero/storage/QFP5ANN6/Kleindessner and Awasthi - 2018 - Crowdsourcing with Arbitrary Adversaries.pdf}
}

@article{kleinhaus_Electrophysiological_1975,
  title = {Electrophysiological {{Actions}} of {{Convulsants}} and {{Anticonvulsants}} on {{Neurons}} of the {{Leech Subesophageal Ganglion}}},
  author = {Kleinhaus, A. L.},
  date = {1975-10-01},
  journaltitle = {Comp Biochem Physiol C Comp Pharmacol},
  volume = {52},
  number = {1},
  eprint = {199},
  eprinttype = {pmid},
  pages = {27--34},
  issn = {0306-4492},
  doi = {10.1016/0306-4492(75)90008-8},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Animals,Bemegride,{Ganglia, Autonomic},Leeches,Magnesium,Membrane Potentials,Neurons,Penicillin G,Pentylenetetrazole,Phenobarbital,Strychnine},
  annotation = {12 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{klemkowsky_Plenoptic_2017,
  title = {Plenoptic {{Background Oriented Schlieren Imaging}}},
  author = {Klemkowsky, Jenna N. and Fahringer, Timothy W. and Clifford, Christopher J. and Bathel, Brett F. and Thurow, Brian S. and Klemkowsky, Jenna N. and Fahringer, Timothy W. and Clifford, Christopher J. and Bathel, Brett F. and Thurow, Brian S.},
  date = {2017},
  journaltitle = {MeScT},
  volume = {28},
  number = {9},
  pages = {095404},
  issn = {0957-0233},
  doi = {10.1088/1361-6501/AA7F3D},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{klibaite_Unsupervised_2017,
  title = {An {{Unsupervised Method}} for {{Quantifying}} the {{Behavior}} of {{Paired Animals}}},
  author = {Klibaite, Ugne and Berman, Gordon J. and Cande, Jessica and Stern, David L. and Shaevitz, Joshua W.},
  date = {2017-02},
  journaltitle = {Phys. Biol.},
  volume = {14},
  number = {1},
  pages = {15006},
  doi = {10.1088/1478-3975/aa5c50},
  abstract = {Behaviors involving the interaction of multiple individuals are complex and frequently crucial for an animal's survival. These interactions, ranging across sensory modalities, length scales, and time scales, are often subtle and difficult to characterize. Contextual effects on the frequency of behaviors become even more difficult to quantify when physical interaction between animals interferes with conventional data analysis, e.g. due to visual occlusion. We introduce a method for quantifying behavior in fruit fly interaction that combines high-throughput video acquisition and tracking of individuals with recent unsupervised methods for capturing an animal's entire behavioral repertoire. We find behavioral differences between solitary flies and those paired with an individual of the opposite sex, identifying specific behaviors that are affected by social and spatial context. Our pipeline allows for a comprehensive description of the interaction between two individuals using unsupervised machine learning methods, and will be used to answer questions about the depth of complexity and variance in fruit fly courtship.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {57 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{kluge_Artificial_2020,
  title = {Artificial {{Intelligence}} in {{Healthcare}}: {{Ethical Considerations}}},
  author = {Kluge, Eike Henner W.},
  date = {2020},
  journaltitle = {Healthc. Manage. Forum},
  eprint = {31340674},
  eprinttype = {pmid},
  issn = {08404704},
  doi = {10.1177/0840470419850438},
  abstract = {The term Artificial Intelligence (AI) is systematically ambiguous between electronic expert systems that are used by healthcare professionals in carrying out their tasks and full AIs, which are stand-alone independent electronic entities that function much like human healthcare professionals except that they are electronic and not biological in nature. This discussion sketches the distinct ethical considerations that are relevant to the two kinds of AI while acknowledging that currently there are no full AIs.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {6 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{knierim_Hippocampal_2006,
  title = {Hippocampal {{Place Cells}}: {{Parallel Input Streams}}, {{Subregional Processing}}, and {{Implications}} for {{Episodic Memory}}},
  author = {Knierim, James J. and Lee, Inah and Hargreaves, Eric L.},
  date = {2006},
  journaltitle = {Hippocampus},
  volume = {16},
  number = {9},
  pages = {755--764},
  doi = {10.1002/hipo.20203},
  abstract = {The hippocampus is thought to be involved in episodic memory in humans. Place cells of the rat hippocampus offer a potentially important model system to understand episodic memory. However, the difficulties in determining whether rats have episodic memory are profound. Progress can be made by considering the hippocampus as a computational device that presumably performs similar transformations on its inputs in both rats and in humans. Understanding the input/output transformations of rat place cells can thus inform research on the computational basis of human episodic memory. Two examples of different transformations in the CA3 and CA1 regions are presented. In one example, CA3 place fields are shown to maintain a greater degree of population coherence than CA1 place fields after a rearrangement of the salient landmarks in an environment, in agreement with computational models of CA3 as an autoassociative network. In the second example, CA3 place field appears to store information about the spatiotemporal sequences of place fields, starting with the first exposure to a cue-altered environment, whereas CA1 place fields store this information only on a temporary basis. Finally, recordings of hippocampal afferents from the lateral and medial entorhinal cortex (EC) suggest that these two regions convey fundamentally different representations to the hippocampus, with spatial information conveyed by the medial EC and nonspatial information conveyed by the lateral EC. The dentate gyrus and CA3 regions may create configural object+place (or item+context) representations that provide the spatiotemporal context of an episodic memory.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {236 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{knight_Entrepreneurship_2001,
  title = {Entrepreneurship and {{Strategy}} in the {{International SME}}},
  author = {Knight, Gary A.},
  date = {2001-09},
  journaltitle = {J. Int. Manag.},
  volume = {7},
  number = {3},
  pages = {155--171},
  doi = {10.1016/S1075-4253(01)00042-4},
  abstract = {Small and medium enterprises (SMEs) have begun to play a critical role in international trade. Statistics from the Organization for Economic Cooperation and Development (OECD) and other sources indicate that SMEs now account for a very substantial proportion of exports from most industrialized nations. But very little is known about the effect of having an international entrepreneurial orientation, or the role of specific strategies associated with this construct, on the foreign performance of such firms. Using data from an empirical study of SMEs, we devise a structural model that reveals the role of international entrepreneurial orientation, key strategic activities, and the collective effect of these constructs on the international performance of the modern, international SME. These findings and their implications for scholars and managers are discussed.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,International entrepreneurial orientation,Strateg},
  annotation = {500 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{knight_Magnetic_2016,
  title = {Magnetic {{Resonance Imaging}} to {{Detect Early Molecular}} and {{Cellular Changes}} in {{Alzheimer}}'s {{Disease}}},
  author = {Knight, Michael J. and McCann, Bryony and Kauppinen, Risto A. and Coulthard, Elizabeth J.},
  date = {2016-06},
  journaltitle = {Front. Aging Neurosci.},
  volume = {8},
  pages = {139},
  abstract = {Recent pharmaceutical trials have demonstrated that slowing or reversing pathology in Alzheimer's disease is likely to be possible only in the earliest stages of disease, perhaps even before significant symptoms develop. Pathology in Alzheimer's disease accumulates for well over a decade before symptoms are detected giving a large potential window of opportunity for intervention. It is therefore important that imaging techniques detect subtle changes in brain tissue before significant macroscopic brain atrophy. Current diagnostic techniques often do not permit early diagnosis or are too expensive for routine clinical use. Magnetic Resonance Imaging (MRI) is the most versatile, affordable, and powerful imaging modality currently available, being able to deliver detailed analyses of anatomy, tissue volumes, and tissue state. In this mini-review, we consider how MRI might detect patients at risk of future dementia in the early stages of pathological change when symptoms are mild. We consider the contributions made by the various modalities of MRI (structural, diffusion, perfusion, relaxometry) in identifying not just atrophy (a late-stage AD symptom) but more subtle changes reflective of early dementia pathology. The sensitivity of MRI not just to gross anatomy but to the underlying ``health'' at the cellular (and even molecular) scales, makes it very well suited to this task.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found,Alzheimer's,diffusion tensor imaging,magnetic re}
}

@article{knutsson_Producing_1985,
  title = {Producing a {{Continuous}} and {{Distance Preserving}} 5-{{D Vector Representation}} of 3-{{D Orientation}}},
  author = {Knutsson, Hans},
  date = {1985},
  pages = {175--182},
  abstract = {DiVA portal is a finding tool for research publications and student theses written at the following 47 universities and research institutions.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{kohl_Probabilistic_2018,
  title = {A {{Probabilistic U-Net}} for {{Segmentation}} of {{Ambiguous Images}}},
  author = {Kohl, Simon A. A. and Romera-Paredes, Bernardino and Meyer, Clemens and Fauw, Jeffrey De and Ledsam, Joseph R. and Maier-Hein, Klaus H. and Eslami, S. M. Ali and Rezende, Danilo Jimenez and Ronneberger, Olaf},
  date = {2018-06},
  abstract = {Many real-world vision problems suffer from inherent ambiguities. In clinical applications for example, it might not be clear from a CT scan alone which particular region is cancer tissue. Therefore a group of graders typically produces a set of diverse but plausible segmentations. We consider the task of learning a distribution over segmentations given an input. To this end we propose a generative segmentation model based on a combination of a U-Net with a conditional variational autoencoder that is capable of efficiently producing an unlimited number of plausible hypotheses. We show on a lung abnormalities segmentation task and on a Cityscapes segmentation task that our model reproduces the possible segmentation variants as well as the frequencies with which they occur, doing so significantly better than published approaches. These models could have a high impact in real-world applications, such as being used as clinical decision-making algorithms accounting for multiple plausible semantic segmentation hypotheses to provide possible diagnoses and recommend further actions to resolve the present ambiguities.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@inproceedings{kohler_Uncertainty_2019,
  title = {Uncertainty {{Based Detection}} and {{Relabeling}} of {{Noisy Image Labels}}},
  booktitle = {Proc. {{IEEE Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}. {{Workshop}}},
  author = {K\"ohler, Jan M. and Autenrieth, Maximilian and Beluch, William H.},
  date = {2019},
  pages = {33--37},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{kohli_Medical_2017,
  title = {Medical {{Image Data}} and {{Datasets}} in the {{Era}} of {{Machine Learning}}\textemdash{{Whitepaper From}} the 2016 {{C-Mimi Meeting Dataset Session}}},
  author = {Kohli, Marc D. and Summers, Ronald M. and Geis, J. Raymond},
  date = {2017-08},
  journaltitle = {J Digit Imaging},
  volume = {30},
  number = {4},
  pages = {392--399},
  issn = {0897-1889, 1618-727X},
  doi = {10.1007/s10278-017-9976-3},
  url = {http://link.springer.com/10.1007/s10278-017-9976-3},
  urldate = {2022-11-21},
  abstract = {At the first annual Conference on Machine Intelligence in Medical Imaging (C-MIMI), held in September 2016, a conference session on medical image data and datasets for machine learning identified multiple issues. The common theme from attendees was that everyone participating in medical image evaluation with machine learning is data starved. There is an urgent need to find better ways to collect, annotate, and reuse medical imaging data. Unique domain issues with medical image datasets require further study, development, and dissemination of best practices and standards, and a coordinated effort among medical imaging domain experts, medical imaging informaticists, government and industry data scientists, and interested commercial, academic, and government entities. High-level attributes of reusable medical image datasets suitable to train, test, validate, verify, and regulate ML products should be better described. NIH and other government agencies should promote and, where applicable, enforce, access to medical image datasets. We should improve communication among medical imaging domain experts, medical imaging informaticists, academic clinical and basic science researchers, government and industry data scientists, and interested commercial entities.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {138 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/M7SBSQBF/Kohli et al. - 2017 - Medical Image Data and Datasets in the Era of Mach.pdf;/Users/personal-macbook/Zotero/storage/GLHSV6GH/s10278-017-9976-3.html}
}

@article{kompa_Second_2021,
  title = {Second {{Opinion Needed}}: {{Communicating Uncertainty}} in {{Medical Machine Learning}}},
  shorttitle = {Second Opinion Needed},
  author = {Kompa, Benjamin and Snoek, Jasper and Beam, Andrew L.},
  date = {2021-01-05},
  journaltitle = {npj Digit. Med.},
  volume = {4},
  number = {1},
  pages = {1--6},
  publisher = {{Nature Publishing Group}},
  issn = {2398-6352},
  doi = {10.1038/s41746-020-00367-3},
  url = {https://www.nature.com/articles/s41746-020-00367-3},
  urldate = {2022-06-14},
  abstract = {There is great excitement that medical artificial intelligence (AI) based on machine learning (ML) can be used to improve decision making at the patient level in a variety of healthcare settings. However, the quantification and communication of uncertainty for individual predictions is often neglected even though uncertainty estimates could lead to more principled decision-making and enable machine learning models to automatically or semi-automatically abstain on samples for which there is high uncertainty. In this article, we provide an overview of different approaches to uncertainty quantification and abstention for machine learning and highlight how these techniques could improve the safety and reliability of current ML systems being used in healthcare settings. Effective quantification and communication of uncertainty could help to engender trust with healthcare workers, while providing safeguards against known failure modes of current machine learning approaches. As machine learning becomes further integrated into healthcare environments, the ability to say ``I'm not sure'' or ``I don't know'' when uncertain is a necessary capability to enable safe clinical deployment.},
  issue = {1},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Health care,Medical research},
  file = {/Users/personal-macbook/Zotero/storage/JLMC5PAG/Kompa et al. - 2021 - Second opinion needed communicating uncertainty i.pdf}
}

@article{konev_Luminescence_1975,
  title = {Luminescence Study of the Effect of Temperature on the Conformational State of Fibrinogen},
  author = {Konev, S. V. and Katibnikov, M. A. and Bandarin, V. A. and Niamaa, D. and Barkovski{\u \i}, E. V.},
  year = {1975 Jul-Aug},
  journaltitle = {Biofizika},
  volume = {20},
  number = {4},
  eprint = {95},
  eprinttype = {pmid},
  pages = {586--590},
  issn = {0006-3029},
  abstract = {Results are presented of measuring fibrinogen fluorescence parameters in temperature range of 20-80 degrees C at different pH of the solution. It was found that the temperature increase from 20 to 40 degrees C for solutions with pH of 4,5-9,3 were not accompanied by the conformational changes of fibrinogen macromolecules. In the temperature range of 40-50 degrees C for neutral solutions conformational reconstruction of fibrinogen of undenatured character took place. Temperature increase above 50-55 degrees C brings about significant structural changes of fibrinogen molecule which are of denaturation nature.},
  langid = {russian},
  keywords = {⛔ No INSPIRE recid found,Fibrinogen,Hydrogen-Ion Concentration,Molecular Conformation,{Spectrometry, Fluorescence},Temperature}
}

@inproceedings{kowsari_HDLTex_2017,
  title = {{{HDLTex}}: {{Hierarchical Deep Learning}} for {{Text Classification}}},
  shorttitle = {{{HDLTex}}},
  booktitle = {16th {{IEEE Int}}. {{Conf}}. {{Mach}}. {{Learn}}. {{Appl}}. {{ICMLA}}},
  author = {Kowsari, Kamran and Brown, Donald E. and Heidarysafa, Mojtaba and Jafari Meimandi, Kiana and Gerber, Matthew S. and Barnes, Laura E.},
  date = {2017-12},
  pages = {364--371},
  publisher = {{IEEE}},
  location = {{Cancun, Mexico}},
  doi = {10.1109/ICMLA.2017.0-134},
  url = {http://ieeexplore.ieee.org/document/8260658/},
  urldate = {2022-11-21},
  eventtitle = {16th {{IEEE International Conference}} on {{Machine Learning}} and {{Applications}} ({{ICMLA}})},
  isbn = {978-1-5386-1418-1},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {267 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/R74XF9NL/Kowsari et al. - 2017 - HDLTex Hierarchical Deep Learning for Text Classi.pdf}
}

@article{krauth_Mean_2010,
  title = {A {{Mean Three-Dimensional Atlas}} of the {{Human Thalamus}}: {{Generation From Multiple Histological Data}}},
  shorttitle = {A {{Mean Three-Dimensional Atlas}} of the {{Human Thalamus}}},
  author = {Krauth, Axel and Blanc, Remi and Poveda, Alejandra and Jeanmonod, Daniel and Morel, Anne and Sz\'ekely, G\'abor},
  date = {2010-02},
  journaltitle = {NeuroImage},
  volume = {49},
  number = {3},
  pages = {2053--2062},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2009.10.042},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811909011136},
  urldate = {2023-05-08},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {292 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{Kremer2018RobustAL,
  ids = {_Robust_,_pdfrobustactivelabelcorrectionsemanticscholar_},
  title = {Robust {{Active Label Correction}}},
  booktitle = {Int. {{Conf}}. {{Artif}}. {{Intell}}. {{Stat}}.},
  author = {Kremer, Jan and Sha, Fei and Igel, C.},
  date = {2018},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@book{krippendorff_Content_2018,
  title = {Content {{Analysis}}: {{An Introduction}} to {{Its Methodology}}},
  shorttitle = {Content {{Analysis}}},
  author = {Krippendorff, Klaus},
  date = {2018},
  edition = {Fourth Edition},
  publisher = {{SAGE}},
  location = {{Los Angeles}},
  isbn = {978-1-5063-9566-1},
  pagetotal = {451},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Content analysis (Communication)}
}

@article{krizhevsky_Imagenet_2017,
  ids = {Krizhevsky_2017,krizhevsky12,krizhevsky_ImageNet_2017,krizhevsky_Image_2017},
  title = {{{ImageNet Classification}} with {{Deep Convolutional Neural Networks}}},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  date = {2017-05-24},
  journaltitle = {Commun. ACM},
  volume = {60},
  number = {6},
  pages = {84--90},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/3065386},
  url = {https://dl.acm.org/doi/10.1145/3065386},
  urldate = {2023-01-11},
  abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {9998 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/Q4HIJ9RZ/Krizhevsky et al. - 2017 - ImageNet classification with deep convolutional ne.pdf;/Users/personal-macbook/Zotero/storage/XEBSNNB6/Krizhevsky et al. - 2017 - ImageNet classification with deep convolutional ne.pdf}
}

@online{krizhevsky_One_2014,
  title = {One {{Weird Trick}} for {{Parallelizing Convolutional Neural Networks}}},
  author = {Krizhevsky, Alex},
  date = {2014-04-23},
  eprint = {1404.5997},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1404.5997},
  url = {http://arxiv.org/abs/1404.5997},
  urldate = {2023-01-11},
  abstract = {I present a new way to parallelize the training of convolutional neural networks across multiple GPUs. The method scales significantly better than all alternatives when applied to modern convolutional neural networks.},
  pubstate = {preprint},
  version = {1},
  keywords = {⛔ No INSPIRE recid found,{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,{Distributed, Parallel, and Cluster Computing (cs.DC)},FOS: Computer and information sciences,Machine Learning (cs.LG),Neural and Evolutionary Computing (cs.NE)},
  file = {/Users/personal-macbook/Zotero/storage/TGNIQJZF/citation.bib;/Users/personal-macbook/Zotero/storage/XBPRY97D/Krizhevsky - 2014 - One weird trick for parallelizing convolutional ne.pdf;/Users/personal-macbook/Zotero/storage/EMH9GFCP/1404.html}
}

@article{krzywicki_NonContact_2014,
  ids = {krzywicki_Noncontact_2014},
  title = {A {{Non-Contact Technique}} for {{Measuring Eccrine Sweat Gland Activity Using Passive Thermal Imaging}}},
  author = {Krzywicki, Alan T. and Berntson, Gary G. and O'Kane, Barbara L.},
  date = {2014-10},
  journaltitle = {International Journal of Psychophysiology},
  volume = {94},
  number = {1},
  pages = {25--34},
  issn = {01678760},
  doi = {10.1016/j.ijpsycho.2014.06.011},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167876014001482},
  urldate = {2023-05-08},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Eccrine sweat glands,Electrodermal activity,Pore activation index,Pore count,Skin conductance,Thermal imaging},
  annotation = {21 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{kumar_Boosted_2018,
  title = {Boosted {{Cascaded Convnets}} for {{Multilabel Classification}} of {{Thoracic Diseases}} in {{Chest Radiographs}}},
  booktitle = {Image {{Anal}}. {{Recognit}}.},
  author = {Kumar, Pulkit and Grewal, Monika and Srivastava, Muktabh Mayank},
  editor = {Campilho, Aur\'elio and Karray, Fakhri and family=Haar Romeny, given=Bart, prefix=ter, useprefix=true},
  date = {2018},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {546--552},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-93000-8_62},
  abstract = {Chest X-ray is one of the most accessible medical imaging technique for diagnosis of multiple diseases. With the availability of ChestX-ray14, which is a massive dataset of chest X-ray images and provides annotations for 14 thoracic diseases; it is possible to train Deep Convolutional Neural Networks (DCNN) to build Computer Aided Diagnosis (CAD) systems. In this work, we experiment a set of deep learning models and present a cascaded deep neural network that can diagnose all 14 pathologies better than the baseline and is competitive with other published methods. Our work provides the quantitative results to answer following research questions for the dataset: (1) What loss functions to use for training DCNN from scratch on ChestX-ray14 dataset that demonstrates high class imbalance and label co occurrence? (2) How to use cascading to model label dependency and to improve accuracy of the deep learning model?},
  isbn = {978-3-319-93000-8},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Boosted Cascade,Model Label Dependencies,Multilabel Classification,Thoracic Disease,Training DCNN},
  annotation = {93 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/EXDAKPCH/Kumar et al. - 2018 - Boosted Cascaded Convnets for Multilabel Classific.pdf}
}

@article{kumar_Direct_2015,
  title = {Direct {{Diffusion-Based Parcellation}} of the {{Human Thalamus}}},
  author = {Kumar, Vinod and Mang, Sarah and Grodd, Wolfgang},
  date = {2015-05},
  journaltitle = {Brain Struct. Funct.},
  volume = {220},
  number = {3},
  pages = {1619--1635},
  publisher = {{Springer Verlag}},
  issn = {18632661},
  doi = {10.1007/s00429-014-0748-2},
  abstract = {To assess stable anatomical features of the human thalamus, an unbiased diffusion tensor parcellation approach was used to segment thalamic substructures with similar spatial orientation. We determined localization, size and individual variations of 21 thalamic clusters in a group of 63 healthy human subjects (32 males/31 females). The laterality differences accounted for {$\pm$}6 \% and gender differences for {$\pm$}4 \% of the thalamic volume. Consecutively, five stable clusters in the anterior, medial, lateral and posterior thalamus were selected, which were common to 90 \% of all subjects and contained at least 10 voxels. These clusters could be assigned to the anteroventral nucleus (AN) group, the mediodorsal (MD) nucleus, the medial pulvinar (PuM), and the lateral nuclei group. The subcortical and cortical connectivity of these clusters revealed that: (1) the oblique cranio-caudal-oriented fibers of the AN cluster mainly connect to limbic structures, (2) the numerous dorso-frontal-oriented fibers of MD mainly project to the prefrontal cortex and the medial temporal lobe, (3) the fibers of the PuM running in parallel with the x-axis project to medio-occipital and medio-temporal areas and connect visual areas with the hippocampus and amygdala and via intrathalamic pathways with medio-frontal areas, and (4) the oblique caudo-cranial fibers of the two lateral clusters located anteriorly in the motor and posteriorly in the sensory thalamus are routing sensory\textendash motor information from the brain stem via the internal capsule to pre- and peri-central regions of the cortex.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Anatomy,Connectivity,Diffusion tensor imaging,Gender,Laterality,Thalamus},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{kumar_Functional_2017,
  title = {Functional {{Anatomy}} of the {{Human Thalamus}} at {{Rest}}},
  author = {Kumar, Vinod Jangir and family=Oort, given=Erik, prefix=van, useprefix=false and Scheffler, Klaus and Beckmann, Christian F. and Grodd, Wolfgang},
  date = {2017-02},
  journaltitle = {Neuroimage},
  volume = {147},
  pages = {678--691},
  doi = {10.1016/j.neuroimage.2016.12.071},
  abstract = {In the present work, we used resting state-fMRI to investigate the functional anatomy of the thalamus at rest by applying an Independent Component Analysis to delineate thalamic substructures into stable and reproducible parcels for the left and right thalamus. We determined 15 functionally distinct thalamic parcels, which differed in laterality and size but exhibited a correspondence with 18 cytoarchitectonally defined nuclei. We characterized their structural connectivity in determining DWI based cortical fiber pathways and found selected projections to different cortical areas. In contrast, the functional connections of these parcels were not confined to certain cortical areas or lobes. We, finally evaluated cortical projections and found particular subcortical and cortical pattern for each parcel, which partly exhibited a correspondence with the thalamo-cortical connectivity maps of the mouse.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Cortical connectivity,Diffusion imaging,Histolog},
  annotation = {51 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{kumar_Semisupervised_2017,
  title = {Semi-{{Supervised Learning With GANs}}: {{Manifold Invariance With Improved Inference}}},
  booktitle = {Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.},
  author = {Kumar, Abhishek and Sattigeri, Prasanna and Fletcher, P. Thomas},
  date = {2017},
  issn = {10495258},
  abstract = {Semi-supervised learning methods using Generative adversarial networks (GANs) have shown promising empirical success recently. Most of these methods use a shared discriminator/classifier which discriminates real examples from fake while also predicting the class label. Motivated by the ability of the GANs generator to capture the data manifold well, we propose to estimate the tangent space to the data manifold using GANs and employ it to inject invariances into the classifier. In the process, we propose enhancements over existing methods for learning the inverse mapping (i.e., the encoder) which greatly improves in terms of semantic similarity of the reconstructed sample with the input sample. We observe considerable empirical gains in semi-supervised learning over baselines, particularly in the cases when the number of labeled examples is low. We also provide insights into how fake examples influence the semi-supervised learning procedure.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{kumari_Functional_2010,
  ids = {kumari_Functional_2008},
  title = {Functional {{MRI}} of {{Verbal Self-Monitoring}} in {{Schizophrenia}}: {{Performance}} and {{Illness-Specific Effects}}},
  author = {Kumari, Veena and Fannon, Dominic and Ffytche, Dominic H. and Raveendran, Vinodkumar and Antonova, Elena and Premkumar, Preethi and Cooke, Michael A. and Anilkumar, Ananatha P. P. and Williams, Steven C. R. and Andrew, Christopher and Johns, Louise C. and Fu, Cynthia H. Y. and McGuire, Philip K. and Kuipers, Elizabeth},
  date = {2010-07},
  journaltitle = {Schizophr. Bull.},
  volume = {36},
  number = {4},
  pages = {740--755},
  doi = {10.1093/schbul/sbn148},
  abstract = {Previous small-sample studies have shown altered frontotemporal activity in schizophrenia patients with auditory hallucinations and impaired monitoring of self-generated speech. We examined a large cohort of patients with schizophrenia (n = 63) and a representative group of healthy controls (n = 20) to disentangle performance, illness, and symptom-related effects in functional magnetic resonance imaging-detected brain abnormalities during monitoring of self- and externally generated speech in schizophrenia. Our results revealed activation of the thalamus (medial geniculate nucleus, MGN) and frontotemporal regions with accurate monitoring across all participants. Less activation of the thalamus (MGN, pulvinar) and superior-middle temporal and inferior frontal gyri occurred in poorly performing patients (1 standard deviation below controls' mean; n = 36), relative to the combined group of controls and well-performing patients. In patients, (1) greater deactivation of the ventral striatum and hypothalamus to own voice, combined with nonsignificant activation of the same regions to others' voice, associated positively with negative symptoms (blunted affect, emotional withdrawal, poor rapport, passive social avoidance) regardless of performance and (2) exaggerated activation of the right superior-middle temporal gyrus during undistorted, relative to distorted, feedback associated with both positive symptoms (hallucinations, persecution) and poor performance. A further thalamic abnormality characterized schizophrenia patients regardless of performance and symptoms. We conclude that hypoactivation of a neural network comprised of the thalamus and frontotemporal regions underlies impaired speech monitoring in schizophrenia. Positive symptoms and poor monitoring share a common activation abnormality in the right superior temporal gyrus during processing of degraded speech. Altered striatal and hypothalamic modulation to own and others' voice characterizes emotionally withdrawn and socially avoidant patients.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {68 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@thesis{kumbier_Domaininspired_2019,
  title = {Domain-{{Inspired Machine Learning}} for {{Hypothesis Extraction}} in {{Biological Data}}},
  author = {Kumbier, Karl},
  date = {2019},
  journaltitle = {Berkeley},
  institution = {{Berkeley}},
  abstract = {Rapidly moving technologies are transforming the rate at which researchers accumu- late information. Large, rich datasets hold promises of new insights into complex natural phenomena that will help advance the frontier of science. Here we aim to develop new statis- tics/data science principles and scalable algorithms for extracting reliable and reproducible information from these data. Chapter 1 provides an overview of the work contained in this thesis. It discusses the growing availability of genomic data and the statistical machine learning tools that are being used to provide a systems-level understanding of genomic phenomena. Chapter 2 introduces the predictability, computability, and stability (PCS) framework. The PCS framework builds on key ideas in machine learning, using predictability as a real- ity check and evaluating computational considerations in data collection, data storage and algorithm design. It augments predictability and computability with an overarching sta- bility principle, which expands statistical uncertainty considerations to assesses how results vary with respect to choices (or perturbations) made across the data science life cycle. In this chapter, we develop PCS inference through perturbation intervals and PCS hypothe- sis testing to investigate the reliability of data results. We compare PCS inference with existing methods in high-dimensional sparse linear model simulations to demonstrate that our approach compares favorably to others, in terms of ROC curves, over a wide range of simulation settings. Finally, we propose documentation based on R Markdown, iPython, or Jupyter Notebook, with publicly available, reproducible codes and narratives to justify human choices made throughout an analysis. As an example of the PCS framework in practice, chapter 3 develops the iterative Ran- dom Forest algorithm (iRF). iRF trains a feature-weighted ensemble of decision trees to detect stable, high-order interactions with same order of computational cost as Random Forests (RF). We demonstrate the utility of iRF for high-order interaction discovery in two prediction problems: enhancer activity in the early Drosophila embryo and alternative splicing of primary transcripts in human derived cell lines. In Drosophila, 80\% of the pair- wise transcription factor interactions iRF identified as stable have been previously reported as physical interactions. Moreover, novel third-order interactions, e.g. between Zelda (Zld), Giant (Gt), and Twist (Twi), suggest high-order relationships that are candidates for follow- up experiments. In human-derived cells, iRF re-discovered a central role of H3K36me3 in chromatin-mediated splicing regulation, and identified novel 5th and 6th order interactions, indicative of multi-valent nucleosomes with specific roles in splicing regulation. By decou- pling the order of interactions from the computational cost of identification, iRF opens new avenues of inquiry into the molecular mechanisms underlying genome biology. Chapter 4 refines iRF to explicitly map responses as a function of interacting features. Our proposed method, signed iRF (siRF), describes ``subsets'' of rules that frequently occur on RF decision paths. We refer to these rule subsets as signed interactions. RF decision paths containing the same signed interaction share not only a set of interacting features but also exhibit similar thresholding behavior, and thus describe a consistent functional re- lationship between interacting features and responses. We formulate stable and predictive importance metrics (SPIMs) to rank signed interactions in terms of their stability, predictive accuracy, and strength of interaction. For each SPIM, we define null importance metrics that characterize its expected behavior under known structure. We evaluate siRF in bio- logically inspired simulations and two case studies: predicting enhancer activity and spatial gene expression patterns. In the case of spatial gene expression patterns, siRF recovered all 11 reported links in the gap gene network. In the case of enhancer activity, siRF discovered rules that identify enhancer elements in Drosophila embryos with high precision, suggesting candidate biological mechanisms for experimental studies. By refining the process of interac- tion discovery, siRF has the potential to guide mechanistic inquiry into systems whose scale and complexity is beyond human comprehension.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{kunde_Recommending_2020,
  title = {Recommending in {{Changing Times}}},
  booktitle = {Fourteenth {{ACM Conf}}. {{Recomm}}. {{Syst}}.},
  author = {Kunde, Shruti and Mishra, Mayank and Pandit, Amey and Singhal, Rekha and Nambiar, Manoj Karunakaran and Shroff, Gautam and Gupta, Shashank},
  date = {2020-09-22},
  pages = {714--719},
  publisher = {{ACM}},
  location = {{Virtual Event Brazil}},
  doi = {10.1145/3383313.3418492},
  url = {https://dl.acm.org/doi/10.1145/3383313.3418492},
  urldate = {2022-12-28},
  eventtitle = {{{RecSys}} '20: {{Fourteenth ACM Conference}} on {{Recommender Systems}}},
  isbn = {978-1-4503-7583-2},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Automated Data Labeling,Labeled Data Threshold,Machine Learning,Supervised Learning},
  annotation = {0 citations (Semantic Scholar/DOI) [2022-12-28]},
  file = {/Users/personal-macbook/Zotero/storage/GEYF8J43/Kunde et al. - 2020 - Recommending in changing times.pdf}
}

@article{kurve_MultiCategory_2015,
  title = {Multi-{{Category Crowdsourcing Accounting}} for {{Variable Task Difficulty}}, {{Worker Skill}}, and {{Worker Intention}}},
  author = {Kurve, Aditya and Miller, David J. and Kesidis, George},
  date = {2015-03-01},
  journaltitle = {IEEE Trans. Knowl. Data Eng.},
  volume = {27},
  number = {3},
  pages = {794--809},
  issn = {1041-4347},
  doi = {10.1109/TKDE.2014.2327026},
  url = {http://ieeexplore.ieee.org/document/6823710/},
  urldate = {2022-12-28},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Accuracy,Aggregates,Computational modeling,Crowdsourcing,Data models,ensemble classification,expectation-maximization,inference,multicategory,Probes,Stochastic processes},
  annotation = {43 citations (Semantic Scholar/DOI) [2022-12-28]}
}

@article{kushibar_Automated_2018,
  title = {Automated {{Sub-Cortical Brain Structure Segmentation Combining Spatial}} and {{Deep Convolutional Features}}},
  author = {Kushibar, Kaisar and Valverde, Sergi and Gonz\'alez-Vill\`a, Sandra and Bernal, Jose and Cabezas, Mariano and Oliver, Arnau and Llad\'o, Xavier},
  date = {2018-08},
  journaltitle = {Med. Image Anal.},
  volume = {48},
  pages = {177--186},
  doi = {10.1016/j.media.2018.06.006},
  abstract = {Sub-cortical brain structure segmentation in Magnetic Resonance Images (MRI) has attracted the interest of the research community for a long time as morphological changes in these structures are related to different neurodegenerative disorders. However, manual segmentation of these structures can be tedious and prone to variability, highlighting the need for robust automated segmentation methods. In this paper, we present a novel convolutional neural network based approach for accurate segmentation of the sub-cortical brain structures that combines both convolutional and prior spatial features for improving the segmentation accuracy. In order to increase the accuracy of the automated segmentation, we propose to train the network using a restricted sample selection to force the network to learn the most difficult parts of the structures. We evaluate the accuracy of the proposed method on the public MICCAI 2012 challenge and IBSR 18 datasets, comparing it with different traditional and deep learning state-of-the-art methods. On the MICCAI 2012 dataset, our method shows an excellent performance comparable to the best participant strategy on the challenge, while performing significantly better than state-of-the-art techniques such as FreeSurfer and FIRST. On the IBSR 18 dataset, our method also exhibits a significant increase in the performance with respect to not only FreeSurfer and FIRST, but also comparable or better results than other recent deep learning approaches. Moreover, our experiments show that both the addition of the spatial priors and the restricted sampling strategy have a significant effect on the accuracy of the proposed method. In order to encourage the reproducibility and the use of the proposed method, a public version of our approach is available to download for the neuroimaging community.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Brain,Convolutional neural networks,MRI,Segment,Segmentation,Sub-cortical structures},
  annotation = {87 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{kustner_MachineLearning_2018,
  title = {A {{Machine-Learning Framework}} for {{Automatic Reference-Free Quality Assessment}} in {{Mri}}},
  author = {K\"ustner, T. and Gatidis, S. and Liebgott, A. and Schwartz, M. and Mauch, L. and Martirosian, P. and Schmidt, H. and family=Schwenzer, given=Nf., given-i={{Nf}} and Nikolaou, K. and Bamberg, F. and Yang, B. and Schick, F.},
  date = {2018-11},
  journaltitle = {Magnetic Resonance Imaging},
  volume = {53},
  pages = {134--147},
  issn = {0730725X},
  doi = {10.1016/j.mri.2018.07.003},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0730725X18302893},
  urldate = {2023-05-08},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {41 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/SFWHRYSY/Küstner et al. - 2018 - A machine-learning framework for automatic referen.pdf}
}

@thesis{kuusisto_Machine_2015,
  title = {Machine {{Learning}} for {{Medical Decision Support}} and {{Individualized Treatment Assignment}}},
  author = {Kuusisto, by Finn C.},
  date = {2015},
  journaltitle = {Wisconsin \textendash{} Madison},
  volume = {151},
  number = {2005},
  institution = {{Wisconsin \textendash{} Madison}},
  doi = {10.1145/3132847.3132886},
  isbn = {9781450349185},
  pagetotal = {10-17},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{laine_Temporal_2017,
  title = {Temporal {{Ensembling}} for {{Semi-Supervised Learning}}},
  booktitle = {5th {{Int}}. {{Conf}}. {{Learn}}. {{Represent}}. {{ICLR}} 2017 - {{Conf}}. {{Track Proc}}.},
  author = {Laine, Samuli and Aila, Timo},
  date = {2017},
  abstract = {In this paper, we present a simple and efficient method for training deep neural networks in a semi-supervised setting where only a small portion of training data is labeled. We introduce self-ensembling, where we form a consensus prediction of the unknown labels using the outputs of the network-in-training on different epochs, and most importantly, under different regularization and input augmentation conditions. This ensemble prediction can be expected to be a better predictor for the unknown labels than the output of the network at the most recent training epoch, and can thus be used as a target for training. Using our method, we set new records for two standard semi-supervised learning benchmarks, reducing the (non-augmented) classification error rate from 18.44\% to 7.05\% in SVHN with 500 labels and from 18.63\% to 16.55\% in CIFAR-10 with 4000 labels, and further to 5.12\% and 12.16\% by enabling the standard augmentations. We additionally obtain a clear improvement in CIFAR-100 classification accuracy by using random images from the Tiny Images dataset as unlabeled extra inputs during training. Finally, we demonstrate good tolerance to incorrect labels.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{lakhani_Deep_2017,
  title = {Deep {{Learning}} at {{Chest Radiography}}: {{Automated Classification}} of {{Pulmonary Tuberculosis}} by {{Using Convolutional Neural Networks}}},
  shorttitle = {Deep {{Learning}} at {{Chest Radiography}}},
  author = {Lakhani, Paras and Sundaram, Baskaran},
  date = {2017-08},
  journaltitle = {Radiology},
  volume = {284},
  number = {2},
  pages = {574--582},
  publisher = {{Radiological Society of North America}},
  issn = {0033-8419},
  doi = {10.1148/radiol.2017162326},
  url = {https://pubs.rsna.org/doi/abs/10.1148/radiol.2017162326},
  urldate = {2022-11-21},
  abstract = {Purpose To evaluate the efficacy of deep convolutional neural networks (DCNNs) for detecting tuberculosis (TB) on chest radiographs. Materials and Methods Four deidentified HIPAA-compliant datasets were used in this study that were exempted from review by the institutional review board, which consisted of 1007 posteroanterior chest radiographs. The datasets were split into training (68.0\%), validation (17.1\%), and test (14.9\%). Two different DCNNs, AlexNet and GoogLeNet, were used to classify the images as having manifestations of pulmonary TB or as healthy. Both untrained and pretrained networks on ImageNet were used, and augmentation with multiple preprocessing techniques. Ensembles were performed on the best-performing algorithms. For cases where the classifiers were in disagreement, an independent board-certified cardiothoracic radiologist blindly interpreted the images to evaluate a potential radiologist-augmented workflow. Receiver operating characteristic curves and areas under the curve (AUCs) were used to assess model performance by using the DeLong method for statistical comparison of receiver operating characteristic curves. Results The best-performing classifier had an AUC of 0.99, which was an ensemble of the AlexNet and GoogLeNet DCNNs. The AUCs of the pretrained models were greater than that of the untrained models (P {$<$} .001). Augmenting the dataset further increased accuracy (P values for AlexNet and GoogLeNet were .03 and .02, respectively). The DCNNs had disagreement in 13 of the 150 test cases, which were blindly reviewed by a cardiothoracic radiologist, who correctly interpreted all 13 cases (100\%). This radiologist-augmented approach resulted in a sensitivity of 97.3\% and specificity 100\%. Conclusion Deep learning with DCNNs can accurately classify TB at chest radiography with an AUC of 0.99. A radiologist-augmented approach for cases where there was disagreement among the classifiers further improved accuracy. \textcopyright{} RSNA, 2017},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {1179 citations (Semantic Scholar/DOI) [2023-05-08] 901 citations (Crossref) [2022-11-20]}
}

@inproceedings{lakkaraju_Bayesian_2015,
  title = {A {{Bayesian Framework}} for {{Modeling Human Evaluations}}},
  booktitle = {Proc. 2015 {{SIAM Int}}. {{Conf}}. {{Data Min}}.},
  author = {Lakkaraju, Himabindu and Leskovec, Jure and Kleinberg, Jon and Mullainathan, Sendhil},
  date = {2015-06-30},
  pages = {181--189},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9781611974010.21},
  url = {https://epubs.siam.org/doi/10.1137/1.9781611974010.21},
  urldate = {2023-05-08},
  eventtitle = {Proceedings of the 2015 {{SIAM International Conference}} on {{Data Mining}} ({{SDM}})},
  isbn = {978-1-61197-401-0},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {21 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/5M28SMGE/Lakkaraju et al. - 2015 - A Bayesian Framework for Modeling Human Evaluation.pdf}
}

@inproceedings{lakkaraju_Confusions_2016,
  title = {Confusions {{Over Time}}: {{An Interpretable Bayesian Model}} to {{Characterize Trends}} in {{Decision Making}}},
  booktitle = {Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.},
  author = {Lakkaraju, Himabindu and Leskovec, Jure},
  date = {2016},
  issn = {10495258},
  abstract = {We propose Confusions over Time (CoT), a novel generative framework which facilitates a multi-granular analysis of the decision making process. The CoT not only models the confusions or error properties of individual decision makers and their evolution over time, but also allows us to obtain diagnostic insights into the collective decision making process in an interpretable manner. To this end, the CoT models the confusions of the decision makers and their evolution over time via time-dependent confusion matrices. Interpretable insights are obtained by grouping similar decision makers (and items being judged) into clusters and representing each such cluster with an appropriate prototype and identifying the most important features characterizing the cluster via a subspace feature indicator vector. Experimentation with real world data on bail decisions, asthma treatments, and insurance policy approval decisions demonstrates that CoT can accurately model and explain the confusions of decision makers and their evolution over time.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@thesis{lakkaraju_HumanCentric_2018,
  title = {Human-{{Centric Machine Learning}}: {{Enabling Machine Learning}} for {{High-Stakes Decision-Making}}},
  author = {Lakkaraju, Himabindu},
  date = {2018},
  journaltitle = {Stanford},
  institution = {{STANFORD}},
  issue = {December},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {Backup Publisher: STANFORD}
}

@inproceedings{lakkaraju_Interpretable_2016,
  title = {Interpretable {{Decision Sets}}: {{A Joint Framework}} for {{Description}} and {{Prediction}}},
  shorttitle = {Interpretable {{Decision Sets}}},
  booktitle = {Proc. 22nd {{ACM SIGKDD Int}}. {{Conf}}. {{Knowl}}. {{Discov}}. {{Data Min}}.},
  author = {Lakkaraju, Himabindu and Bach, Stephen H. and Leskovec, Jure},
  date = {2016-08-13},
  pages = {1675--1684},
  publisher = {{ACM}},
  location = {{San Francisco California USA}},
  doi = {10.1145/2939672.2939874},
  url = {https://dl.acm.org/doi/10.1145/2939672.2939874},
  urldate = {2023-05-08},
  eventtitle = {{{KDD}} '16: {{The}} 22nd {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  isbn = {978-1-4503-4232-2},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {588 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/QKV7HBJD/Lakkaraju et al. - 2016 - Interpretable Decision Sets A Joint Framework for.pdf}
}

@online{lakkaraju_interpretableexplorableapproximationsblackboxmodels_2017,
  ids = {lakkaraju_Interpretable_,lakkaraju_Interpretable_2017},
  title = {Interpretable \& {{Explorable Approximations}} of {{Black Box Models}}},
  author = {Lakkaraju, Himabindu and Kamar, Ece and Caruana, Rich and Leskovec, Jure},
  date = {2017-07-04},
  eprint = {1707.01154},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {doi.org/10.48550/arXiv.1707.01154},
  url = {http://arxiv.org/abs/1707.01154},
  urldate = {2023-05-08},
  abstract = {We propose Black Box Explanations through Transparent Approximations (BETA), a novel model agnostic framework for explaining the behavior of any black-box classifier by simultaneously optimizing for fidelity to the original model and interpretability of the explanation. To this end, we develop a novel objective function which allows us to learn (with optimality guarantees), a small number of compact decision sets each of which explains the behavior of the black box model in unambiguous, well-defined regions of feature space. Furthermore, our framework also is capable of accepting user input when generating these approximations, thus allowing users to interactively explore how the black-box model behaves in different subspaces that are of interest to the user. To the best of our knowledge, this is the first approach which can produce global explanations of the behavior of any given black box model through joint optimization of unambiguity, fidelity, and interpretability, while also allowing users to explore model behavior based on their preferences. Experimental evaluation with real-world datasets and user studies demonstrates that our approach can generate highly compact, easy-to-understand, yet accurate approximations of various kinds of predictive models compared to state-of-the-art baselines.},
  pubstate = {preprint},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Artificial Intelligence (cs.AI),Computer Science - Artificial Intelligence,FOS: Computer and information sciences},
  annotation = {205 citations (Semantic Scholar/arXiv) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/YU6XA622/Lakkaraju et al. - 2017 - Interpretable & Explorable Approximations of Black.pdf;/Users/personal-macbook/Zotero/storage/9245BL52/1707.html}
}

@inproceedings{lallich_Improving_2002,
  title = {Improving {{Classification}} by {{Removing}} or {{Relabeling Mislabeled Instances}}},
  booktitle = {Lect. {{Notes Comput}}. {{Sci}}. {{Subser}}. {{Lect}}. {{Notes Artif}}. {{Intell}}. {{Lect}}. {{Notes Bioinforma}}.},
  author = {Lallich, St\'ephane and Muhlenbach, Fabrice and Zighed, Djamel A.},
  date = {2002},
  issn = {16113349},
  doi = {10.1007/3-540-48050-1_3},
  abstract = {It is common that a database contains noisy data. An important source of noise consists in mislabeled training instances. We present a new approach that deals with improving classification accuracies in such a case by using a preliminary filtering procedure. An example is suspect when in its neighborhood defined by a geometrical graph the proportion of examples of the same class is not significantly greater than in the whole database. Such suspect examples in the training data can be removed or relabeled. The filtered training set is then provided as input to learning algorithm. Our experiments on ten benchmarks of UCI Machine Learning Repository using 1-NN as the final algorithm show that removing give better results than relabeling. Removing allows maintaining the generalization error rate when we introduce from 0 to 20\% of noise on the class, especially when classes are well separable. \textcopyright{} Springer-Verlag Berlin Heidelberg 2002.},
  isbn = {3-540-43785-1},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {31 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{lan_Modeling_2019,
  title = {Modeling {{Local Geometric Structure}} of {{3D Point Clouds Using Geo-CNN}}},
  booktitle = {2019 {{IEEECVF Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}. {{CVPR}}},
  author = {Lan, Shiyi and Yu, Ruichi and Yu, Gang and Davis, Larry S.},
  date = {2019-06},
  pages = {998--1008},
  publisher = {{IEEE}},
  location = {{Long Beach, CA, USA}},
  doi = {10.1109/CVPR.2019.00109},
  url = {https://ieeexplore.ieee.org/document/8954486/},
  urldate = {2022-07-28},
  abstract = {Recent advances in deep convolutional neural networks (CNNs) have motivated researchers to adapt CNNs to directly model points in 3D point clouds. Modeling local structure has been proven to be important for the success of convolutional architectures, and researchers exploited the modeling of local point sets in the feature extraction hierarchy. However, limited attention has been paid to explicitly model the geometric structure amongst points in a local region. To address this problem, we propose GeoCNN, which applies a generic convolution-like operation dubbed as GeoConv to each point and its local neighborhood. Local geometric relationships among points are captured when extracting edge features between the center and its neighboring points. We first decompose the edge feature extraction process onto three orthogonal bases, and then aggregate the extracted features based on the angles between the edge vector and the bases. This encourages the network to preserve the geometric structure in Euclidean space throughout the feature extraction hierarchy. GeoConv is a generic and efficient operation that can be easily integrated into 3D point cloud analysis pipelines for multiple applications. We evaluate Geo-CNN on ModelNet40 and KITTI and achieve state-of-the-art performance.},
  eventtitle = {2019 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-72813-293-8},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {95 citations (Semantic Scholar/DOI) [2022-08-30]},
  file = {/Users/personal-macbook/Zotero/storage/HEFYK5WH/Lan et al. - 2019 - Modeling Local Geometric Structure of 3D Point Clo.pdf}
}

@article{landis_Measurement_1977,
  title = {The {{Measurement}} of {{Observer Agreement}} for {{Categorical Data}}},
  author = {Landis, J. Richard and Koch, Gary G.},
  date = {1977-03},
  journaltitle = {Biometrics},
  volume = {33},
  number = {1},
  eprint = {2529310},
  eprinttype = {jstor},
  pages = {159},
  issn = {0006341X},
  doi = {10.2307/2529310},
  url = {https://www.jstor.org/stable/2529310?origin=crossref},
  urldate = {2022-12-29},
  keywords = {⛔ No INSPIRE recid found,Humans,Multiple Sclerosis,Statistics as Topic},
  annotation = {9991 citations (Semantic Scholar/DOI) [2022-12-28]}
}

@article{langley_Structured_2022,
  ids = {_Structured_2022},
  title = {Structured {{Uncertainty}} in the {{Observation Space}} of {{Variational Autoencoders}}},
  author = {Langley, James and Monteiro, Miguel and Jones, Charles and Pawlowski, Nick and Glocker, Ben},
  date = {2022-10-30},
  journaltitle = {Trans. Mach. Learn. Res.},
  issn = {2835-8856},
  url = {https://openreview.net/forum?id=cxp7n9q5c4},
  urldate = {2023-05-14},
  abstract = {Variational autoencoders (VAEs) are a popular class of deep generative models with many variants and a wide range of applications. Improvements upon the standard VAE mostly focus on the modelling of the posterior distribution over the latent space and the properties of the neural network decoder. In contrast, improving the model for the observational distribution is rarely considered and typically defaults to a pixel-wise independent categorical or normal distribution. In image synthesis, sampling from such distributions produces spatially-incoherent results with uncorrelated pixel noise, resulting in only the sample mean being somewhat useful as an output prediction. In this paper, we aim to stay true to VAE theory by improving the samples from the observational distribution. We propose SOS-VAE, an alternative model for the observation space, encoding spatial dependencies via a low-rank parameterisation. We demonstrate that this new observational distribution has the ability to capture relevant covariance between pixels, resulting in spatially-coherent samples. In contrast to pixel-wise independent distributions, our samples seem to contain semantically-meaningful variations from the mean allowing the prediction of multiple plausible outputs with a single forward pass.},
  langid = {english},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/3XF29CPZ/2022 - Structured Uncertainty in the Observation Space of.pdf;/Users/personal-macbook/Zotero/storage/WZ5P3CAQ/Langley et al. - 2022 - Structured Uncertainty in the Observation Space of.pdf;/Users/personal-macbook/Zotero/storage/RZZ9LTKT/forum.html}
}

@article{langlotz_RadLex_2006,
  title = {{{RadLex}}: {{A New Method}} for {{Indexing Online Educational Materials}}},
  shorttitle = {{{RadLex}}},
  author = {Langlotz, Curtis P.},
  date = {2006-11},
  journaltitle = {RadioGraphics},
  volume = {26},
  number = {6},
  pages = {1595--1597},
  issn = {0271-5333, 1527-1323},
  doi = {10.1148/rg.266065168},
  url = {http://pubs.rsna.org/doi/10.1148/rg.266065168},
  urldate = {2022-11-21},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {408 citations (Semantic Scholar/DOI) [2022-11-20]}
}

@article{lapin_Analysis_2018,
  title = {Analysis and {{Optimization}} of {{Loss Functions}} for {{Multiclass}}, {{Top-K}}, and {{Multilabel Classification}}},
  author = {Lapin, Maksim and Hein, Matthias and Schiele, Bernt},
  date = {2018-07},
  journaltitle = {IEEE Trans. Pattern Anal. Mach. Intell.},
  volume = {40},
  number = {7},
  eprint = {28920896},
  eprinttype = {pmid},
  pages = {1533--1554},
  publisher = {{IEEE Computer Society}},
  issn = {01628828},
  doi = {10.1109/TPAMI.2017.2751607},
  abstract = {Top-k error is currently a popular performance measure on large scale image classification benchmarks such as ImageNet and Places. Despite its wide acceptance, our understanding of this metric is limited as most of the previous research is focused on its special case, the top-1 error. In this work, we explore two directions that shed more light on the top-k error. First, we provide an in-depth analysis of established and recently proposed single-label multiclass methods along with a detailed account of efficient optimization algorithms for them. Our results indicate that the softmax loss and the smooth multiclass SVM are surprisingly competitive in top-k error uniformly across all k, which can be explained by our analysis of multiclass top-k calibration. Further improvements for a specific k are possible with a number of proposed top-k loss functions. Second, we use the top-k methods to explore the transition from multiclass to multilabel learning. In particular, we find that it is possible to obtain effective multilabel classifiers on Pascal VOC using a single label per image for training, while the gap between multiclass and multilabel methods on MS COCO is more significant. Finally, our contribution of efficient algorithms for training with the considered top-k and multilabel loss functions is of independent interest.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Multiclass classification,multilabel classification,SDCA optimization,top-k calibration,top-k error},
  annotation = {82 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{larsson_Monitoring_2017,
  title = {Monitoring of {{Lung Function}} in {{Acute Respiratory Distress Syndrome}}},
  author = {Larsson, Anders and Guerin, Claude},
  date = {2017},
  journaltitle = {Ann. Transl. Med.},
  issn = {23055847},
  doi = {10.21037/atm.2017.06.56},
  abstract = {Monitoring of lung function is essential to assess changes in the lung condition, and to correct and improve ventilator and adjuvant therapies in acute respiratory distress syndrome (ARDS). In this review we discuss the use of monitoring of gas exchange, lung mechanics and shortly on lung imaging in this condition.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Acute respiratory distress syndrome (ARDS),Gas exchange,Lung imaging,Lung mechanics,Monitering}
}

@article{lasswell_Legal_1943a,
  ids = {lasswell_Legal_1943},
  title = {Legal {{Education}} and {{Public Policy}}: {{Professional Training}} in the {{Public Interest}}},
  shorttitle = {Legal {{Education}} and {{Public Policy}}},
  author = {Lasswell, Harold D. and McDougal, Myres S.},
  date = {1943-03},
  journaltitle = {The Yale Law Journal},
  volume = {52},
  number = {2},
  eprint = {792244},
  eprinttype = {jstor},
  pages = {203},
  issn = {00440094},
  doi = {10.2307/792244},
  url = {https://www.jstor.org/stable/792244?origin=crossref},
  urldate = {2023-05-08},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {10 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/7UM835RY/Lasswell and McDougal - 1943 - Legal Education and Public Policy Professional Tr.pdf}
}

@article{latonero_Governing_2018,
  title = {Governing {{Artificial Intelligence}}: {{Upholding Human Rights}} \& {{Dignity}}. {{Data}} \& {{Society}}},
  author = {Latonero, M.},
  date = {2018},
  journaltitle = {Data Soc.},
  abstract = {Can international human rights help guide and govern artificial intelligence (AI)? Currently, much of society is uncertain about the real human impacts of AI systems. Amid hopes that AI can bring forth "global good" there is evidence that some AI systems are already violating fundamental rights and freedoms. As stakeholders look for a North Star to guide AI development, we can rely on human rights to help chart the course ahead. International human rights are a powerful tool for identifying, preventing , and redressing an important class of risks and harms. A human rights-based frame could provide those developing AI with the aspirational, normative, and legal guidance to uphold human dignity and the inherent worth of every individual regardless of country or jurisdiction. Simply put: In order for AI to benefit the common good, at the very least its design and deployment should avoid harms to fundamental human values. International human rights provide a robust and global formulation of those values. This report is intended as a resource for anyone working in the field of AI and gover-nance. It is also intended for those in the human rights field, outlining why they should be concerned about the present-day impacts of AI. What follows translates between},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{laves_Uncertainty_2021,
  title = {Uncertainty {{Calibration Error}}: {{A New Metric}} for {{Multi-Class Classification}}},
  shorttitle = {Uncertainty {{Calibration Error}}},
  author = {Laves, Max-Heinrich and Ihler, Sontje and Kortmann, Karl-Philipp and Ortmaier, Tobias},
  date = {2021-03-05},
  url = {https://openreview.net/forum?id=XOuAOv_-5Fx},
  urldate = {2022-07-04},
  abstract = {Various metrics have recently been proposed to measure uncertainty calibration of deep models for classification. However, these metrics either fail to capture miscalibration correctly or lack...},
  langid = {english},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/2I4GRIS5/Laves et al. - 2021 - Uncertainty Calibration Error A New Metric for Mu.pdf;/Users/personal-macbook/Zotero/storage/JDUQ6FWT/forum.html}
}

@article{lecun_Backpropagation_1989,
  title = {Backpropagation {{Applied}} to {{Handwritten Zip Code Recognition}}},
  author = {LeCun, Y. and Boser, B. and Denker, J. S. and Henderson, D. and Howard, R. E. and Hubbard, W. and Jackel, L. D.},
  date = {1989-12},
  journaltitle = {Neural Comput.},
  volume = {1},
  number = {4},
  pages = {541--551},
  publisher = {{MIT Press}},
  doi = {10.1162/neco.1989.1.4.541},
  abstract = {The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {9089 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{lecun_deeplearning_2015,
  ids = {lecun15},
  title = {Deep {{Learning}}},
  author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  date = {2015-05-28},
  journaltitle = {Nature},
  volume = {521},
  number = {7553},
  pages = {436--444},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/nature14539},
  url = {https://www.nature.com/articles/nature14539},
  urldate = {2023-06-03},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {9997 citations (Semantic Scholar/DOI) [2023-06-02]}
}

@article{lecun_Tutorial_2006a,
  ids = {lecun_Tutorial_2006},
  title = {A {{Tutorial}} on {{Energy-Based Learning}}},
  author = {LeCun, Yann and Chopra, Sumit and Hadsell, Raia and Ranzato, M. and Huang, Fujie},
  date = {2006},
  journaltitle = {Predict. Struct. Data},
  volume = {1},
  number = {0},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@inproceedings{lee_Convolutional_2009,
  title = {Convolutional {{Deep Belief Networks}} for {{Scalable Unsupervised Learning}} of {{Hierarchical Representations}}},
  booktitle = {Proc. 26th {{Annu}}. {{Int}}. {{Conf}}. {{Mach}}. {{Learn}}.},
  author = {Lee, Honglak and Grosse, Roger and Ranganath, Rajesh and Ng, Andrew Y.},
  date = {2009},
  pages = {609--616},
  publisher = {{ACM}},
  doi = {10.1145/1553374.1553453},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {2646 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{lee_Deep_2011,
  title = {Towards a {{Deep Learning Approach}} to {{Brain Parcellation}}},
  booktitle = {2011 {{IEEE Int}}. {{Symp}}. {{Biomed}}. {{Imaging Nano Macro}}},
  author = {Lee, N. and Laine, A. F. and Klein, A.},
  date = {2011-03},
  pages = {321--324},
  abstract = {Establishing correspondences across structural and functional brain images via labeling, or parcellation, is an important and challenging task for clinical neuroscience and cognitive psychology. A limitation with existing approaches is that they i) possess shallow architectures, ii) are based on heuristic manual feature engineering, and iii) assume the validity of the designed feature model. In contrast, we advocate a deep learning approach to automate brain parcellation. We present a novel application of convolutional networks to build discriminative features for brain parcellation, which are automatically learned from labels provided by human experts. Initial validation experiments show promising results for automatic brain parcellation, suggesting that the proposed approach has potential to be an alternative to template or atlas-based parcellation approaches.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,brain,cognition,feature extraction,heuristic progr}
}

@article{lee_Lateral_2016,
  title = {Lateral {{Geniculate Atrophy}} in {{Parkinson}}'s {{With Visual Hallucination}}: {{A Trans-Synaptic Degeneration}}?},
  author = {Lee, Jee-Young and Yoon, Eun Jin and Lee, Woong Woo and Kim, Yu Kyeong and Lee, Jun-Young and Jeon, Beomseok},
  date = {2016-04},
  journaltitle = {Mov. Disord.},
  volume = {31},
  number = {4},
  pages = {547--554},
  doi = {10.1002/mds.26533},
  abstract = {INTRODUCTION: Defective visual information processing contributes to visual hallucination in PD, for which ``top-down'' and ``bottom-up'' impairment are suggested mechanisms. This study was aimed to investigate macro- and microstructural neural changes in afferent visual pathways in relation to visual hallucination in nondemented PD patients. METHODS: This study included 24 nondemented, nondepressed PD patients (10 hallucinating and 14 nonhallucinating) and 15 age-matched healthy controls. We analyzed volumetric and diffusion tensor MRI data by applying region of interest analyses on the visual pathways, including the optic chiasm, bilateral optic nerves, lateral geniculate bodies, optic radiations, and primary visual cortex. RESULTS: Patients' demographic characteristics, daily medication doses, as well as duration and motor severity of PD were similar in the two PD groups. Compared to PD patients without hallucination, those with hallucination had fractional anisotropy decrease in the left optic nerve and showed atrophy of lateral geniculate bodies, especially in the left side. In addition, the PD with hallucination group had diffusivity increase in the left optic radiation compared to that in the PD without hallucination and healthy control groups. There were no differences in the primary visual cortex volume among the study groups. CONCLUSIONS: We found microstructural alterations in visual pathways in nondemented PD patients with hallucination, mainly in first-order neurons and atrophy in the lateral geniculate body where the retinal ganglion cells synapse to second-order neurons. Afferent visual pathway degeneration may occur in a trans-synaptic way in PD. Further studies warrant to be conducted.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,diffusion tensor analysis,Diffusion tensor analysis,Parkinson's disease,vi,Visual hallucination,Visual pathway,Volumetric analysis},
  annotation = {32 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{lee_Minimax_2018,
  title = {Minimax {{Statistical Learning With Wasserstein Distances}}},
  booktitle = {Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.},
  author = {Lee, Jaeho and Raginsky, Maxim},
  date = {2018},
  issn = {10495258},
  abstract = {As opposed to standard empirical risk minimization (ERM), distributionally robust optimization aims to minimize the worst-case risk over a larger ambiguity set containing the original empirical distribution of the training data. In this work, we describe a minimax framework for statistical learning with ambiguity sets given by balls in Wasserstein space. In particular, we prove generalization bounds that involve the covering number properties of the original ERM problem. As an illustrative example, we provide generalization guarantees for transport-based domain adaptation problems where the Wasserstein distance between the source and target domain distributions can be reliably estimated from unlabeled samples.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{leemput_Automated_1999,
  title = {Automated {{Model-Based Tissue Classification}} of {{Mr Images}} of the {{Brain}}},
  author = {Leemput, K. Van and Maes, F. and Vandermeulen, D. and Suetens, P.},
  date = {1999-10},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {18},
  number = {10},
  pages = {897--908},
  doi = {10.1109/42.811270},
  abstract = {We describe a fully automated method for model-based tissue classification of magnetic resonance (MR) images of the brain. The method interleaves classification with estimation of the model parameters, improving the classification at each iteration. The algorithm is able to segment single- and multispectral MR images, corrects for MR signal inhomogeneities, and incorporates contextual information by means of Markov random Fields (MRF's). A digital brain atlas containing prior expectations about the spatial location of tissue classes is used to initialize the algorithm. This makes the method fully automated and therefore it provides objective and reproducible segmentations. We have validated the technique on simulated as well as on real MR images of the brain.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {1131 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{leemput_Automated_2009,
  title = {Automated {{Segmentation}} of {{Hippocampal Subfields From Ultra-High Resolution}} in {{Vivo Mri}}},
  author = {Leemput, Koen Van and Bakkour, Akram and Benner, Thomas and Wiggins, Graham and Wald, Lawrence L. and Augustinack, Jean and Dickerson, Bradford C. and Golland, Polina and Fischl, Bruce},
  date = {2009-06},
  journaltitle = {Hippocampus},
  volume = {19},
  number = {6},
  pages = {549--557},
  doi = {10.1002/hipo.20615},
  abstract = {Recent developments in MRI data acquisition technology are starting to yield images that show anatomical features of the hippocampal formation at an unprecedented level of detail, providing the basis for hippocampal subfield measurement. However, a fundamental bottleneck in MRI studies of the hippocampus at the subfield level is that they currently depend on manual segmentation, a laborious process that severely limits the amount of data that can be analyzed. In this article, we present a computational method for segmenting the hippocampal subfields in ultra-high resolution MRI data in a fully automated fashion. Using Bayesian inference, we use a statistical model of image formation around the hippocampal area to obtain automated segmentations. We validate the proposed technique by comparing its segmentations to corresponding manual delineations in ultra-high resolution MRI scans of 10 individuals, and show that automated volume measurements of the larger subfields correlate well with manual volume estimates. Unlike manual segmentations, our automated technique is fully reproducible, and fast enough to enable routine analysis of the hippocampal subfields in large imaging studies.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {394 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{leemput_Encoding_2009,
  title = {Encoding {{Probabilistic Brain Atlases Using Bayesian Inference}}},
  author = {Van Leemput, K.},
  date = {2009-06},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {28},
  number = {6},
  pages = {822--837},
  issn = {0278-0062, 1558-254X},
  doi = {10.1109/TMI.2008.2010434},
  url = {http://ieeexplore.ieee.org/document/4695995/},
  urldate = {2023-05-28},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Atlas formation,Bayesian inference,Brain modeling,Computational anatomy,Image registration,Mesh generation,Model comparison},
  annotation = {83 citations (Semantic Scholar/DOI) [2023-05-28]},
  file = {/Users/personal-macbook/Zotero/storage/BGFIEW8I/Van Leemput - 2009 - Encoding Probabilistic Brain Atlases Using Bayesia.pdf}
}

@article{lefkowitz_Identification_1975,
  title = {Identification of {{Adenylate Cyclase-Coupled Beta-Adrenergic Receptors With Radiolabeled Beta-Adrenergic Antagonists}}},
  author = {Lefkowitz, Robert J.},
  date = {1975-09},
  journaltitle = {Biochemical Pharmacology},
  volume = {24},
  number = {18},
  pages = {1651--1658},
  issn = {00062952},
  doi = {10.1016/0006-2952(75)90001-5},
  url = {https://linkinghub.elsevier.com/retrieve/pii/0006295275900015},
  urldate = {2022-12-29},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Adenylyl Cyclases,Adrenergic beta-Antagonists,Alprenolol,Animals,Anura,Binding Sites,Catecholamines,Cattle,Cell Membrane,Eels,Erythrocytes,Guinea Pigs,In Vitro Techniques,Isoproterenol,Kinetics,Propranolol,{Receptors, Adrenergic},Stereoisomerism,Tritium},
  annotation = {57 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{lei_Feature_2012,
  title = {Feature {{Extraction Using Orthogonal Discriminant Local Tangent Space Alignment}}},
  author = {Lei, Ying-Ke and Xu, Yang-Ming and Yang, Jun-An and Ding, Zhi-Guo and Gui, Jie},
  date = {2012-08-01},
  journaltitle = {Pattern Anal Applic},
  volume = {15},
  number = {3},
  pages = {249--259},
  issn = {1433-755X},
  doi = {10.1007/s10044-011-0231-0},
  url = {https://doi.org/10.1007/s10044-011-0231-0},
  urldate = {2021-11-16},
  abstract = {A novel algorithm called orthogonal discriminant local tangent space alignment (O-DLTSA) is proposed for supervised feature extraction. Derived from local tangent space alignment (LTSA), O-DLTSA not only inherits the advantages of LTSA which uses local tangent space as a representation of the local geometry so as to preserve the local structure, but also makes full use of class information and orthogonal subspace to improve discriminant power. The experimental results of applying O-DLTSA to standard face databases demonstrate the effectiveness of the proposed method.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {13 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/E7Y3IUM7/Lei et al. - 2012 - Feature Extraction Using Orthogonal Discriminant L.pdf}
}

@article{leibig_Leveraging_2017,
  title = {Leveraging {{Uncertainty Information From Deep Neural Networks}} for {{Disease Detection}}},
  author = {Leibig, Christian and Allken, Vaneeda and Ayhan, Murat Se\c{c}kin and Berens, Philipp and Wahl, Siegfried},
  date = {2017},
  journaltitle = {Sci. Rep.},
  eprint = {29259224},
  eprinttype = {pmid},
  issn = {20452322},
  doi = {10.1038/s41598-017-17876-z},
  abstract = {Deep learning (DL) has revolutionized the field of computer vision and image processing. In medical imaging, algorithmic solutions based on DL have been shown to achieve high performance on tasks that previously required medical experts. However, DL-based solutions for disease detection have been proposed without methods to quantify and control their uncertainty in a decision. In contrast, a physician knows whether she is uncertain about a case and will consult more experienced colleagues if needed. Here we evaluate drop-out based Bayesian uncertainty measures for DL in diagnosing diabetic retinopathy (DR) from fundus images and show that it captures uncertainty better than straightforward alternatives. Furthermore, we show that uncertainty informed decision referral can improve diagnostic performance. Experiments across different networks, tasks and datasets show robust generalization. Depending on network capacity and task/dataset difficulty, we surpass 85\% sensitivity and 80\% specificity as recommended by the NHS when referring 0-20\% of the most uncertain decisions for further inspection. We analyse causes of uncertainty by relating intuitions from 2D visualizations to the high-dimensional image space. While uncertainty is sensitive to clinically relevant cases, sensitivity to unfamiliar data samples is task dependent, but can be rendered more robust.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {382 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{lemaire_Anatomy_2010,
  title = {Anatomy of the {{Human Thalamus Based}} on {{Spontaneous Contrast}} and {{Microscopic Voxels}} in {{High-Field Magnetic Resonance Imaging}}},
  author = {Lemaire, Jean-Jacques and Sakka, Laurent and Ouchchane, Lemlih and Caire, Fran\c{c}ois and Gabrillargues, Jean and Bonny, Jean-Marie},
  date = {2010-03},
  journaltitle = {Neurosurgery},
  volume = {66},
  pages = {161--172},
  abstract = {BACKGROUND: Since the pioneering studies of human thalamic anatomy based on histology and binding techniques, little new work has been done to bring this knowledge into clinical practice. OBJECTIVE: With the advent of magnetic resonance imaging (MRI) we hypothesized that it was possible, in vitro, to make use of high spontaneous MRI contrasts between white and grey matter to directly identify the subcompartmentalisation of the thalamus. METHODS: An anatomic specimen was imaged at high field (4.7 T) (basal ganglia plus thalamus block; 3-dimensional (3D) T1-weighted spin echo sequence; matrix, 256 x 256 x 256; isotropic voxel, 0.250 mm/edge; total acquisition time, 14 hours 30 minutes). Nuclei were manually contoured on the basis of spontaneous contrasted structures; labeling relied on 3D identification from classic knowledge; stereotactic location of centers of nuclei was computed. RESULTS: Almost all intrathalamic substructures, nuclei, and white matter laminae were identified. Using 3D analysis, a simplified classification of intrathalamic nuclei into 9 groups was proposed, based on topographic MRI anatomy, designed for clinical practice: anterior (oral), posterior, dorsal, intermediate, ventral, medial, laminar, superficial, and related (epi and metathalamus). The overall 4.7-T anatomy matches that presented in the atlases of Schaltenbrand and Bailey (1959), Talairach et al (1957), and Morel et al (1997). CONCLUSION: It seems possible to identify the subcompartments of the thalamus by spontaneous MRI contrast, allowing a tissue architectural approach. In addition, the MRI tissue architecture matches the earlier subcompartmentalization based on cyto- and chemoarchitecture. This true 3D anatomic study of the thalamus may be useful in clinical neuroscience and neurosurgical applications.},
  issue = {3 Suppl Operative},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{lepetit_Keypoint_2006,
  title = {Keypoint {{Recognition Using Randomized Trees}}},
  author = {Lepetit, V. and Fua, P.},
  date = {2006-09},
  journaltitle = {IEEE Trans. Pattern Anal. Mach. Intell.},
  volume = {28},
  number = {9},
  pages = {1465--1479},
  issn = {0162-8828, 2160-9292},
  doi = {10.1109/TPAMI.2006.188},
  url = {http://ieeexplore.ieee.org/document/1661548/},
  urldate = {2023-01-11},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {795 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/AUSZF9CH/Lepetit and Fua - 2006 - Keypoint recognition using randomized trees.pdf;/Users/personal-macbook/Zotero/storage/7I9HXB9U/1661548.html}
}

@article{lesca_Protein_1976,
  title = {Protein {{Inhibitor}} of {{Acid Deoxyribonucleases}}. {{Improved Purification Procedure}} and {{Properties}}},
  author = {Lesca, P.},
  date = {1976-01-10},
  journaltitle = {J Biol Chem},
  volume = {251},
  number = {1},
  eprint = {396},
  eprinttype = {pmid},
  pages = {116--123},
  issn = {0021-9258},
  abstract = {A method is described for the extensive purification of acid deoxyribonuclease (acid DNase) and its specific inhibitor from beef liver, the existence of which had been only supported by indirect evidence. By the use of insolubilized acid deoxyribonuclease, eight other proteins interacting with the enzyme have been detected. One of them (molecular weight, 59,000) was identified as responsible for phosphodiesterase activity which is often a contaminant of DNase preparations. Acid DNase (free of phosphodiesterase) and its inhibitor have been obtained as homogeneous proteins, as determined by sodium dodecyl sulfate-polyacrylamide gel electrophoresis. The molecular weight of acid DNase and its inhibitor are, respectively, 26,500 and 21,500; those of other proteins range from 17,000 to 112,000. The properties of beef liver acid DNase are similar to those described for the enzymes extracted from other sources. The same alteration of DNase kinetics by this inhibitor, as that previously demonstrated with an impure protein has been confirmed; the sigmoidal shape observed at pH 5 for the plot of initial rate versus substrate concentration progressively disappears with increasing pH. We have also demonstrated that RNA, which inhibits the acid DNase through a competitive binding to the catalytic site, is able, like the substrate, to reverse the binding of inhibitor to the enzyme.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Animals,Cattle,Deoxyribonucleases,Drug Stability,Enzyme Inhibitors,{Helix, Snails},Hydrogen-Ion Concentration,Hydroxymercuribenzoates,Iodoacetates,Kinetics,Liver,Phosphodiesterase Inhibitors},
  file = {/Users/personal-macbook/Zotero/storage/34KUFCUV/Lesca - 1976 - Protein inhibitor of acid deoxyribonucleases. Impr.pdf;/Users/personal-macbook/Zotero/storage/4KW4T6RH/fulltext.html}
}

@article{lewin_Politically_2001,
  title = {Politically {{Feasible}} and {{Practical Public Policies}} to {{Help Academic Medical Centers}}},
  author = {Lewin, Lawrence S.},
  date = {2001},
  journaltitle = {Future Acad. Med. Cent.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@online{lewis_sequentialalgorithmtrainingtextclassifiers_1994,
  ids = {lewis_Sequential_1994,lewis_Sequential_1994b,lewis_Sequential_1994c,lewis_Sequential_1994d},
  title = {A {{Sequential Algorithm}} for {{Training Text Classifiers}}},
  author = {Lewis, David D. and Gale, William A.},
  date = {1994},
  doi = {10.48550/ARXIV.CMP-LG/9407020},
  url = {https://arxiv.org/abs/cmp-lg/9407020},
  urldate = {2023-05-08},
  abstract = {The ability to cheaply train text classifiers is critical to their use in information retrieval, content analysis, natural language processing, and other tasks involving data which is partly or fully textual. An algorithm for sequential sampling during machine learning of statistical classifiers was developed and tested on a newswire text categorization task. This method, which we call uncertainty sampling, reduced by as much as 500-fold the amount of training data that would have to be manually classified to achieve a given level of effectiveness.},
  pubstate = {preprint},
  version = {2},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found,Computation and Language (cs.CL),Computer Science - Computation and Language,FOS: Computer and information sciences},
  annotation = {2599 citations (Semantic Scholar/arXiv) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/SFN4V2IF/Lewis and Gale - 1994 - A Sequential Algorithm for Training Text Classifie.pdf;/Users/personal-macbook/Zotero/storage/QB33MF3T/9407020.html}
}

@article{li_Acute_2020,
  title = {Acute {{Respiratory Failure}} in {{Covid-19}}: {{Is It}} "{{Typical}}" {{Ards}}?},
  author = {Li, Xu and Ma, Xiaochun},
  date = {2020},
  journaltitle = {Crit. Care Lond. Engl.},
  volume = {24},
  number = {1},
  eprint = {32375845},
  eprinttype = {pmid},
  pages = {198},
  issn = {1466609X},
  doi = {10.1186/s13054-020-02911-9},
  abstract = {In December 2019, an outbreak of coronavirus disease 2019 (COVID-19) was identified in Wuhan, China. The World Health Organization (WHO) declared this outbreak a significant threat to international health. COVID-19 is highly infectious and can lead to fatal comorbidities especially acute respiratory distress syndrome (ARDS). Thus, fully understanding the characteristics of COVID-19-related ARDS is conducive to early identification and precise treatment. We aimed to describe the characteristics of COVID-19-related ARDS and to elucidate the differences from ARDS caused by other factors. COVID-19 mainly affected the respiratory system with minor damage to other organs. Injury to the alveolar epithelial cells was the main cause of COVID-19-related ARDS, and endothelial cells were less damaged with therefore less exudation. The clinical manifestations were relatively mild in some COVID-19 patients, which was inconsistent with the severity of laboratory and imaging findings. The onset time of COVID-19-related ARDS was 8-12 days, which was inconsistent with ARDS Berlin criteria, which defined a 1-week onset limit. Some of these patients might have a relatively normal lung compliance. The severity was redefined into three stages according to its specificity: mild, mild-moderate, and moderate-severe. HFNO can be safe in COVID-19-related ARDS patients, even in some moderate-severe patients. The more likely cause of death is severe respiratory failure. Thus, the timing of invasive mechanical ventilation is very important. The effects of corticosteroids in COVID-19-related ARDS patients were uncertain. We hope to help improve the prognosis of severe cases and reduce the mortality.},
  isbn = {1305402002911},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {467 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@thesis{li_Advances_2019,
  title = {Advances in {{Machine Learning}} : {{Nearest Neighbour Search}} , {{Learning}} to {{Optimize}} and {{Generative Modelling}}},
  author = {Li, Ke},
  date = {2019},
  journaltitle = {Berkeley},
  institution = {{Berkeley}},
  abstract = {Machine learning is the embodiment of an unapologetically data-driven philosophy that has increasingly become one of the most important drivers of progress in artificial intelligence and beyond. Existing machine learning methods, however, entail making trade-offs in terms of computational efficiency, modelling flexibility and/or formulation faithfulness. In this dissertation, we will cover three different ways in which limitations along each axis can be overcome, without compromising on other axes. Computational Efficiency We start with limitations on computational efficiency. Many modern machine learning meth- ods require performing large-scale similarity search under the hood. For example, classifying an input into one of a large number of classes requires comparing the weight vector asso- ciated with each class to the activations of the penultimate layer, attending to particular memory cells of a neural net requires comparing the keys associated with each memory cell to the query, and sparse recovery requires comparing each dictionary element to the residual. Similarity search in many cases can be reduced to nearest neighbour search, which is both a blessing and a curse. On the plus side, the nearest neighbour search problem has been exten- sively studied for more than four decades. On the minus side, no exact algorithm developed over the past four decades can run faster than na\textasciidieresis\i ve exhaustive search when the intrinsic dimensionality is high, which is almost certainly the case in machine learning. Given this state of affairs, should we give up any hope of doing any better than the na\textasciidieresis\i ve approach of exhaustive comparing each element one-by-one? It turns out this pessimism, while tempting, is unwarranted. We introduce a new family of exact randomized algorithms, known as Dynamic Continuous Indexing, which overcomes both the curse of ambient dimensionality and the curse of intrinsic dimensionality: more specifically, DCI simultaneously achieves a query time complexity with a linear dependence on ambient dimensionality, a sublinear dependence on intrinsic dimensionality and a sublinear dependence on dataset size. The key insight is that the curse of intrinsic dimensionality in many cases arises from space partitioning, which is a divide-and-conquer strategy used by most nearest neighbour search algorithms. While space partitioning makes intuitive sense and works well in low dimensions, we argue that it fundamentally fails in high dimensions, because it requires distances between each point and every possible query to be approximately preserved in the data structure. We develop a new indexing scheme that only requires the ordering of nearby points relative to distant points to be approximately preserved, and show that the number of out-of-place points after projecting to just a single dimension is sublinear in the intrinsic dimensionality. In practice, our algorithm achieves a 14-116\texttimes{} speedup and a 21\texttimes{} reduction in memory consumption compared to locality-sensitive hashing (LSH). Modelling Modelling Flexibility Next we move onto probabilistic modelling, which is critical to realizing one of the cen- tral objectives of machine learning, which is to model the uncertainty that is inherent in prediction. The community has wrestled with the problem of how to strike the right bal- ance between modelling flexibility and computational efficiency. Simple models can often be learned straightforwardly and efficiently but are not expressive; complex models are expres- sive, but in general cannot be learned both exactly and efficiently, often because learning requires evaluating some intractable integral. The success of deep learning has motivated the development of probabilistic models that can leverage the inductive bias and modelling power of deep neural nets, such as variational autoencoders (VAEs) and generative adver- sarial nets (GANs), which belong to a subclass of probabilistic models known as implicit probabilistic models. Implicit probabilistic models are defined by a procedure from draw- ing samples from them, rather than an explicit of the probability density function. On the positive side, sampling is always easy by definition; on the negative side, learning is difficult because not even the unnormalized complete likelihood can be expressed analytically. So these models must be learned using likelihood-free methods, but none have been shown to be able to learn the underlying distribution with a finite number of samples. Perhaps the most popular likelihood-free method is the GAN. Unfortunately, GANs suffer from the well-documented issue of mode collapse, where the learned model (generator in the GAN parlance) cannot generate some modes of the true data distribution. We argue this arises from the direction in which generated samples are matched to the real data. Under the GAN objective, each generated sample is made indistinguishable from some data example. Some data examples may not be chosen by any generated sample, resulting in mode collapse. We introduce a new likelihood-free method, known as Implicit Maximum Likelihood Estimation (IMLE) that overcomes mode collapse by inverting the direction - instead of ensuring each generated sample has a similar data example, our method ensures that each data example has a similar generated sample. This can be shown to be equivalent to maximizing a lower bound on the log-likelihood when the model class is richly parameterized and the density is smooth in parameters and data, hence the name. Compared to VAEs, which are not likelihood-free, IMLE eliminates the need for an approx- imate posterior and avoids the bias towards parameters where the true posteriors are less informative, a phenomenon known as ``posterior collapse'' Formulation Faithfulness Finally Finally we introduce a novel formulation that can enable the automatic discovery of new it- erative gradient-based optimization algorithms, which have become the workhorse of modern machine learning. This effectively allows us to apply machine learning to improve machine learning, which has been a dream of machine learning researchers since the early days of the field. The key challenge, however, is that it is unclear how to represent a complex object like an algorithm in a way that is amenable to machine learning. Prior approaches [58] represent algorithms as imperative programs, i.e.: sequences of elementary operations, and therefore induces a search space whose size is exponential in the length of the optimal pro- gram. Searching in this space is unfortunately not tractable for anything but the simplest and shortest algorithms. Other approaches [31] enumerate a small set of manually designed algorithms and search for the best algorithm within this set. Searching in this space is tractable, but the optimal algorithm may lie outside this space. It remains an open question as to how to parameterize the space of possible algorithms in a way that is both complete and efficiently searchable. We get around this issue by observing that an optimization algorithm can be uniquely characterized by its update formula \textendash{} different iterative optimization algorithms only differ in their choice of the update formula. In gradient descent, for example, it is taken to be a scaled negative gradient, whereas in gradient descent with momentum, it is taken to be a scaled exponentially-weighted average of the history of gradients. Therefore, if we can learn the update formula, we can then automatically discover new optimization algorithms. The update formula can be formulated as a mapping from the history of gradients, iterates and objective values to the update step, which can be approximated with a neural net. We can then learn the optimization algorithm by learning the parameters of the neural net.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{li_Compactness_2017,
  title = {On the {{Compactness}}, {{Efficiency}}, and {{Representation}} of {{3D Convolutional Networks}}: {{Brain Parcellation}} as a {{Pretext Task}}},
  booktitle = {Inf. {{Process}}. {{Med}}. {{Imaging}}},
  author = {Li, Wenqi and Wang, Guotai and Fidon, Lucas and Ourselin, Sebastien and Cardoso, M. Jorge and Vercauteren, Tom},
  date = {2017},
  pages = {348--360},
  publisher = {{Springer International Publishing}},
  doi = {10.1007/978-3-319-59050-9_28},
  abstract = {Deep convolutional neural networks are powerful tools for learning visual representations from images. However, designing efficient deep architectures to analyse volumetric medical images remains challenging. This work investigates efficient and flexible elements of modern convolutional networks such as dilated convolution and residual connection. With these essential building blocks, we propose a high-resolution, compact convolutional network for volumetric image segmentation. To illustrate its efficiency of learning 3D representation from large-scale image data, the proposed network is validated with the challenging task of parcellating 155 neuroanatomical structures from brain MR images. Our experiments show that the proposed network architecture compares favourably with state-of-the-art volumetric segmentation networks while being an order of magnitude more compact. We consider the brain parcellation task as a pretext task for volumetric image segmentation; our trained network potentially provides a good starting point for transfer learning. Additionally, we show the feasibility of voxel-level uncertainty estimation using a sampling approximation through dropout.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{li_ConfidenceAware_2014,
  title = {A {{Confidence-Aware Approach}} for {{Truth Discovery}} on {{Long-Tail Data}}},
  author = {Li, Qi and Li, Yaliang and Gao, Jing and Su, Lu and Zhao, Bo and Demirbas, Murat and Fan, Wei and Han, Jiawei},
  date = {2014-12},
  journaltitle = {Proc. VLDB Endow.},
  volume = {8},
  number = {4},
  pages = {425--436},
  issn = {2150-8097},
  doi = {10.14778/2735496.2735505},
  url = {https://dl.acm.org/doi/10.14778/2735496.2735505},
  urldate = {2022-12-28},
  abstract = {In many real world applications, the same item may be described by multiple sources. As a consequence, conflicts among these sources are inevitable, which leads to an important task: how to identify which piece of information is trustworthy, i.e., the truth discovery task. Intuitively, if the piece of information is from a reliable source, then it is more trustworthy, and the source that provides trustworthy information is more reliable. Based on this principle, truth discovery approaches have been proposed to infer source reliability degrees and the most trustworthy information (i.e., the truth) simultaneously. However, existing approaches overlook the ubiquitous long-tail phenomenon in the tasks, i.e., most sources only provide a few claims and only a few sources make plenty of claims, which causes the source reliability estimation for small sources to be unreasonable. To tackle this challenge, we propose a confidence-aware truth discovery (CATD) method to automatically detect truths from conflicting data with long-tail phenomenon. The proposed method not only estimates source reliability, but also considers the confidence interval of the estimation, so that it can effectively reflect real source reliability for sources with various levels of participation. Experiments on four real world tasks as well as simulated multi-source long-tail datasets demonstrate that the proposed method outperforms existing state-of-the-art truth discovery approaches by successful discounting the effect of small sources.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {285 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/QGH68W9C/A confidence-aware approach for truth discovery on long-tail data.pdf}
}

@inproceedings{li_Crowdsourced_2017,
  title = {Crowdsourced {{Data Management}}: {{Overview}} and {{Challenges}}},
  shorttitle = {Crowdsourced {{Data Management}}},
  booktitle = {Proc. 2017 {{ACM Int}}. {{Conf}}. {{Manag}}. {{Data}}},
  author = {Li, Guoliang and Zheng, Yudian and Fan, Ju and Wang, Jiannan and Cheng, Reynold},
  date = {2017-05-09},
  pages = {1711--1716},
  publisher = {{ACM}},
  location = {{Chicago Illinois USA}},
  doi = {10.1145/3035918.3054776},
  url = {https://dl.acm.org/doi/10.1145/3035918.3054776},
  urldate = {2022-12-28},
  eventtitle = {{{SIGMOD}}/{{PODS}}'17: {{International Conference}} on {{Management}} of {{Data}}},
  isbn = {978-1-4503-4197-4},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {83 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/CZBC78G8/Li et al. - 2017 - Crowdsourced Data Management Overview and Challen.pdf}
}

@article{li_Deep_2021,
  title = {Deep {{Learning}} for {{LiDAR Point Clouds}} in {{Autonomous Driving}}: {{A Review}}},
  shorttitle = {Deep {{Learning}} for {{LiDAR Point Clouds}} in {{Autonomous Driving}}},
  author = {Li, Ying and Ma, Lingfei and Zhong, Zilong and Liu, Fei and Chapman, Michael A. and Cao, Dongpu and Li, Jonathan},
  date = {2021-08},
  journaltitle = {IEEE Trans. Neural Netw. Learn. Syst.},
  volume = {32},
  number = {8},
  pages = {3412--3432},
  issn = {2162-2388},
  doi = {10.1109/TNNLS.2020.3015992},
  abstract = {Recently, the advancement of deep learning (DL) in discriminative feature learning from 3-D LiDAR data has led to rapid development in the field of autonomous driving. However, automated processing uneven, unstructured, noisy, and massive 3-D point clouds are a challenging and tedious task. In this article, we provide a systematic review of existing compelling DL architectures applied in LiDAR point clouds, detailing for specific tasks in autonomous driving, such as segmentation, detection, and classification. Although several published research articles focus on specific topics in computer vision for autonomous vehicles, to date, no general survey on DL applied in LiDAR point clouds for autonomous vehicles exists. Thus, the goal of this article is to narrow the gap in this topic. More than 140 key contributions in the recent five years are summarized in this survey, including the milestone 3-D deep architectures, the remarkable DL applications in 3-D semantic segmentation, object detection, and classification; specific data sets, evaluation metrics, and the state-of-the-art performance. Finally, we conclude the remaining challenges and future researches.},
  eventtitle = {{{IEEE Transactions}} on {{Neural Networks}} and {{Learning Systems}}},
  keywords = {⛔ No INSPIRE recid found,Autonomous driving,Autonomous vehicles,deep learning (DL),Laser radar,LiDAR,object classification,object detection,Object detection,point clouds,semantic segmentation,Semantics,Solid modeling,Task analysis,Three-dimensional displays},
  annotation = {136 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/EXZKDZYV/Li et al. - 2021 - Deep Learning for LiDAR Point Clouds in Autonomous.pdf}
}

@inproceedings{li_Deeper_2017,
  title = {Deeper, {{Broader}} and {{Artier Domain Generalization}}},
  booktitle = {Proc. {{IEEE Int}}. {{Conf}}. {{Comput}}. {{Vis}}.},
  author = {Li, Da and Yang, Yongxin and Song, Yi Zhe and Hospedales, Timothy M.},
  date = {2017},
  issn = {15505499},
  doi = {10.1109/ICCV.2017.591},
  abstract = {The problem of domain generalization is to learn from multiple training domains, and extract a domain-agnostic model that can then be applied to an unseen domain. Domain generalization (DG) has a clear motivation in contexts where there are target domains with distinct characteristics, yet sparse data for training. For example recognition in sketch images, which are distinctly more abstract and rarer than photos. Nevertheless, DG methods have primarily been evaluated on photo-only benchmarks focusing on alleviating the dataset bias where both problems of domain distinctiveness and data sparsity can be minimal. We argue that these benchmarks are overly straightforward, and show that simple deep learning baselines perform surprisingly well on them. In this paper, we make two main contributions: Firstly, we build upon the favorable domain shift-robust properties of deep learning methods, and develop a low-rank parameterized CNN model for end-to-end DG learning. Secondly, we develop a DG benchmark dataset covering photo, sketch, cartoon and painting domains. This is both more practically relevant, and harder (bigger domain shift) than existing benchmarks. The results show that our method outperforms existing DG alternatives, and our dataset provides a more significant DG challenge to drive future research.},
  isbn = {978-1-5386-1032-9},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {788 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{li_Domain_2018,
  title = {Domain {{Generalization With Adversarial Feature Learning}}},
  booktitle = {Proc. {{IEEE Comput}}. {{Soc}}. {{Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}.},
  author = {Li, Haoliang and Pan, Sinno Jialin and Wang, Shiqi and Kot, Alex C.},
  date = {2018},
  issn = {10636919},
  doi = {10.1109/CVPR.2018.00566},
  abstract = {In this paper, we tackle the problem of domain generalization: How to learn a generalized feature representation for an 'unseen' target domain by taking the advantage of multiple seen source-domain data. We present a novel framework based on adversarial autoencoders to learn a generalized latent feature representation across domains for domain generalization. To be specific, we extend adversarial autoencoders by imposing the Maximum Mean Discrepancy (MMD) measure to align the distributions among different domains, and matching the aligned distribution to an arbitrary prior distribution via adversarial feature learning. In this way, the learned feature representation is supposed to be universal to the seen source domains because of the MMD regularization, and is expected to generalize well on the target domain because of the introduction of the prior distribution. We proposed an algorithm to jointly train different components of our proposed framework. Extensive experiments on various vision tasks demonstrate that our proposed framework can learn better generalized features for the unseen target domain compared with state-of-the-art domain generalization methods.},
  isbn = {978-1-5386-6420-9},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {688 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{li_Double_2019,
  title = {Double {{Weighted K-Nearest Voting}} for {{Label Aggregation}} in {{Crowdsourcing Learning}}},
  author = {Li, Jiaye and Yu, Hao and Zhang, Leyuan and Wen, Guoqiu},
  date = {2019-12},
  journaltitle = {Multimed Tools Appl},
  volume = {78},
  number = {23},
  pages = {33357--33374},
  issn = {1380-7501, 1573-7721},
  doi = {10.1007/s11042-019-08054-6},
  url = {http://link.springer.com/10.1007/s11042-019-08054-6},
  urldate = {2021-11-16},
  abstract = {In this article, we propose a new voting strategy in crowdsourcing learning by avoiding the effects of missing labels and poor workers. To achieve this, we apply K-nearest neighbor idea and fitting learning to consider the importance of neighbor sample labels and the importance of workers, respectively. Specifically, we apply different weights to different neighbors based on the distance of the sample neighbors, which is important for the neighbor sample labels. At the same time, we propose an effective worker model to consider the importance of workers by removing redundant workers. In addition, we use an alternate iterative optimization algorithm to solve our proposed model. The experimental results show that the proposed algorithm achieves better performance in label aggregation accuracy than the comparison algorithm.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {1 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/9EV7GI23/Li et al. - 2019 - Double weighted K-nearest voting for label aggrega.pdf}
}

@inproceedings{li_Error_2013,
  title = {Error {{Rate Analysis}} of {{Labeling}} by {{Crowdsourcing}}},
  booktitle = {{{ICML Workshop Mach}}. {{Learn}}. {{Meets Crowdsourcing Atalanta Ga}}. {{USA}}},
  author = {Li, Hongwei and Yu, Bin and Zhou, Dengyong},
  date = {2013},
  publisher = {{Citeseer}},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/829Z7XFP/Li et al. - 2013 - Error Rate Analysis of Labeling by Crowdsourcing.pdf}
}

@online{li_errorrateboundscrowdsourcingmodels_2013,
  title = {Error {{Rate Bounds}} in {{Crowdsourcing Models}}},
  author = {Li, Hongwei and Yu, Bin and Zhou, Dengyong},
  date = {2013},
  doi = {10.48550/ARXIV.1307.2674},
  url = {https://arxiv.org/abs/1307.2674},
  urldate = {2022-12-28},
  abstract = {Crowdsourcing is an effective tool for human-powered computation on many tasks challenging for computers. In this paper, we provide finite-sample exponential bounds on the error rate (in probability and in expectation) of hyperplane binary labeling rules under the Dawid-Skene crowdsourcing model. The bounds can be applied to analyze many common prediction methods, including the majority voting and weighted majority voting. These bound results could be useful for controlling the error rate and designing better algorithms. We show that the oracle Maximum A Posterior (MAP) rule approximately optimizes our upper bound on the mean error rate for any hyperplane binary labeling rule, and propose a simple data-driven weighted majority voting (WMV) rule (called one-step WMV) that attempts to approximate the oracle MAP and has a provable theoretical guarantee on the error rate. Moreover, we use simulated and real data to demonstrate that the data-driven EM-MAP rule is a good approximation to the oracle MAP rule, and to demonstrate that the mean error rate of the data-driven EM-MAP rule is also bounded by the mean error rate bound of the oracle MAP rule with estimated parameters plugging into the bound.},
  pubstate = {preprint},
  version = {1},
  keywords = {⛔ No INSPIRE recid found,Applications (stat.AP),Computer Science - Machine Learning,FOS: Computer and information sciences,Machine Learning (cs.LG),Machine Learning (stat.ML),Statistics - Applications,Statistics - Machine Learning},
  annotation = {21 citations (Semantic Scholar/arXiv) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/HMSFREZQ/Li et al. - 2013 - Error Rate Bounds in Crowdsourcing Models.pdf}
}

@online{li_errorrateboundsiterativeweightedmajorityvotingcrowdsourcing_2014,
  title = {Error {{Rate Bounds}} and {{Iterative Weighted Majority Voting}} for {{Crowdsourcing}}},
  author = {Li, Hongwei and Yu, Bin},
  date = {2014-11-14},
  eprint = {1411.4086},
  eprinttype = {arxiv},
  eprintclass = {cs, math, stat},
  doi = {10.48550/arXiv.1411.4086},
  url = {http://arxiv.org/abs/1411.4086},
  urldate = {2022-12-28},
  abstract = {Crowdsourcing has become an effective and popular tool for human-powered computation to label large datasets. Since the workers can be unreliable, it is common in crowdsourcing to assign multiple workers to one task, and to aggregate the labels in order to obtain results of high quality. In this paper, we provide finite-sample exponential bounds on the error rate (in probability and in expectation) of general aggregation rules under the Dawid-Skene crowdsourcing model. The bounds are derived for multi-class labeling, and can be used to analyze many aggregation methods, including majority voting, weighted majority voting and the oracle Maximum A Posteriori (MAP) rule. We show that the oracle MAP rule approximately optimizes our upper bound on the mean error rate of weighted majority voting in certain setting. We propose an iterative weighted majority voting (IWMV) method that optimizes the error rate bound and approximates the oracle MAP rule. Its one step version has a provable theoretical guarantee on the error rate. The IWMV method is intuitive and computationally simple. Experimental results on simulated and real data show that IWMV performs at least on par with the state-of-the-art methods, and it has a much lower computational cost (around one hundred times faster) than the state-of-the-art methods.},
  pubstate = {preprint},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found,Computer Science - Human-Computer Interaction,Computer Science - Machine Learning,Mathematics - Probability,Mathematics - Statistics Theory,Statistics - Machine Learning},
  annotation = {64 citations (Semantic Scholar/arXiv) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/W38DLKKW/Li and Yu - 2014 - Error Rate Bounds and Iterative Weighted Majority .pdf}
}

@article{li_Experimental_1995,
  title = {Experimental {{Study}} on {{Mass}}/{{Heat Transfer}} of {{Circular Jet Impingement}} in {{Cubical Cavities}}},
  author = {Li, P. W. and Tao, W. Q.},
  date = {1995},
  journaltitle = {J. Enhanc. Heat Transf.},
  volume = {2},
  number = {4},
  pages = {251--261},
  publisher = {{Gordon \& Breach Science Publ Inc}},
  issn = {10655131},
  doi = {10.1615/JEnhHeatTransf.v2.i4.10},
  abstract = {Heat/mass transfer characteristics of a circular jet impingement in cubical cavity with flat or curved bottom surface are investigated experimentally using naphthalene sublimation technique. The effects of the distance between jet exit and bottom surface (H) and jet Reynolds number are parametrically studied. The jet Reynolds number varied from 7 \texttimes{} 103 to 1.1 \texttimes{} 105, and the ratio of H/D (D-jet delivery nozzle diameter) varied from 0.5 to 4.0. The surface averaged Sherwood numbers for the bottom and lateral walls are correlated with jet exit Reynolds number by a power law equation. In the parameter range tested, the averaged Sherwood number of the bottom surface is always lower than that of the lateral walls.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {1 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{li_Improved_2018,
  ids = {li_Improved_2018a},
  title = {An {{Improved Deep Learning Approach}} for {{Detection}} of {{Thyroid Papillary Cancer}} in {{Ultrasound Images}}},
  author = {Li, Hailiang and Weng, Jian and Shi, Yujian and Gu, Wanrong and Mao, Yijun and Wang, Yonghua and Liu, Weiwei and Zhang, Jiajie},
  date = {2018-04-26},
  journaltitle = {Sci Rep},
  volume = {8},
  number = {1},
  pages = {6600},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/s41598-018-25005-7},
  url = {https://www.nature.com/articles/s41598-018-25005-7},
  urldate = {2022-05-16},
  abstract = {Unlike daily routine images, ultrasound images are usually monochrome and low-resolution. In ultrasound images, the cancer regions are usually blurred, vague margin and irregular in shape. Moreover, the features of cancer region are very similar to normal or benign tissues. Therefore, training ultrasound images with original Convolutional Neural Network (CNN) directly is not satisfactory. In our study, inspired by state-of-the-art object detection network Faster R-CNN, we develop a detector which is more suitable for thyroid papillary carcinoma detection in ultrasound images. In order to improve the accuracy of the detection, we add a spatial constrained layer to CNN so that the detector can extract the features of surrounding region in which the cancer regions are residing. In addition, by concatenating the shallow and deep layers of the CNN, the detector can detect blurrier or smaller cancer regions. The experiments demonstrate that the potential of this new methodology can reduce the workload for pathologists and increase the objectivity of diagnoses. We find that 93:5\% of papillary thyroid carcinoma regions could be detected automatically while 81:5\% of benign and normal tissue could be excluded without the use of any additional immunohistochemical markers or human intervention.},
  issue = {1},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Cancer imaging,Computational science},
  annotation = {9 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/N2E8XS8W/Li et al. - 2018 - An improved deep learning approach for detection o.pdf;/Users/personal-macbook/Zotero/storage/L4EQTPIW/Li et al. - 2018 - An improved deep learning approach for detection o.html;/Users/personal-macbook/Zotero/storage/ZXP8F4XN/Li et al. - 2018 - An improved deep learning approach for detection o.html}
}

@inproceedings{li_Incorporating_2018,
  title = {Incorporating {{Worker Similarity}} for {{Label Aggregation}} in {{Crowdsourcing}}},
  author = {Li, Jiyi and Baba, Yukino and Kashima, Hisashi},
  date = {2018},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {11140},
  pages = {596--606},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-01421-6_57},
  url = {http://link.springer.com/10.1007/978-3-030-01421-6_57},
  urldate = {2022-12-29},
  eventtitle = {Artificial {{Neural Networks}} and {{Machine Learning}} ({{ICANN}})},
  isbn = {978-3-030-01420-9 978-3-030-01421-6},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {13 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{li_Multigas_2003,
  title = {Multi-{{Gas Transportation}} and {{Electrochemical Performance}} of a {{Polymer Electrolyte Fuel Cell With Complex Flow Channels}}},
  author = {Li, Pei Wen and Schaefer, Laura and Wang, Qing Ming and Zhang, Tao and Chyu, Minking K.},
  date = {2003-03},
  journaltitle = {J. Power Sources},
  volume = {115},
  number = {1},
  pages = {90--100},
  issn = {03787753},
  doi = {10.1016/S0378-7753(02)00723-1},
  abstract = {A three-dimensional (3D) numerical model associating the heat/mass transfer and the electrochemical reaction in a proton exchange membrane (PEM) fuel cell is developed in this study, and a miniaturized PEM fuel cell with complex flow channels is simulated. The numerical computation is based on the finite-volume method. Governing equations for flow and heat/mass transfer are coupled with the electrochemical reactions and are solved simultaneously. The latent heat from the condensation of water vapor in cathode channel, if any, is considered. The perimeters of the bipolar plates are also included in the computational domain to account for their heat conduction effect. The miniaturized PEM fuel cell has a membrane electrode assembly (MEA) sandwiched by two brass bipolar plates etched with a number of winding gas channels with a flow area of 250 {$\mu$}m \texttimes{} 250 {$\mu$}m. The influence of anode gas humidity on the performance of the fuel cell is investigated through model prediction. Finally, field details of velocity, mass fraction and electromotive force are illustrated and discussed. \textcopyright{} 2003 Published by Elsevier Science B.V.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,3D numerical model,Complex flow channels,Heat/mass transfer,PEM fuel cell}
}

@inproceedings{li_Neural_2020,
  title = {A {{Neural Model}} for {{Aggregating Coreference Annotation}} in {{Crowdsourcing}}},
  booktitle = {Proc. 28th {{Int}}. {{Conf}}. {{Comput}}. {{Linguist}}.},
  author = {Li, Maolin and Takamura, Hiroya and Ananiadou, Sophia},
  date = {2020-12},
  pages = {5760--5773},
  publisher = {{International Committee on Computational Linguistics}},
  location = {{Barcelona, Spain (Online)}},
  doi = {10.18653/v1/2020.coling-main.507},
  url = {https://aclanthology.org/2020.coling-main.507},
  urldate = {2021-11-16},
  abstract = {Coreference resolution is the task of identifying all mentions in a text that refer to the same real-world entity. Collecting sufficient labelled data from expert annotators to train a high-performance coreference resolution system is time-consuming and expensive. Crowdsourcing makes it possible to obtain the required amounts of data rapidly and cost-effectively. However, crowd-sourced labels can be noisy. To ensure high-quality data, it is crucial to infer the correct labels by aggregating the noisy labels. In this paper, we split the aggregation into two subtasks, i.e, mention classification and coreference chain inference. Firstly, we predict the general class of each mention using an autoencoder, which incorporates contextual information about each mention, while at the same time taking into account the mention's annotation complexity and annotators' reliability at different levels. Secondly, to determine the coreference chain of each mention, we use weighted voting which takes into account the learned reliability in the first subtask. Experimental results demonstrate the effectiveness of our method in predicting the correct labels. We also illustrate our model's interpretability through a comprehensive analysis of experimental results.},
  eventtitle = {{{COLING}} 2020},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {7 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/DR2H4BRF/Li et al. - 2020 - A Neural Model for Aggregating Coreference Annotat.pdf}
}

@article{li_Noise_2016,
  title = {Noise {{Filtering}} to {{Improve Data}} and {{Model Quality}} for {{Crowdsourcing}}},
  author = {Li, Chaoqun and Sheng, Victor S. and Jiang, Liangxiao and Li, Hongwei},
  date = {2016-09},
  journaltitle = {Knowledge-Based Systems},
  volume = {107},
  pages = {96--103},
  issn = {09507051},
  doi = {10.1016/j.knosys.2016.06.003},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0950705116301666},
  urldate = {2022-12-20},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Crowdsourcing learning,Integrated labels,Label noise,Noise filtering},
  annotation = {35 citations (Semantic Scholar/DOI) [2022-12-20]},
  file = {/Users/personal-macbook/Zotero/storage/538TFYE9/Li et al. - 2016 - Noise Filtering to Improve Data and Model Quality .pdf}
}

@article{li_Noise_2019,
  title = {Noise {{Correction}} to {{Improve Data}} and {{Model Quality}} for {{Crowdsourcing}}},
  author = {Li, Chaoqun and Jiang, Liangxiao and Xu, Wenqiang},
  date = {2019-06},
  journaltitle = {Engineering Applications of Artificial Intelligence},
  volume = {82},
  pages = {184--191},
  issn = {09521976},
  doi = {10.1016/j.engappai.2019.04.004},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0952197619300818},
  urldate = {2022-12-20},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Class noise,Crowdsourcing learning,Integrated labels,Noise correction},
  annotation = {18 citations (Semantic Scholar/DOI) [2022-12-20]},
  file = {/Users/personal-macbook/Zotero/storage/6GLTZXL2/Li et al. - 2019 - Noise correction to improve data and model quality.pdf}
}

@article{li_Novel_2005,
  title = {Novel {{Gas Distributors}} and {{Optimization}} for {{High Power Density}} in {{Fuel Cells}}},
  author = {Li, P. W. and Chen, S. P. and Chyu, M. K.},
  date = {2005},
  journaltitle = {J. Power Sources},
  issn = {03787753},
  doi = {10.1016/j.jpowsour.2004.08.031},
  abstract = {A novel gas distributor for fuel cells is proposed. It has three-dimensional current-collecting elements distributed in gas-delivery fields for effective current collection and heat/mass transfer enhancement. An analysis model has been developed in order to understand the performance of the output power density when the dimensions and distributive arrangement of the current collectors are different. Optimization analysis for a planar-type SOFC was conducted in order to outline the approach in optimizing a gas-delivery field when adopting three-dimensional current-collecting elements in a fuel cell. Experimental test of a proton exchange membrane (PEM) fuel cell adopting the novel gas distributor was conducted for verification of the new approach. Significant improvement of power output was obtained for the proposed new PEM fuel cells compared to the conventional ones under the same conditions except for the different gas distributors. Both the experimental results and modeling analysis are of great significance to the design of fuel cells of high power density. \textcopyright{} 2004 Elsevier B.V. All rights reserved.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Fuel cells,High power density,Novel gas distributors,Optimization}
}

@inproceedings{li_PointCNN_2018,
  title = {{{PointCNN}}: {{Convolution}} on {{X-Transformed Points}}},
  shorttitle = {{{PointCNN}}},
  booktitle = {Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.},
  author = {Li, Yangyan and Bu, Rui and Sun, Mingchao and Wu, Wei and Di, Xinhan and Chen, Baoquan},
  date = {2018},
  volume = {31},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2018/hash/f5f8590cd58a54e94377e6ae2eded4d9-Abstract.html},
  urldate = {2022-07-28},
  abstract = {We present a simple and general framework for feature learning from point cloud. The key to the success of CNNs is the convolution operator that is capable of leveraging spatially-local correlation in data represented densely in grids (e.g. images). However, point cloud are irregular and unordered, thus a direct convolving of kernels against the features associated with the points will result in deserting the shape information while being variant to the orders. To address these problems, we propose to learn a X-transformation from the input points, which is used for simultaneously weighting the input features associated with the points and permuting them into latent potentially canonical order. Then element-wise product and sum operations of typical convolution operator are applied on the X-transformed features. The proposed method is a generalization of typical CNNs into learning features from point cloud, thus we call it PointCNN. Experiments show that PointCNN achieves on par or better performance than state-of-the-art methods on multiple challenging benchmark datasets and tasks.},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/EPM958X4/Li et al. - 2018 - PointCNN Convolution On X-Transformed Points.pdf}
}

@article{li_Rapid_2002,
  title = {Rapid {{Natural Scene Categorization}} in the {{Near Absence}} of {{Attention}}},
  author = {Li, Fei Fei and VanRullen, Rufin and Koch, Christof and Perona, Pietro},
  date = {2002},
  journaltitle = {Proc. Natl. Acad. Sci. U. S. A.},
  eprint = {12077298},
  eprinttype = {pmid},
  issn = {00278424},
  doi = {10.1073/pnas.092277599},
  abstract = {What can we see when we do not pay attention? It is well known that we can be "blind" even to major aspects of natural scenes when we attend elsewhere. The only tasks that do not need attention appear to be carried out in the early stages of the visual system. Contrary to this common belief, we report that subjects can rapidly detect animals or vehicles in briefly presented novel natural scenes while simultaneously performing another attentionally demanding task. By comparison, they are unable to discriminate large T's from L's, or bisected two-color disks from their mirror images under the same conditions. We conclude that some visual tasks associated with "high-level" cortical areas may proceed in the near absence of attention.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{li_Resolving_2014,
  title = {Resolving {{Conflicts}} in {{Heterogeneous Data}} by {{Truth Discovery}} and {{Source Reliability Estimation}}},
  booktitle = {Proc. 2014 {{ACM SIGMOD Int}}. {{Conf}}. {{Manag}}. {{Data}}},
  author = {Li, Qi and Li, Yaliang and Gao, Jing and Zhao, Bo and Fan, Wei and Han, Jiawei},
  date = {2014-06-18},
  pages = {1187--1198},
  publisher = {{ACM}},
  location = {{Snowbird Utah USA}},
  doi = {10.1145/2588555.2610509},
  url = {https://dl.acm.org/doi/10.1145/2588555.2610509},
  urldate = {2022-12-28},
  eventtitle = {{{SIGMOD}}/{{PODS}}'14: {{International Conference}} on {{Management}} of {{Data}}},
  isbn = {978-1-4503-2376-5},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,data fusion,heterogeneous data,truth discovery},
  annotation = {380 citations (Semantic Scholar/DOI) [2022-12-28]},
  file = {/Users/personal-macbook/Zotero/storage/GR8Z832M/Li et al. - 2014 - Resolving conflicts in heterogeneous data by truth.pdf;/Users/personal-macbook/Zotero/storage/BNBQJZVF/2588555.html;/Users/personal-macbook/Zotero/storage/IGK32GD3/2588555.html}
}

@article{li_SelfTraining_2008,
  ids = {li_Selftraining_2008},
  title = {A {{Self-Training Semi-Supervised SVM Algorithm}} and {{Its Application}} in an {{Eeg-Based Brain Computer Interface Speller System}}},
  author = {Li, Yuanqing and Guan, Cuntai and Li, Huiqi and Chin, Zhengyang},
  date = {2008-07},
  journaltitle = {Pattern Recognition Letters},
  volume = {29},
  number = {9},
  pages = {1285--1294},
  issn = {01678655},
  doi = {10.1016/j.patrec.2008.01.030},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S016786550800055X},
  urldate = {2023-05-08},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,10,170,90,Brain computer interface (BCI),Convergence,Electroencephalogram (EEG),Model selection,Semi-supervised support vector machine (SVM)},
  annotation = {240 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{li_Thoracic_2018,
  title = {Thoracic {{Disease Identification}} and {{Localization With Limited Supervision}}},
  booktitle = {{{IEEECVF Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}.},
  author = {Li, Zhe and Wang, Chong and Han, Mei and Xue, Yuan and Wei, Wei and Li, Li-Jia and Fei-Fei, Li},
  date = {2018-06},
  pages = {8290--8299},
  publisher = {{IEEE}},
  location = {{Salt Lake City, UT}},
  doi = {10.1109/CVPR.2018.00865},
  url = {https://ieeexplore.ieee.org/document/8578963/},
  urldate = {2022-11-21},
  eventtitle = {{{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-5386-6420-9},
  keywords = {⛔ No INSPIRE recid found,❓ Multiple DOI},
  annotation = {250 citations (Semantic Scholar/DOI) [2022-11-21]},
  file = {/Users/personal-macbook/Zotero/storage/V98F6GD7/Li et al. - 2018 - Thoracic Disease Identification and Localization w.pdf}
}

@inproceedings{li_Turbulent_2000,
  ids = {Li2000TurbulentSI},
  title = {Turbulent {{Structure}} in a {{Drag-Reducing Channel Flow With Surfactant Additives Investigated}} by {{PIV System}}},
  booktitle = {10th {{Int}}. {{Symp}}. {{Appl}}. {{Laser Tech}}. {{Fluid Mech}}.},
  author = {Li, P. W. and Kawaguchi, Y. and Segawa, T. and Yabe, A.},
  date = {2000},
  abstract = {The turbulent frictional drag of water can be reduced dramatically by adding small amounts of drag-reducing materials, such as polymers or surfactants. The amount of percentage drag reduction easily reaches 80\%. In this work, a double pulse PIV system was used to clarify the spatial velocity distribution of surfactant solution flow in a two-dimensional channel of height 40mm, width 500mm and length 6m. A type of cationic surfactant CTAC (C 16 H 33 N(CH 3) 3 Cl) mixed with counter-ion material NaSal (HOC 6 H 4 COONa) was used as a drag-reducing additives to water at a mass concentration of 40ppm. Instantaneous velocity distribution taken by PIV was examined to clarify the effect of surfactant additives as well as Reynolds number dependency of drag reducing flow. The following conclusions were drawn from the present study.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{li_Unified_2021,
  title = {A {{Unified Task Recommendation Strategy}} for {{Realistic Mobile Crowdsourcing System}}},
  author = {Li, Zhiyao and Cheng, Bosen and Gao, Xiaofeng and Chen, Huai and Chen, Guihai},
  date = {2021-02-12},
  journaltitle = {Theoretical Computer Science},
  volume = {857},
  pages = {43--58},
  issn = {0304-3975},
  doi = {10.1016/j.tcs.2020.12.034},
  url = {https://www.sciencedirect.com/science/article/pii/S030439752030757X},
  urldate = {2021-11-16},
  abstract = {A well-designed task recommendation framework aims to protect the data quality as well as increase the task execution results. However, current crowdsourcing systems ignore the fact that there are few duplicate task expectations because of the budget limitation in realistic conditions. Besides, a practical crowdsourcing system needs to recommend new tasks without previous knowledge about the concrete task content due to short task lifespan. Thus, most of the existing studies are not applicable due to the idealized assumptions. In this paper, we formally define the problem and prove it is NP-Hard. For the problem, we design a unified task recommendation system for realistic conditions to address the mentioned problems, Pioneer-Assisted Task RecommendatiON (PATRON) framework. The framework first selects a set of pioneer workers to collect initial knowledge of the new tasks. Then it adopts the k-medoids clustering algorithm to split the workers into subsets based on the worker similarity. Cluster selection and worker pruning provides accurate and efficient recommendations that satisfy the valid recommendation requirements from requesters. Finally, we conducted our experiments based on real datasets from a famous Chinese crowdsourcing platform, Tencent SOHO. The experimental results show the efficiency and accuracy of PATRON compared with three baseline methods from several perspectives, such as recommendation success rate and recommended worker quality.},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Crowdsourcing,K-medoids,Recommendation system},
  annotation = {2 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{li_Voxelwise_2013,
  title = {Voxelwise {{Spectral Diffusional Connectivity}} and {{Its Applications}} to {{Alzheimer}}'s {{Disease}} and {{Intelligence Prediction}}},
  author = {Li, Junning and Jin, Yan and Shi, Yonggang and Dinov, Ivo D. and Wang, Danny J. and Toga, Arthur W. and Thompson, Paul M.},
  date = {2013},
  journaltitle = {Med. Image Comput. Comput. Assist. Interv.},
  volume = {16},
  pages = {655--662},
  abstract = {Human brain connectivity can be studied using graph theory. Many connectivity studies parcellate the brain into regions and count fibres extracted between them. The resulting network analyses require validation of the tractography, as well as region and parameter selection. Here we investigate whole brain connectivity from a different perspective. We propose a mathematical formulation based on studying the eigenvalues of the Laplacian matrix of the diffusion tensor field at the voxel level. This voxelwise matrix has over a million parameters, but we derive the Kirchhoff complexity and eigen-spectrum through elegant mathematical theorems, without heavy computation. We use these novel measures to accurately estimate the voxelwise connectivity in multiple biomedical applications such as Alzheimer's disease and intelligence prediction.},
  issue = {Pt 1},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{lian_Multichannel_2018,
  title = {Multi-{{Channel Multi-Scale Fully Convolutional Network}} for {{3D Perivascular Spaces Segmentation}} in {{7T MR Images}}},
  author = {Lian, Chunfeng and Zhang, Jun and Liu, Mingxia and Zong, Xiaopeng and Hung, Sheng-Che and Lin, Weili and Shen, Dinggang},
  date = {2018-05},
  journaltitle = {Med. Image Anal.},
  volume = {46},
  pages = {106--117},
  doi = {10.1016/j.media.2018.02.009},
  abstract = {Accurate segmentation of perivascular spaces (PVSs) is an important step for quantitative study of PVS morphology. However, since PVSs are the thin tubular structures with relatively low contrast and also the number of PVSs is often large, it is challenging and time-consuming for manual delineation of PVSs. Although several automatic/semi-automatic methods, especially the traditional learning-based approaches, have been proposed for segmentation of 3D PVSs, their performance often depends on the hand-crafted image features, as well as sophisticated preprocessing operations prior to segmentation (e.g., specially defined regions-of-interest (ROIs)). In this paper, a novel fully convolutional neural network (FCN) with no requirement of any specified hand-crafted features and ROIs is proposed for efficient segmentation of PVSs. Particularly, the original T2-weighted 7T magnetic resonance (MR) images are first filtered via a non-local Haar-transform-based line singularity representation method to enhance the thin tubular structures. Both the original and enhanced MR images are used as multi-channel inputs to complementarily provide detailed image information and enhanced tubular structural information for the localization of PVSs. Multi-scale features are then automatically learned to characterize the spatial associations between PVSs and adjacent brain tissues. Finally, the produced PVS probability maps are recursively loaded into the network as an additional channel of inputs to provide the auxiliary contextual information for further refining the segmentation results. The proposed multi-channel multi-scale FCN has been evaluated on the 7T brain MR images scanned from 20 subjects. The experimental results show its superior performance compared with several state-of-the-art methods.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,7T MR images,Deep learning,Fully convolutional n}
}

@inproceedings{liang_Recurrent_2015,
  title = {Recurrent {{Convolutional Neural Network}} for {{Object Recognition}}},
  author = {Liang, Ming and Hu, Xiaolin},
  date = {2015},
  pages = {3367--3375},
  url = {https://openaccess.thecvf.com/content_cvpr_2015/html/Liang_Recurrent_Convolutional_Neural_2015_CVPR_paper.html},
  urldate = {2023-01-11},
  eventtitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  keywords = {⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/2YUFEGVE/Liang and Hu - 2015 - Recurrent Convolutional Neural Network for Object .pdf}
}

@article{liao_Modelling_2020,
  title = {On {{Modelling Label Uncertainty}} in {{Deep Neural Networks}}: {{Automatic Estimation}} of {{Intra- Observer Variability}} in {{2D Echocardiography Quality Assessment}}},
  author = {Liao, Zhibin and Girgis, Hany and Abdi, Amir and Vaseli, Hooman and Hetherington, Jorden and Rohling, Robert and Gin, Ken and Tsang, Teresa and Abolmaesumi, Purang},
  date = {2020},
  journaltitle = {IEEE Trans. Med. Imaging},
  eprint = {31841401},
  eprinttype = {pmid},
  issn = {1558254X},
  doi = {10.1109/TMI.2019.2959209},
  abstract = {Uncertainty of labels in clinical data resulting from intra-observer variability can have direct impact on the reliability of assessments made by deep neural networks. In this paper, we propose a method for modelling such uncertainty in the context of 2D echocardiography (echo), which is a routine procedure for detecting cardiovascular disease at point-of-care. Echo imaging quality and acquisition time is highly dependent on the operator's experience level. Recent developments have shown the possibility of automating echo image quality quantification by mapping an expert's assessment of quality to the echo image via deep learning techniques. Nevertheless, the observer variability in the expert's assessment can impact the quality quantification accuracy. Here, we aim to model the intra-observer variability in echo quality assessment as an aleatoric uncertainty modelling regression problem with the introduction of a novel method that handles the regression problem with categorical labels. A key feature of our design is that only a single forward pass is sufficient to estimate the level of uncertainty for the network output. Compared to the 0.11 {$\pm$} 0.09 absolute error (in a scale from 0 to 1) archived by the conventional regression method, the proposed method brings the error down to 0.09 {$\pm$} 0.08, where the improvement is statistically significant and equivalents to 5.7\% test accuracy improvement. The simplicity of the proposed approach means that it could be generalized to other applications of deep learning in medical imaging, where there is often uncertainty in clinical labels.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,2D echocardiography,cross-entropy,deep learning,deep neural networks,DenseNet,Label uncertainty,loss regularization,LSTM,modelling,quality assessment}
}

@article{liao_Surprising_2018,
  title = {A {{Surprising Linear Relationship Predicts Test Performance}} in {{Deep Networks}}},
  author = {Liao, Qianli and Miranda, Brando and Banburski, Andrzej and Hidary, Jack and Poggio, Tomaso},
  date = {2018-07},
  url = {https://arxiv.org/abs/1807.09659},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found},
  annotation = {31 citations (Semantic Scholar/arXiv) [2023-05-08]}
}

@article{litjens_Survey_2017a,
  ids = {litjens_Survey_2017},
  title = {A {{Survey}} on {{Deep Learning}} in {{Medical Image Analysis}}},
  author = {Litjens, Geert and Kooi, Thijs and Bejnordi, Babak Ehteshami and Setio, Arnaud Arindra Adiyoso and Ciompi, Francesco and Ghafoorian, Mohsen and family=Laak, given=Jeroen A.W.M., prefix=van der, useprefix=true and family=Ginneken, given=Bram, prefix=van, useprefix=true and S\'anchez, Clara I.},
  date = {2017-12},
  journaltitle = {Medical Image Analysis},
  volume = {42},
  pages = {60--88},
  issn = {13618415},
  doi = {10.1016/j.media.2017.07.005},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1361841517301135},
  urldate = {2023-04-02},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Convolutional neural networks,Deep learning,Medi},
  annotation = {7691 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/VMNUQTQV/Litjens et al. - 2017 - A survey on deep learning in medical image analysi.pdf}
}

@article{liu_CFD_2010,
  title = {{{CFD Study}} on {{Flow Distribution Uniformity}} in {{Fuel Distributors Having Multiple Structural Bifurcations}} of {{Flow Channels}}},
  author = {Liu, Hong and Li, Peiwen and Lew, Jon Van},
  date = {2010-09},
  journaltitle = {Int. J. Hydrog. Energy},
  volume = {35},
  number = {17},
  pages = {9186--9198},
  publisher = {{Pergamon}},
  issn = {03603199},
  doi = {10.1016/j.ijhydene.2010.06.043},
  abstract = {This work studied the issues of uniform flow distribution for general application in fuel cells, fuel processing chemical reactors, and other industrial devices. A novel method for uniform flow distribution was proposed, in which multiple levels of flow channel bifurcations were considered to uniformly distribute a flow into 2n flow channels at the final stage, after n levels of bifurcation. To study the effect of the flow channel bifurcation structure and dimensions on the flow distribution uniformity, numerical analysis was conducted. Parameters such as the flow channel length and width at each level of bifurcation as well as the curvature of the turning area of flow channels were particularly investigated. Important results concerning the geometrical design of flow distributors for better flow distribution and uniformity are presented. The best structure of a flow distributor was selected based on the criterion of flow distribution uniformity and low pressure loss. Since the studied novel flow distributor distributes a flow into a number of parallel channels in a remarkable uniformity, the flow distribution structure is expected to be widely used in fuel cells, fuel cell systems, and variety of industrial reactors and heat exchangers to significantly improve the performance of these devices. The studied flow regime is limited to laminar flow. A CFD tool FLUENTat the was used for the simulation. The numerical treatment of convection terms in governing equations was based on the QUICK scheme, and the coupled computation solving for pressure and velocity fields was based on the SIMPLE algorithm. \textcopyright{} 2009 Professor T. Nejat Veziroglu. Published by Elsevier Ltd. All rights reserved.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,CFD analysis,Flow distributor,Flow uniformity,Fuel cells,Reactors},
  annotation = {130 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{liu_Deep_2019,
  ids = {liu_Deep_2019a},
  title = {Deep {{Learning}} in {{Medical Ultrasound Analysis}}: {{A Review}}},
  shorttitle = {Deep {{Learning}} in {{Medical Ultrasound Analysis}}},
  author = {Liu, Shengfeng and Wang, Yi and Yang, Xin and Lei, Baiying and Liu, Li and Li, Shawn Xiang and Ni, Dong and Wang, Tianfu},
  date = {2019-04-01},
  journaltitle = {Engineering},
  volume = {5},
  number = {2},
  pages = {261--275},
  issn = {2095-8099},
  doi = {10.1016/j.eng.2018.11.020},
  url = {https://www.sciencedirect.com/science/article/pii/S2095809918301887},
  urldate = {2022-05-16},
  abstract = {Ultrasound (US) has become one of the most commonly performed imaging modalities in clinical practice. It is a rapidly evolving technology with certain advantages and with unique challenges that include low imaging quality and high variability. From the perspective of image analysis, it is essential to develop advanced automatic US image analysis methods to assist in US diagnosis and/or to make such assessment more objective and accurate. Deep learning has recently emerged as the leading machine learning tool in various research fields, and especially in general imaging analysis and computer vision. Deep learning also shows huge potential for various automatic US image analysis tasks. This review first briefly introduces several popular deep learning architectures, and then summarizes and thoroughly discusses their applications in various specific tasks in US image analysis, such as classification, detection, and segmentation. Finally, the open challenges and potential trends of the future application of deep learning in medical US image analysis are discussed.},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Classification,Deep learning,Detection,Medical ultrasound analysis,Segmentation},
  annotation = {383 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/6L37E942/Liu et al. - 2019 - Deep Learning in Medical Ultrasound Analysis A Re.pdf;/Users/personal-macbook/Zotero/storage/4VWCYCR9/Liu et al. - 2019 - Deep Learning in Medical Ultrasound Analysis A Re.html;/Users/personal-macbook/Zotero/storage/HIJHMXIT/Liu et al. - 2019 - Deep Learning in Medical Ultrasound Analysis A Re.html}
}

@article{liu_Deep_2019b,
  title = {Deep {{Learning}} on {{Point Clouds}} and {{Its Application}}: {{A Survey}}},
  author = {Liu, Weiping and Sun, Jia and Li, Wanyi and Hu, Ting and Wang, Peng and Wang, Peng and Wang, Peng},
  date = {2019},
  journaltitle = {Sensors},
  eprint = {null},
  eprinttype = {pmid},
  doi = {10.3390/s19194188},
  abstract = {Point cloud is a widely used 3D data form, which can be produced by depth sensors, such as Light Detection and Ranging (LIDAR) and RGB-D cameras. Being unordered and irregular, many researchers focused on the feature engineering of the point cloud. Being able to learn complex hierarchical structures, deep learning has achieved great success with images from cameras. Recently, many researchers have adapted it into the applications of the point cloud. In this paper, the recent existing point cloud feature learning methods are classified as point-based and tree-based. The former directly takes the raw point cloud as the input for deep learning. The latter first employs a k-dimensional tree (Kd-tree) structure to represent the point cloud with a regular representation and then feeds these representations into deep learning models. Their advantages and disadvantages are analyzed. The applications related to point cloud feature learning, including 3D object classification, semantic segmentation, and 3D object detection, are introduced, and the datasets and evaluation metrics are also collected. Finally, the future research trend is predicted.},
  pmcid = {6806315},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {122 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/BMEGGGU8/Liu et al. - 2019 - Deep Learning on Point Clouds and Its Application.pdf}
}

@article{liu_Deep_2020a,
  ids = {_Deep_,liu_Deep_2020},
  title = {Deep {{Learning}} for {{Generic Object Detection}}: {{A Survey}}},
  shorttitle = {Deep {{Learning}} for {{Generic Object Detection}}},
  author = {Liu, Li and Ouyang, Wanli and Wang, Xiaogang and Fieguth, Paul and Chen, Jie and Liu, Xinwang and Pietik\"ainen, Matti},
  date = {2020-02-01},
  journaltitle = {Int J Comput Vis},
  volume = {128},
  number = {2},
  pages = {261--318},
  issn = {1573-1405},
  doi = {10.1007/s11263-019-01247-4},
  url = {https://doi.org/10.1007/s11263-019-01247-4},
  urldate = {2022-05-16},
  abstract = {Object detection, one of the most fundamental and challenging problems in computer vision, seeks to locate object instances from a large number of predefined categories in natural images. Deep learning techniques have emerged as a powerful strategy for learning feature representations directly from data and have led to remarkable breakthroughs in the field of generic object detection. Given this period of rapid evolution, the goal of this paper is to provide a comprehensive survey of the recent achievements in this field brought about by deep learning techniques. More than 300 research contributions are included in this survey, covering many aspects of generic object detection: detection frameworks, object feature representation, object proposal generation, context modeling, training strategies, and evaluation metrics. We finish the survey by identifying promising directions for future research.},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Convolutional neural networks,Deep learning,Object detection,Object recognition},
  annotation = {22 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/HKVVYIRC/Liu et al. - 2020 - Deep Learning for Generic Object Detection A Surv.pdf}
}

@article{liu_Exploiting_2021,
  title = {Exploiting {{Predicted Answer}} in {{Label Aggregation}} to {{Make Better Use}} of the {{Crowd Wisdom}}},
  author = {Liu, Jiacheng and Tang, Feilong and Chen, Long and Zhu, Yanmin},
  date = {2021-10},
  journaltitle = {Information Sciences},
  volume = {574},
  pages = {66--83},
  issn = {00200255},
  doi = {10.1016/j.ins.2021.05.060},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0020025521005326},
  urldate = {2023-04-05},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {2 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{liu_FlowNet3D_2019,
  title = {{{FlowNet3D}}: {{Learning Scene Flow}} in {{3D Point Clouds}}},
  booktitle = {Proc. {{IEEE Comput}}. {{Soc}}. {{Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}.},
  author = {Liu, Xingyu and Qi, Charles R. and Guibas, Leonidas J.},
  date = {2019},
  pages = {529--537},
  issn = {10636919},
  doi = {10.1109/CVPR.2019.00062},
  abstract = {Many applications in robotics and human-computer interaction can benefit from understanding 3D motion of points in a dynamic environment, widely noted as scene flow. While most previous methods focus on stereo and RGB-D images as input, few try to estimate scene flow directly from point clouds. In this work, we propose a novel deep neural network named FlowNet3D that learns scene flow from point clouds in an end-to-end fashion. Our network simultaneously learns deep hierarchical features of point clouds and flow embeddings that represent point motions , supported by two newly proposed learning layers for point sets. We evaluate the network on both challenging synthetic data from FlyingThings3D and real Lidar scans from KITTI. Trained on synthetic data only, our network successfully generalizes to real scans, outperforming various baselines and showing competitive results to the prior art. We also demonstrate two applications of our scene flow output (scan registration and motion segmentation) to show its potential wide use cases.},
  isbn = {978-1-72813-293-8},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Deep Learning,Low-level Vision,Motion and Tracking,Robotics + Driving},
  annotation = {282 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{liu_Generation_2020,
  title = {Generation of {{Human Thalamus Atlases From}} 7 {{T Data}} and {{Application}} to {{Intrathalamic Nuclei Segmentation}} in {{Clinical}} 3 {{T T1-Weighted Images}}},
  author = {Liu, Yuan and D'Haese, Pierre Fran\c{c}ois and Newton, Allen T. and Dawant, Benoit M.},
  date = {2020},
  journaltitle = {Magn. Reson. Imaging},
  issn = {18735894},
  doi = {10.1016/j.mri.2019.09.004},
  abstract = {The thalamus serves as the central relay station for the brain. It processes and relays sensory and motor signals between different subcortical regions and the cerebral cortex and it can be divided into several neuronal clusters referred to as nuclei. Each of these can possibly be subdivided into sub-nuclei. Accurate and reliable identification of thalamic nuclei is important for surgical interventions and neuroanatomical studies. This is however a challenging task because the small size of the nuclei and the lack of contrast over the thalamus region in clinically acquired images does not permit the visualization of their boundaries. A number of methods have been developed for thalamus parcellation but the vast majority of these relies on diffusion imaging or functional imaging. The low resolution of these images only permit localizing the largest nuclei. In this work we propose a method to segment smaller nuclei. We first present a protocol to build histological-like atlases from a series of high-field (7 Tesla) MR images acquired with different pulse sequences that each permits to visualize the boundaries of a subset of the nuclei. We use this protocol to scan 9 subjects and we manually delineate 23 thalamic nuclei following the Morel atlas naming convention for each of these subjects. Manual contours for the nuclei are subsequently utilized to create statistical shape models. With these data, we compare four methods for the segmentation of thalamic nuclei in 3 T images we have also acquired for the 9 subjects included in the study: (1) single atlas, (2) multi atlas, (3) statistical shape, and (4) hierarchical statistical shape in which thalamic nuclei are hierarchically fitted to the images, starting from the largest ones. Results of a leave-one-out validation study conducted on the nine image sets we have acquired show that the multi atlas approach improves upon the single atlas approach for most nuclei. Segmentations obtained with the hierarchical statistical shape model yield the highest accuracy, with dice coefficients ranging from 0.53 to 0.90, mean surface errors from 0.27 mm to 0.64 mm, and maximum surface errors from 1.31 mm to 2.52 mm for all nuclei averaged across test cases. This suggests the feasibility of using such approach for localizing thalamic substructures in clinically acquired MR volumes. It may have a direct impact on surgeries such as Deep Brain Stimulation procedures that require the implantation of stimulating electrodes in specific thalamic nuclei.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {26 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{liu_Improving_2017,
  title = {Improving {{Learning-From-Crowds Through Expert Validation}}},
  booktitle = {Proc. 26th {{Int}}. {{Jt}}. {{Conf}}. {{Artif}}. {{Intell}}.},
  author = {Liu, Mengchen and Jiang, Liu and Liu, Junlin and Wang, Xiting and Zhu, Jun and Liu, Shixia},
  date = {2017-08},
  pages = {2329--2336},
  location = {{Melbourne, Australia}},
  doi = {10.24963/ijcai.2017/324},
  url = {https://www.ijcai.org/proceedings/2017/324},
  urldate = {2022-12-28},
  abstract = {Although several effective learning-from-crowd methods have been developed to infer correct labels from noisy crowdsourced labels, a method for post-processed expert validation is still needed. This paper introduces a semi-supervised learning algorithm that is capable of selecting the most informative instances and maximizing the influence of expert labels. Specifically, we have developed a complete uncertainty assessment to facilitate the selection of the most informative instances. The expert labels are then propagated to similar instances via regularized Bayesian inference. Experiments on both real-world and simulated datasets indicate that given a specific accuracy goal (e.g., 95\%) our method reduces expert effort from 39\% to 60\% compared with the state-of-the-art method.},
  eventtitle = {Artificial {{Intelligence}}},
  isbn = {978-0-9992411-0-3},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {25 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/4Y886BPQ/Liu et al. - 2017 - Improving Learning-from-Crowds Through Expert Vali.pdf}
}

@inproceedings{liu_Nonparametric_2009,
  title = {Nonparametric {{Scene Parsing}}: {{Label Transfer}} via {{Dense Scene Alignment}}},
  booktitle = {2009 {{IEEE Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}.},
  author = {Liu, C. and Yuen, J. and Torralba, A.},
  date = {2009-06},
  pages = {1972--1979},
  abstract = {In this paper we propose a novel nonparametric approach for object recognition and scene parsing using dense scene alignment. Given an input image, we retrieve its best matches from a large database with annotated images using our modified, coarse-to-fine SIFT flow algorithm that aligns the structures within two images. Based on the dense scene correspondence obtained from the SIFT flow, our system warps the existing annotations, and integrates multiple cues in a Markov random field framework to segment and recognize the query image. Promising experimental results have been achieved by our nonparametric scene parsing system on a challenging database. Compared to existing object recognition approaches that require training for each object category, our system is easy to implement, has few parameters, and embeds contextual information naturally in the retrieval/alignment procedure.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,image matching,image segmentation,Markov processes}
}

@inproceedings{liu_RelationShape_2019,
  title = {Relation-{{Shape Convolutional Neural Network}} for {{Point Cloud Analysis}}},
  booktitle = {2019 {{IEEECVF Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}. {{CVPR}}},
  author = {Liu, Yongcheng and Fan, Bin and Xiang, Shiming and Pan, Chunhong},
  date = {2019-06},
  pages = {8887--8896},
  publisher = {{IEEE}},
  location = {{Long Beach, CA, USA}},
  doi = {10.1109/CVPR.2019.00910},
  url = {https://ieeexplore.ieee.org/document/8953930/},
  urldate = {2022-07-28},
  abstract = {Point cloud analysis is very challenging, as the shape implied in irregular points is difficult to capture. In this paper, we propose RS-CNN, namely, Relation-Shape Convolutional Neural Network, which extends regular grid CNN to irregular configuration for point cloud analysis. The key to RS-CNN is learning from relation, i.e., the geometric topology constraint among points. Specifically, the convolutional weight for local point set is forced to learn a high-level relation expression from predefined geometric priors, between a sampled point from this point set and the others. In this way, an inductive local representation with explicit reasoning about the spatial layout of points can be obtained, which leads to much shape awareness and robustness. With this convolution as a basic operator, RS-CNN, a hierarchical architecture can be developed to achieve contextual shape-aware learning for point cloud analysis. Extensive experiments on challenging benchmarks across three tasks verify RS-CNN achieves the state of the arts.},
  eventtitle = {2019 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-72813-293-8},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {393 citations (Semantic Scholar/DOI) [2022-08-30]},
  file = {/Users/personal-macbook/Zotero/storage/3VHU4NNN/Liu et al. - 2019 - Relation-Shape Convolutional Neural Network for Po.pdf}
}

@article{liu_SDFN_2019,
  title = {{{SDFN}}: {{Segmentation-Based Deep Fusion Network}} for {{Thoracic Disease Classification}} in {{Chest X-Ray Images}}},
  shorttitle = {Sdfn},
  author = {Liu, Han and Wang, Lei and Nan, Yandong and Jin, Faguang and Wang, Qi and Pu, Jiantao},
  date = {2019-07},
  journaltitle = {Computerized Medical Imaging and Graphics},
  volume = {75},
  pages = {66--73},
  issn = {08956111},
  doi = {10.1016/j.compmedimag.2019.05.005},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0895611118306177},
  urldate = {2022-11-21},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {53 citations (Semantic Scholar/DOI) [2022-11-21]},
  file = {/Users/personal-macbook/Zotero/storage/6E5J8Q46/Liu et al. - 2019 - SDFN Segmentation-based deep fusion network for t.pdf}
}

@inproceedings{liu_Thalamic_2015,
  title = {Thalamic {{Nuclei Segmentation}} in {{Clinical}} 3t {{T1-Weighted Images Using High-Resolution}} 7t {{Shape Models}}},
  booktitle = {Med. {{Imaging}} 2015 {{Image-Guid}}. {{Proced}}. {{Robot}}. {{Interv}}. {{Model}}.},
  author = {Liu, Yuan and D'Haese, Pierre-Fran\c{c}ois and Newton, Allen T. and Dawant, Benoit M.},
  editor = {Webster, Robert J. and Yaniv, Ziv R.},
  date = {2015-03},
  volume = {9415},
  pages = {94150E},
  publisher = {{SPIE}},
  doi = {10.1117/12.2081660},
  url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2081660},
  abstract = {\textcopyright{} 2015 SPIE. Accurate and reliable identification of thalamic nuclei is important for surgical interventions and neuroanatomical studies. This is a challenging task due to their small sizes and low intra-thalamic contrast in standard T1-weighted or T2-weighted images. Previously proposed techniques rely on diffusion imaging or functional imaging. These require additional scanning and suffer from the low resolution and signal-to-noise ratio in these images. In this paper, we aim to directly segment the thalamic nuclei in standard 3T T1-weighted images using shape models. We manually delineate the structures in high-field MR images and build high resolution shape models from a group of subjects. We then investigate if the nuclei locations can be inferred from the whole thalamus. To do this, we hierarchically fit joint models. We start from the entire thalamus and fit a model that captures the relation between the thalamus and large nuclei groups. This allows us to infer the boundaries of these nuclei groups and we repeat the process until all nuclei are segmented. We validate our method in a leave-one-out fashion with seven subjects by comparing the shape-based segmentations on 3T images to the manual contours. Results we have obtained for major nuclei (dice coefficients ranging from 0.57 to 0.88 and mean surface errors from 0.29mm to 0.72mm) suggest the feasibility of using such joint shape models for localization. This may have a direct impact on surgeries such as Deep Brain Stimulation procedures that require the implantation of stimulating electrodes in specific thalamic nuclei.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,7T,computer-assisted surgery,functional surgery,shape models,Thalamic nuclei segmentation}
}

@inproceedings{liu_TrueLabel_2012,
  title = {{{TrueLabel}} + {{Confusions}}: {{A Spectrum}} of {{Probabilistic Models}} in {{Analyzing Multiple Ratings}}},
  booktitle = {Proc. 29th {{Int}}. {{Conf}}. {{Mach}}. {{Learn}}. {{ICML}} 2012},
  author = {Liu, Chao and Wang, Yi Min},
  date = {2012},
  abstract = {This paper revisits the problem of analyzing multiple ratings given by different judges. Different from previous work that focuses on distilling the true labels from noisy crowdsourcing ratings, we emphasize gaining diagnostic insights into our in-house well-trained judges. We generalize the well-known DAWIDSKENE model (Dawid \& Skene, 1979) to a spectrum of probabilistic models under the same "TrueLabel + Confusion" paradigm, and show that our proposed hierarchical Bayesian model, called HYBRIDCONFUSION, consistently outperforms DAWIDSKENE on both synthetic and real-world data sets. Copyright 2012 by the author(s)/owner(s).},
  isbn = {978-1-4503-1285-1},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{liu_Variational_2012,
  title = {Variational {{Inference}} for {{Crowdsourcing}}},
  booktitle = {Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.},
  author = {Liu, Qiang and Peng, Jian and Ihler, Alexander T},
  date = {2012},
  volume = {25},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2012/hash/cd00692c3bfe59267d5ecfac5310286c-Abstract.html},
  urldate = {2022-12-20},
  abstract = {Crowdsourcing has become a popular paradigm for labeling large datasets. However, it has given rise to the computational task of aggregating the crowdsourced labels provided by a collection of unreliable annotators. We approach this problem by transforming it into a standard inference problem in graphical models, and applying approximate variational methods, including belief propagation (BP) and mean field (MF). We show that our BP algorithm generalizes both majority voting and a recent algorithm by Karger et al, while our MF method is closely related to a commonly used EM algorithm. In both cases, we find that the performance of the algorithms critically depends on the choice of a prior distribution on the workers' reliability; by choosing the prior properly, both BP and MF (and EM) perform surprisingly well on both simulated and real-world datasets, competitive with state-of-the-art algorithms based on more complicated modeling assumptions.},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found,Artificial Intelligence (cs.AI),FOS: Computer and information sciences,Machine Learning (cs.LG),Machine Learning (stat.ML)},
  file = {/Users/personal-macbook/Zotero/storage/23GME74N/Liu et al. - 2012 - Variational Inference for Crowdsourcing.pdf;/Users/personal-macbook/Zotero/storage/JKDTW2K5/Liu et al. - 2012 - Variational Inference for Crowdsourcing.pdf;/Users/personal-macbook/Zotero/storage/WYWIRQUD/Liu et al. - 2012 - Variational Inference for Crowdsourcing.pdf;/Users/personal-macbook/Zotero/storage/45WZ6CJT/cd00692c3bfe59267d5ecfac5310286c-Abstract.html;/Users/personal-macbook/Zotero/storage/8EV4V5WZ/cd00692c3bfe59267d5ecfac5310286c-Abstract.html;/Users/personal-macbook/Zotero/storage/KU2JLMAD/cd00692c3bfe59267d5ecfac5310286c-Abstract.html;/Users/personal-macbook/Zotero/storage/ZFUYLGZA/cd00692c3bfe59267d5ecfac5310286c-Abstract.html}
}

@article{loane_Rapid_2006,
  title = {Rapid {{Internationalisation Among Entrepreneurial Firms}} in {{Australia}}, {{Canada}}, {{Ireland}} and {{New Zealand}}: {{An Extension}} to the {{Network Approach}}},
  author = {Loane, Sharon and Bell, Jim},
  date = {2006},
  journaltitle = {Int. Mark. Rev.},
  volume = {23},
  number = {5},
  pages = {467--485},
  doi = {10.1108/02651330610703409},
  abstract = {Purpose \textendash{} The importance of networks in the internationalisation of entrepreneurial firms is widely accepted. However, while the literature tends to focus on the existing networks of firms, there is growing evidence that many rapid internationalisers have to build new networks. This cross-national study investigates the networks of internationalising entrepreneurial firms in Australia, Canada, Ireland and New Zealand.Design/methodology/approach \textendash{} A multi-stage approach and mixed methods were employed. Online sources were used to gather information on 218 internationalising small firms, then an e-mail instrument was administered to verify data and address information gaps, resulting in 143 usable responses (66 per cent) evenly distributed across locations. A representative sub-sample of 53 firms was selected for further in-depth investigation via face-to-face interviews with CEOs.Findings \textendash{} A high proportion of firms (25 per cent) actively used existing networks to develop their knowledge of international markets and improve their international competitiveness. However, an even larger number (34 per cent) had to build new networks because of the advanced nature of their offering. In-depth interviews provided rich insights into the nature and scope of the firms' network development activities.Research limitations/implications \textendash{} While the sample size is relatively small, the findings are consistent across locations. They suggest that further investigation of network building activities among internationalising entrepreneurial firms is required.Practical implications \textendash{} The results have implications on firm strategy, in terms of the strategic nature of network building and the need for systematic approaches. They also are pertinent to public policy in support of internationalisation. In particular, there is a need for support agencies to shift their focus from providing objective knowledge to supporting experiential learning and network development.Originality/value \textendash{} The linkage of extant network approaches to the emerging knowledge-based view (KBV) of internationalisation enhances and advances both perspectives.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{long_Fully_2015,
  title = {Fully {{Convolutional Networks}} for {{Semantic Segmentation}}},
  booktitle = {Proc. {{IEEE Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}.},
  author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
  date = {2015},
  pages = {3431--3440},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@inproceedings{long_Learning_2015,
  title = {Learning {{Transferable Features With Deep Adaptation Networks}}},
  booktitle = {32nd {{Int}}. {{Conf}}. {{Mach}}. {{Learn}}.},
  author = {Long, Mingsheng and Cao, Yue and Wang, Jianmin and Jordan, Michael I.},
  date = {2015},
  abstract = {Recent studies reveal that a deep neural network can learn transferable features which generalize well to novel tasks for domain adaptation. However, as deep features eventually transition from general to specific along the network, the feature transferability drops significantly in higher layers with increasing domain discrepancy. Hence, it is important to formally reduce the dataset bias and enhance the transferability in task-specific layers. In this paper, we propose a new Deep Adaptation Network (DAN) architecture, which generalizes deep convolutional neural network to the domain adaptation scenario. In DAN, hidden representations of all task-specific layers are embedded in a reproducing kernel Hilbert space where the mean embeddings of different domain distributions can be explicitly matched. The domain discrepancy is further reduced using an optimal multi-kernel selection method for mean embedding matching. DAN can learn transferable features with statistical guarantees, and can scale linearly by unbiased estimate of kernel embedding. Extensive empirical evidence shows that the proposed architecture yields state-of-the-art image classification error rates on standard domain adaptation benchmarks.},
  isbn = {978-1-5108-1058-7},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{longoni_Resistance_2019,
  title = {Resistance to {{Medical Artificial Intelligence}}},
  author = {Longoni, Chiara and Bonezzi, Andrea and Morewedge, Carey K.},
  date = {2019},
  journaltitle = {J. Consum. Res.},
  issn = {00935301},
  doi = {10.1093/jcr/ucz013},
  abstract = {Artificial intelligence (AI) is revolutionizing healthcare, but little is known about consumer receptivity to AI in medicine. Consumers are reluctant to utilize healthcare provided by AI in real and hypothetical choices, separate and joint evaluations. Consumers are less likely to utilize healthcare (study 1), exhibit lower reservation prices for healthcare (study 2), are less sensitive to differences in provider performance (studies 3A-3C), and derive negative utility if a provider is automated rather than human (study 4). Uniqueness neglect, a concern that AI providers are less able than human providers to account for consumers' unique characteristics and circumstances, drives consumer resistance to medical AI. Indeed, resistance to medical AI is stronger for consumers who perceive themselves to be more unique (study 5). Uniqueness neglect mediates resistance to medical AI (study 6), and is eliminated when AI provides care (a) that is framed as personalized (study 7), (b) to consumers other than the self (study 8), or (c) that only supports, rather than replaces, a decision made by a human healthcare provider (study 9). These findings make contributions to the psychology of automation and medical decision making, and suggest interventions to increase consumer acceptance of AI in medicine.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,artificial intelligence,automation,healthcare,medical decision making,uniqueness}
}

@article{loquercio_General_2020,
  title = {A {{General Framework}} for {{Uncertainty Estimation}} in {{Deep Learning}}},
  author = {Loquercio, Antonio and Segu, Mattia and Scaramuzza, Davide},
  date = {2020-04},
  journaltitle = {IEEE Robot. Autom. Lett.},
  volume = {5},
  number = {2},
  pages = {3153--3160},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2020.2974682},
  url = {https://ieeexplore.ieee.org/document/9001195/},
  urldate = {2023-05-08},
  keywords = {⛔ No INSPIRE recid found,AI-Based Methods,Index Terms-Deep Learning in Robotics and Automation,Probability and Statistical Methods},
  annotation = {165 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/MGZMF3TY/Loquercio et al. - 2020 - A General Framework for Uncertainty Estimation in .pdf}
}

@article{lorato_Unobtrusive_2019,
  title = {Unobtrusive {{Respiratory Flow Monitoring Using}} a {{Thermopile Array}}: {{A Feasibility Study}}},
  author = {Lorato, Ilde and Bakkes, Tom and Stuijk, Sander and Meftah, Mohammed and family=Haan, given=Gerard, prefix=de, useprefix=false},
  date = {2019-06},
  journaltitle = {Appl. Sci.},
  volume = {9},
  number = {12},
  pages = {2449},
  publisher = {{MDPI AG}},
  issn = {2076-3417},
  doi = {10.3390/app9122449},
  url = {https://www.mdpi.com/2076-3417/9/12/2449},
  abstract = {Low-resolution thermal cameras have already been used in the detection of respiratory flow. However, microbolometer technology has a high production cost compared to thermopile arrays. In this work, the feasibility of using a thermopile array to detect respiratory flow has been investigated in multiple settings. To prove the concept, we tested the detector on six healthy subjects. Our method automatically selects the region-of-interest by discriminating between sensor elements that output noise and flow-induced signals. The thermopile array yielded an average root mean squared error of 1.59 b r e a t h s p e r m i n u t e . Parameters such as distance, breathing rate, orientation, and oral or nasal breathing resulted in being fundamental in the detection of respiratory flow. The paper provides the proof-of-concept that low-cost thermopile-arrays can be used to monitor respiratory flow in a lab setting and without the need for facial landmark detection. Further development could provide a more attractive alternative for the earlier bolometer-based proposals.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Camera,Distance,Health,Remote,Respiration,Thermal,Thermopile,Unobtrusive}
}

@inproceedings{lorente_Active_2014,
  title = {Active {{Learning}} for {{Image Quality Assessment}} by {{Model Observer}}},
  booktitle = {2014 {{IEEE}} 11th {{Int}}. {{Symp}}. {{Biomed}}. {{Imaging ISBI}}},
  author = {Lorente, Iris and Brankov, Jovan G.},
  date = {2014-04},
  pages = {1352--1355},
  publisher = {{IEEE}},
  location = {{Beijing, China}},
  doi = {10.1109/ISBI.2014.6868128},
  url = {http://ieeexplore.ieee.org/document/6868128/},
  urldate = {2023-05-08},
  eventtitle = {2014 {{IEEE}} 11th {{International Symposium}} on {{Biomedical Imaging}} ({{ISBI}} 2014)},
  isbn = {978-1-4673-1961-4},
  keywords = {\#nosource,⛔ No INSPIRE recid found,feature extraction,learning (artificial intelligen},
  annotation = {8 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{lotjonen_Fast_2010,
  title = {Fast and {{Robust Multi-Atlas Segmentation}} of {{Brain Magnetic Resonance Images}}},
  author = {L\"otj\"onen, Jyrki Mp and Wolz, Robin and Koikkalainen, Juha R. and Thurfjell, Lennart and Waldemar, Gunhild and Soininen, Hilkka and Rueckert, Daniel and Initiative, Alzheimer's Disease Neuroimaging},
  date = {2010-02},
  journaltitle = {Neuroimage},
  volume = {49},
  number = {3},
  pages = {2352--2365},
  doi = {10.1016/j.neuroimage.2009.10.026},
  abstract = {We introduce an optimised pipeline for multi-atlas brain MRI segmentation. Both accuracy and speed of segmentation are considered. We study different similarity measures used in non-rigid registration. We show that intensity differences for intensity normalised images can be used instead of standard normalised mutual information in registration without compromising the accuracy but leading to threefold decrease in the computation time. We study and validate also different methods for atlas selection. Finally, we propose two new approaches for combining multi-atlas segmentation and intensity modelling based on segmentation using expectation maximisation (EM) and optimisation via graph cuts. The segmentation pipeline is evaluated with two data cohorts: IBSR data (N=18, six subcortial structures: thalamus, caudate, putamen, pallidum, hippocampus, amygdala) and ADNI data (N=60, hippocampus). The average similarity index between automatically and manually generated volumes was 0.849 (IBSR, six subcortical structures) and 0.880 (ADNI, hippocampus). The correlation coefficient for hippocampal volumes was 0.95 with the ADNI data. The computation time using a standard multicore PC computer was about 3-4 min. Our results compare favourably with other recently published results.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {386 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{lou_Nearinfrared_2019,
  title = {Near-{{Infrared Tunable Diode Laser Absorption Spectroscopy-Based Determination}} of {{Carbon Dioxide}} in {{Human Exhaled Breath}}},
  author = {Lou, Cunguang and Jing, Congrui and Wang, Xin and Chen, Yuhao and Zhang, Jiantao and Hou, Kaixuan and Yao, Jianquan and Liu, Xiuling},
  date = {2019},
  journaltitle = {Biomed. Opt. Express},
  issn = {2156-7085},
  doi = {10.1364/boe.10.005486},
  abstract = {A spectroscopic detection system for the accurate monitoring of carbon dioxide (CO2) in exhaled breath was realized by tunable diode laser absorption spectroscopy (TDLAS) in conjunction with a vertical-cavity surface-emitting laser (VCSEL) and a multipass cell with an effective optical path-length of 20 m. The VCSEL diode emitting light with an output power of 0.8 mW, covered the strong absorption line of CO2 at 6330.82 cm(-1) by drive-current tuning. The minimum detectable concentration of 0.769 parts per thousand for CO2 detection was obtained, and a measurement precision of approximately 100 ppm was achieved with an integration time of 168 s. Real-time online measurements were carried out for the detection of CO2 expirograms from healthy subjects, different concentrations were obtained in dead space and alveolar gas. The exhaled CO2 increased significantly with the increasing physical activity, reaches its maximal value at the beginning of respiratory compensation and then decreased slightly until maximal exercise. The developed measurement system has a great potential to be applied in practice for the detection of pulmonary diseases associated with CO2 retention. (C) 2019 Optical Society of America under the terms of the OSA Open Access Publishing Agreement},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{louizos_Structured_2016,
  title = {Structured and {{Efficient Variational Deep Learning With Matrix Gaussian Posteriors}}},
  booktitle = {33rd {{Int}}. {{Conf}}. {{Mach}}. {{Learn}}. {{ICML}} 2016},
  author = {Louizos, Christos and Welling, Max},
  date = {2016},
  abstract = {We introduce a variational Bayesian neural network where the parameters are governed via a probability distribution on random matrices. Specifically, we employ a matrix variate Gaussian (Gupta \& Nagar, 1999) parameter posterior distribution where we explicitly model the co- variance among the input and output dimensions of each layer. Furthermore, with approximate covariance matrices we can achieve a more efficient way to represent those correlations that is also cheaper than fully factorized parameter posteriors. We further show that with the "local reprarametrization trick" (Kingma et al., 2015) on this posterior distribution we arrive at a Gaussian Process (Rasmussen, 2006) interpretation of the hidden units in each layer and we, simi-larly with (Gal \& Ghahramani, 2015), provide connections with deep Gaussian processes. We continue in taking advantage of this duality and incorporate "pseudo-data" (Snelson \& Ghahramani, 2005) in our model, which in turn allows for more efficient posterior sampling while maintaining the properties of the original model. The validity of the proposed approach is verified through extensive experiments.},
  isbn = {978-1-5108-2900-8},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{lu_Deep_2020,
  title = {Deep {{Learning}} for {{3D Point Cloud Understanding}}: {{A Survey}}},
  shorttitle = {Deep {{Learning}} for {{3D Point Cloud Understanding}}},
  author = {Lu, Haoming and Shi, Humphrey},
  date = {2020},
  journaltitle = {ArXiv},
  abstract = {This paper summarizes recent remarkable research contributions in this area from several different directions (classification, segmentation, detection, tracking, flow estimation, registration, augmentation and completion), together with commonly used datasets, metrics and state-of-the-art performances. The development of practical applications, such as autonomous driving and robotics, has brought increasing attention to 3D point cloud understanding. While deep learning has achieved remarkable success on image-based tasks, there are many unique challenges faced by deep neural networks in processing massive, unstructured and noisy 3D points. To demonstrate the latest progress of deep learning for 3D point cloud understanding, this paper summarizes recent remarkable research contributions in this area from several different directions (classification, segmentation, detection, tracking, flow estimation, registration, augmentation and completion), together with commonly used datasets, metrics and state-of-the-art performances. More information regarding this survey can be found at: this https URL.},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/FL388F6V/Lu and Shi - 2020 - Deep Learning for 3D Point Cloud Understanding A .pdf}
}

@inproceedings{lu_Regularizing_2017,
  title = {Regularizing the {{Loss Layer}} of {{CNNS}} for {{Facial Expression Recognition Using Crowdsourced Labels}}},
  booktitle = {2017 21st {{Asia Pac}}. {{Symp}}. {{Intell}}. {{Evol}}. {{Syst}}. {{IES}}},
  author = {Lu, Philip and Li, Boyi and Shama, Saila and King, Irwin and Chan, Jonathan H.},
  date = {2017-11},
  pages = {31--36},
  publisher = {{IEEE}},
  location = {{Hanoi}},
  doi = {10.1109/IESYS.2017.8233557},
  url = {http://ieeexplore.ieee.org/document/8233557/},
  urldate = {2022-12-28},
  eventtitle = {2017 21st {{Asia Pacific Symposium}} on {{Intelligent}} and {{Evolutionary Systems}} ({{IES}})},
  isbn = {978-1-5386-0743-5},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {2 citations (Semantic Scholar/DOI) [2022-12-28]},
  file = {/Users/personal-macbook/Zotero/storage/NZXLDP65/8233557.html;/Users/personal-macbook/Zotero/storage/QZAKGT9Z/8233557.html}
}

@article{luengo-oroz_Artificial_2020,
  title = {Artificial {{Intelligence Cooperation}} to {{Support}} the {{Global Response}} to {{COVID-19}}},
  author = {Luengo-Oroz, Miguel and Pham, Katherine Hoffmann and Bullock, Joseph and Kirkpatrick, Robert and Luccioni, Alexandra and Rubel, Sasha and Wachholz, Cedric and Chakchouk, Moez and Biggs, Phillippa and Nguyen, Tim and Purnat, Tina and Mariano, Bernardo},
  date = {2020},
  journaltitle = {Nat. Mach. Intell.},
  issn = {25225839},
  doi = {10.1038/s42256-020-0184-3},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{ma_Adversarial_2020,
  title = {Adversarial {{Crowdsourcing Through Robust Rank-One Matrix Completion}}},
  booktitle = {Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.},
  author = {Ma, Qianqian and Olshevsky, Alex},
  date = {2020},
  volume = {33},
  pages = {21841--21852},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2020/file/f86890095c957e9b949d11d15f0d0cd5-Paper.pdf},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found,Computer Science - Machine Learning},
  file = {/Users/personal-macbook/Zotero/storage/QWBUZ4TR/Ma and Olshevsky - 2020 - Adversarial Crowdsourcing Through Robust Rank-One .pdf}
}

@article{ma_adversarialcrowdsourcingrobustrankonematrixcompletion_2020,
  title = {Adversarial {{Crowdsourcing Through Robust Rank-One Matrix Completion}}},
  author = {Ma, Qianqian and Olshevsky, Alex},
  date = {2020},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.2010.12181},
  url = {https://arxiv.org/abs/2010.12181},
  urldate = {2023-06-30},
  abstract = {We consider the problem of reconstructing a rank-one matrix from a revealed subset of its entries when some of the revealed entries are corrupted with perturbations that are unknown and can be arbitrarily large. It is not known which revealed entries are corrupted. We propose a new algorithm combining alternating minimization with extreme-value filtering and provide sufficient and necessary conditions to recover the original rank-one matrix. In particular, we show that our proposed algorithm is optimal when the set of revealed entries is given by an Erd\H{o}s-R\'enyi random graph. These results are then applied to the problem of classification from crowdsourced data under the assumption that while the majority of the workers are governed by the standard single-coin David-Skene model (i.e., they output the correct answer with a certain probability), some of the workers can deviate arbitrarily from this model. In particular, the "adversarial" workers could even make decisions designed to make the algorithm output an incorrect answer. Extensive experimental results show our algorithm for this problem, based on rank-one matrix completion with perturbations, outperforms all other state-of-the-art methods in such an adversarial scenario.},
  version = {1},
  keywords = {⛔ No INSPIRE recid found,FOS: Computer and information sciences,Machine Learning (cs.LG)},
  annotation = {16 citations (Semantic Scholar/arXiv) [2023-06-30]}
}

@inproceedings{ma_FaitCrowd_2015,
  title = {{{FaitCrowd}}: {{Fine Grained Truth Discovery}} for {{Crowdsourced Data Aggregation}}},
  shorttitle = {{{FaitCrowd}}},
  booktitle = {Proc. 21th {{ACM SIGKDD Int}}. {{Conf}}. {{Knowl}}. {{Discov}}. {{Data Min}}.},
  author = {Ma, Fenglong and Li, Yaliang and Li, Qi and Qiu, Minghui and Gao, Jing and Zhi, Shi and Su, Lu and Zhao, Bo and Ji, Heng and Han, Jiawei},
  date = {2015-08-10},
  series = {{{KDD}} '15},
  pages = {745--754},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/2783258.2783314},
  url = {https://doi.org/10.1145/2783258.2783314},
  urldate = {2021-11-02},
  abstract = {In crowdsourced data aggregation task, there exist conflicts in the answers provided by large numbers of sources on the same set of questions. The most important challenge for this task is to estimate source reliability and select answers that are provided by high-quality sources. Existing work solves this problem by simultaneously estimating sources' reliability and inferring questions' true answers (i.e., the truths). However, these methods assume that a source has the same reliability degree on all the questions, but ignore the fact that sources' reliability may vary significantly among different topics. To capture various expertise levels on different topics, we propose FaitCrowd, a fine grained truth discovery model for the task of aggregating conflicting data collected from multiple users/sources. FaitCrowd jointly models the process of generating question content and sources' provided answers in a probabilistic model to estimate both topical expertise and true answers simultaneously. This leads to a more precise estimation of source reliability. Therefore, FaitCrowd demonstrates better ability to obtain true answers for the questions compared with existing approaches. Experimental results on two real-world datasets show that FaitCrowd can significantly reduce the error rate of aggregation compared with the state-of-the-art multi-source aggregation approaches due to its ability of learning topical expertise from question content and collected answers.},
  isbn = {978-1-4503-3664-2},
  keywords = {⛔ No INSPIRE recid found,Crowdsourcing,source reliability,truth discovery},
  annotation = {169 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/SWJXBCMW/Ma et al. - 2015 - FaitCrowd Fine Grained Truth Discovery for Crowds.pdf}
}

@inproceedings{ma_Gradient_2018,
  title = {Gradient {{Descent}} for {{Sparse Rank-One Matrix Completion}} for {{Crowd-Sourced Aggregation}} of {{Sparsely Interacting Workers}}},
  booktitle = {Int. {{Conf}}. {{Mach}}. {{Learn}}.},
  author = {Ma, Yao and Olshevsky, Alexander and Szepesvari, Csaba and Saligrama, Venkatesh},
  date = {2018},
  pages = {3335--3344},
  publisher = {{PMLR}},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/MZ2TZNVK/Ma et al. - 2018 - Gradient Descent for Sparse Rank-One Matrix Comple.pdf}
}

@article{ma_Gradient_2020,
  title = {Gradient {{Descent}} for {{Sparse Rank-One Matrix Completion}} for {{Crowd-Sourced Aggregation}} of {{Sparsely Interacting Workers}}},
  author = {Ma, Yao and Olshevsky, Alex and Saligrama, Venkatesh and Szepesvari, Csaba},
  date = {2020},
  journaltitle = {J. Mach. Learn. Res.},
  volume = {21},
  number = {1},
  pages = {5245--5280},
  publisher = {{JMLR.org}},
  issn = {1532-4435},
  abstract = {We consider worker skill estimation for the single-coin Dawid-Skene crowdsourcing model. In practice, skill-estimation is challenging because worker assignments are sparse and irregular due to the arbitrary and uncontrolled availability of workers. We formulate skill estimation as a rank-one correlation-matrix completion problem, where the observed components correspond to observed label correlation between workers. We show that the correlation matrix can be successfully recovered and skills are identifiable if and only if the sampling matrix (observed components) does not have a bipartite connected component. We then propose a projected gradient descent scheme and show that skill estimates converge to the desired global optima for such sampling matrices. Our proof is original and the results are surprising in light of the fact that even the weighted rank-one matrix factorization problem is NP-hard in general. Next, we derive sample complexity bounds in terms of spectral properties of the signless Laplacian of the sampling matrix. Our proposed scheme achieves state-of-art performance on a number of real-world datasets.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found,distributed optimization,stochastic gradient descent}
}

@inproceedings{maas_Rectifier_2013,
  title = {Rectifier {{Nonlinearities Improve Neural Network Acoustic Models}}},
  booktitle = {Int. {{Conf}}. {{Mach}}. {{Learn}}.},
  author = {Maas, Andrew L. and Hannun, Awni Y. and Ng, Andrew Y.},
  date = {2013},
  volume = {30},
  pages = {3},
  abstract = {Deep neural network acoustic models produce substantial gains in large vocabulary continuous speech recognition systems. Emerging work with rectified linear (ReL) hidden units demonstrates additional gains in final system performance relative to more commonly used sigmoidal nonlinearities. In this work, we explore the use of deep rectifier networks as acoustic models for the 300 hour Switchboard conversational speech recognition task. Using simple training procedures without pretraining, networks with rectifier nonlinearities produce 2\% absolute reductions in word error rates over their sigmoidal counterparts. We analyze hidden layer representations to quantify differences in how ReL units encode inputs as compared to sigmoidal units. Finally, we evaluate a variant of the ReL unit with a gradient more amenable to optimization in an attempt to further improve deep rectifier networks.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@thesis{macarthur_LOOKING_2003,
  title = {{{LOOKING AT ADHD}}: {{A Personal Exploration}} of {{Attention Deficit}}/{{Hyperactivity Disorder}}},
  author = {MacArthur, Karen},
  date = {2003},
  journaltitle = {MIT},
  institution = {{MIT}},
  pagetotal = {1-120},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{macdonald_Gender_2001,
  title = {Gender {{Bias}} and {{Juvenile Justice Revisited}}: {{A Multiyear Analysis}}},
  author = {MacDonald, John M. and Chesney-Lind, Meda},
  date = {2001},
  journaltitle = {Crime Delinquency},
  issn = {00111287},
  doi = {10.1177/0011128701047002002},
  abstract = {This study presents a multiyear empirical examination of gender bias in the handling of juvenile court cases in Hawaii. Based on prior qualitative and quantitative data, it is hypothesized that once female juvenile offenders are found delinquent, they will be sanctioned more severely than male offenders by the juvenile court, holding other factors constant. Results from a series of analyses indicate significant differences between male and female juvenile justice outcomes, particularly for youth of color. Female offenders are more likely than male offenders to be handled informally at the early stages of the system, but the court's benevolence declines as girls move into the disposition stage. The implications of these findings for resolving inconsistencies in prior research are discussed. Also considered are policy implications with regard to congressional initiatives to de-emphasize the deinstitutionalization of status offenses and reduce concerns about minority overrepresentation in the juvenile justice system. \textcopyright{} 2001 Sage Publications, Inc.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {160 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{mackay_Practical_1992a,
  ids = {mackay_Practical_1992},
  title = {A {{Practical Bayesian Framework}} for {{Backpropagation Networks}}},
  author = {MacKay, David J. C.},
  date = {1992-05},
  journaltitle = {Neural Computation},
  volume = {4},
  number = {3},
  pages = {448--472},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/neco.1992.4.3.448},
  url = {https://direct.mit.edu/neco/article/4/3/448-472/5654},
  urldate = {2023-05-08},
  abstract = {A quantitative and practical Bayesian framework is described for learning of mappings in feedforward networks. The framework makes possible (1) objective comparisons between solutions using alternative network architectures, (2) objective stopping rules for network pruning or growing procedures, (3) objective choice of magnitude and type of weight decay terms or additive regularizers (for penalizing large weights, etc.), (4) a measure of the effective number of well-determined parameters in a model, (5) quantified estimates of the error bars on network parameters and on network output, and (6) objective comparisons with alternative learning and interpolation models such as splines and radial basis functions. The Bayesian "evidence" automatically embodies "Occam's razor," penalizing overflexible and overcomplex models. The Bayesian approach helps detect poor underlying assumptions in learning models. For learning models well matched to a problem, a good correlation between generalization ability and the Bayesian evidence is obtained.},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {2821 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/Y4EQGJU8/MacKay - 1992 - A Practical Bayesian Framework for Backpropagation.pdf}
}

@thesis{madani_Machine_2019,
  title = {Machine {{Learning Approaches Toward Diagnosis}} and {{Biomechanical Analysis}} of {{Cardiovascular Disease}} by {{Ali Madani}} a {{Dissertation Submitted}} in {{Partial Satisfaction}} of the {{Requirements}} for the {{Degree}} of {{Doctor}} of {{Philosophy}} in {{Engineering}} \textendash{} {{Applied Science An}}},
  author = {Madani, Ali},
  date = {2019},
  journaltitle = {Berkeley},
  institution = {{Berkeley}},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{magnotta_Measurement_1999,
  title = {Measurement of {{Brain Structures With Artificial Neural Networks}}: {{Two- And Three-Dimensional Applications}}},
  author = {Magnotta, V. A. and Heckel, D. and Andreasen, N. C. and Cizadlo, T. and Corson, P. W. and Ehrhardt, J. C. and Yuh, W. T.},
  date = {1999-06},
  journaltitle = {Radiology},
  volume = {211},
  number = {3},
  pages = {781--790},
  doi = {10.1148/radiology.211.3.r99ma07781},
  abstract = {PURPOSE: To evaluate the ability of an artificial neural network (ANN) to identify brain structures. This ANN was applied to postprocessed magnetic resonance (MR) images to segment various brain structures in both two- and three-dimensional applications. MATERIALS AND METHODS: An ANN was designed that learned from experience to define the corpus callosum, whole brain, caudate, and putamen. Manual segmentation was used as a training set for the ANN. The ANN was trained on two-thirds of the manually segmented images and was tested on the remaining one-third. The reliability of the ANN was compared against manual segmentations by two technicians. RESULTS: The ANN was able to identify the brain structures as readily and as well as did the two technicians. Reliability of the ANN compared with the technicians was 0.96 for the corpus callosum, 0.95 for the whole brain, 0.86 (right) and 0.93 (left) for the caudate, and 0.71 (right) and 0.88 (left) for the putamen. CONCLUSION: The ANN was able to identify the structures used in this study as well as did the two technicians. The ANN could do this much more rapidly and without rater drift. Several other cortical and subcortical structures could also be readily identified with this method.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {200 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{magnotta_Visualization_2000,
  title = {Visualization of {{Subthalamic Nuclei With Cortex Attenuated Inversion Recovery MR Imaging}}},
  author = {Magnotta, Vincent A. and Gold, Sherri and Andreasen, Nancy C. and Ehrhardt, James C. and Yuh, William T.C.},
  date = {2000-04},
  journaltitle = {NeuroImage},
  volume = {11},
  number = {4},
  pages = {341--346},
  issn = {10538119},
  doi = {10.1006/nimg.2000.0552},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811900905524},
  urldate = {2023-05-10},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {55 citations (Semantic Scholar/DOI) [2023-05-09]}
}

@article{majdi_Automated_2020,
  ids = {majdi_Robust_2019,majdi_automatedthalamicnucleisegmentationusingmultiplanarcascadedconvolutionalneuralnetworks_2020a},
  title = {Automated {{Thalamic Nuclei Segmentation Using Multi-Planar Cascaded Convolutional Neural Networks}}},
  author = {Majdi, Mohammad S. and Keerthivasan, Mahesh B. and Rutt, Brian K. and Zahr, Natalie M. and Rodriguez, Jeffrey J. and Saranathan, Manojkumar},
  date = {2020-11},
  journaltitle = {Magnetic Resonance Imaging},
  volume = {73},
  eprint = {1912.07209},
  eprinttype = {arxiv},
  eprintclass = {cs, eess, stat},
  pages = {45--54},
  issn = {0730725X},
  doi = {10.1016/j.mri.2020.08.005},
  url = {http://arxiv.org/abs/1912.07209},
  urldate = {2023-05-12},
  abstract = {A cascaded multi-planar scheme with a modified residual U-Net architecture was used to segment thalamic nuclei on conventional and white-matter-nulled (WMn) magnetization prepared rapid gradient echo (MPRAGE) data. A single network was optimized to work with images from healthy controls and patients with multiple sclerosis (MS) and essential tremor (ET), acquired at both 3T and 7T field strengths. Dice similarity coefficient and volume similarity index (VSI) were used to evaluate performance. Clinical utility was demonstrated by applying this method to study the effect of MS on thalamic nuclei atrophy. Segmentation of each thalamus into twelve nuclei was achieved in under a minute. For 7T WMn-MPRAGE, the proposed method outperforms current state-of-the-art on patients with ET with statistically significant improvements in Dice for five nuclei (increase in the range of 0.05-0.18) and VSI for four nuclei (increase in the range of 0.05-0.19), while performing comparably for healthy and MS subjects. Dice and VSI achieved using 7T WMn-MPRAGE data are comparable to those using 3T WMn-MPRAGE data. For conventional MPRAGE, the proposed method shows a statistically significant Dice improvement in the range of 0.14-0.63 over FreeSurfer for all nuclei and disease types. Effect of noise on network performance shows robustness to images with SNR as low as half the baseline SNR. Atrophy of four thalamic nuclei and whole thalamus was observed for MS patients compared to healthy control subjects, after controlling for the effect of parallel imaging, intracranial volume, gender, and age (p{$<$}0.004). The proposed segmentation method is fast, accurate, performs well across disease types and field strengths, and shows great potential for improving our understanding of thalamic nuclei involvement in neurological diseases.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing,Statistics - Machine Learning},
  annotation = {0 citations (Semantic Scholar/arXiv) [2023-05-12] 5 citations (Semantic Scholar/DOI) [2023-05-12]},
  file = {/Users/personal-macbook/Zotero/storage/XM7GLQ3U/Majdi et al. - 2020 - Automated Thalamic Nuclei Segmentation Using Multi.pdf;/Users/personal-macbook/Zotero/storage/ZFXXEPS7/Majdi et al. - 2020 - Automated thalamic nuclei segmentation using multi.pdf}
}

@inproceedings{majdi_Deep_2020,
  title = {Deep {{Learning Classification}} of {{Chest X-Ray Images}}},
  booktitle = {Southwest {{Symp}}. {{Image Anal}}. {{Interpret}}. {{SSIAI}}},
  author = {Majdi, Mohammad S. and Salman, Khalil N. and Morris, Michael F. and Merchant, Nirav C. and Rodriguez, Jeffrey J.},
  date = {2020-03},
  pages = {116--119},
  publisher = {{IEEE}},
  location = {{Albuquerque, NM, USA}},
  doi = {10.1109/SSIAI49293.2020.9094612},
  url = {https://ieeexplore.ieee.org/document/9094612/},
  urldate = {2022-11-21},
  eventtitle = {Southwest {{Symposium}} on {{Image Analysis}} and {{Interpretation}} ({{SSIAI}})},
  isbn = {978-1-72815-745-0},
  keywords = {\#nosource,⛔ No INSPIRE recid found,cardiomegaly,cardiomegaly.,chest X-ray,classification,deep learning,Diagnostic radiography,Diseases,Lung,Machine learning,Pathology,pulmonary nodule,Training,X-ray imaging},
  annotation = {4 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/FR54M67Y/Majdi et al. - 2020 - Deep Learning Classification of Chest X-Ray Images.pdf;/Users/personal-macbook/Zotero/storage/UVTW8T4B/9094612.html}
}

@inproceedings{majdi_DriveNet_2018,
  title = {Drive-{{Net}}: {{Convolutional Network}} for {{Driver Distraction Detection}}},
  booktitle = {2018 {{IEEE Southwest Symp}}. {{Image Anal}}. {{Interpret}}. {{SSIAI}}},
  author = {Majdi, Mohammed S. and Ram, Sundaresh and Gill, Jonathan T. and Rodriguez, Jeffrey J.},
  date = {2018-04},
  pages = {1--4},
  publisher = {{IEEE}},
  doi = {10.1109/SSIAI.2018.8470309},
  url = {https://ieeexplore.ieee.org/document/8470309/},
  isbn = {978-1-5386-6568-8},
  keywords = {\#nosource,⛔ No INSPIRE recid found,convolutional neural networks,driver distraction,driver distraction.,Image classification,random forest},
  annotation = {34 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{majdi_Laplacian_2015,
  ids = {majdi_Laplacian_2016},
  title = {Laplacian {{Mixture Model Point Based Registration}}},
  booktitle = {2015 9th {{Iran}}. {{Conf}}. {{Mach}}. {{Vis}}. {{Image Process}}. {{MVIP}}},
  author = {Majdi, Mohammad Sadegh and Fatemizadeh, Emad},
  date = {2015-11},
  pages = {57--60},
  publisher = {{IEEE}},
  location = {{Tehran, Iran}},
  doi = {10.1109/IranianMVIP.2015.7397504},
  url = {http://ieeexplore.ieee.org/document/7397504/},
  urldate = {2023-05-08},
  eventtitle = {2015 9th {{Iranian Conference}} on {{Machine Vision}} and {{Image Processing}} ({{MVIP}})},
  isbn = {978-1-4673-8539-8},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Affine,Alignment,Correspondence,Laplacian,Mixture model,Point base,Registration,Rigid},
  annotation = {1 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/5P32YW4V/Majdi and Fatemizadeh - 2015 - Laplacian mixture model point based registration.pdf}
}

@article{mak_Subcortical_2014,
  title = {Subcortical {{Atrophy Is Associated With Cognitive Impairment}} in {{Mild Parkinson Disease}}: {{A Combined Investigation}} of {{Volumetric Changes}}, {{Cortical Thickness}}, and {{Vertex-Based Shape Analysis}}},
  author = {Mak, E. and Bergsland, N. and Dwyer, M. G. and Zivadinov, R. and Kandiah, N.},
  date = {2014},
  journaltitle = {AJNR Am. J. Neuroradiol.},
  volume = {35},
  number = {12},
  pages = {2257--2264},
  publisher = {{Am Soc Neuroradiology}},
  doi = {10.3174/ajnr.A4055},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{makar_Formate_1975,
  title = {Formate {{Assay}} in {{Body Fluids}}: {{Application}} in {{Methanol Poisoning}}},
  shorttitle = {Formate Assay in Body Fluids},
  author = {Makar, A. B. and McMartin, K. E. and Palese, M. and Tephly, T. R.},
  date = {1975-06},
  journaltitle = {Biochem Med},
  volume = {13},
  number = {2},
  eprint = {1},
  eprinttype = {pmid},
  pages = {117--126},
  issn = {0006-2944},
  doi = {10.1016/0006-2944(75)90147-7},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Aldehyde Oxidoreductases,Animals,Body Fluids,Carbon Dioxide,Formates,Haplorhini,Humans,Hydrogen-Ion Concentration,Kinetics,Methanol,Methods,Pseudomonas},
  annotation = {160 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{malinin_Uncertainty_2020,
  title = {Uncertainty in {{Structured Prediction}}.},
  author = {Malinin, Andrey and Gales, Mark J. F.},
  date = {2020-05-28},
  url = {https://openreview.net/forum?id=V6CqWDCLQq5},
  urldate = {2022-07-04},
  abstract = {Uncertainty estimation is important for ensuring safety and robustness of AI systems, especially for high-risk applications. While much progress has recently been made in this area, most research...},
  langid = {english},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/6GR54QEA/forum.html}
}

@inproceedings{malinin_Uncertainty_2021,
  title = {Uncertainty in {{Gradient Boosting}} via {{Ensembles}}},
  author = {Malinin, Andrey and Prokhorenkova, Liudmila and Ustimenko, Aleksei},
  date = {2021-03-23},
  url = {https://openreview.net/forum?id=1Jv6b0Zq3qi},
  urldate = {2022-07-04},
  abstract = {For many practical, high-risk applications, it is essential to quantify uncertainty in a model's predictions to avoid costly mistakes. While predictive uncertainty is widely studied for neural...},
  eventtitle = {International {{Conference}} on {{Learning Representations}}},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/8FGH4C7X/Malinin et al. - 2021 - Uncertainty in Gradient Boosting via Ensembles.pdf;/Users/personal-macbook/Zotero/storage/9Q43W5XN/forum.html}
}

@inproceedings{mallah_Plant_2013,
  title = {Plant {{Leaf Classification Using Probabilistic Integration}} of {{Shape}}, {{Texture}} and {{Margin Features}}},
  booktitle = {Comput. {{Graph}}. {{Imaging}} 798 {{Signal Process}}. {{Pattern Recognit}}. {{Appl}}.},
  author = {Mallah, Charles and Cope, James and Orwell, James},
  date = {2013},
  publisher = {{ACTAPRESS}},
  location = {{Innsbruck, Austria}},
  doi = {10.2316/P.2013.798-098},
  url = {http://www.actapress.com/PaperInfo.aspx?paperId=455022},
  urldate = {2022-12-28},
  eventtitle = {Computer {{Graphics}} and {{Imaging}}},
  isbn = {978-0-88986-944-8},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {115 citations (Semantic Scholar/DOI) [2022-12-28]},
  file = {/Users/personal-macbook/Zotero/storage/XNULYYNQ/Mallah et al. - 2013 - Plant Leaf Classification using Probabilistic Inte.pdf}
}

@article{malykhin_Vivo_2010,
  title = {In {{Vivo Quantification}} of {{Hippocampal Subfields Using}} 4.7 {{T Fast Spin Echo Imaging}}},
  author = {Malykhin, N. V. and Lebel, R. M. and Coupland, N. J. and Wilman, A. H. and Carter, R.},
  date = {2010-01},
  journaltitle = {Neuroimage},
  volume = {49},
  number = {2},
  pages = {1224--1230},
  doi = {10.1016/j.neuroimage.2009.09.042},
  abstract = {Several neuropsychiatric disorders involving hippocampal structural changes have been studied extensively using volumetric magnetic resonance imaging (MRI). These studies have mostly measured total hippocampal volume while the present study aimed to delineate and measure hippocampal subfields within the whole hippocampus and subdivisions along its longitudinal axis. Images were acquired at 4.7 T in 11 healthy subjects (5 males and 6 females, aged 23-56 years), using a fast spin echo (FSE) sequence with 0.52 x 0.68 x 1.0 mm(3) native resolution, collecting 90 contiguous coronal slices. Subiculum, cornu ammonis (CA1-3), and dentate gyrus were traced manually within the hippocampal head, body, and tail. We reported volumes for the subfields and demonstrated differences in the distribution within the hippocampus and its parts. The biggest part of the dentate gyrus was located in the hippocampal body, following the hippocampal head and tail. In contrast, the hippocampal head had the largest part of CA1-3, following the hippocampal body and tail. The hippocampal tail had the smallest portion of the subiculum compared to hippocampal head and tail. Subfield volumes were consistent between hemispheres and showed distributions within the longitudinal subdivisions that were consistent with histological data. Direct measurements of subfield distribution along the longitudinal axis of the hippocampus may be more sensitive to detecting disease effects than total volume measures and the differential distribution of subfield volumes may aid in the interpretation of measurements obtained at lower field strength and spatial resolution.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {120 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{mancini_Robust_2018,
  title = {Robust {{Place Categorization With Deep Domain Generalization}}},
  author = {Mancini, Massimiliano and Bulo, Samuel Rota and Caputo, Barbara and Ricci, Elisa},
  date = {2018},
  journaltitle = {IEEE Robot. Autom. Lett.},
  issn = {23773766},
  doi = {10.1109/LRA.2018.2809700},
  abstract = {Traditional place categorization approaches in robot vision assume that training and test images have similar visual appearance. Therefore, any seasonal, illumination, and environmental changes typically lead to severe degradation in performance. To cope with this problem, recent works have been proposed to adopt domain adaptation techniques. While effective, these methods assume that some prior information about the scenario where the robot will operate is available at training time. Unfortunately, in many cases, this assumption does not hold, as we often do not know where a robot will be deployed. To overcome this issue, in this paper, we present an approach that aims at learning classification models able to generalize to unseen scenarios. Specifically, we propose a novel deep learning framework for domain generalization. Our method develops from the intuition that, given a set of different classification models associated to known domains (e.g., corresponding to multiple environments, robots), the best model for a new sample in the novel domain can be computed directly at test time by optimally combining the known models. To implement our idea, we exploit recent advances in deep domain adaptation and design a convolutional neural network architecture with novel layers performing a weighted version of batch normalization. Our experiments, conducted on three common datasets for robot place categorization, confirm the validity of our contribution.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Recognition,semantic scene understanding,visual learning}
}

@article{mang_Thalamus_2012,
  title = {Thalamus Segmentation Based on the Local Diffusion Direction: {{A}} Group Study: {{Thalamus Segmentation}}: {{A Group Study}}},
  shorttitle = {Thalamus Segmentation Based on the Local Diffusion Direction},
  author = {Mang, Sarah C. and Busza, Ania and Reiterer, Susanne and Grodd, Wolfgang and Klose, Uwe},
  date = {2012-01},
  journaltitle = {Magn. Reson. Med.},
  volume = {67},
  number = {1},
  pages = {118--126},
  issn = {07403194},
  doi = {10.1002/mrm.22996},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/mrm.22996},
  urldate = {2023-05-18},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,DTI,segmentation,validation},
  annotation = {51 citations (Semantic Scholar/DOI) [2023-05-17]},
  file = {/Users/personal-macbook/Zotero/storage/4U6TGRSM/Mang et al. - 2012 - Thalamus segmentation based on the local diffusion.pdf}
}

@article{manivanan_Automatic_2010,
  title = {Automatic {{Detection}} of {{Active Sweat Pores}} of {{Fingerprint Using Highpass}} and {{Correlation Filtering}}},
  author = {Manivanan, N. and Memon, S. and Balachandran, W.},
  date = {2010},
  journaltitle = {Electron. Lett.},
  issn = {00135194},
  doi = {10.1049/el.2010.1549},
  abstract = {A new technique is introduced for the automatic extraction and location of active sweat pores in a fingertip image. The combined technique includes highpass filtering followed by correlation. Results are presented for a fingertip image obtained using a high-resolution micro-capture camera. This automated method of detecting active sweat pores will help to implement liveness detection in existing fingerprint sensors. \textcopyright{} 2010 The Institution of Engineering and Technology.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {49 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{marneffe_Universal_2014,
  title = {Universal {{Stanford Dependencies}}: {{A Cross-Linguistic Typology}}},
  booktitle = {{{LREC}}},
  author = {Marneffe, Marie-Catherine De and Dozat, Timothy and Silveira, Natalia and Haverinen, Katri and Ginter, Filip and Nivre, Joakim and Manning, Christopher D.},
  date = {2014},
  volume = {14},
  pages = {4585--4592},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{martinez_Segmentation_,
  title = {Segmentation {{Certainty Through Uncertainty}}: {{Uncertainty-Refined Binary Volumetric Segmentation Under Multifactor Domain Shift}}},
  author = {Martinez, Carianne and Potter, Kevin M. and Smith, Matthew D. and Donahue, Emily A. and Collins, Lincoln and Korbin, John P. and Roberts, Scott A.},
  doi = {10.1109/CVPRW.2019.00066},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{martinez-ramirez_Cerebral_2014,
  title = {Cerebral {{Microbleeds}}: {{Overview}} and {{Implications}} in {{Cognitive Impairment}}},
  author = {Martinez-Ramirez, Sergi and Greenberg, Steven M. and Viswanathan, Anand},
  date = {2014-06},
  journaltitle = {Alzheimers. Res. Ther.},
  volume = {6},
  number = {3},
  pages = {33},
  doi = {10.1186/alzrt263},
  abstract = {Cerebral microbleeds (MBs) are small chronic brain hemorrhages which are likely caused by structural abnormalities of the small vessels of the brain. Owing to the paramagnetic properties of blood degradation products, MBs can be detected in vivo by using specific magnetic resonance imaging (MRI) sequences. Over the last decades, the implementation of these MRI sequences in both epidemiological and clinical studies has revealed MBs as a common finding in many different populations, including healthy individuals. Also, the topographic distribution of these MBs has been shown to be potentially associated with specific underlying vasculopathies. However, the clinical and prognostic significance of these small hemorrhages is still a matter of debate as well as a focus of extensive research. In this article, we aim to review the current knowledge on the pathophysiology and clinical implications of MBs, with special emphasis on the links between lobar MBs, cerebral amyloid angiopathy, and Alzheimer's disease.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {3 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{mathalon_Correction_1993,
  title = {Correction for {{Head Size}} in {{Brain-Imaging Measurements}}},
  author = {Mathalon, Daniel H. and Sullivan, Edith V. and Rawles, Jody M. and Pfefferbaum, Adolf},
  date = {1993},
  journaltitle = {Psychiatry Res. Neuroimaging},
  volume = {50},
  number = {2},
  pages = {121--139},
  issn = {09254927},
  doi = {10.1016/0925-4927(93)90016-B},
  abstract = {Structural brain-imaging measurements based on computed tomography (CT) or magnetic resonance imaging (MRI) are often corrected or adjusted for normal variation in head size. Some methods of head-size correction, such as the ventricle-brain ratio (VBR), are based on taking the brain structure size as a proportion of the estimated head size, while other methods have used a regression model to obtain head-size residualized structure measures. Recently, head-size correction was shown to result in less reliable volumetric measures of brain structures (Arndt et al., 1991). In the present study, MRI was used to examine the effects of head-size correction on the interrater reliability of volumetric measures of gray matter, white matter, and cerebrospinal fluid. Four raters independently scored MRI brain images from 26 subjects, generating separate estimates of head size and region of interest (ROI) size. Two methods were used to correct MRI values for differences in head size, one based on proportions and the other based on linear regression. Results confirmed that head-size correction did produce measures with lower reliability; however, further analysis based on classical measurement theory showed that the lower reliability was attributable not only to increased measurement error variance, but also to reduced true score variance. Subsequent analyses of criterion validity compared the raw (uncorrected) and head-size-corrected ROI measures in terms of their correlations with age in a sample of 43 normal control subjects, and in terms of their ability to differentiate schizophrenic patients (n = 22) from normal control subjects (n = 20). Results indicated that head-size correction often improved criterion validity, producing higher correlations with age and with diagnostic status than those produced by the raw measures. These findings suggest that head-size correction removes irrelevant true-score variance which reduces reliability yet improves the correlations with validity criteria such as age and diagnostic status. \textcopyright{} 1993.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,magnetic resonance imaging,schizophrenia,Ventricle-brain ratio},
  annotation = {230 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@report{matheny_Artificial_2019,
  title = {Artificial {{Intelligence}} in {{Health Care}}: {{The Hope}}, the {{Hype}}, the {{Promise}}, the {{Peril}}},
  author = {Matheny, Michael and Israni, Sonoo Thadaney and Ahmed, Mahnoor and Whicher, Danielle},
  date = {2019},
  journaltitle = {NAM Special Publication},
  abstract = {The emergence of artificial intelligence (AI) as a tool for better health care offers unprecedented opportunities to improve patient and clinical team outcomes, reduce costs, and impact population health. Examples include but are not limited to automation; providing patient, ``fRamily'' (friends and family unpaid caregivers), and health care professionals' information synthesis; and recommendations and visualization of information for shared decision making. While there have been a number of promising examples of AI applications in health care, we believe it is imperative to proceed with caution, else we may end up with user disillusionment and another AI winter, and/or further exacerbate existing health and technology driven disparities. The National Academy of Medicine's Special Publication: Artificial Intelligence in Health Care: The Hope, The Hype, The Promise, The Peril synthesizes current knowledge to offer a reference document for relevant health care stakeholders such as: AI model developers, clinical implementers, clinicians and patients, regula- tors, and policy makers, to name a few. It outlines the current and near-term AI solutions; highlights the challenges, limitations, and best practices for AI development, adoption, and maintenance; offers an overview of the legal and regulatory landscape for AI tools designed for health care application; priori- tizes the need for equity, inclusion, and a human rights lens for this work; and outlines key consider- ations for moving forward. The major theses are summarized in the section below.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{matsunaga_Image_2017,
  title = {Image {{Classification}} of {{Melanoma}}, {{Nevus}} and {{Seborrheic Keratosis}} by {{Deep Neural Network Ensemble}}},
  author = {Matsunaga, Kazuhisa and Hamada, Akira and Minagawa, Akane and Koga, Hiroshi},
  date = {2017-03},
  url = {http://arxiv.org/abs/1703.03108},
  abstract = {This short paper reports the method and the evaluation results of Casio and Shinshu University joint team for the ISBI Challenge 2017 - Skin Lesion Analysis Towards Melanoma Detection - Part 3: Lesion Classification hosted by ISIC. Our online validation score was 0.958 with melanoma classifier AUC 0.924 and seborrheic keratosis classifier AUC 0.993.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found},
  annotation = {148 citations (Semantic Scholar/arXiv) [2023-05-08]}
}

@article{matthay_Acute_2012,
  title = {The {{Acute Respiratory Distress Syndrome}}},
  author = {Matthay, Michael A. and Ware, Lorraine B. and Zimmerman, Guy A.},
  date = {2012-08},
  journaltitle = {J. Clin. Invest.},
  volume = {122},
  number = {8},
  eprint = {22850883},
  eprinttype = {pmid},
  pages = {2731--2740},
  publisher = {{J Clin Invest}},
  issn = {00219738},
  doi = {10.1172/JCI60331},
  abstract = {The acute respiratory distress syndrome (ARDS) is an important cause of acute respiratory failure that is often associated with multiple organ failure. Several clinical disorders can precipitate ARDS, including pneumonia, sepsis, aspiration of gastric contents, and major trauma. Physiologically, ARDS is characterized by increased permeability pulmonary edema, severe arterial hypoxemia, and impaired carbon dioxide excretion. Based on both experimental and clinical studies, progress has been made in understanding the mechanisms responsible for the pathogenesis and the resolution of lung injury, including the contribution of environmental and genetic factors. Improved survival has been achieved with the use of lung-protective ventilation. Future progress will depend on developing novel therapeutics that can facilitate and enhance lung repair.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{mazzara_Brain_2004,
  title = {Brain {{Tumor Target Volume Determination}} for {{Radiation Treatment Planning Through Automated MRI Segmentation}}},
  author = {Mazzara, Gloria P. and Velthuizen, Robert P. and Pearlman, James L. and Greenberg, Harvey M. and Wagner, Henry},
  date = {2004-05},
  journaltitle = {Int. J. Radiat. Oncol. Biol. Phys.},
  volume = {59},
  number = {1},
  pages = {300--312},
  doi = {10.1016/j.ijrobp.2004.01.026},
  abstract = {PURPOSE: To assess the effectiveness of two automated magnetic resonance imaging (MRI) segmentation methods in determining the gross tumor volume (GTV) of brain tumors for use in radiation therapy treatment planning. METHODS AND MATERIALS: Two automated MRI tumor segmentation methods (supervised k-nearest neighbors [kNN] and automatic knowledge-guided [KG]) were evaluated for their potential as ``cyber colleagues.'' This required an initial determination of the accuracy and variability of radiation oncologists engaged in the manual definition of the GTV in MRI registered with computed tomography images for 11 glioma patients. Three sets of contours were defined for each of these patients by three radiation oncologists. These outlines were compared directly to establish inter- and intraoperator variability among the radiation oncologists. A novel, probabilistic measurement of accuracy was introduced to compare the level of agreement among the automated MRI segmentations. The accuracy was determined by comparing the volumes obtained by the automated segmentation methods with the weighted average volumes prepared by the radiation oncologists. RESULTS: Intra- and inter-operator variability in outlining was found to be an average of 20\% +/- 15\% and 28\% +/- 12\%, respectively. Lowest intraoperator variability was found for the physician who spent the most time producing the contours. The average accuracy of the kNN segmentation method was 56\% +/- 6\% for all 11 cases, whereas that of the KG method was 52\% +/- 7\% for 7 of the 11 cases when compared with the physician contours. For the areas of the contours where the oncologists were in substantial agreement (i.e., the center of the tumor volume), the accuracy of kNN and KG was 75\% and 72\%, respectively. The automated segmentation methods were found to be least accurate in outlining at the edges of the tumor volume. CONCLUSIONS: The kNN method was able to segment all cases, whereas the KG method was limited to enhancing tumors and gliomas with clear enhancing edges and no cystic formation. Both methods undersegment the tumor volume when compared with the radiation oncologists and performed within the variability of the contouring performed by experienced radiation oncologists based on the same data.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {209 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@thesis{mcclosky_Any_2010,
  title = {Any {{Domain Parsing}}: {{Automatic Domain Adaptation}} for {{Natural Language Parsing}}},
  author = {Mcclosky, David},
  date = {2010},
  institution = {{Brown University}},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{mcclure_Robustly_2016,
  title = {Robustly {{Representing Uncertainty}} in {{Deep Neural Networks Through Sampling}}},
  author = {McClure, Patrick and Kriegeskorte, Nikolaus},
  date = {2016-11},
  journaltitle = {arXiv},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{mcdougall_Comparison_2003,
  title = {A {{Comparison}} of {{International}} and {{Domestic New Ventures}}},
  shorttitle = {J. {{Int}}. {{Entrepreneurship}}},
  author = {McDougall, Patricia P. and Oviatt, Benjamin M. and Shrader, Rodney C.},
  date = {2003},
  journaltitle = {J. Int. Entrep.},
  volume = {1},
  number = {1},
  pages = {59--82},
  issn = {15707385},
  doi = {10.1023/A:1023246622972},
  url = {http://link.springer.com/10.1023/A:1023246622972},
  urldate = {2023-05-08},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {581 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{mcdougall_Explaining_1994,
  title = {Explaining the {{Formation}} of {{International New Ventures}}: {{The Limits}} of {{Theories From International Business Research}}},
  author = {McDougall, Patricia Phillips and Shane, Scott and Oviatt, Benjamin M.},
  date = {1994-11},
  journaltitle = {J Bus Ventur.},
  volume = {9},
  number = {6},
  pages = {469--487},
  doi = {10.1016/0883-9026(94)90017-5},
  abstract = {International new ventures (INVs) represent a growing and important type of start-up. An INV is defined as a business organization that, from inception, seeks to derive significant competitive advantage from the use of resources and the sale of outputs in multiple countries (Oviatt and McDougall 1994). Their increasing prevalence and important role in international competition indicates a need for greater understanding of these new ventures (Oviatt and McDougall 1994). Logitech, as described in a case study by Alahuhta (1990), is a vivid example of an INV. Its founders were from two different countries and had a global vision for the company from its inception. The venture, which produces peripheral devices for personal computers, established headquarters in both Switzerland and the U.S. Manufacturing and R\&D were split between the U.S. and Switzerland, and then quickly spread to Taiwan and Ireland. The venture's first commercial contract was with a Japanese company. Using 24 case studies of INVs, we found that their formation process is not explained by existing theories from the field of international business. Specifically, neither monopolistic advantage theory, product cycle theory, stage theory of internationalization, oligopolistic reaction theory, nor internalization theory can explain the formation process of INVs. These theories fail because they assume that firms become international long after they have been formed, and they therefore highlight large, mature firms. They also focus too much on the firm level and largely ignore the individual and small group level of analysis (i.e., the entrepreneur and his or her network of business alliances). We propose that an explanation for the formation process of INVs must answer three questions: (1) who are the founders of INVs? (2) why do these entrepreneurs choose to compete internationally rather than just in their home countries? and (3) what form do their international business activities take? Who are the founders of INVs? We argue that founders of INVs are individuals who see opportunities from establishing ventures that operate across national borders. They are ``alert'' to the possibilities of combining resources from different national markets because of the competencies (networks, knowledge, and background) that they have developed from their earlier activities. Following the logic of the resource-based view of the firm, we argue that the possession of these competencies is not matched by other entrepreneurs. Only the entrepreneur possessing these competencies is able to combine a particular set of resources across national borders and form a given INV. Why do these entrepreneurs choose to compete internationally rather than just in their home countries? The founders of INVs recognize they must create international business competencies from the time of venture formation. Otherwise, the venture may become path-dependent on the development of domestic competencies and the entrepreneur will find it difficult to change strategic direction when international expansion eventually becomes necessary. As the founder of one INV explained, ``The advantage of starting internationally is that you establish an international spirit from the very beginning'' (Mamis 1989:38). What form do their international business activities take? Founders of INVs prefer to use hybrid structures (i.e., strategic alliances and networks) for their international activities as a way to overcome the usual poverty of resources at the time of start-up. This study has important implications for the practice of management. In financing decisions relating to INVs, venture capitalists and other venture financiers should look for entrepreneurs who have a global vision, international business competence, and an established international network. When entrepreneurs start INVs they should create hybrid structures to preserve scarce resources. Finally, given the path-dependence of competence development, founders of new ventures should consider whether establishing a domestic new venture with plans to later internationalize will be as successful a strategy as establishing a new venture that is international from inception.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {1763 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{mcdougall_International_2000,
  title = {International {{Entrepreneurship}}: {{The Intersection}} of {{Two Research Paths}}},
  author = {McDougall, Patricia Phillips and Oviatt, Benjamin M.},
  date = {2000-10},
  journaltitle = {AMJ},
  volume = {43},
  number = {5},
  pages = {902--906},
  publisher = {{Academy of Management}},
  doi = {10.2307/1556418},
  abstract = {Reflecting the internationalization of the marketplace and the increasing prominence of entrepreneurial firms in the global economy, the research paths of international business and entrepreneurship are intersecting with increasing frequency. International business researchers are broadening their traditional focus on large multinational companies to also include entrepreneurial firms in their research agendas. Cross-border business activity is of increasing interest to entrepreneurship researchers, and accelerated internationalization is being observed in even the smallest and newest organizations. This Special Research Forum on International Entrepreneurship reflects the fusion of these two areas and the developing worldwide academic interest in this topic.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{mckinley_PoolingFree_2018,
  title = {Pooling-{{Free Fully Convolutional Networks With Dense Skip Connections}} for {{Semantic Segmentation}}, {{With Application}} to {{Brain Tumor Segmentation}}},
  booktitle = {Brainlesion {{Glioma Mult}}. {{Scler}}. {{Stroke Trauma}}. {{Brain Inj}}.},
  author = {McKinley, Richard and Jungo, Alain and Wiest, Roland and Reyes, Mauricio},
  date = {2018},
  pages = {169--177},
  publisher = {{Springer International Publishing}},
  doi = {10.1007/978-3-319-75238-9_15},
  abstract = {Segmentation of medical images requires multi-scale information, combining local boundary detection with global context. State-of-the-art convolutional neural network (CNN) architectures for semantic segmentation are often composed of a downsampling path which computes features at multiple scales, followed by an upsampling path, required to recover those features at the same scale as the input image. Skip connections allow features discovered in the downward path to be integrated in the upward path. The downsampling mechanism is typically a pooling operation. However, pooling was introduced in CNNs to enable translation invariance, which is not desirable in segmentation tasks. For this reason, we propose an architecture, based on the recently proposed Densenet, for semantic segmentation, in which pooling has been replaced with dilated convolutions. We also present a variant approach, used in the 2017 BRATS challenge, in which a cascade of densely connected nets is used to first exclude non-brain tissue, and then segment tumor structures. We present results on the validation dataset of the Multimodal Brain Tumor Segmentation Challenge 2017.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{mehta_Propagating_2019,
  title = {Propagating {{Uncertainty Across Cascaded Medical Imaging Tasks}} for {{Improved Deep Learning Inference}}},
  booktitle = {Lect. {{Notes Comput}}. {{Sci}}.},
  author = {Mehta, Raghav and Christinck, Thomas and Nair, Tanya and Lemaitre, Paul and Arnold, Douglas and Arbel, Tal},
  date = {2019-10},
  volume = {11840 LNCS},
  pages = {23--32},
  issn = {16113349},
  doi = {10.1007/978-3-030-32689-0_3},
  abstract = {Although deep networks have been shown to perform very well on a variety of tasks, inference in the presence of pathology in medical images presents challenges to traditional networks. Given that medical image analysis typically requires a sequence of inference tasks to be performed (e.g. registration, segmentation), this results in an accumulation of errors over the sequence of deterministic outputs. In this paper, we explore the premise that, by embedding uncertainty estimates across cascaded inference tasks, the final prediction results should improve over simply cascading the deterministic classification results or performing inference in a single stage. Specifically, we develop a deep learning framework that propagates voxel-based uncertainty measures (e.g. Monte Carlo (MC) dropout sample variance) across inference tasks in order to improve the detection and segmentation of focal pathologies (e.g. lesions, tumours) in brain MR images. We apply the framework to two different contexts. First, we demonstrate that propagating multiple sclerosis T2 lesion segmentation results along with their associated uncertainty measures improves subsequent T2 lesion detection accuracy when evaluated on a proprietary large-scale, multi-site, clinical trial dataset. Second, we show how by propagating uncertainties associated with a regressed 3D MRI volume as an additional input to a follow-on brain tumour segmentation task, one can improve segmentation results on the publicly available BraTS-2018 dataset.},
  isbn = {978-3-030-32688-3},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{mehta_RSnet_2018,
  title = {{{RS-net}}: {{Regression-Segmentation}} 3d {{CNN}} for {{Synthesis}} of {{Full Resolution Missing Brain Mri}} in the {{Presence}} of {{Tumours}}},
  booktitle = {Lect. {{Notes Comput}}. {{Sci}}.},
  author = {Mehta, Raghav and Arbel, Tal},
  date = {2018},
  issn = {16113349},
  doi = {10.1007/978-3-030-00536-8_13},
  abstract = {Accurate synthesis of a full 3D MR image containing tumours from available MRI (e.g. to replace an image that is currently unavailable or corrupted) would provide a clinician as well as downstream inference methods with important complementary information for disease analysis. In this paper, we present an end-to-end 3D convolution neural network that takes a set of acquired MR image sequences (e.g. T1, T2, T1ce) as input and concurrently performs (1) regression of the missing full resolution 3D MRI (e.g. FLAIR) and (2) segmentation of the tumour into subtypes (e.g. enhancement, core). The hypothesis is that this would focus the network to perform accurate synthesis in the area of the tumour. Experiments on the BraTS 2015 and 2017 datasets [1] show that: (1) the proposed method gives better performance than state-of-the art methods in terms of established global evaluation metrics (e.g. PSNR), (2) replacing real MR volumes with the synthesized MRI does not lead to significant degradation in tumour and sub-structure segmentation accuracy. The system further provides uncertainty estimates based on Monte Carlo (MC) dropout [11] for the synthesized volume at each voxel, permitting quantification of the system's confidence in the output at each location.},
  isbn = {978-3-030-00535-1},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Brain MRI,Deep learning,Image synthesis}
}

@inproceedings{mehta_Uncertainty_2020,
  title = {Uncertainty {{Evaluation Metric}} for {{Brain Tumour Segmentation}}},
  author = {Mehta, Raghav and Filos, Angelos and Gal, Yarin and Arbel, Tal},
  date = {2020-06-26},
  url = {https://openreview.net/forum?id=H-PvDNIex},
  urldate = {2022-07-04},
  abstract = {Developing a metric to evaluate uncertainties produced for the task of brain tumour segmentation},
  eventtitle = {Medical {{Imaging}} with {{Deep Learning}}},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/8U9TFLIG/Mehta et al. - 2020 - Uncertainty Evaluation Metric for Brain Tumour Seg.pdf;/Users/personal-macbook/Zotero/storage/MD8YMZJS/forum.html}
}

@article{meijerink_Uncertainty_2020,
  title = {Uncertainty {{Estimation}} for {{Classification}} and {{Risk Prediction}} on {{Medical Tabular Data}}},
  author = {Meijerink, Lotta and Cin\`a, Giovanni and Tonutti, Michele},
  date = {2020-04},
  url = {http://arxiv.org/abs/2004.05824},
  abstract = {In a data-scarce field such as healthcare, where models often deliver predictions on patients with rare conditions, the ability to measure the uncertainty of a model's prediction could potentially lead to improved effectiveness of decision support tools and increased user trust. This work advances the understanding of uncertainty estimation for classification and risk prediction on medical tabular data, in a two-fold way. First, we expand and refine the set of heuristics to select an uncertainty estimation technique, introducing tests for clinically-relevant scenarios such as generalization to uncommon pathologies, changes in clinical protocol and simulations of corrupted data. We furthermore differentiate these heuristics depending on the clinical use-case. Second, we observe that ensembles and related techniques perform poorly when it comes to detecting out-of-domain examples, a critical task which is carried out more successfully by auto-encoders. These remarks are enriched by considerations of the interplay of uncertainty estimation with class imbalance, post-modeling calibration and other modeling procedures. Our findings are supported by an array of experiments on toy and real-world data.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{melendez_Automated_2016,
  title = {An {{Automated Tuberculosis Screening Strategy Combining X-Ray-Based Computer-Aided Detection}} and {{Clinical Information}}},
  author = {Melendez, Jaime and S\'anchez, Clara I. and Philipsen, Rick H. H. M. and Maduskar, Pragnya and Dawson, Rodney and Theron, Grant and Dheda, Keertan and Van Ginneken, Bram},
  date = {2016-04-29},
  journaltitle = {Sci Rep},
  volume = {6},
  number = {1},
  pages = {25265},
  issn = {2045-2322},
  doi = {10.1038/srep25265},
  url = {https://www.nature.com/articles/srep25265},
  urldate = {2023-05-12},
  abstract = {Abstract             Lack of human resources and radiological interpretation expertise impair tuberculosis (TB) screening programmes in TB-endemic countries. Computer-aided detection (CAD) constitutes a viable alternative for chest radiograph (CXR) reading. However, no automated techniques that exploit the additional clinical information typically available during screening exist. To address this issue and optimally exploit this information, a machine learning-based combination framework is introduced. We have evaluated this framework on a database containing 392 patient records from suspected TB subjects prospectively recruited in Cape Town, South Africa. Each record comprised a CAD score, automatically computed from a CXR and 12 clinical features. Comparisons with strategies relying on either CAD scores or clinical information alone were performed. Our results indicate that the combination framework outperforms the individual strategies in terms of the area under the receiving operating characteristic curve (0.84 versus 0.78 and 0.72), specificity at 95\% sensitivity (49\% versus 24\% and 31\%) and negative predictive value (98\% versus 95\% and 96\%). Thus, it is believed that combining CAD and clinical information to estimate the risk of active disease is a promising tool for TB screening.},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {98 citations (Semantic Scholar/DOI) [2023-05-12]},
  file = {/Users/personal-macbook/Zotero/storage/H3PFM6S7/Melendez et al. - 2016 - An automated tuberculosis screening strategy combi.pdf}
}

@article{meliones_Saving_2000,
  title = {Saving {{Money}}, {{Saving Lives}}},
  author = {Meliones, J.},
  date = {2000-11},
  journaltitle = {Harv. Bus. Rev.},
  volume = {78},
  number = {6},
  pages = {57--62,64,66--67},
  abstract = {In 1996, Duke Children's Hospital was in serious trouble. Its \$11 million annual operating loss had forced administrators to make cutbacks. As a result, some caregivers felt that the quality of care had deteriorated. Parents' complaints were on the rise. Frustrated staff members were quitting. In this article, Jon Meliones, DCH's chief medical director, candidly describes how his debt-ridden hospital transformed itself into a vibrant and profitable one. The problem, he realized, was that each group in DCH was focusing only on its individual mission. Doctors and nurses wanted to restore their patients to health; they didn't want to have to think about costs. Hospital administrators, for their part, were focused only on controlling wildly escalating health care costs. To keep DCH afloat, clinicians and administrators needed to work together. By listening to staff concerns, turning reams of confusing data into useful information, taking a fresh approach to teamwork, and using the balanced scorecard method, Meliones and his colleagues brought DCH back to life. Developing and implementing the balanced scorecard approach wasn't easy: it took a pilot project, a top-down reorganization, development of a customized information system, and systematic work redesign. But their efforts paid off. Customer satisfaction ratings jumped 18\%. Improvements to internal business processes reduced the average length of stay 21\% while the readmission rate fell from 7\% to 3\%. The cost per patient dropped nearly \$5,000. And DCH recorded profits of \$4 million in 2000. This first-person account is required reading for any executive seeking to revitalize a sagging organization. Meliones shares the operating principles DCH followed to become a thriving business.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{menze_Multimodal_2015a,
  ids = {menze_Multimodal_2015},
  title = {The {{Multimodal Brain Tumor Image Segmentation Benchmark}} ({{BRATS}})},
  author = {Menze, Bjoern H. and Jakab, Andras and Bauer, Stefan and Kalpathy-Cramer, Jayashree and Farahani, Keyvan and Kirby, Justin and Burren, Yuliya and Porz, Nicole and Slotboom, Johannes and Wiest, Roland and Lanczi, Levente and Gerstner, Elizabeth and Weber, Marc-Andre and Arbel, Tal and Avants, Brian B. and Ayache, Nicholas and Buendia, Patricia and Collins, D. Louis and Cordier, Nicolas and Corso, Jason J. and Criminisi, Antonio and Das, Tilak and Delingette, Herve and Demiralp, Cagatay and Durst, Christopher R. and Dojat, Michel and Doyle, Senan and Festa, Joana and Forbes, Florence and Geremia, Ezequiel and Glocker, Ben and Golland, Polina and Guo, Xiaotao and Hamamci, Andac and Iftekharuddin, Khan M. and Jena, Raj and John, Nigel M. and Konukoglu, Ender and Lashkari, Danial and Mariz, Jose Antonio and Meier, Raphael and Pereira, Sergio and Precup, Doina and Price, Stephen J. and Raviv, Tammy Riklin and Reza, Syed M. S. and Ryan, Michael and Sarikaya, Duygu and Schwartz, Lawrence and Shin, Hoo-Chang and Shotton, Jamie and Silva, Carlos A. and Sousa, Nuno and Subbanna, Nagesh K. and Szekely, Gabor and Taylor, Thomas J. and Thomas, Owen M. and Tustison, Nicholas J. and Unal, Gozde and Vasseur, Flor and Wintermark, Max and Ye, Dong Hye and Zhao, Liang and Zhao, Binsheng and Zikic, Darko and Prastawa, Marcel and Reyes, Mauricio and Van Leemput, Koen},
  date = {2015-10},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {34},
  number = {10},
  pages = {1993--2024},
  issn = {0278-0062, 1558-254X},
  doi = {10.1109/TMI.2014.2377694},
  url = {http://ieeexplore.ieee.org/document/6975210/},
  urldate = {2023-05-08},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Benchmark,Brain,Image segmentation,MRI,Oncology/tumor},
  annotation = {3525 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/U53W5ASY/Menze et al. - 2015 - The Multimodal Brain Tumor Image Segmentation Benc.pdf}
}

@inproceedings{menze_Object_2015,
  title = {Object {{Scene Flow}} for {{Autonomous Vehicles}}},
  booktitle = {Proc. {{IEEE Comput}}. {{Soc}}. {{Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}.},
  author = {Menze, Moritz and Geiger, Andreas},
  date = {2015},
  issn = {10636919},
  doi = {10.1109/CVPR.2015.7298925},
  url = {http://hci.iwr.uni-heidelberg.de/Benchmarks/},
  abstract = {This paper proposes a novel model and dataset for 3D scene flow estimation with an application to autonomous driving. Taking advantage of the fact that outdoor scenes often decompose into a small number of independently moving objects, we represent each element in the scene by its rigid motion parameters and each superpixel by a 3D plane as well as an index to the corresponding object. This minimal representation increases robustness and leads to a discrete-continuous CRF where the data term decomposes into pairwise potentials between superpixels and objects. Moreover, our model intrinsically segments the scene into its constituting dynamic components. We demonstrate the performance of our model on existing benchmarks as well as a novel realistic dataset with scene flow ground truth. We obtain this dataset by annotating 400 dynamic scenes from the KITTI raw data collection using detailed 3D CAD models for all vehicles in motion. Our experiments also reveal novel challenges which cannot be handled by existing methods.},
  isbn = {978-1-4673-6964-0},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{mesko_Will_2018,
  title = {Will {{Artificial Intelligence Solve}} the {{Human Resource Crisis}} in {{Healthcare}}?},
  author = {Mesk\'o, Bertalan and Het\'enyi, Gergely and Gyorffy, Zsuzsanna},
  date = {2018},
  journaltitle = {BMC Health Serv. Res.},
  eprint = {30001717},
  eprinttype = {pmid},
  issn = {14726963},
  doi = {10.1186/s12913-018-3359-4},
  abstract = {Artificial intelligence (AI) has the potential to ease the human resources crisis in healthcare by facilitating diagnostics, decision-making, big data analytics and administration, among others. For this we must first tackle the technological, ethical and legal obstacles. The human resource crisis is widening worldwide, and it is obvious that it is not possible to provide care without workforce. How can disruptive technologies in healthcare help solve the variety of human resource problems? Will technology empower physicians or replace them? How can the medical curriculum, including post-graduate education prepare professionals for the meaningful use of technology? These questions have been growing for decades, and the promise of disruptive technologies filling them is imminent with digital health becoming widespread. Authors of this essay argue that AI might not only fill the human resources gap, but also raises ethical questions we need to deal with today. While there are even more questions to address, our stand is that AI is not meant to replace caregivers, but those who use AI will probably replace those who don't. And it is possible to prepare for that.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Artificial intelligence,Digital health,Healthcare,Human resources,Medicine,Physicians}
}

@article{mettler_Radiologic_2009,
  title = {Radiologic and {{Nuclear Medicine Studies}} in the {{United States}} and {{Worldwide}}: {{Frequency}}, {{Radiation Dose}}, and {{Comparison With Other Radiation Sources}}\textemdash 1950\textendash 2007},
  shorttitle = {Radiologic and {{Nuclear Medicine Studies}} in the {{United States}} and {{Worldwide}}},
  author = {Mettler, Fred A. and Bhargavan, Mythreyi and Faulkner, Keith and Gilley, Debbie B. and Gray, Joel E. and Ibbott, Geoffrey S. and Lipoti, Jill A. and Mahesh, Mahadevappa and McCrohan, John L. and Stabin, Michael G. and Thomadsen, Bruce R. and Yoshizumi, Terry T.},
  date = {2009-11},
  journaltitle = {Radiology},
  volume = {253},
  number = {2},
  pages = {520--531},
  publisher = {{Radiological Society of North America}},
  issn = {0033-8419},
  doi = {10.1148/radiol.2532082010},
  url = {https://pubs.rsna.org/doi/10.1148/radiol.2532082010},
  urldate = {2022-11-21},
  abstract = {The U.S. National Council on Radiation Protection and Measurements and United Nations Scientific Committee on Effects of Atomic Radiation each conducted respective assessments of all radiation sources in the United States and worldwide. The goal of this article is to summarize and combine the results of these two publicly available surveys and to compare the results with historical information. In the United States in 2006, about 377 million diagnostic and interventional radiologic examinations and 18 million nuclear medicine examinations were performed. The United States accounts for about 12\% of radiologic procedures and about one-half of nuclear medicine procedures performed worldwide. In the United States, the frequency of diagnostic radiologic examinations has increased almost 10-fold (1950\textendash 2006). The U.S. per-capita annual effective dose from medical procedures has increased about sixfold (0.5 mSv [1980] to 3.0 mSv [2006]). Worldwide estimates for 2000\textendash 2007 indicate that 3.6 billion medical procedures with ionizing radiation (3.1 billion diagnostic radiologic, 0.5 billion dental, and 37 million nuclear medicine examinations) are performed annually. Worldwide, the average annual per-capita effective dose from medicine (about 0.6 mSv of the total 3.0 mSv received from all sources) has approximately doubled in the past 10\textendash 15 years. \textcopyright{} RSNA, 2009},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {758 citations (Semantic Scholar/DOI) [2022-11-20]},
  file = {/Users/personal-macbook/Zotero/storage/3FGVGK5S/19789227.html}
}

@article{miao_RBoost_2016,
  title = {{{RBoost}}: {{Label Noise-Robust Boosting Algorithm Based}} on a {{Nonconvex Loss Function}} and the {{Numerically Stable Base Learners}}},
  shorttitle = {{{RBoost}}},
  author = {Miao, Qiguang and Cao, Ying and Xia, Ge and Gong, Maoguo and Liu, Jiachen and Song, Jianfeng},
  date = {2016-11},
  journaltitle = {IEEE Trans. Neural Netw. Learning Syst.},
  volume = {27},
  number = {11},
  pages = {2216--2228},
  issn = {2162-237X, 2162-2388},
  doi = {10.1109/TNNLS.2015.2475750},
  url = {https://ieeexplore.ieee.org/document/7273923/},
  urldate = {2022-12-28},
  keywords = {⛔ No INSPIRE recid found,AdaBoost,adaptive Newton step,Algorithm design and analysis,antinoise,Boosting,Estimation,loss function,Noise,Noise measurement,Robustness,Training},
  annotation = {71 citations (Semantic Scholar/DOI) [2022-12-28]},
  file = {/Users/personal-macbook/Zotero/storage/EB64FRVE/Miao et al. - 2016 - RBoost Label Noise-Robust Boosting Algorithm Base.pdf}
}

@article{micle_Legal_2013,
  title = {Legal and {{Extralegal Factors Influencing Judge}}'s {{Penal Decisions}}},
  author = {Micle, Mihai Ioan and Gabriel, Oancea and S\u{a}ucan, Doina \c{S}tefana},
  date = {2013},
  journaltitle = {Procedia - Soc. Behav. Sci.},
  issn = {18770428},
  doi = {10.1016/j.sbspro.2013.04.378},
  abstract = {The current study aims to identify legal and extralegal factors that might influence judges' penal decision in criminal cases. It the same time, it intends to determine how the imposed penalties effect on prisons overcrowding, on ensuring public safety protection, as well as on solving related problems faced by offenders. Our study showed that judges perceive the decision process as being mainly based on a rational approach, minimizing or even denying an external influence from extralegal factors, while being interested in accessing personal data like offender's personality, psychosocial identity, education or economic status. Hence, our study may represents a starting point for exploring the mechanism underlying judicial decision, as a prerequisite for improving sentence's predictability.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {5 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{mier_Lysosomal_1975,
  title = {Lysosomal {{Hydrolases}} of the {{Epidermis}}. {{I}}. {{Glycosidases}}},
  author = {Mier, P. D. and family=Hurk, given=J. J., prefix=van den, useprefix=true},
  date = {1975-07},
  journaltitle = {Br J Dermatol},
  volume = {93},
  number = {1},
  eprint = {30},
  eprinttype = {pmid},
  pages = {1--10},
  issn = {0007-0963},
  doi = {10.1111/j.1365-2133.1975.tb06468.x},
  abstract = {Seven distinct glycosidases (EC 3.2) have been characterized in guinea-pig epidermis. Their properties indicate them to be of lysosomal origin. The 'profile' of the epidermal glycosidases is significantly different from that reported for whole skin, the activities of beta-galactosidase and beta-acetylglucosaminidase being very high and those of the remaining enzymes relatively low in epidermis.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Acetylglucosaminidase,Animals,Galactosidases,Glycoside Hydrolases,Guinea Pigs,Hydrogen-Ion Concentration,Kinetics,Lysosomes,Skin},
  annotation = {1 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{milletari_HoughCNN_2017,
  ids = {milletari_houghcnndeeplearningsegmentationdeepbrainregionsmriultrasound_2017},
  title = {Hough-{{CNN}}: {{Deep Learning}} for {{Segmentation}} of {{Deep Brain Regions}} in {{MRI}} and {{Ultrasound}}},
  shorttitle = {Hough-{{Cnn}}},
  author = {Milletari, Fausto and Ahmadi, Seyed-Ahmad and Kroll, Christine and Plate, Annika and Rozanski, Verena and Maiostre, Juliana and Levin, Johannes and Dietrich, Olaf and Ertl-Wagner, Birgit and B\"otzel, Kai and Navab, Nassir},
  date = {2017-11},
  journaltitle = {Computer Vision and Image Understanding},
  volume = {164},
  pages = {92--102},
  issn = {10773142},
  doi = {10.1016/j.cviu.2017.04.002},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1077314217300620},
  urldate = {2023-05-12},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,thalamus},
  annotation = {307 citations (Semantic Scholar/DOI) [2023-05-12]},
  file = {/Users/personal-macbook/Zotero/storage/ZJXRYWWE/Milletari et al. - 2017 - Hough-CNN Deep learning for segmentation of deep .pdf}
}

@inproceedings{milletari_VNet_2016,
  title = {V-{{Net}}: {{Fully Convolutional Neural Networks}} for {{Volumetric Medical Image Segmentation}}},
  booktitle = {Proc. - 2016 4th {{Int}}. {{Conf}}. {{3D Vis}}. {{3DV}} 2016},
  author = {Milletari, Fausto and Navab, Nassir and Ahmadi, Seyed Ahmad},
  date = {2016},
  doi = {10.1109/3DV.2016.79},
  abstract = {Convolutional Neural Networks (CNNs) have been recently employed to solve problems from both the computer vision and medical image analysis fields. Despite their popularity, most approaches are only able to process 2D images while most medical data used in clinical practice consists of 3D volumes. In this work we propose an approach to 3D image segmentation based on a volumetric, fully convolutional, neural network. Our CNN is trained end-to-end on MRI volumes depicting prostate, and learns to predict segmentation for the whole volume at once. We introduce a novel objective function, that we optimise during training, based on Dice coefficient. In this way we can deal with situations where there is a strong imbalance between the number of foreground and background voxels. To cope with the limited number of annotated volumes available for training, we augment the data applying random non-linear transformations and histogram matching. We show in our experimental evaluation that our approach achieves good performances on challenging test data while requiring only a fraction of the processing time needed by other previous methods.},
  isbn = {978-1-5090-5407-7},
  keywords = {\#nosource,⛔ No INSPIRE recid found,convolutional neural networks,Deep learning,machine learning,prostate,segmentation}
}

@thesis{milutinovic_Automatic_2019,
  title = {Towards {{Automatic Machine Learning Pipeline Design}}},
  author = {Milutinovic, Mitar},
  date = {2019},
  journaltitle = {Berkeley},
  institution = {{Berkeley}},
  pagetotal = {105},
  keywords = {\#nosource,⛔ No INSPIRE recid found,algorithms,learning algorithms,machine learning,programs}
}

@article{minaeian_Effective_2018,
  title = {Effective and {{Efficient Detection}} of {{Moving Targets From}} a {{UAV}}'s {{Camera}}},
  author = {Minaeian, Sara and Liu, Jian and Son, Young Jun},
  date = {2018},
  journaltitle = {IEEE Trans. Intell. Transp. Syst.},
  issn = {15249050},
  doi = {10.1109/TITS.2017.2782790},
  abstract = {Accurate and fast detection of the moving targets from a moving camera are an important yet challenging problem, especially when the computational resources are limited. In this paper, we propose an effective, efficient, and robust method to accurately detect and segment multiple independently moving foreground targets from a video sequence taken by a monocular moving camera [e.g., onboard an unmanned aerial vehicle (UAV)]. Our proposed method advances the existing methods in a number of ways, where: 1) camera motion is estimated through tracking background keypoints using pyramidal Lucas-Kanade at every detection interval, for efficiency; 2) foreground segmentation is applied by integrating a local motion history function with spatio-Temporal differencing over a sliding window for detecting multiple moving targets, while the perspective homography is used at image registration for effectiveness; and 3) the detection interval is adjusted dynamically based on a rule-of-Thumb technique and considering camera setup parameters for robustness. The proposed method has been tested on a variety of scenarios using a UAV camera, as well as publically available data sets. Based on the reported results and through comparison with the existing methods, the accuracy of the proposed method in detecting multiple moving targets as well as its capability for real-Time implementation has been successfully demonstrated. Our method is also robustly applicable to ground-level cameras for the ITS applications, as confirmed by the experimental results. More specifically, the proposed method shows promising performance compared with the literature in terms of quantitative metrics, while the run-Time measures are significantly improved for real-Time implementation.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Effectiveness,image motion analysis,object detection,robustness,unmanned aerial vehicles},
  annotation = {54 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{minagar_Thalamus_2013,
  title = {The {{Thalamus}} and {{Multiple Sclerosis}}: {{Modern Views}} on {{Pathologic}}, {{Imaging}}, and {{Clinical Aspects}}},
  author = {Minagar, Alireza and Barnett, Michael H. and Benedict, Ralph H. B. B. and Pelletier, Daniel and Pirko, Istvan and Sahraian, Mohamad Ali and Frohman, Elliott and Zivadinov, Robert},
  date = {2013-01},
  journaltitle = {Neurology},
  volume = {80},
  number = {2},
  pages = {210--219},
  publisher = {{American Academy of Neurology}},
  doi = {10.1212/WNL.0b013e31827b910b},
  url = {http://www.neurology.org/cgi/doi/10.1212/WNL.0b013e31827b910b},
  abstract = {The paired thalamic nuclei are gray matter (GM) structures on both sides of the third ventricle that play major roles in cortical activation, relaying sensory information to the higher cortical centers that influence cognition. Multiple sclerosis (MS) is an immune-mediated disease of the human CNS that affects both the white matter (WM) and GM. A number of clinical observations as well as recent neuropathologic and neuroimaging studies have clearly demonstrated extensive involvement of the thalamus, basal ganglia, and neocortex in patients with MS. Modern MRI techniques permit visualization of GM lesions and measurement of atrophy. These contemporary methods have fundamentally altered our understanding of the pathophysiologic nature of MS. Evidence confirms the contention that GM injury can be detected in the earliest phases of MS, and that iron deposition and atrophy of deep gray nuclei are closely related to the magnitude of inflammation. Extensive involvement of GM, and particularly of the thalamus, is associated with a wide range of clinical manifestations including cognitive decline, motor deficits, fatigue, painful syndromes, and ocular motility disturbances in patients with MS. In this review, we characterize the neuropathologic, neuroimaging, and clinical features of thalamic involvement in MS. Further, we underscore the contention that neuropathologic and neuroimaging correlative investigations of thalamic derangements in MS may elucidate not heretofore considered pathobiological underpinnings germane to understanding the ontogeny, magnitude, and progression of the disease process.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{mirnezami_Surgery_2018,
  title = {Surgery 3.0, {{Artificial Intelligence}} and the {{Next-Generation Surgeon}}},
  author = {Mirnezami, R. and Ahmed, A.},
  date = {2018},
  journaltitle = {Br. J. Surg.},
  eprint = {29603133},
  eprinttype = {pmid},
  issn = {13652168},
  doi = {10.1002/bjs.10860},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{miyato_Virtual_2019,
  title = {Virtual {{Adversarial Training}}: {{A Regularization Method}} for {{Supervised}} and {{Semi-Supervised Learning}}},
  author = {Miyato, Takeru and Maeda, Shin Ichi and Koyama, Masanori and Ishii, Shin},
  date = {2019},
  journaltitle = {IEEE Trans. Pattern Anal. Mach. Intell.},
  eprint = {30040630},
  eprinttype = {pmid},
  issn = {19393539},
  doi = {10.1109/TPAMI.2018.2858821},
  abstract = {We propose a new regularization method based on virtual adversarial loss: a new measure of local smoothness of the conditional label distribution given input. Virtual adversarial loss is defined as the robustness of the conditional label distribution around each input data point against local perturbation. Unlike adversarial training, our method defines the adversarial direction without label information and is hence applicable to semi-supervised learning. Because the directions in which we smooth the model are only virtually adversarial, we call our method virtual adversarial training (VAT). The computational cost of VAT is relatively low. For neural networks, the approximated gradient of virtual adversarial loss can be computed with no more than two pairs of forward- and back-propagations. In our experiments, we applied VAT to supervised and semi-supervised learning tasks on multiple benchmark datasets. With a simple enhancement of the algorithm based on the entropy minimization principle, our VAT achieves state-of-the-art performance for semi-supervised learning tasks on SVHN and CIFAR-10.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,adversarial examples,adversarial training,deep learning,robustness,Semi-supervised learning,supervised learning}
}

@article{miyoshi_Lithium_2009,
  ids = {miyoshi09},
  title = {Lithium {{Treatment Elongates Primary Cilia}} in the {{Mouse Brain}} and in {{Cultured Cells}}},
  author = {Miyoshi, Ko and Kasahara, Kyosuke and Miyazaki, Ikuko and Asanuma, Masato},
  date = {2009-10},
  journaltitle = {Biochemical and Biophysical Research Communications},
  volume = {388},
  number = {4},
  pages = {757--762},
  issn = {0006291X},
  doi = {10.1016/j.bbrc.2009.08.099},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0006291X09016787},
  urldate = {2023-06-03},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {92 citations (Semantic Scholar/DOI) [2023-06-02]}
}

@article{moeskops_Automatic_2016,
  title = {Automatic {{Segmentation}} of {{MR Brain Images With}} a {{Convolutional Neural Network}}},
  shorttitle = {Automatic {{Segmentation}} of {{MR Brain Images With}} a {{Convolutional Neural Network}}},
  author = {Moeskops, Pim and Viergever, Max A. and Mendrik, Adrienne M. and De Vries, Linda S. and Benders, Manon J. N. L. and Isgum, Ivana},
  date = {2016-05},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {35},
  number = {5},
  pages = {1252--1261},
  issn = {0278-0062, 1558-254X},
  doi = {10.1109/TMI.2016.2548501},
  url = {http://ieeexplore.ieee.org/document/7444155/},
  urldate = {2023-05-10},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Adult brain,automatic image segmentation,convolutional neural networks,deep learning,MRI,preterm neonatal brain,thalamus},
  file = {/Users/personal-macbook/Zotero/storage/WUXCBNX9/Moeskops et al. - 2016 - Automatic Segmentation of MR Brain Images With a C.pdf}
}

@inproceedings{moeskops_Deep_2016,
  title = {Deep {{Learning}} for {{Multi-Task Medical Image Segmentation}} in {{Multiple Modalities}}},
  booktitle = {Lect. {{Notes Comput}}. {{Sci}}. {{Subser}}. {{Lect}}. {{Notes Artif}}. {{Intell}}. {{Lect}}. {{Notes Bioinforma}}.},
  author = {Moeskops, Pim and Wolterink, Jelmer M. and family=Velden, given=Bas H. M., prefix=van der, useprefix=false and Gilhuijs, Kenneth G. A. and Leiner, Tim and Viergever, Max A. and I\v{s}gum, Ivana},
  date = {2016},
  volume = {9901 LNCS},
  issn = {16113349},
  doi = {10.1007/978-3-319-46723-8_55},
  abstract = {Automatic segmentation of medical images is an important task for many clinical applications. In practice,a wide range of anatomical structures are visualised using different imaging modalities. In this paper,we investigate whether a single convolutional neural network (CNN) can be trained to perform different segmentation tasks. A single CNN is trained to segment six tissues in MR brain images,the pectoral muscle in MR breast images,and the coronary arteries in cardiac CTA. The CNN therefore learns to identify the imaging modality,the visualised anatomical structures,and the tissue classes. For each of the three tasks (brain MRI,breast MRI and cardiac CTA),this combined training procedure resulted in a segmentation performance equivalent to that of a CNN trained specifically for that task,demonstrating the high capacity of CNN architectures. Hence,a single system could be used in clinical practice to automatically perform diverse segmentation tasks without task-specific training.},
  isbn = {978-3-319-46722-1},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {269 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{moghaddam_Automatic_2009,
  title = {Automatic {{Segmentation}} of {{Brain Structures Using Geometric Moment Invariants}} and {{Artificial Neural Networks}}},
  booktitle = {Inf. {{Process}}. {{Med}}. {{Imaging}}},
  author = {Jabarouti Moghaddam, Mostafa and Soltanian-Zadeh, Hamid},
  editor = {Prince, Jerry L. and Pham, Dzung L. and Myers, Kyle J.},
  date = {2009},
  volume = {5636},
  pages = {326--337},
  publisher = {{Springer Berlin Heidelberg}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-02498-6_27},
  url = {http://link.springer.com/10.1007/978-3-642-02498-6_27},
  urldate = {2023-05-12},
  isbn = {978-3-642-02497-9 978-3-642-02498-6},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@dataset{momeni_Synthetic_2021,
  title = {Synthetic {{Cerebral Microbleed}} on {{SWI Images}}},
  author = {Momeni, Saba and Fazlollahi, Amir and Yates, Paul and Christopher, Rowe and Gao, Yongsheng and Wee-Chung Liew, Alan and Salvado, Olivier},
  date = {2021},
  publisher = {{CSIRO}},
  doi = {10.25919/AEGY-NY12},
  url = {https://data.csiro.au/collections/collection/CIcsiro:50304v1/DItrue},
  urldate = {2023-05-09},
  abstract = {This data was used and is explained in the publication listed and provided in the "Related Links" section. The dataset comprises 75 MRI SWI with real Microbleed of the brain and the locations defined by experts of 175 microbleeds. In addition, we provide the same datasets with added 10 synthetics Microbleed lesions along with their locations for each SWI, created using a mathematical model. Our publication demonstrated that the data with synthetics could be used for training to yield superior performance when tested on real lesions},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{mondal_Fewshot_2018,
  title = {Few-{{Shot 3D Multi-Modal Medical Image Segmentation Using Generative Adversarial Learning}}},
  author = {Mondal, Arnab Kumar and Dolz, Jose and Desrosiers, Christian},
  date = {2018-10},
  journaltitle = {arXiv},
  abstract = {We address the problem of segmenting 3D multi-modal medical images in scenarios where very few labeled examples are available for training. Leveraging the recent success of adversarial learning for semi-supervised segmentation, we propose a novel method based on Generative Adversarial Networks (GANs) to train a segmentation model with both labeled and unlabeled images. The proposed method prevents over-fitting by learning to discriminate between true and fake patches obtained by a generator network. Our work extends current adversarial learning approaches, which focus on 2D single-modality images, to the more challenging context of 3D volumes of multiple modalities. The proposed method is evaluated on the problem of segmenting brain MRI from the iSEG-2017 and MRBrainS 2013 datasets. Significant performance improvement is reported, compared to state-of-art segmentation networks trained in a fully-supervised manner. In addition, our work presents a comprehensive analysis of different GAN architectures for semi-supervised segmentation, showing recent techniques like feature matching to yield a higher performance than conventional adversarial training approaches. Our code is publicly available at https://github.com/arnab39/FewShot\_GAN-Unet3D},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{mongodi_Lung_2020,
  title = {Lung {{Ultrasound}} in {{Patients With Acute Respiratory Failure Reduces Conventional Imaging}} and {{Health Care Provider Exposure}} to {{COVID-19}}},
  author = {Mongodi, Silvia and Orlando, Anita and Arisi, Eric and Tavazzi, Guido and Santangelo, Erminio and Caneva, Luca and Pozzi, Marco and Pariani, Eleonora and Bettini, Giada and Maggio, Giuseppe and Perlini, Stefano and Preda, Lorenzo and Iotti, Giorgio Antonio and Mojoli, Francesco},
  date = {2020},
  journaltitle = {Ultrasound Med. Biol.},
  volume = {00},
  number = {00},
  pages = {1--4},
  issn = {03015629},
  doi = {10.1016/j.ultrasmedbio.2020.04.033},
  abstract = {Abstract\textemdash{} Lung ultrasound gained a leading position in the last year as an imaging technique for the assessment and management of patients with acute respiratory failure. In coronavirus disease 2019 (COVID-19), its role may be of further importance because it is performed bedside and may limit chest X-ray and the need for transport to radiology for computed tomography (CT) scan. Since February 21, we progressively turned into a coronavirus-dedicated intensive care unit and applied an ultrasound-based approach to avoid traditional imaging and limit contamination as much as possible. We performed a complete daily examination with lung ultrasound score computation and systematic search of complications (pneumothorax, ventilator-associated pneumonia); on-duty physicians were free to perform CT or chest X-ray when deemed indicated. We compared conventional imaging exams performed in the first 4 wk of the COVID-19 epidemic with those in the same time frame in 2019: there were 84 patients in 2020 and 112 in 2019; 64 and 22 (76.2\% vs. 19.6\%, p {$<$} 0.001) had acute respiratory failure, respectively, of which 55 (85.9\%) were COVID-19 in 2020. When COVID-19 patients in 2020 were compared with acute respiratory failure patients in 2019, the median number of chest X-rays was 1.0 (1.0\textendash 2.0) versus 3.0 (1.0\textendash 4.0) (p = 0.0098); 2 patients 2 (3.6\%) versus 7 patients (31.8\%) had undergone at least one thoracic CT scan (p = 0.001). A self-imposed ultrasound-based approach reduces the number of chest X-rays and thoracic CT scans in COVID-19 patients compared with patients with standard acute respiratory failure, thus reducing the number of health care providers exposed to possible contamination and sparing personal protective equipment.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {62 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@misc{montoya_State_2016,
  title = {State {{Farm Distracted Driver Detection}}},
  author = {Montoya, Anna and Holman, Dan and Smith, Taylor and Kan, Wendy},
  date = {2016},
  publisher = {{Kaggle}},
  url = {https://kaggle.com/competitions/state-farm-distracted-driver-detection},
  urldate = {2023-01-11},
  abstract = {Can computer vision spot distracted drivers?},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/8TQ6MGTW/state-farm-distracted-driver-detection.html}
}

@thesis{morales_Lagrangian_2018,
  title = {Lagrangian {{Schlieren Image Velocimetry Measurements}} in {{Exhaust Plumes}}},
  author = {Morales, Rudy},
  date = {2018},
  journaltitle = {ProQuest Dissertations and Theses},
  abstract = {Schlieren image velocimetry (SIV) is a non-intrusive flow visualization technique. SIV is the combination of schlieren optics and image processing methods to simultaneously characterize and measure the velocity fields of naturally occurring turbulent flow features. The focus of this work was image processing methods for SIV analysis. Image processing methods were explored with MATLAB to enhance the appearance of the turbulent flow features to convert them into optical particles. The optical particles were individually identified to determine their characteristics for subsequent tracking to measure velocities. With known parameters such as size, location, and centroid, filters were applied to isolate specified particles. Manual SIV was performed due to the limitations in an automated pattern recognition script to construct a path from the optical particles. Here the SIV technique is applied to a free jet, a micro-turbine, and a small-scale liquid rocket engine to construct a velocity distribution in the exhaust plumes at various locations from the exit plane. Velocity distributions in the testbeds revealed similar trends to those of published data for free jets. Experimental results were limited to the lower velocity turbulent regions because SIV is only valid where the optical particles are present and visible in schlieren images.},
  isbn = {978-0-438-33286-7},
  keywords = {\#nosource,⛔ No INSPIRE recid found,0537:Engineering,Applied sciences,Engineering,Exhaust plumes,Imaging,Optics,Schlieren,Tracking,Turbulent}
}

@inproceedings{morerio_Generative_2020,
  title = {Generative {{Pseudo-Label Refinement}} for {{Unsupervised Domain Adaptation}}},
  booktitle = {Proc. - 2020 {{IEEE Winter Conf}}. {{Appl}}. {{Comput}}. {{Vis}}. {{WACV}} 2020},
  author = {Morerio, Pietro and Volpi, Riccardo and Ragonesi, Ruggero and Murino, Vittorio},
  date = {2020},
  doi = {10.1109/WACV45572.2020.9093579},
  abstract = {We investigate and characterize the inherent resilience of conditional Generative Adversarial Networks (cGANs) against noise in their conditioning labels, and exploit this fact in the context of Unsupervised Domain Adaptation (UDA). In UDA, a classifier trained on the labelled source set can be used to infer pseudo-labels on the unlabelled target set. However, this will result in a significant amount of misclassified examples (due to the well-known domain shift issue), which can be interpreted as noise injection in the ground-truth labels for the target set. We show that cGANs are, to some extent, robust against such "shift noise". Indeed, cGANs trained with noisy pseudo-labels, are able to filter such noise and generate cleaner target samples. We exploit this finding in an iterative procedure where a generative model and a classifier are jointly trained: in turn, the generator allows to sample cleaner data from the target distribution, and the classifier allows to associate better labels to target samples, progressively refining target pseudo-labels. Results on common benchmarks show that our method performs better or comparably with the unsupervised domain adaptation state of the art.},
  isbn = {978-1-72816-553-0},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {27 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{morerio_Minimalentropy_2018,
  title = {Minimal-{{Entropy Correlation Alignment}} for {{Unsupervised Deep Domain Adaptation}}},
  booktitle = {6th {{Int}}. {{Conf}}. {{Learn}}. {{Represent}}. {{ICLR}} 2018 - {{Conf}}. {{Track Proc}}.},
  author = {Morerio, Pietro and Cavazza, Jacopo and Murino, Vittorio},
  date = {2018},
  abstract = {In this work, we face the problem of unsupervised domain adaptation with a novel deep learning approach which leverages our finding that entropy minimization is induced by the optimal alignment of second order statistics between source and target domains. We formally demonstrate this hypothesis and, aiming at achieving an optimal alignment in practical cases, we adopt a more principled strategy which, differently from the current Euclidean approaches, deploys alignment along geodesics. Our pipeline can be implemented by adding to the standard classification loss (on the labeled source domain), a source-to-target regularizer that is weighted in an unsupervised and data-driven fashion. We provide extensive experiments to assess the superiority of our framework on standard domain and modality adaptation benchmarks.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{morgan_Segmentation_2015,
  title = {Segmentation of the {{Thalamus Based}} on {{Bold Frequencies Affected}} in {{Temporal Lobe Epilepsy}}},
  author = {Morgan, Victoria L. and Rogers, Baxter P. and Abou-Khalil, Bassel},
  date = {2015-11},
  journaltitle = {Epilepsia},
  volume = {56},
  number = {11},
  pages = {1819--1827},
  doi = {10.1111/epi.13186},
  abstract = {OBJECTIVE: Temporal lobe epilepsy is associated with functional changes throughout the brain, particularly including a putative seizure propagation network involving the hippocampus, insula, and thalamus. We identified a specified frequency range where functional connectivity in this network was related to duration of disease. Then, to identify specific thalamic nuclei involved in seizure propagation, we determined the subregions of the thalamus that have increased resting functional oscillations in this frequency range. METHODS: Resting-state functional magnetic resonance imaging (fMRI) was acquired from 20 patients with unilateral temporal lobe epilepsy (TLE; 14 right and 6 left) and 20 healthy controls who were each age and gender matched to a specific patient. Wavelet-based fMRI connectivity mapping across the network was computed at each frequency to determine those frequencies where connectivity significantly decreases with duration of disease consistent with impairment due to repeated seizures. The voxel-wise power of the spontaneous blood oxygenation fluctuations of this frequency band was computed in the thalamus of each subject. RESULTS: Functional connectivity was impaired in the proposed seizure propagation network over a specific range (0.0067-0.013 Hz and 0.024-0.032 Hz) of blood oxygenation oscillations. Increased power in this frequency band ({$<$}0.032 Hz) was detected bilaterally in the pulvinar and anterior nucleus of the thalamus of healthy controls, and was increased over the ipsilateral thalamus compared to the contralateral thalamus in TLE. SIGNIFICANCE: This study identified frequencies of impaired connectivity in a TLE seizure propagation network and used them to localize the anterior nucleus and pulvinar of the thalamus as subregions most susceptible to TLE seizures. Further examinations of these frequencies in healthy and TLE subjects may provide unique information relating to the mechanism of seizure propagation and potential treatment using electrical stimulation.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Functional neuroimaging,T,Temporal lobe epilepsy}
}

@article{moroi_Comparison_1975,
  title = {Comparison {{Between Procaine}} and {{Isocarboxazid Metabolism}} in {{Vitro}} by a {{Liver Microsomal Amidase-Esterase}}},
  author = {Moroi, K. and Sato, T.},
  date = {1975-08-15},
  journaltitle = {Biochem Pharmacol},
  volume = {24},
  number = {16},
  eprint = {8},
  eprinttype = {pmid},
  pages = {1517--1521},
  issn = {1873-2968},
  doi = {10.1016/0006-2952(75)90029-5},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Amidohydrolases,Animals,Esterases,Hydrogen-Ion Concentration,In Vitro Techniques,Isocarboxazid,Kinetics,Male,Metals,{Microsomes, Liver},Phospholipids,Procaine,Proteins,Rats,Subcellular Fractions,Temperature},
  annotation = {41 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{morra_comparisonadaboostsupportvectormachinesdetectingalzheimerdiseaseautomatedhippocampalsegmentation_2010,
  ids = {morra_Comparison_2010},
  title = {Comparison of {{AdaBoost}} and {{Support Vector Machines}} for {{Detecting Alzheimer}}'s {{Disease Through Automated Hippocampal Segmentation}}},
  author = {Morra, J.H. and {Zhuowen Tu} and Apostolova, L.G. and Green, A.E. and Toga, A.W. and Thompson, P.M.},
  date = {2010-01},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {29},
  number = {1},
  pages = {30--43},
  issn = {0278-0062, 1558-254X},
  doi = {10.1109/TMI.2009.2021941},
  url = {http://ieeexplore.ieee.org/document/4957035/},
  urldate = {2023-05-13},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {220 citations (Semantic Scholar/DOI) [2023-05-13]},
  file = {/Users/personal-macbook/Zotero/storage/QQ5KLR7B/Morra et al. - 2010 - Comparison of AdaBoost and Support Vector Machines.pdf}
}

@inproceedings{motiian_Unified_2017,
  title = {Unified {{Deep Supervised Domain Adaptation}} and {{Generalization}}},
  booktitle = {Proc. {{IEEE Int}}. {{Conf}}. {{Comput}}. {{Vis}}.},
  author = {Motiian, Saeid and Piccirilli, Marco and Adjeroh, Donald A. and Doretto, Gianfranco},
  date = {2017},
  issn = {15505499},
  doi = {10.1109/ICCV.2017.609},
  abstract = {This work provides a unified framework for addressing the problem of visual supervised domain adaptation and generalization with deep models. The main idea is to exploit the Siamese architecture to learn an embedding subspace that is discriminative, and where mapped visual domains are semantically aligned and yet maximally separated. The supervised setting becomes attractive especially when only few target data samples need to be labeled. In this scenario, alignment and separation of semantic probability distributions is difficult because of the lack of data. We found that by reverting to point-wise surrogates of distribution distances and similarities provides an effective solution. In addition, the approach has a high 'speed' of adaptation, which requires an extremely low number of labeled target training samples, even one per category can be effective. The approach is extended to domain generalization. For both applications the experiments show very promising results.},
  isbn = {978-1-5386-1032-9},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{mozejko_Inhibited_2018,
  title = {Inhibited {{Softmax}} for {{Uncertainty Estimation}} in {{Neural Networks}}},
  author = {Mo\.zejko, Marcin and Susik, Mateusz and Karczewski, Rafa\l},
  date = {2018-11-26},
  url = {https://openreview.net/forum?id=rJxA-h05KQ},
  urldate = {2022-07-04},
  abstract = {Uncertainty estimation in a single forward pass without additional learnable parameters.},
  langid = {english},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/N5SHEVEY/Możejko et al. - 2018 - Inhibited Softmax for Uncertainty Estimation in Ne.pdf;/Users/personal-macbook/Zotero/storage/JVKSD7SG/forum.html}
}

@inproceedings{muandet_Domain_2013,
  title = {Domain {{Generalization}} via {{Invariant Feature Representation}}},
  booktitle = {30th {{Int}}. {{Conf}}. {{Mach}}. {{Learn}}. {{ICML}} 2013},
  author = {Muandet, Krikamol and Balduzzi, David and Sch\"olkopf, Bernhard},
  date = {2013},
  abstract = {This paper investigates domain generalization: How to take knowledge acquired from an arbitrary number of related domains and apply it to previously unseen domains? We propose Domain-Invariant Component Analysis (DICA), a kernel-based optimization algorithm that learns an invariant transformation by minimizing the dissimilarity across domains, whilst preserving the functional relationship between input and output variables. A learning-theoretic analysis shows that reducing dissimilarity improves the expected generalization ability of classifiers on new domains, motivating the proposed algorithm. Experimental results on synthetic and real-world datasets demonstrate that DICA successfully learns invariant features and improves classifier performance in practice. Copyright 2013 by the author(s).},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{mueller_Hippocampal_2010,
  title = {Hippocampal {{Atrophy Patterns}} in {{Mild Cognitive Impairment}} and {{Alzheimer}}'s {{Disease}}},
  author = {Mueller, Susanne G. and Schuff, Norbert and Yaffe, Kristine and Madison, Catherine and Miller, Bruce and Weiner, Michael W.},
  date = {2010-09},
  journaltitle = {Hum. Brain Mapp.},
  volume = {31},
  number = {9},
  pages = {1339--1347},
  doi = {10.1002/hbm.20934},
  abstract = {BACKGROUND: Histopathological studies and animal models suggest that hippocampal subfields may be differently affected by aging, Alzheimer's disease (AD), and other diseases. High-resolution images at 4 Tesla depict details of the internal structure of the hippocampus allowing for in vivo volumetry of different subfields. The aims of this study were as follows: (1) to determine patterns of volume loss in hippocampal subfields in normal aging, AD, and amnestic mild cognitive impairment (MCI). (2) To determine if measurements of hippocampal subfields provide advantages over total hippocampal volume for differentiation between groups. METHODS: Ninety-one subjects (53 controls (mean age: 69.3 \$\textbackslash pm\$ 7.3), 20 MCI (mean age: 73.6 \$\textbackslash pm\$ 7.1), and 18 AD (mean age: 69.1 \$\textbackslash pm\$ 9.5) were studied with a high-resolution T2 weighted imaging sequence aimed at the hippocampus. Entorhinal cortex (ERC), subiculum, CA1, CA1-CA2 transition zone (CA1-2), CA3 \& dentate gyrus (CA3\&DG) were manually marked in the anterior third of the hippocampal body. Hippocampal volume was obtained from the Freesurfer and manually edited. RESULTS: Compared to controls, AD had smaller volumes of ERC, subiculum, CA1, CA1-2, and total hippocampal volumes. MCI had smaller CA1-2 volumes. Discriminant analysis and power analysis showed that CA1-2 was superior to total hippocampal volume for distinction between controls and MCI. CONCLUSION: The patterns of subfield atrophy in AD and MCI were consistent with patterns of neuronal cell loss/reduced synaptic density described by histopathology. These preliminary findings suggest that hippocampal subfield volumetry might be a better measure for diagnosis of early AD and for detection of other disease effects than measurement of total hippocampus.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {293 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{muhammadi_Unified_2015,
  title = {A {{Unified Statistical Framework}} for {{Crowd Labeling}}},
  author = {Muhammadi, Jafar and Rabiee, Hamid R. and Hosseini, Abbas},
  date = {2015-11},
  journaltitle = {Knowl Inf Syst},
  volume = {45},
  number = {2},
  pages = {271--294},
  issn = {0219-1377, 0219-3116},
  doi = {10.1007/s10115-014-0790-7},
  url = {http://link.springer.com/10.1007/s10115-014-0790-7},
  urldate = {2022-12-20},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/8QDFGGAM/Muhammadi et al. - 2015 - A Unified Statistical Framework for Crowd Labeling.pdf}
}

@online{mullachery_Bayesian_2018,
  ids = {mullachery_Bayesian_2018a,mullachery_bayesianneuralnetworks_2018},
  title = {Bayesian {{Neural Networks}}},
  author = {Mullachery, Vikram and Khera, Aniruddh and Husain, Amir},
  date = {2018},
  doi = {10.48550/ARXIV.1801.07710},
  url = {https://arxiv.org/abs/1801.07710},
  urldate = {2023-05-03},
  abstract = {This paper describes and discusses Bayesian Neural Network (BNN). The paper showcases a few different applications of them for classification and regression problems. BNNs are comprised of a Probabilistic Model and a Neural Network. The intent of such a design is to combine the strengths of Neural Networks and Stochastic modeling. Neural Networks exhibit continuous function approximator capabilities. Stochastic models allow direct specification of a model with known interaction between parameters to generate data. During the prediction phase, stochastic models generate a complete posterior distribution and produce probabilistic guarantees on the predictions. Thus BNNs are a unique combination of neural network and stochastic models with the stochastic model forming the core of this integration. BNNs can then produce probabilistic guarantees on it's predictions and also generate the distribution of parameters that it has learnt from the observations. That means, in the parameter space, one can deduce the nature and shape of the neural network's learnt parameters. These two characteristics makes them highly attractive to theoreticians as well as practitioners. Recently there has been a lot of activity in this area, with the advent of numerous probabilistic programming libraries such as: PyMC3, Edward, Stan etc. Further this area is rapidly gaining ground as a standard machine learning approach for numerous problems},
  pubstate = {preprint},
  version = {2},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found,Artificial Intelligence (cs.AI),FOS: Computer and information sciences,Machine Learning (cs.LG),Machine Learning (stat.ML)},
  annotation = {7 citations (Semantic Scholar/arXiv) [2023-05-08]}
}

@inproceedings{muller_When_2019a,
  ids = {muller_When_2019},
  title = {When {{Does Label Smoothing Help}}?},
  booktitle = {Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.},
  author = {M\"uller, Rafael and Kornblith, Simon and Hinton, Geoffrey E},
  editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and family=Alch\'e-Buc, given=F., prefix=d', useprefix=false and Fox, E. and Garnett, R.},
  date = {2019},
  volume = {32},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2019/file/f1748d6b0fd9d439f71450117eba2725-Paper.pdf},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/WJFPGZT8/Müller et al. - 2019 - When does label smoothing help.pdf}
}

@article{murdoch_Inevitable_2013,
  title = {The {{Inevitable Application}} of {{Big Data}} to {{Health Care}}},
  author = {Murdoch, Travis B. and Detsky, Allan S.},
  date = {2013},
  journaltitle = {JAMA - J. Am. Med. Assoc.},
  eprint = {23549579},
  eprinttype = {pmid},
  issn = {00987484},
  doi = {10.1001/jama.2013.393},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@online{nado_uncertaintybaselinesbenchmarksuncertaintyrobustnessdeeplearning_2022,
  title = {Uncertainty {{Baselines}}: {{Benchmarks}} for {{Uncertainty}} \& {{Robustness}} in {{Deep Learning}}},
  shorttitle = {Uncertainty {{Baselines}}},
  author = {Nado, Zachary and Band, Neil and Collier, Mark and Djolonga, Josip and Dusenberry, Michael W. and Farquhar, Sebastian and Feng, Qixuan and Filos, Angelos and Havasi, Marton and Jenatton, Rodolphe and Jerfel, Ghassen and Liu, Jeremiah and Mariet, Zelda and Nixon, Jeremy and Padhy, Shreyas and Ren, Jie and Rudner, Tim G. J. and Sbahi, Faris and Wen, Yeming and Wenzel, Florian and Murphy, Kevin and Sculley, D. and Lakshminarayanan, Balaji and Snoek, Jasper and Gal, Yarin and Tran, Dustin},
  date = {2022-01-05},
  eprint = {2106.04015},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2106.04015},
  url = {http://arxiv.org/abs/2106.04015},
  urldate = {2022-07-04},
  abstract = {High-quality estimates of uncertainty and robustness are crucial for numerous real-world applications, especially for deep learning which underlies many deployed ML systems. The ability to compare techniques for improving these estimates is therefore very important for research and practice alike. Yet, competitive comparisons of methods are often lacking due to a range of reasons, including: compute availability for extensive tuning, incorporation of sufficiently many baselines, and concrete documentation for reproducibility. In this paper we introduce Uncertainty Baselines: high-quality implementations of standard and state-of-the-art deep learning methods on a variety of tasks. As of this writing, the collection spans 19 methods across 9 tasks, each with at least 5 metrics. Each baseline is a self-contained experiment pipeline with easily reusable and extendable components. Our goal is to provide immediate starting points for experimentation with new methods or applications. Additionally we provide model checkpoints, experiment outputs as Python notebooks, and leaderboards for comparing results. Code available at https://github.com/google/uncertainty-baselines.},
  pubstate = {preprint},
  keywords = {⛔ No INSPIRE recid found,Computer Science - Machine Learning},
  file = {/Users/personal-macbook/Zotero/storage/ZDPPRVU4/Nado et al. - 2022 - Uncertainty Baselines Benchmarks for Uncertainty .pdf}
}

@article{nagendran_Artificial_2020,
  title = {Artificial {{Intelligence Versus Clinicians}}: {{Systematic Review}} of {{Design}}, {{Reporting Standards}}, and {{Claims}} of {{Deep Learning Studies}} in {{Medical Imaging}}},
  author = {Nagendran, Myura and Chen, Yang and Lovejoy, Christopher A. and Gordon, Anthony C. and Komorowski, Matthieu and Harvey, Hugh and Topol, Eric J. and Ioannidis, John P. A. and Collins, Gary S. and Maruthappu, Mahiben},
  date = {2020},
  journaltitle = {The BMJ},
  eprint = {32213531},
  eprinttype = {pmid},
  issn = {17561833},
  doi = {10.1136/bmj.m689},
  abstract = {To systematically examine the design, reporting standards, risk of bias, and claims of studies comparing the performance of diagnostic deep learning algorithms for medical imaging with that of expert clinicians. Design Systematic review. Data sources Medline, Embase, Cochrane Central Register of Controlled Trials, and the World Health Organization trial registry from 2010 to June 2019. Eligibility criteria for selecting studies Randomised trial registrations and non-randomised studies comparing the performance of a deep learning algorithm in medical imaging with a contemporary group of one or more expert clinicians. Medical imaging has seen a growing interest in deep learning research. The main distinguishing feature of convolutional neural networks (CNNs) in deep learning is that when CNNs are fed with raw data, they develop their own representations needed for pattern recognition. The algorithm learns for itself the features of an image that are important for classification rather than being told by humans which features to use. The selected studies aimed to use medical imaging for predicting absolute risk of existing disease or classification into diagnostic groups (eg, disease or non-disease). For example, raw chest radiographs tagged with a label such as pneumothorax or no pneumothorax and the CNN learning which pixel patterns suggest pneumothorax. Review methods Adherence to reporting standards was assessed by using CONSORT (consolidated standards of reporting trials) for randomised studies and TRIPOD (transparent reporting of a multivariable prediction model for individual prognosis or diagnosis) for non-randomised studies. Risk of bias was assessed by using the Cochrane risk of bias tool for randomised studies and PROBAST (prediction model risk of bias assessment tool) for non-randomised studies. Results Only 10 records were found for deep learning randomised clinical trials, two of which have been published (with low risk of bias, except for lack of blinding, and high adherence to reporting standards) and eight are ongoing. Of 81 non-randomised clinical trials identified, only nine were prospective and just six were tested in a real world clinical setting. The median number of experts in the comparator group was only four (interquartile range 2-9). Full access to all datasets and code was severely limited (unavailable in 95\% and 93\% of studies, respectively). The overall risk of bias was high in 58 of 81 studies and adherence to reporting standards was suboptimal ({$<$}50\% adherence for 12 of 29 TRIPOD items). 61 of 81 studies stated in their abstract that performance of artificial intelligence was at least comparable to (or better than) that of clinicians. Only 31 of 81 studies (38\%) stated that further prospective studies or trials were required. Conclusions Few prospective deep learning studies and randomised trials exist in medical imaging. Most non-randomised trials are not prospective, are at high risk of bias, and deviate from existing reporting standards. Data and code availability are lacking in most studies, and human comparator groups are often small. Future studies should diminish risk of bias, enhance real world clinical relevance, improve reporting and transparency, and appropriately temper conclusions. Study registration PROSPERO CRD42019123605.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {444 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{nair_Exploring_2018,
  title = {Exploring {{Uncertainty Measures}} in {{Deep Networks}} for {{Multiple Sclerosis Lesion Detection}} and {{Segmentation}}},
  booktitle = {Lect. {{Notes Comput}}. {{Sci}}. {{Subser}}. {{Lect}}. {{Notes Artif}}. {{Intell}}. {{Lect}}. {{Notes Bioinforma}}.},
  author = {Nair, Tanya and Precup, Doina and Arnold, Douglas L. and Arbel, Tal},
  date = {2018},
  issn = {16113349},
  doi = {10.1007/978-3-030-00928-1_74},
  abstract = {Deep learning (DL) networks have recently been shown to outperform other segmentation methods on various public, medical-image challenge datasets [3, 11, 16], especially for large pathologies. However, in the context of diseases such as Multiple Sclerosis (MS), monitoring all the focal lesions visible on MRI sequences, even very small ones, is essential for disease staging, prognosis, and evaluating treatment efficacy. Moreover, producing deterministic outputs hinders DL adoption into clinical routines. Uncertainty estimates for the predictions would permit subsequent revision by clinicians. We present the first exploration of multiple uncertainty estimates based on Monte Carlo (MC) dropout [4] in the context of deep networks for lesion detection and segmentation in medical images. Specifically, we develop a 3D MS lesion segmentation CNN, augmented to provide four different voxel-based uncertainty measures based on MC dropout. We train the network on a proprietary, large-scale, multi-site, multi-scanner, clinical MS dataset, and compute lesion-wise uncertainties by accumulating evidence from voxel-wise uncertainties within detected lesions. We analyze the performance of voxel-based segmentation and lesion-level detection by choosing operating points based on the uncertainty. Empirical evidence suggests that uncertainty measures consistently allow us to choose superior operating points compared only using the network's sigmoid output as a probability.},
  isbn = {978-3-030-00927-4},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Detection,Multiple sclerosis,Segmentation,Uncertainty},
  annotation = {309 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{nair_Exploring_2020,
  title = {Exploring {{Uncertainty Measures}} in {{Deep Networks}} for {{Multiple Sclerosis Lesion Detection}} and {{Segmentation}}},
  author = {Nair, Tanya and Precup, Doina and Arnold, Douglas L. and Arbel, Tal},
  date = {2020-01},
  journaltitle = {Med. Image Anal.},
  volume = {59},
  pages = {101557},
  abstract = {Deep learning networks have recently been shown to outperform other segmentation methods on various public, medical-image challenge datasets, particularly on metrics focused on large pathologies. For diseases such as Multiple Sclerosis (MS), however, monitoring all the focal lesions visible on MRI sequences, even very small ones, is essential for disease staging, prognosis, and evaluating treatment efficacy. Small lesion segmentation presents significant challenges to popular deep learning models. This, coupled with their deterministic predictions, hinders their clinical adoption. Uncertainty estimates for these predictions would permit subsequent revision by clinicians. We present the first exploration of multiple uncertainty estimates based on Monte Carlo (MC) dropout (Gal and Ghahramani, 2016) in the context of deep networks for lesion detection and segmentation in medical images. Specifically, we develop a 3D MS lesion segmentation CNN, augmented to provide four different voxel-based uncertainty measures based on MC dropout. We train the network on a proprietary, large-scale, multi-site, multi-scanner, clinical MS dataset, and compute lesion-wise uncertainties by accumulating evidence from voxel-wise uncertainties within detected lesions. We analyze the performance of voxel-based segmentation and lesion-level detection by choosing operating points based on the uncertainty. Uncertainty filtering improves both voxel and lesion-wise TPR and FDR on remaining, certain predictions compared to sigmoid-based TPR/FDR curves. Small lesions and lesion-boundaries are the most uncertain regions, which is consistent with human-rater variability.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found,Deep learning,Detection,Multiple sclerosis,Segm}
}

@article{naude_Artificial_2020,
  title = {Artificial {{Intelligence}} vs {{COVID-19}}: {{Limitations}}, {{Constraints}} and {{Pitfalls}}},
  author = {Naud\'e, Wim},
  date = {2020},
  journaltitle = {AI Soc.},
  issn = {14355655},
  doi = {10.1007/s00146-020-00978-0},
  abstract = {This paper provides an early evaluation of Artificial Intelligence (AI) against COVID-19. The main areas where AI can contribute to the fight against COVID-19 are discussed. It is concluded that AI has not yet been impactful against COVID-19. Its use is hampered by a lack of data, and by too much data. Overcoming these constraints will require a careful balance between data privacy and public health, and rigorous human-AI interaction. It is unlikely that these will be addressed in time to be of much help during the present pandemic. In the meantime, extensive gathering of diagnostic data on who is infectious will be essential to save lives, train AI, and limit economic damages.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,AI,COVID-19,Data science,Public health,Surveillance},
  annotation = {20 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{navis_Right_2016,
  title = {The {{Right People}} in the {{Wrong Places}}: {{The Paradox}} of {{Entrepreneurial Entry}} and {{Successful Opportunity Realization}}},
  author = {Navis, Chad and Ozbek, O. Volkan},
  date = {2016},
  journaltitle = {Acad. Manage. Rev.},
  issn = {03637425},
  doi = {10.5465/amr.2013.0175},
  abstract = {We advance a model that highlights contingent linkages between overconfidence and narcissism, entrepreneurial entry, and the successful realization of venture opportunities. Overall, our proposals point to a paradox in which entrepreneurs high in overconfidence and narcissism are propelled toward more novel venture contexts-where these qualities are most detrimental to venture success-and are repelled from more familiar venture contexts-where these qualities are least harmful and may even facilitate venture success. To illuminate these patterns of misalignment, we attend to the defining characteristics of alternative venture contexts and the focal constructs of overconfidence and narcissism.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@book{neal_bayesian_1996,
  ids = {_BAYESIAN_,neal_Bayesian_1996a,neal_Bayesian_2012,neal_bayesianlearningneuralnetworks_1996,neal_bayesianlearningneuralnetworks_1996a},
  title = {Bayesian {{Learning}} for {{Neural Networks}}},
  author = {Neal, Radford M.},
  editorb = {Bickel, P. and Diggle, P. and Fienberg, S. and Krickeberg, K. and Olkin, I. and Wermuth, N. and Zeger, S.},
  editorbtype = {redactor},
  date = {1996},
  series = {Lecture {{Notes}} in {{Statistics}}},
  edition = {1},
  volume = {118},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4612-0745-0},
  url = {http://link.springer.com/10.1007/978-1-4612-0745-0},
  urldate = {2023-05-18},
  isbn = {978-0-387-94724-2 978-1-4612-0745-0},
  pagetotal = {204},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found,Bayesian statistical decision theory,Machine learning,Neural networks (Computer science)},
  file = {/Users/personal-macbook/Zotero/storage/SNSCTR9J/Neal - 1996 - Bayesian Learning for Neural Networks.pdf}
}

@article{nelson_Hippocampal_1997,
  ids = {nelson_430_1997},
  title = {Hippocampal {{Volume Reduction}} in {{Schizophrenia}} as {{Assessed}} by {{Magnetic Resonance Imaging}}: {{A Meta-Analytic Study}}},
  shorttitle = {Hippocampal {{Volume Reduction}} in {{Schizophrenia}} as {{Assessed}} by {{Magnetic Resonance Imaging}}},
  author = {Nelson, Michael D. and Saykin, Andrew J. and Flashman, Laura A. and Riordan, Henry J.},
  date = {1997-01},
  journaltitle = {Schizophrenia Research},
  volume = {24},
  number = {1-2},
  pages = {153},
  issn = {09209964},
  doi = {10.1016/S0920-9964(97)82438-3},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0920996497824383},
  urldate = {2023-05-08},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {3 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{nettleton_Study_2010,
  title = {A {{Study}} of the {{Effect}} of {{Different Types}} of {{Noise}} on the {{Precision}} of {{Supervised Learning Techniques}}},
  author = {Nettleton, David F. and Orriols-Puig, Albert and Fornells, Albert},
  date = {2010},
  journaltitle = {Artif. Intell. Rev.},
  issn = {02692821},
  doi = {10.1007/s10462-010-9156-z},
  abstract = {Machine learning techniques often have to deal with noisy data, which may affect the accuracy of the resulting data models. Therefore, effectively dealing with noise is a key aspect in supervised learning to obtain reliable models from data. Although several authors have studied the effect of noise for some particular learners, comparisons of its effect among different learners are lacking. In this paper, we address this issue by systematically comparing how different degrees of noise affect four supervised learners that belong to different paradigms. Specifically, we consider the Na\"ive Bayes probabilistic classifier, the C4.5 decision tree, the IBk instance-based learner and the SMO support vector machine.We have selected four methods which enable us to contrast different learning paradigms, and which are considered to be four of the top ten algorithms in data mining (Yu et al. 2007). We test them on a collection of data sets that are perturbed with noise in the input attributes and noise in the output class. As an initial hypothesis, we assign the techniques to two groups, NB with C4.5 and IBk with SMO, based on their proposed sensitivity to noise, the first group being the least sensitive. The analysis enables us to extract key observations about the effect of different types and degrees of noise on these learning techniques. In general, we find that Na\"ive Bayes appears as the most robust algorithm, and SMO the least, relative to the other two techniques. However, we find that the underlying empirical behavior of the techniques is more complex, and varies depending on the noise type and the specific data set being processed. In general, noise in the training data set is found to give the most difficulty to the learners.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Attribute noise,Class noise,Machine learning techniques,Noise impacts},
  annotation = {356 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{nguyen_VinDrCXR_2022,
  title = {{{VinDr-CXR}}: {{An Open Dataset}} of {{Chest X-Rays With Radiologist}}'s {{Annotations}}},
  shorttitle = {Vindr-{{Cxr}}},
  author = {Nguyen, Ha Q. and Lam, Khanh and Le, Linh T. and Pham, Hieu H. and Tran, Dat Q. and Nguyen, Dung B. and Le, Dung D. and Pham, Chi M. and Tong, Hang T. T. and Dinh, Diep H. and Do, Cuong D. and Doan, Luu T. and Nguyen, Cuong N. and Nguyen, Binh T. and Nguyen, Que V. and Hoang, Au D. and Phan, Hien N. and Nguyen, Anh T. and Ho, Phuong H. and Ngo, Dat T. and Nguyen, Nghia T. and Nguyen, Nhan T. and Dao, Minh and Vu, Van},
  date = {2022-07-20},
  journaltitle = {Sci Data},
  volume = {9},
  number = {1},
  pages = {429},
  issn = {2052-4463},
  doi = {10.1038/s41597-022-01498-w},
  url = {https://www.nature.com/articles/s41597-022-01498-w},
  urldate = {2023-03-28},
  abstract = {Abstract             Most of the existing chest X-ray datasets include labels from a list of findings without specifying their locations on the radiographs. This limits the development of machine learning algorithms for the detection and localization of chest abnormalities. In this work, we describe a dataset of more than 100,000 chest X-ray scans that were retrospectively collected from two major hospitals in Vietnam. Out of this raw data, we release 18,000 images that were manually annotated by a total of 17 experienced radiologists with 22 local labels of rectangles surrounding abnormalities and 6 global labels of suspected diseases. The released dataset is divided into a training set of 15,000 and a test set of 3,000. Each scan in the training set was independently labeled by 3 radiologists, while each scan in the test set was labeled by the consensus of 5 radiologists. We designed and built a labeling platform for DICOM images to facilitate these annotation procedures. All images are made publicly available in DICOM format along with the labels of both the training set and the test set.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-03-27]},
  file = {/Users/personal-macbook/Zotero/storage/IKLLYFKW/Nguyen et al. - 2022 - VinDr-CXR An open dataset of chest X-rays with ra.pdf;/Users/personal-macbook/Zotero/storage/D7J2WWJQ/s41597-022-01498-w.html}
}

@inproceedings{nie_ASDNet_2018,
  title = {{{ASDNet}}: {{Attention Based Semi-Supervised Deep Networks}} for {{Medical Image Segmentation}}},
  booktitle = {Lect. {{Notes Comput}}. {{Sci}}. {{Subser}}. {{Lect}}. {{Notes Artif}}. {{Intell}}. {{Lect}}. {{Notes Bioinforma}}.},
  author = {Nie, Dong and Gao, Yaozong and Wang, Li and Shen, Dinggang},
  date = {2018},
  issn = {16113349},
  doi = {10.1007/978-3-030-00937-3_43},
  abstract = {Segmentation is a key step for various medical image analysis tasks. Recently, deep neural networks could provide promising solutions for automatic image segmentation. The network training usually involves a large scale of training data with corresponding ground truth label maps. However, it is very challenging to obtain the ground-truth label maps due to the requirement of expertise knowledge and also intensive labor work. To address such challenges, we propose a novel semi-supervised deep learning framework, called ``Attention based Semi-supervised Deep Networks'' (ASDNet), to fulfill the segmentation tasks in an end-to-end fashion. Specifically, we propose a fully convolutional confidence network to adversarially train the segmentation network. Based on the confidence map from the confidence network, we then propose a region-attention based semi-supervised learning strategy to include the unlabeled data for training. Besides, sample attention mechanism is also explored to improve the network training. Experimental results on real clinical datasets show that our ASDNet can achieve state-of-the-art segmentation accuracy. Further analysis also indicates that our proposed network components contribute most to the improvement of performance.},
  isbn = {978-3-030-00936-6},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {191 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{nie_FULLY_2016,
  title = {Fully {{Convolutional Networks}} for {{Multi-Modality Isointense Infant Brain Image Segmentation}}},
  author = {Nie, Dong and Wang, Li and Gao, Yaozong and Shen, Dinggang},
  date = {2016},
  journaltitle = {Proc. IEEE Int. Symp. Biomed. Imaging},
  volume = {2016},
  pages = {1342--1345},
  abstract = {The segmentation of infant brain tissue images into white matter (WM), gray matter (GM), and cerebrospinal fluid (CSF) plays an important role in studying early brain development. In the isointense phase (approximately 6-8 months of age), WM and GM exhibit similar levels of intensity in both T1 and T2 MR images, resulting in extremely low tissue contrast and thus making the tissue segmentation very challenging. The existing methods for tissue segmentation in this isointense phase usually employ patch-based sparse labeling on single T1, T2 or fractional anisotropy (FA) modality or their simply-stacked combinations without fully exploring the multi-modality information. To address the challenge, in this paper, we propose to use fully convolutional networks (FCNs) for the segmentation of isointense phase brain MR images. Instead of simply stacking the three modalities, we train one network for each modality image, and then fuse their high-layer features together for final segmentation. Specifically, we conduct a convolution-pooling stream for multimodality information from T1, T2, and FA images separately, and then combine them in high-layer for finally generating the segmentation maps as the outputs. We compared the performance of our approach with that of the commonly used segmentation methods on a set of manually segmented isointense phase brain images. Results showed that our proposed model significantly outperformed previous methods in terms of accuracy. In addition, our results also indicated a better way of integrating multi-modality images, which leads to performance improvement.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found,brain image,FCN,multi-modality,segmentation}
}

@report{nielsen_GAN_2019,
  title = {{{GAN Data Augmentation Through Active Learning Inspired Sample Acquisition}}},
  author = {Nielsen, C. and Okoniewski, M.},
  date = {2019},
  journaltitle = {undefined},
  abstract = {Data augmentation is frequently used to increase the effective training set size when training deep neural networks for supervised learning tasks. This technique is particularly beneficial when the size of the training set is small. Recently, data augmentation using GAN generated samples has been shown to provide performance improvement for supervised learning tasks. In this paper we propose a method of GAN data augmentation for image classification that uses the prediction uncertainty of the classifier network to determine the optimal GAN samples to augment the training set. We apply the acquisition function framework originally developed for active learning to evaluate the sample uncertainty. Preliminary experimental results are provided to demonstrate the benefit of this technique.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{nielsen_Guaranteed_2016,
  title = {Guaranteed {{Bounds}} on {{Information-Theoretic Measures}} of {{Univariate Mixtures Using Piecewise Log-Sum-Exp Inequalities}}},
  author = {Nielsen, Frank and Sun, Ke},
  date = {2016},
  journaltitle = {Entropy},
  issn = {10994300},
  doi = {10.3390/e18120442},
  abstract = {Information-theoreticmeasures, such as the entropy, the cross-entropy and the Kullback-Leibler divergence between two mixture models, are core primitives in many signal processing tasks. Since the Kullback-Leibler divergence of mixtures provably does not admit a closed-form formula, it is in practice either estimated using costly Monte Carlo stochastic integration, approximated or bounded using various techniques. We present a fast and generic method that builds algorithmically closed-form lower and upper bounds on the entropy, the cross-entropy, the Kullback-Leibler and the {$\alpha$}-divergences of mixtures. We illustrate the versatile method by reporting our experiments for approximating the Kullback-Leibler and the {$\alpha$}-divergences between univariate exponential mixtures, Gaussian mixtures, Rayleigh mixtures and Gamma mixtures.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,A-divergences,Information geometry,Log-sum-exp bounds,Mixture models},
  annotation = {66 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{niemann_Morel_2000,
  title = {The {{Morel Stereotactic Atlas}} of the {{Human Thalamus}}: {{Atlas-to-Mr Registration}} of {{Internally Consistent Canonical Model}}},
  author = {Niemann, K. and Mennicken, V. R. and Jeanmonod, D. and Morel, A.},
  date = {2000-12},
  journaltitle = {Neuroimage},
  volume = {12},
  number = {6},
  pages = {601--616},
  doi = {10.1006/nimg.2000.0650},
  abstract = {In 1997, Morel, Magnin, and Jeanmonod presented a microscopic stereotactic atlas of the human thalamus. Parcellations of thalamic nuclei did not only use cyto- and myeloarchitectonic criteria, but were additionally corroborated by staining for calcium-binding proteins, which bears functional significance. The atlas complies with the Anglosaxon nomenclature elaborated by Jones and the data were sampled in three orthogonal planes in the AC-PC reference space. We report on the generation of three-dimensional digital models of the thalamus based on the three sets of sections (sagittal, horizontal, and frontal). Spatial differences between the three anatomical specimens were evaluated using the centers of gravity of 13 selected nuclei as landmarks. Subsequent linear regression analysis yielded equations, which were used to normalize the frontal and horizontal digital models to the sagittal one. The outcome is an internally consistent Canonical Model of Morel's atlas, which minimizes the linear component of the variability between the three sectioned anatomical specimens. In addition, we demonstrate the feasibility of the atlas-to-MRI registration in conjunction with on-line visualization of the trajectory in the digital models.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Brain atlas,Calcium binding proteins,Stereotaxy,Thalamus}
}

@inproceedings{ning_UncertaintyDriven_2022,
  title = {Uncertainty-{{Driven Loss}} for {{Single Image Super-Resolution}}},
  author = {Ning, Qian and Dong, Weisheng and Li, Xin and Wu, Jinjian and Shi, Guangming},
  date = {2022-01-08},
  url = {https://openreview.net/forum?id=WA39qkJvLi},
  urldate = {2022-07-04},
  abstract = {To prioritize visually important image structures (e.g., texture and edge pixels), we propose a novel uncertainty-driven loss function and demonstrate its supriority to traditional MSE/L\_1 losses...},
  eventtitle = {Advances in {{Neural Information Processing Systems}}},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/ERIH7XHP/Ning et al. - 2022 - Uncertainty-Driven Loss for Single Image Super-Res.pdf;/Users/personal-macbook/Zotero/storage/9KPALUC4/forum.html}
}

@inproceedings{nohara_Study_2005,
  title = {Study of {{Dynamics}} of {{Sweat Glands}} of {{Human Finger Tip Using All-Optical-Fiber High-Speed OCT}}},
  booktitle = {2005 {{Pac}}. {{Rim Conf}}. {{Lasers Electro-Opt}}.},
  author = {Nohara, K. and Ueda, Y. and Fuji, T. and Ohmi, M. and Haruna, M.},
  date = {2005-07},
  pages = {92--93},
  abstract = {Dynamics of sweat glands of human finger tip is observed in vivo, for the first time to our knowledge, using high-speed OCT with push-pull driven fiber-optic PZT modulators. Movement of a sweat droplet through a micro spiral duct can be tracked clearly.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Fingers,Humans,Optical interferometry,Sweat glands}
}

@article{nomori_Evaluation_2004,
  title = {Evaluation of {{F-18 Fluorodeoxyglucose}} ({{FDG}}) {{PET Scanning}} for {{Pulmonary Nodules Less Than}} 3 {{Cm}} in {{Diameter}}, {{With Special Reference}} to the {{CT Images}}},
  author = {Nomori, Hiroaki and Watanabe, Kenichi and Ohtsuka, Takashi and Naruke, Tsuguo and Suemasu, Keiichi and Uno, Kimiichi},
  date = {2004-07},
  journaltitle = {Lung Cancer},
  volume = {45},
  number = {1},
  pages = {19--27},
  doi = {10.1016/j.lungcan.2004.01.009},
  abstract = {BACKGROUND: While pulmonary nodules can be substantially divided into solid and ground-glass opacity (GGO) ones on CT image, they have different biological natures which could cause false positive or false negative to diagnose malignancy on positron emission tomography with fluorodeoxyglucose (FDG-PET). To determine the effectiveness of PET for small pulmonary nodules, the nodules were classified into solid and GGO ones, of which results were compared with the data of PET scans. The lower limit size of nodules for PET imaging was also evaluated. METHODS: Prospective FDG-PET scans were undertaken for 136 non-calcified nodules less than 3 cm in diameter. CT density histograms were made for each nodule to classify into solid and GGO ones. RESULTS: Eighty-one nodules were malignant and 55 were benign. All of the 20 nodules less than 1 cm in diameter (n = 8 in malignant, n = 12 in benign), were negative on PET regardless of the histology. In the 116 nodules 1-3 cm in diameter (n = 73 in malignant, n = 43 in benign), there were 15 false negative and 15 false positive nodules, with a sensitivity of 79\% and specificity of 65\%. CT density histograms showed 101 solid nodules (n = 63 in malignant, n = 38 in benign) and 15 GGO nodules ( n = 10 in malignant, n = 5 in benign). All of the 10 malignant nodules with GGO images were histologically well-differentiated adenocarcinoma and 9 of them (90\%) were false negative on PET. Four of the 5 (80\%) benign nodules with GGO images were focal pneumonia with well-preserved air spaces, causing false positive on PET. Sensitivity and specificity for nodules with GGO images were 10 and 20\%, respectively, which were significantly lower than 90 and 71\% for nodules with solid images (P {$<$} 0.001). CONCLUSION: Pulmonary nodules which are less than 1cm in size or show GGO images on CT cannot be evaluated accurately by PET.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {318 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{norouzi_Stacks_2009,
  title = {Stacks of {{Convolutional Restricted Boltzmann Machines}} for {{Shift-Invariant Feature Learning}}},
  booktitle = {2009 {{IEEE Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}.},
  author = {Norouzi, M. and Ranjbar, M. and Mori, G.},
  date = {2009-06},
  pages = {2735--2742},
  abstract = {In this paper we present a method for learning class-specific features for recognition. Recently a greedy layer-wise procedure was proposed to initialize weights of deep belief networks, by viewing each layer as a separate restricted Boltzmann machine (RBM). We develop the convolutional RBM (C-RBM), a variant of the RBM model in which weights are shared to respect the spatial structure of images. This framework learns a set of features that can generate the images of a specific object class. Our feature extraction model is a four layer hierarchy of alternating filtering and maximum subsampling. We learn feature parameters of the first and third layers viewing them as separate C-RBMs. The outputs of our feature extraction hierarchy are then fed as input to a discriminative classifier. It is experimentally demonstrated that the extracted features are effective for object detection, using them to obtain performance comparable to the state of the art on handwritten digit recognition and pedestrian detection.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,belief networks,Boltzmann machines,feature extract}
}

@thesis{northcutt_Confident_2021,
  title = {Confident {{Learning}} for {{Machines}} and {{Humans}}},
  author = {Northcutt, Curtis George},
  date = {2021-05-20},
  institution = {{MIT}},
  url = {https://www.curtisnorthcutt.com/resources/pdf/northcutt-confident-learning-for-machines-and-humans.pdf},
  abstract = {The coupling of machine intelligence and human intelligence has the potential to empower humans with augmented capabilities (e.g., improving rhyme-density while writing song lyrics, enhancing empathy via emotion detection, and personalizing learning in online courses). Unfortunately, humans operate in an uncertain world \textendash{} where the performance of even the most sophisticated model-centric artificially intelligent system often depends on its data-centric ability to deal with the uncertainty in the labels upon which it is trained.},
  langid = {english},
  pagetotal = {258},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/PMMJ76DV/Northcutt - Confident Learning for Machines and Humans.pdf}
}

@article{northcutt_Confident_2021a,
  title = {Confident {{Learning}}: {{Estimating Uncertainty}} in {{Dataset Labels}}},
  shorttitle = {Confident {{Learning}}},
  author = {Northcutt, Curtis and Jiang, Lu and Chuang, Isaac},
  date = {2021},
  journaltitle = {J. Artif. Intell. Res.},
  volume = {70},
  pages = {1373--1411},
  doi = {10.1613/jair.1.12125},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {287 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/IXTRYEKF/Northcutt et al. - 2021 - Confident learning Estimating uncertainty in data.pdf}
}

@article{northcutt_Pervasive_2021,
  title = {Pervasive {{Label Errors}} in {{Test Sets Destabilize Machine Learning Benchmarks}}},
  author = {Northcutt, Curtis G. and Athalye, Anish and Mueller, Jonas},
  date = {2021},
  journaltitle = {ArXiv Prepr. ArXiv210314749},
  eprint = {2103.14749},
  eprinttype = {arxiv},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/C5BE77LS/Northcutt et al. - 2021 - Pervasive label errors in test sets destabilize ma.pdf}
}

@article{novikov_Fully_2018,
  ids = {novikov_Fully_2017},
  title = {Fully {{Convolutional Architectures}} for {{Multiclass Segmentation}} in {{Chest Radiographs}}},
  author = {Novikov, Alexey A. and Lenis, Dimitrios and Major, David and Hladuvka, Jiri and Wimmer, Maria and Buhler, Katja and Hlad\r{u}vka, Jiri and Wimmer, Maria and B\"uhler, Katja and Hladuvka, Jiri and Wimmer, Maria and Buhler, Katja},
  date = {2018-08},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {37},
  number = {8},
  eprint = {29994439},
  eprinttype = {pmid},
  pages = {1865--1876},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  doi = {10.1109/TMI.2018.2806086},
  url = {http://arxiv.org/abs/1701.08816 https://ieeexplore.ieee.org/document/8302848/},
  abstract = {The success of deep convolutional neural networks (NNs) on image classification and recognition tasks has led to new applications in very diversified contexts, including the field of medical imaging. In this paper, we investigate and propose NN architectures for automated multiclass segmentation of anatomical organs in chest radiographs (CXRs), namely for lungs, clavicles, and heart. We address several open challenges including model overfitting, reducing number of parameters, and handling of severely imbalanced data in CXR by fusing recent concepts in convolutional networks and adapting them to the segmentation problem task in CXR. We demonstrate that our architecture combining delayed subsampling, exponential linear units, highly restrictive regularization, and a large number of high-resolution low-level abstract features outperforms state-of-the-art methods on all considered organs, as well as the human observer on lungs and heart. The models use a multiclass configuration with three target classes and are trained and tested on the publicly available Japanese Society of Radiological Technology database, consisting of 247 X-ray images the ground-truth masks for which are available in the segmentation in CXR database. Our best performing model, trained with the loss function based on the Dice coefficient, reached mean Jaccard overlap scores of 95\% for lungs, 86.8\% for clavicles, and 88.2\% for heart. This architecture outperformed the human observer results for lungs and heart.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,chest radiographs,clavicle segmentation,fully convolutional network,heart segmentation,imbalanced data,JSRT dataset,Lung segmentation,multi-class segmentation,regularization},
  annotation = {182 citations (Semantic Scholar/arXiv) [2023-05-08] 182 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{nyul_Standardizing_1999,
  title = {On {{Standardizing}} the {{Mr Image Intensity Scale}}},
  author = {Ny\'ul, L. G. and Udupa, J. K.},
  date = {1999-12},
  journaltitle = {Magn. Reson. Med.},
  volume = {42},
  number = {6},
  pages = {1072--1081},
  doi = {10.1002/(SICI)1522-2594(199912)42:6<1072::AID-MRM11>3.0.CO;2-M},
  abstract = {The lack of a standard image intensity scale in MRI causes many difficulties in image display and analysis. A two-step postprocessing method is proposed for standardizing the intensity scale in such a way that for the same MR protocol and body region, similar intensities will have similar tissue meaning. In the first step, the parameters of the standardizing transformation are ``learned'' from a set of images. In the second step, for each MR study these parameters are used to map their histogram into the standardized histogram. The method was tested quantitatively on 90 whole-brain studies of multiple sclerosis patients for several protocols and qualitatively for several other protocols and body regions. Measurements using mean squared difference showed that the standardized image intensities have statistically significantly (P {$<$} 0.01) more consistent range and meaning than the originals. Fixed gray level windows can be established for the standardized images and used for display without the need of per case adjustment. Preliminary results also indicate that the method facilitates improving the degree of automation of image segmentation. Magn Reson Med 42:1072-1081, 1999.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{obermeyer_Predicting_2016,
  title = {Predicting the {{Future-Big Data}}, {{Machine Learning}}, and {{Clinical Medicine}}},
  author = {Obermeyer, Ziad and Emanuel, Ezekiel J.},
  date = {2016},
  journaltitle = {N. Engl. J. Med.},
  eprint = {27682033},
  eprinttype = {pmid},
  issn = {15334406},
  doi = {10.1056/NEJMp1606181},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@book{oecd_Artificial_2019,
  ids = {_Artificial_2019},
  title = {Artificial {{Intelligence}} in {{Society}}},
  author = {{OECD}},
  date = {2019-06-11},
  publisher = {{OECD}},
  doi = {10.1787/eedfee77-en},
  url = {https://www.oecd-ilibrary.org/science-and-technology/artificial-intelligence-in-society_eedfee77-en},
  urldate = {2023-05-09},
  isbn = {978-92-64-58254-5 978-92-64-92543-4 978-92-64-36603-9 978-92-64-54519-9},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{ohmi_Dynamic_2012,
  title = {Dynamic {{Analysis}} for {{Mental Sweating}} of a {{Group}} of {{Eccrine Sweat Glands}} on a {{Human Fingertip}} by {{Optical Coherence Tomography}}},
  author = {Ohmi, Masato and Tanigawa, Motomu and Wada, Yuki and Haruna, Masamitsu},
  date = {2012},
  journaltitle = {Skin Res. Technol.},
  eprint = {22092881},
  eprinttype = {pmid},
  issn = {0909752X},
  doi = {10.1111/j.1600-0846.2011.00580.x},
  abstract = {Background: An important function of skin physiology is mental sweating, where sweating is accelerated via the sympathetic nerve by mental or physical stress externally applied to a volunteer. Aim: Activity of the sympathetic nerve (ASN) is evaluated by quantitative measurement of mental sweating. Material and Methods: Optical coherence tomography (OCT) is highly potential for in vivo observation of human sweating dynamics which affects ASN. We demonstrate dynamic OCT analysis of mental sweating of a group of eccrine sweat glands. The sweating dynamics is tracked simultaneously for 19 sweat glands by time-sequential piled-up en-face OCT images with the frame spacing of 3.3 s. The en-face OCT images of the spiral lumen of the eccrine sweat gland are constructed by data acquisition of the 128 B-mode OCT images. Results: It is thus found that the response to mental stress is different for each sweat gland even though the sweat glands are adjacent to each other. Such strong non-uniformity is observed in mental sweating where the amount of excess sweat is different for each sweat gland although the sweat glands are adjacent to each other. Discussion: The non-uniformity should be necessary to adjust as precisely the total amount of excess sweat as possible through the sympathetic nerve in response to strength of the stress. \textcopyright{} 2011 John Wiley \& Sons A/S.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Eccrine sweat gland,Maximum-intensity-projection (MIP),Mental sweating,Optical coherence tomography (OCT),Sympathetic nerve},
  annotation = {22 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{olabarriaga_Interaction_2001,
  title = {Interaction in the {{Segmentation}} of {{Medical Images}}: {{A Survey}}},
  author = {Olabarriaga, S. D. and Smeulders, A. W.},
  date = {2001-06},
  journaltitle = {Med. Image Anal.},
  volume = {5},
  number = {2},
  pages = {127--142},
  doi = {10.1016/S1361-8415(00)00041-4},
  abstract = {Segmentation of the object of interest is a difficult step in the analysis of digital images. Fully automatic methods sometimes fail, producing incorrect results and requiring the intervention of a human operator. This is often true in medical applications, where image segmentation is particularly difficult due to restrictions imposed by image acquisition, pathology and biological variation. In this paper we present an early review of the largely unknown territory of human-computer interaction in image segmentation. The purpose is to identify patterns in the use of interaction and to develop qualitative criteria to evaluate interactive segmentation methods. We discuss existing interactive methods with respect to the following aspects: the type of information provided by the user, how this information affects the computational part, and the purpose of interaction in the segmentation process. The discussion is based on the potential impact of each strategy on the accuracy, repeatability and interaction efficiency. Among others, these are important aspects to characterise and understand the implications of interaction to the results generated by an interactive segmentation method. This survey is focused on medical imaging, however similar patterns are expected to hold for other applications as well.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {416 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{omoumi_Buy_2021,
  title = {To {{Buy}} or {{Not}} to {{Buy}}\textemdash Evaluating {{Commercial AI Solutions}} in {{Radiology}} ({{The ECLAIR Guidelines}})},
  author = {Omoumi, Patrick and Ducarouge, Alexis and Tournier, Antoine and Harvey, Hugh and Kahn, Charles E. and Louvet-de Verch\`ere, Fanny and Pinto Dos Santos, Daniel and Kober, Tobias and Richiardi, Jonas},
  date = {2021-06-01},
  journaltitle = {Eur Radiol},
  volume = {31},
  number = {6},
  pages = {3786--3796},
  issn = {1432-1084},
  doi = {10.1007/s00330-020-07684-x},
  url = {https://doi.org/10.1007/s00330-020-07684-x},
  urldate = {2022-06-14},
  abstract = {Artificial intelligence (AI) has made impressive progress over the past few years, including many applications in medical imaging. Numerous commercial solutions based on AI techniques are now available for sale, forcing radiology practices to learn how to properly assess these tools. While several guidelines describing good practices for conducting and reporting AI-based research in medicine and radiology have been published, fewer efforts have focused on recommendations addressing the key questions to consider when critically assessing AI solutions before purchase. Commercial AI solutions are typically complicated software products, for the evaluation of which many factors are to be considered. In this work, authors from academia and industry have joined efforts to propose a practical framework that will help stakeholders evaluate commercial AI solutions in radiology (the ECLAIR guidelines) and reach an informed decision. Topics to consider in the evaluation include the relevance of the solution from the point of view of each stakeholder, issues regarding performance and validation, usability and integration, regulatory and legal aspects, and financial and support services.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Artificial intelligence,Equipment and supplies,Legislation,Software,Workload},
  file = {/Users/personal-macbook/Zotero/storage/U8B5TTIT/Omoumi et al. - 2021 - To buy or not to buy—evaluating commercial AI solu.pdf}
}

@article{opbroek_Transfer_2015,
  title = {Transfer {{Learning Improves Supervised Image Segmentation Across Imaging Protocols}}},
  author = {family=Opbroek, given=Annegreet, prefix=van, useprefix=false and Ikram, M. Arfan and Vernooij, Meike W. and family=Bruijne, given=Marleen, prefix=de, useprefix=false},
  date = {2015-05},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {34},
  number = {5},
  pages = {1018--1030},
  doi = {10.1109/TMI.2014.2366792},
  abstract = {The variation between images obtained with different scanners or different imaging protocols presents a major challenge in automatic segmentation of biomedical images. This variation especially hampers the application of otherwise successful supervised-learning techniques which, in order to perform well, often require a large amount of labeled training data that is exactly representative of the target data. We therefore propose to use transfer learning for image segmentation. Transfer-learning techniques can cope with differences in distributions between training and target data, and therefore may improve performance over supervised learning for segmentation across scanners and scan protocols. We present four transfer classifiers that can train a classification scheme with only a small amount of representative training data, in addition to a larger amount of other training data with slightly different characteristics. The performance of the four transfer classifiers was compared to that of standard supervised classification on two magnetic resonance imaging brain-segmentation tasks with multi-site data: white matter, gray matter, and cerebrospinal fluid segmentation; and white-matter-/MS-lesion segmentation. The experiments showed that when there is only a small amount of representative training data available, transfer learning can greatly outperform common supervised-learning approaches, minimizing classification errors by up to 60\%.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{oquab_Learning_2014,
  title = {Learning and {{Transferring Mid-Level Image Representations Using Convolutional Neural Networks}}},
  booktitle = {2014 {{IEEE Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}.},
  author = {Oquab, Maxime and Bottou, Leon and Laptev, Ivan and Sivic, Josef},
  date = {2014-06},
  pages = {1717--1724},
  publisher = {{IEEE}},
  location = {{Columbus, OH, USA}},
  doi = {10.1109/CVPR.2014.222},
  url = {https://ieeexplore.ieee.org/document/6909618},
  urldate = {2023-05-10},
  eventtitle = {2014 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-4799-5118-5},
  file = {/Users/personal-macbook/Zotero/storage/H6L9FBI5/Oquab et al. - 2014 - Learning and Transferring Mid-level Image Represen.pdf}
}

@book{organization_Global_2013,
  title = {Global {{Tuberculosis Report}} 2013},
  author = {Organization, World Health},
  date = {2013},
  eprint = {1rQXDAAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {{World Health Organization}},
  abstract = {This is the eighteenth global report on tuberculosis (TB) published by WHO in a series that started in 1997. It provides a comprehensive and up-to-date assessment of the TB epidemic and progress in implementing and financing TB prevention care and control at global regional and country levels using data reported by almost 200 countries that account for over 99\% of the world's TB cases. Two years before the 2015 deadline for achievement of global TB targets the 2013 report includes a special supplement that assesses progress towards the 2015 targets and the actions needed to accelerate towards or move beyond them.The report has 8 main chapters. The introductory chapter provides general background on TB as well as an explanation of global targets for TB control the WHO's Stop TB Strategy that covers the period 2006-2015 and the development of a post-2015 global TB strategy. The remaining seven chapters cover the disease burden caused by TB (incidence prevalence mortality); TB case notifications and treatment outcomes; drug resistance surveillance among TB patients and the programmatic response in detecting and providing treatment for multidrug-resistant TB; diagnostics and laboratory strengthening for TB; addressing the co-epidemics of TB and HIV; financing TB care and control; and research and development for new TB diagnostics drugs and vaccines.The four annexes of the report include a thorough explanation of methods used to estimate the burden of disease caused by TB one-page profiles for 22 high TB-burden countries and tables of data on key indicators for all countries organized by WHO region.},
  isbn = {978-92-4-156465-6},
  langid = {english},
  pagetotal = {303},
  keywords = {⛔ No INSPIRE recid found,Medical / Infectious Diseases,Medical / Public Health},
  file = {/Users/personal-macbook/Zotero/storage/7HS63QNC/1rQXDAAAQBAJ.html;/Users/personal-macbook/Zotero/storage/EV6WN7UA/global-tuberculosis-report-2013.html}
}

@book{organization_Global_2015,
  title = {Global {{Tuberculosis Report}} 2015},
  author = {Organization, World Health Organization},
  date = {2015},
  publisher = {{World Health Organization}},
  url = {https://apps.who.int/iris/handle/10665/191102},
  urldate = {2022-11-21},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/5NA4L6T8/191102.html;/Users/personal-macbook/Zotero/storage/PNHGQ3IZ/global-tuberculosis-report-2015.html}
}

@article{otsu_Threshold_1979,
  title = {A {{Threshold Selection Method From Gray-Level Histograms}}},
  author = {Otsu, Nobuyuki},
  date = {1979-01},
  journaltitle = {IEEE Trans. Syst. Man Cybern.},
  volume = {9},
  number = {1},
  pages = {62--66},
  issn = {0018-9472, 2168-2909},
  doi = {10.1109/tsmc.1979.4310076},
  url = {http://ieeexplore.ieee.org/document/4310076/},
  urldate = {2023-05-08},
  keywords = {\#nosource},
  annotation = {9996 citations (Semantic Scholar/DOI) [2023-05-08] 22 citations (INSPIRE 2023/5/8) 22 citations w/o self (INSPIRE 2023/5/8)}
}

@article{ozdemir_Propagating_2017,
  title = {Propagating {{Uncertainty}} in {{Multi-Stage Bayesian Convolutional Neural Networks With Application}} to {{Pulmonary Nodule Detection}}},
  author = {Ozdemir, Onur and Woodward, Benjamin and Berlin, Andrew A.},
  date = {2017-12},
  url = {http://arxiv.org/abs/1712.00497},
  abstract = {Motivated by the problem of computer-aided detection (CAD) of pulmonary nodules, we introduce methods to propagate and fuse uncertainty information in a multi-stage Bayesian convolutional neural network (CNN) architecture. The question we seek to answer is "can we take advantage of the model uncertainty provided by one deep learning model to improve the performance of the subsequent deep learning models and ultimately of the overall performance in a multi-stage Bayesian deep learning architecture?". Our experiments show that propagating uncertainty through the pipeline enables us to improve the overall performance in terms of both final prediction accuracy and model confidence.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{pan_Domain_2011,
  title = {Domain {{Adaptation}} via {{Transfer Component Analysis}}},
  author = {Pan, Sinno Jialin and Tsang, Ivor W. and Kwok, James T. and Yang, Qiang},
  date = {2011},
  journaltitle = {IEEE Trans. Neural Netw.},
  eprint = {21095864},
  eprinttype = {pmid},
  issn = {10459227},
  doi = {10.1109/TNN.2010.2091281},
  abstract = {Domain adaptation allows knowledge from a source domain to be transferred to a different but related target domain. Intuitively, discovering a good feature representation across domains is crucial. In this paper, we first propose to find such a representation through a new learning method, transfer component analysis (TCA), for domain adaptation. TCA tries to learn some transfer components across domains in a reproducing kernel Hilbert space using maximum mean miscrepancy. In the subspace spanned by these transfer components, data properties are preserved and data distributions in different domains are close to each other. As a result, with the new representations in this subspace, we can apply standard machine learning methods to train classifiers or regression models in the source domain for use in the target domain. Furthermore, in order to uncover the knowledge hidden in the relations between the data labels from the source and target domains, we extend TCA in a semisupervised learning setting, which encodes label information into transfer components learning. We call this extension semisupervised TCA. The main contribution of our work is that we propose a novel dimensionality reduction framework for reducing the distance between domains in a latent space for domain adaptation. We propose both unsupervised and semisupervised feature extraction approaches, which can dramatically reduce the distance between domain distributions by projecting data onto the learned transfer components. Finally, our approach can handle large datasets and naturally lead to out-of-sample generalization. The effectiveness and efficiency of our approach are verified by experiments on five toy datasets and two real-world applications: cross-domain indoor WiFi localization and cross-domain text classification. \textcopyright{} 2010 IEEE.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Dimensionality reduction,domain adaptation,Hilbert space embedding of distributions,transfer learning},
  annotation = {3131 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{panch_Inconvenient_2019,
  title = {The ``{{Inconvenient Truth}}'' {{About AI}} in {{Healthcare}}},
  author = {Panch, Trishan and Mattie, Heather and Celi, Leo Anthony},
  date = {2019},
  journaltitle = {Npj Digit. Med.},
  issn = {23986352},
  doi = {10.1038/s41746-019-0155-4},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{papernot_Deep_2018,
  title = {Deep {{K-Nearest Neighbors}}: {{Towards Confident}}, {{Interpretable}} and {{Robust Deep Learning}}},
  author = {Papernot, Nicolas and McDaniel, Patrick},
  date = {2018-03},
  url = {https://arxiv.org/abs/1803.04765},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found},
  annotation = {395 citations (Semantic Scholar/arXiv) [2023-05-08]}
}

@article{paris_Local_,
  title = {Local {{Laplacian Filters}}: {{Edge-Aware Image Processing With}} a {{Laplacian Pyramid}}},
  author = {Paris, Sylvain and Hasinoff, Samuel W.},
  keywords = {⛔ No INSPIRE recid found,❓ Multiple DOI}
}

@inproceedings{park_Digital_2012,
  title = {Digital {{Restoration}} of {{Seokguram Grotto}}: {{The Digital Archiving}} and the {{Exhibition}} of {{South Korea}}'s {{Representative UNESCO World Heritage}}},
  booktitle = {Proc. - 2012 {{Int}}. {{Symp}}. {{Ubiquitous Virtual Real}}. {{ISUVR}} 2012},
  author = {Park, Jin Ho},
  date = {2012},
  pages = {26--29},
  doi = {10.1109/ISUVR.2012.23},
  abstract = {The digitalization of Seokguram Grotto, a UNESCO World Heritage: KAIST GSCT produced a digitalized mapping of Seokguram Grotto, a UNESCO World Heritage and South Korea's representative cultural heritage, on two separate occasions in year 2008 and 2011. The Seokguram Grotto was the first to be registered at UNESCO among South Korean cultural heritages in year 1996. Hence, we are able to understand the value and the significance of the existence of Seokguram Grotto amongst numerous cultural heritages of South Korea. The team had performed the digitalization process of Seokguram Grotto in cooperation with the National Museum of Korea in year 2008 and had also performed the digitalization process of Seokguram Grotto with the Cultural Heritage Administration in year 2011. Through the process of 3D Scans and et cetera, the team had successfully digitalized the Seokguram Grotto as the world's first. This thesis consists of the process of the digitalization of Seokguram Grotto, the process of generating its 3D stereopsis and the future blueprints for creating Seokguram Grotto's Virtual Museum in the future. In other words, the current level is limited to archiving and creating 3D stereopsis of Seokguram Grotto, and the Seokguram Grotto Virtual Museum is expected to be built at Sejong City in the future on the basis of 3D scan data of Seokguram Grotto. The values of Seokguram Grotto which upholds cultural legacy and how they can be digitalized with advanced exhibition technology in delivering quality approaches of its exhibition are the core subjects of this thesis. \textcopyright{} 2012 IEEE.},
  isbn = {978-0-7695-4766-4},
  keywords = {\#nosource,⛔ No INSPIRE recid found,3D Scan,Digital Cultural Heritage Museum,Digital Restoration,Sejong City,Seokguram Grotto,Seokguram Grotto's Virtual Museum},
  annotation = {6 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{parmar_Healthfocused_2022,
  title = {Health-{{Focused Conversational Agents}} in {{Person-Centered Care}}: {{A Review}} of {{Apps}}},
  shorttitle = {Health-Focused Conversational Agents in Person-Centered Care},
  author = {Parmar, Pritika and Ryu, Jina and Pandya, Shivani and Sedoc, Jo\~ao and Agarwal, Smisha},
  date = {2022-02-17},
  journaltitle = {npj Digit. Med.},
  volume = {5},
  number = {1},
  pages = {1--9},
  publisher = {{Nature Publishing Group}},
  issn = {2398-6352},
  doi = {10.1038/s41746-022-00560-6},
  url = {https://www.nature.com/articles/s41746-022-00560-6},
  urldate = {2022-06-14},
  abstract = {Health-focused apps with chatbots (``healthbots'') have a critical role in addressing gaps in quality healthcare. There is limited evidence on how such healthbots are developed and applied in practice. Our review of healthbots aims to classify types of healthbots, contexts of use, and their natural language processing capabilities. Eligible apps were those that were health-related, had an embedded text-based conversational agent, available in English, and were available for free download through the Google Play or Apple iOS store. Apps were identified using 42Matters software, a mobile app search engine. Apps were assessed using an evaluation framework addressing chatbot characteristics and natural language processing features. The review suggests uptake across 33 low- and high-income countries. Most healthbots are patient-facing, available on a mobile interface and provide a range of functions including health education and counselling support, assessment of symptoms, and assistance with tasks such as scheduling. Most of the 78 apps reviewed focus on primary care and mental health, only 6 (7.59\%) had a theoretical underpinning, and 10 (12.35\%) complied with health information privacy regulations. Our assessment indicated that only a few apps use machine learning and natural language processing approaches, despite such marketing claims. Most apps allowed for a finite-state input, where the dialogue is led by the system and follows a predetermined algorithm. Healthbots are potentially transformative in centering care around the user; however, they are in a nascent state of development and require further research on development, automation and adoption for a population-level health impact.},
  issue = {1},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Lifestyle modification,Patient education,Public health,Quality of life},
  annotation = {9 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/KEMKFW3J/Parmar et al. - 2022 - Health-focused conversational agents in person-cen.pdf;/Users/personal-macbook/Zotero/storage/CTSQTXSG/s41746-022-00560-6.html}
}

@article{parnaudeau_Mediodorsal_2018,
  title = {The {{Mediodorsal Thalamus}}: {{An Essential Partner}} of the {{Prefrontal Cortex}} for {{Cognition}}},
  author = {Parnaudeau, S\'ebastien and Bolkan, Scott S. and Kellendonk, Christoph},
  date = {2018-04},
  journaltitle = {Biol. Psychiatry},
  volume = {83},
  number = {8},
  pages = {648--656},
  doi = {10.1016/j.biopsych.2017.11.008},
  abstract = {Deficits in cognition are a core feature of many psychiatric conditions, including schizophrenia, where the severity of such deficits is a strong predictor of long-term outcome. Impairment in cognitive domains such as working memory and behavioral flexibility has typically been associated with prefrontal cortex (PFC) dysfunction. However, there is increasing evidence that the PFC cannot be dissociated from its main thalamic counterpart, the mediodorsal thalamus (MD). Since the causal relationships between MD-PFC abnormalities and cognitive impairment, as well as the neuronal mechanisms underlying them, are difficult to address in humans, animal models have been employed for mechanistic insight. In this review, we discuss anatomical, behavioral, and electrophysiological findings from animal studies that provide a new understanding on how MD-PFC circuits support higher-order cognitive function. We argue that the MD may be required for amplifying and sustaining cortical representations under different behavioral conditions. These findings advance a new framework for the broader involvement of distributed thalamo-frontal circuits in cognition and point to the MD as a potential therapeutic target for improving cognitive deficits in schizophrenia and other disorders.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Behavioral flexibility,Mediodorsal thalamus,Pref,Prefrontal cortex,Schizophrenia,Thalamo-cortical connectivity,thalamus,Working memory}
}

@article{pasa_Efficient_2019,
  title = {Efficient {{Deep Network Architectures}} for {{Fast Chest X-Ray Tuberculosis Screening}} and {{Visualization}}},
  author = {Pasa, F. and Golkov, V. and Pfeiffer, F. and Cremers, D. and Pfeiffer, D.},
  date = {2019-12},
  journaltitle = {Sci Rep},
  volume = {9},
  number = {1},
  pages = {6268},
  issn = {2045-2322},
  doi = {10.1038/s41598-019-42557-4},
  url = {http://www.nature.com/articles/s41598-019-42557-4},
  urldate = {2022-11-21},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {201 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/7BEWFFST/Pasa et al. - 2019 - Efficient Deep Network Architectures for Fast Ches.pdf;/Users/personal-macbook/Zotero/storage/ZF6VSFL9/s41598-019-42557-4.html}
}

@article{paschalidis_How_2017,
  title = {How {{Machine Learning Is Helping Us Predict Heart Disease}} and {{Diabetes}}},
  author = {Paschalidis, Ioannis},
  date = {2017},
  journaltitle = {Harv. Bus. Rev.},
  abstract = {While debate drags on about legislation, regulations, and other measures to improve the U.S. health care system, a new wave of analytics and technology could help dramatically cut costly and unnecessary hospitalizations while improving outcomes for patients. For example, by preventing hospitalizations in cases of just two widespread chronic illnesses-heart disease and diabetes-the United States could save billions of dollars a year. 2},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{patenaude_Bayesian_2011,
  title = {A {{Bayesian Model}} of {{Shape}} and {{Appearance}} for {{Subcortical Brain Segmentation}}},
  author = {Patenaude, Brian and Smith, Stephen M. and Kennedy, David N. and Jenkinson, Mark},
  date = {2011-06},
  journaltitle = {NeuroImage},
  volume = {56},
  number = {3},
  pages = {907--922},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2011.02.046},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811911002023},
  urldate = {2023-05-08},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Bayesian,Classification,Segmentation,Shape model,Subcortical structures},
  annotation = {1977 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/CHCKVRJJ/Patenaude et al. - 2011 - A Bayesian model of shape and appearance for subco.pdf}
}

@article{pavlidis_Fast_2012,
  title = {Fast by {{Nature}} - {{How Stress Patterns Define Human Experience}} and {{Performance}} in {{Dexterous Tasks}}},
  author = {Pavlidis, I. and Tsiamyrtzis, P. and Shastri, D. and Wesley, A. and Zhou, Y. and Lindner, P. and Buddharaju, P. and Joseph, R. and Mandapati, A. and Dunkin, B. and Bass, B.},
  date = {2012-03},
  journaltitle = {Sci. Rep.},
  volume = {2},
  pages = {305},
  abstract = {In the present study we quantify stress by measuring transient perspiratory responses on the perinasal area through thermal imaging. These responses prove to be sympathetically driven and hence, a likely indicator of stress processes in the brain. Armed with the unobtrusive measurement methodology we developed, we were able to monitor stress responses in the context of surgical training, the quintessence of human dexterity. We show that in dexterous tasking under critical conditions, novices attempt to perform a task's step equally fast with experienced individuals. We further show that while fast behavior in experienced individuals is afforded by skill, fast behavior in novices is likely instigated by high stress levels, at the expense of accuracy. Humans avoid adjusting speed to skill and rather grow their skill to a predetermined speed level, likely defined by neurophysiological latency.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@thesis{pawlowski_Machine_2019,
  title = {Machine {{Learning}} for {{Problems With Missing}} and {{Uncertain Data With Applications}} to {{Personalized Medicine}}},
  author = {Pawlowski, Colin},
  date = {2019},
  journaltitle = {MIT},
  institution = {{MIT}},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{pearson_Reversible_2007,
  title = {Reversible {{Photoregulation}} of {{Binding}} of the {{Serine Protease $A$-Chymotrypsin}} to a {{Functional Surface}}},
  author = {Pearson, D. S.},
  date = {2007},
  url = {http://hdl.handle.net/10092/2508},
  urldate = {2022-05-16},
  abstract = {This thesis presents the first example of reversible photoregulation of the binding of a protease, {$\alpha$}-chymotrypsin, to a surface. A modular approach is used involving the azobenzene photoswitch group, a surface linker and an enzyme binding group. This approach is designed to be easily extended to the photoregulation of binding of other proteases to surfaces by use of enzyme binding groups selective to these proteases. Chapter one gives a brief outline of some of the important areas involved in to this work, including molecular switches, proteases and surface modification. Chapter two describes the synthesis of azobenzene-containing boronate esters designed as photoswitch inhibitors of {$\alpha$}-chymotrypsin. Boronate esters were prepared containing the aminophenylboronate group or the peptidomimetic borophenylalanine group for enzyme binding and a range of substituents designed for enzyme affinity and/or surface attachment. Syntheses primarily involved peptide coupling reactions and azobenzene formation by condensation of nitrosobenzenes and anilines. Coupling reactions were successfully carried out using EDCI or isobutyl chlorofomate in several cases where other reagents gave unacceptable decomposition. Chapter three describes the syntheses and HPLC stability studies of derivatives of a noncovalent {$\alpha$}-chymotrypsin inhibitor. Several dipeptide-based compounds containing either an amide group for surface attachment or an azobenzene group for photoswitching were prepared, primarily using peptide coupling reactions. Each compound was incubated with {$\alpha$}-chymotrypsin to assess its stability, and all were found by HPLC monitoring to be stable to {$\alpha$}-chymotrypsin catalysed hydrolysis. Chapter four describes syntheses of azobenzene-containing trifluoromethylketones and {$\alpha$}-ketoesters designed as photoswitch inhibitors of {$\alpha$}-chymotrypsin. Trifluoromethylketones/{$\alpha$}-ketoesters containing amine groups for surface attachment were prepared, primarily using peptide coupling reactions, but could not be isolated due to the incompatibility of the electrophilic ketone and primary amine groups. Trifluoromethylketones/{$\alpha$}-ketoesters containing terminal alkynes for surface attachment were prepared either by the attachment of an alkyne substituent group to a symmetrical azobenzene core or by Pd-catalysed reaction of a protected alkyne with an azobenzene having a halide substitutent. Chapter five describes syntheses of sulfur-containing surface linkers for use in surface attachment of the photoswitch inhibitors described in chapters 2-4. A range of compounds containing disulfide or protected thiol groups for surface attachment and azide or carboxylic acid groups for inhibitor attachment were prepared. Syntheses primarily involved coupling of functionalised alcohols/amides to carboxylic acid-containing disulfides/thioacetates. Selected linkers were attached to azobenzenes by amide coupling or azide-alkyne cycloaddition for surface attachment, photoswitching and/or enzyme assay. Azide-alkyne cycloaddition yields were initially poor, but were improved by use of stoichiometric amounts of copper catalyst. Chapter six describes UV/vis photoisomerisation studies and enzyme assays carried out to assess enzyme photoswitching of the compounds described in chapters 2-5. The trifluoromethylketones and {$\alpha$}-ketoesters described in chapter 4 gave the best results, with moderate inhibition of {$\alpha$}-chymotrypsin (\textmu M affinity constants) and up to 5.3 fold changes in inhibition on UV/vis irradiation. Many of the boronate esters described in chapter 2 were found to inhibit {$\alpha$}-chymotrypsin, but were somewhat unstable to irradiation. The dipeptide-based compounds described in chapter 3 were inactive against {$\alpha$}-chymotrypsin. Good photoisomerisation was obtained for an azobenzene containing a symmetrical disulfide surface linker and poor photoisomerisation was obtained for an azobenzene containing a lipoic acid surface linker. Chapter seven describes surface attachment of selected photoswitch inhibitors and studies of photoregulated enzyme binding to the resultant functional surfaces. Self assembled monolayers (SAMs) of disulfides were formed on gold surfaces and characterised by electrochemistry and contact angle measurements. Binding of {$\alpha$}-chymotrypsin to SAMs containing a photoswitch inhibitor was detected by quartz crystal microbalance (QCM), but was found to be largely irreversible. An alkyne-containing photoswitch inhibitor was attached to a surface plasmon resonance (SPR) chip in a two step procedure involving generation of an azide modified surface followed by azide-alkyne cycloaddition. Binding of {$\alpha$}-chymotrypsin to the resultant modified surface was detected by SPR and successfully regulated by UV/vis irradiation. Chapter eight provides conclusions for the work described in this thesis and suggests future directions. Chapter nine gives experimental details for the work described in this thesis.},
  langid = {english},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found,Azobenzene,Chymotrypsin,enzyme inhibitor,Photoswitch,SPR}
}

@inproceedings{pechenizkiy_Class_2006,
  title = {Class {{Noise}} and {{Supervised Learning}} in {{Medical Domains}}: {{The Effect}} of {{Feature Extraction}}},
  booktitle = {Proc. - {{IEEE Symp}}. {{Comput}}.-{{Based Med}}. {{Syst}}.},
  author = {Pechenizkiy, Mykola and Tsymbal, Alexey and Puuronen, Seppo and Pechenizkiy, Oleksandr},
  date = {2006},
  issn = {10637125},
  doi = {10.1109/CBMS.2006.65},
  abstract = {Inductive learning systems have been successfully applied in a number of medical domains. It is generally accepted that the highest accuracy results that an inductive learning system can achieve depend on the quality of data and on the appropriate selection of a learning algorithm for the data. In this paper we analyze the effect of class noise on supervised learning in medical domains. We review the related work on learning from noisy data and propose to use feature extraction as a pre-processing step to diminish the effect of class noise on the learning process. Our experiments with 8 medical datasets show that feature extraction indeed helps to deal with class noise. It clearly results in higher classification accuracy of learnt models without the separate explicit elimination of noisy instances. \textcopyright{} 2006 IEEE.},
  isbn = {0-7695-2517-2},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {105 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{pedraza_Open_2015,
  ids = {pedraza_Open_2015a},
  title = {An {{Open Access Thyroid Ultrasound Image Database}}},
  author = {Pedraza, Lina and Vargas, Carlos and Narv\'aez, Fabi\'an and Dur\'an, Oscar and Mu\~noz, Emma and Romero, Eduardo},
  editor = {Romero, Eduardo and Lepore, Natasha},
  date = {2015-01-28},
  pages = {92870W},
  location = {{Cartagena de Indias, Colombia}},
  doi = {10.1117/12.2073532},
  url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2073532},
  urldate = {2022-05-16},
  eventtitle = {Tenth {{International Symposium}} on {{Medical Information Processing}} and {{Analysis}}},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {74 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/5LSWHSR9/Pedraza et al. - 2015 - An open access thyroid ultrasound image database.pdf;/Users/personal-macbook/Zotero/storage/T8NPS6IV/Pedraza et al. - 2015 - An open access thyroid ultrasound image database.html}
}

@article{pele_Information_2017,
  title = {Information {{Entropy}} and {{Measures}} of {{Market Risk}}},
  author = {Pele, Daniel Traian and Lazar, Emese and Dufour, Alfonso},
  date = {2017},
  journaltitle = {Entropy},
  issn = {10994300},
  doi = {10.3390/e19050226},
  abstract = {In this paper we investigate the relationship between the information entropy of the distribution of intraday returns and intraday and daily measures of market risk. Using data on the EUR/JPY exchange rate, we find a negative relationship between entropy and intraday Value-at-Risk, and also between entropy and intraday Expected Shortfall. This relationship is then used to forecast daily Value-at-Risk, using the entropy of the distribution of intraday returns as a predictor.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Entropy of a distribution function,Expected shortfall,Information entropy,Value at risk},
  annotation = {39 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{peng_NegBio_2018,
  title = {{{NegBio}}: {{A High-Performance Tool}} for {{Negation}} and {{Uncertainty Detection}} in {{Radiology Reports}}},
  author = {Peng, Yifan and Wang, Xiaosong and Lu, Le and Bagheri, Mohammadhadi and Summers, Ronald and Lu, Zhiyong},
  date = {2018-05},
  journaltitle = {AMIA Jt Summits Transl Sci Proc},
  volume = {2017},
  pages = {188--196},
  abstract = {Negative and uncertain medical findings are frequent in radiology reports, but discriminating them from positive findings remains challenging for information extraction. Here, we propose a new algorithm, NegBio, to detect negative and uncertain findings in radiology reports. Unlike previous rule-based methods, NegBio utilizes patterns on universal dependencies to identify the scope of triggers that are indicative of negation or uncertainty. We evaluated NegBio on four datasets, including two public benchmarking corpora of radiology reports, a new radiology corpus that we annotated for this work, and a public corpus of general clinical texts. Evaluation on these datasets demonstrates that NegBio is highly accurate for detecting negative and uncertain findings and compares favorably to a widely-used state-of-the-art system NegEx (an average of 9.5\% improvement in precision and 5.1\% in F1-score). AVAILABILITY: https://github.com/ncbi-nlp/NegBio.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{pereira_Brain_2016,
  title = {Brain {{Tumor Segmentation Using Convolutional Neural Networks}} in {{MRI Images}}},
  author = {Pereira, Sergio and Pinto, Adriano and Alves, Victor and Silva, Carlos A.},
  date = {2016-05},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {35},
  number = {5},
  pages = {1240--1251},
  doi = {10.1109/TMI.2016.2538465},
  abstract = {Among brain tumors, gliomas are the most common and aggressive, leading to a very short life expectancy in their highest grade. Thus, treatment planning is a key stage to improve the quality of life of oncological patients. Magnetic resonance imaging (MRI) is a widely used imaging technique to assess these tumors, but the large amount of data produced by MRI prevents manual segmentation in a reasonable time, limiting the use of precise quantitative measurements in the clinical practice. So, automatic and reliable segmentation methods are required; however, the large spatial and structural variability among brain tumors make automatic segmentation a challenging problem. In this paper, we propose an automatic segmentation method based on Convolutional Neural Networks (CNN), exploring small 3 \$\textbackslash times\$3 kernels. The use of small kernels allows designing a deeper architecture, besides having a positive effect against overfitting, given the fewer number of weights in the network. We also investigated the use of intensity normalization as a pre-processing step, which though not common in CNN-based segmentation methods, proved together with data augmentation to be very effective for brain tumor segmentation in MRI images. Our proposal was validated in the Brain Tumor Segmentation Challenge 2013 database (BRATS 2013), obtaining simultaneously the first position for the complete, core, and enhancing regions in Dice Similarity Coefficient metric (0.88, 0.83, 0.77) for the Challenge data set. Also, it obtained the overall first position by the online evaluation platform. We also participated in the on-site BRATS 2015 Challenge using the same model, obtaining the second place, with Dice Similarity Coefficient metric of 0.78, 0.65, and 0.75 for the complete, core, and enhancing regions, respectively.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {368 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{pereira_Remote_2015,
  title = {Remote {{Monitoring}} of {{Breathing Dynamics Using Infrared Thermography}}},
  author = {Pereira, Carina Barbosa and Yu, Xinchi and Czaplik, Michael and Rossaint, Rolf and Blazek, Vladimir and Leonhardt, Steffen},
  date = {2015-11-01},
  journaltitle = {Biomed. Opt. Express},
  volume = {6},
  number = {11},
  pages = {4378},
  issn = {2156-7085, 2156-7085},
  doi = {10.1364/BOE.6.004378},
  url = {https://opg.optica.org/abstract.cfm?URI=boe-6-11-4378},
  urldate = {2022-12-29},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {122 citations (Semantic Scholar/DOI) [2022-12-28]},
  file = {/Users/personal-macbook/Zotero/storage/UY9TM52Q/Pereira et al. - 2015 - Remote Monitoring of Breathing Dynamics Using Infr.pdf}
}

@article{perez_Misclassified_2007,
  title = {Misclassified {{Multinomial Data}}: {{A Bayesian Approach}}},
  author = {P\'erez, C. and Gonz\'alez-Torre, Francisco Gir\'on and Mart\'in, J. and Ruiz, M. and Rojano, C.},
  date = {2007},
  journaltitle = {Rev. Real Acad. Cienc. Exactas F\'isicas Nat. Ser. Matem\'aticas RACSAM},
  issn = {1578-7303},
  abstract = {In this paper, the problem of inference with misclassified multinomial data is addressed. Over the last years there has been a significant upsurge of interest in the development of Bayesian methods to make inferences with misclassified data. The wide range of applications for several sampling schemes and the importance of including initial information make Bayesian analysis an essential tool to be used in this context. A review of the existing literature followed by a methodological discussion is presented in this paper. Datos Multinomiales Imperfectos: Un Enfoque Bayesiano Resumen. En este art\'iculo se trata el problema de la inferencia con datos multinomiales imperfectos. Durante los\'ultimoslos\textasciiacute los\'ultimos a\~nos ha habido un resurgimiento del inter\'es en el desarrollo de m\'etodos bayesianos para hacer inferencias con datos imperfectos. El an\'alisis Bayesiano se ha convertido en una herramienta fundamental en este contexto debido al gran n\'umero de aplicaciones existentes para diversos tipos de muestreo y a la importancia de incorporar informaci\'on a priori. Se presenta una revisi\'on de la literatura existente seguida de una discusi\'on metodol\'ogica con ejemplos.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@inproceedings{perone_Unsupervised_2019,
  title = {Unsupervised {{Domain Adaptation}} for {{Medical Imaging Segmentation With Self-Ensembling}}},
  booktitle = {{{NeuroImage}}},
  author = {Perone, Christian S. and Ballester, Pedro and Barros, Rodrigo C. and Cohen-Adad, Julien},
  date = {2019},
  eprint = {30898655},
  eprinttype = {pmid},
  doi = {10.1016/j.neuroimage.2019.03.026},
  abstract = {Recent advances in deep learning methods have redefined the state-of-the-art for many medical imaging applications, surpassing previous approaches and sometimes even competing with human judgment in several tasks. Those models, however, when trained to reduce the empirical risk on a single domain, fail to generalize when applied to other domains, a very common scenario in medical imaging due to the variability of images and anatomical structures, even across the same imaging modality. In this work, we extend the method of unsupervised domain adaptation using self-ensembling for the semantic segmentation task and explore multiple facets of the method on a small and realistic publicly-available magnetic resonance (MRI) dataset. Through an extensive evaluation, we show that self-ensembling can indeed improve the generalization of the models even when using a small amount of unlabeled data.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{peterson_Human_2019,
  title = {Human {{Uncertainty Makes Classification More Robust}}},
  booktitle = {Proc. {{IEEE Int}}. {{Conf}}. {{Comput}}. {{Vis}}.},
  author = {Peterson, Joshua C. and Battleday, Ruairidh M. and Griffiths, Thomas L. and Russakovsky, Olga},
  date = {2019},
  pages = {9617--9626},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{pham_Interpreting_2021,
  title = {Interpreting {{Chest X-Rays}} via {{CNNS That Exploit Hierarchical Disease Dependencies}} and {{Uncertainty Labels}}},
  author = {Pham, Hieu H. and Le, Tung T. and Tran, Dat Q. and Ngo, Dat T. and Nguyen, Ha Q.},
  date = {2021-05-21},
  journaltitle = {Neurocomputing},
  volume = {437},
  pages = {186--194},
  issn = {0925-2312},
  doi = {10.1016/j.neucom.2020.03.127},
  url = {https://www.sciencedirect.com/science/article/pii/S0925231221000953},
  urldate = {2022-06-27},
  abstract = {Chest radiography is one of the most common types of diagnostic radiology exams, which is critical for screening and diagnosis of many different thoracic diseases. Specialized algorithms have been developed to detect several specific pathologies such as lung nodules or lung cancer. However, accurately detecting the presence of multiple diseases from chest X-rays (CXRs) is still a challenging task. This paper presents a supervised multi-label classification framework based on deep convolutional neural networks (CNNs) for predicting the presence of 14 common thoracic diseases and observations. We tackle this problem by training state-of-the-art CNNs that exploit hierarchical dependencies among abnormality labels. We also propose to use the label smoothing technique for a better handling of uncertain samples, which occupy a significant portion of almost every CXR dataset. Our model is trained on over 200,000 CXRs of the recently released CheXpert dataset and achieves a mean area under the curve (AUC) of 0.940 in predicting 5 selected pathologies from the validation set. This is the highest AUC score yet reported to date. The proposed method is also evaluated on the independent test set of the CheXpert competition, which is composed of 500 CXR studies annotated by a panel of 5 experienced radiologists. The performance is on average better than 2.6 out of 3 other individual radiologists with a mean AUC of 0.930, which ranks first on the CheXpert leaderboard at the time of writing this paper.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Chest X-ray,CheXpert,Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing,Hierarchical learning,Label dependency,Label smoothing,Multi-label classification,Uncertainty label},
  annotation = {103 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/4SIT7MF9/Pham et al. - 2021 - Interpreting chest X-rays via CNNs that exploit hi.pdf;/Users/personal-macbook/Zotero/storage/BJ2JZ852/Pham et al. - 2021 - Interpreting chest X-rays via CNNs that exploit hi.pdf;/Users/personal-macbook/Zotero/storage/K79KBCU6/Pham et al. - 2020 - Interpreting chest X-rays via CNNs that exploit hi.pdf;/Users/personal-macbook/Zotero/storage/9BT2C5GI/Pham et al. - 2021 - Interpreting chest X-rays via CNNs that exploit hi.html;/Users/personal-macbook/Zotero/storage/AMAURKSQ/Pham et al. - 2021 - Interpreting chest X-rays via CNNs that exploit hi.html;/Users/personal-macbook/Zotero/storage/IGWXTASP/Pham et al. - 2021 - Interpreting chest X-rays via CNNs that exploit hi.html}
}

@inproceedings{philip_Comparison_2014,
  title = {A {{Comparison}} of {{Tracking Algorithm Performance}} for {{Objects}} in {{Wide Area Imagery}}},
  booktitle = {2014 {{Southwest Symp}}. {{Image Anal}}. {{Interpret}}.},
  author = {Philip, Rohit C. and Ram, Sundaresh and Gao, Xin and Rodriguez, Jeffrey J.},
  date = {2014-04},
  pages = {109--112},
  publisher = {{IEEE}},
  location = {{San Diego, CA, USA}},
  doi = {10.1109/SSIAI.2014.6806041},
  url = {http://ieeexplore.ieee.org/document/6806041/},
  urldate = {2022-12-29},
  eventtitle = {2014 {{IEEE Southwest Symposium}} on {{Image Analysis}} and {{Interpretation}} ({{SSIAI}})},
  isbn = {978-1-4799-4053-0},
  keywords = {\#nosource,⛔ No INSPIRE recid found,localization error,Object tracking,overlap area,partial occlusion,wide area imagery},
  annotation = {20 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{phillips_Barriers_2006,
  title = {Barriers to {{Entrepreneurship}} in {{Healthcare Organizations}}},
  author = {Phillips, Frank S. and Garman, Andrew N.},
  date = {2006},
  journaltitle = {J. Health Hum. Serv. Adm.},
  volume = {28},
  number = {4},
  pages = {472--484},
  abstract = {Entrepreneurship has received little attention in the healthcare industry, perhaps in part because of barriers inherent in the structure and culture of healthcare organizations. Eliminating barriers can help promote entrepreneurial activities to drive continuing innovation and identify new sources of revenue.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{pierson_LargeScale_2020,
  title = {A {{Large-Scale Analysis}} of {{Racial Disparities}} in {{Police Stops Across}} the {{United States}}},
  author = {Pierson, Emma and Simoiu, Camelia and Overgoor, Jan and Corbett-Davies, Sam and Jenson, Daniel and Shoemaker, Amy and Ramachandran, Vignesh and Barghouty, Phoebe and Phillips, Cheryl and Shroff, Ravi and Goel, Sharad},
  date = {2020},
  journaltitle = {Nat. Hum. Behav.},
  eprint = {32367028},
  eprinttype = {pmid},
  issn = {23973374},
  doi = {10.1038/s41562-020-0858-1},
  abstract = {We assessed racial disparities in policing in the United States by compiling and analysing a dataset detailing nearly 100 million traffic stops conducted across the country. We found that black drivers were less likely to be stopped after sunset, when a `veil of darkness' masks one's race, suggesting bias in stop decisions. Furthermore, by examining the rate at which stopped drivers were searched and the likelihood that searches turned up contraband, we found evidence that the bar for searching black and Hispanic drivers was lower than that for searching white drivers. Finally, we found that legalization of recreational marijuana reduced the number of searches of white, black and Hispanic drivers\textemdash but the bar for searching black and Hispanic drivers was still lower than that for white drivers post-legalization. Our results indicate that police stops and search decisions suffer from persistent racial bias and point to the value of policy interventions to mitigate these disparities.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{pipitone_Multiatlas_2014,
  title = {Multi-{{Atlas Segmentation}} of the {{Whole Hippocampus}} and {{Subfields Using Multiple Automatically Generated Templates}}},
  author = {Pipitone, Jon and Park, Min Tae M. and Winterburn, Julie and Lett, Tristram A. and Lerch, Jason P. and Pruessner, Jens C. and Lepage, Martin and Voineskos, Aristotle N. and Chakravarty, M. Mallar and Initiative, Alzheimer's Disease Neuroimaging},
  date = {2014-11},
  journaltitle = {Neuroimage},
  volume = {101},
  pages = {494--512},
  doi = {10.1016/j.neuroimage.2014.04.054},
  abstract = {INTRODUCTION: Advances in image segmentation of magnetic resonance images (MRI) have demonstrated that multi-atlas approaches improve segmentation over regular atlas-based approaches. These approaches often rely on a large number of manually segmented atlases (e.g. 30-80) that take significant time and expertise to produce. We present an algorithm, MAGeT-Brain (Multiple Automatically Generated Templates), for the automatic segmentation of the hippocampus that minimises the number of atlases needed whilst still achieving similar agreement to multi-atlas approaches. Thus, our method acts as a reliable multi-atlas approach when using special or hard-to-define atlases that are laborious to construct. METHOD: MAGeT-Brain works by propagating atlas segmentations to a template library, formed from a subset of target images, via transformations estimated by nonlinear image registration. The resulting segmentations are then propagated to each target image and fused using a label fusion method. We conduct two separate Monte Carlo cross-validation experiments comparing MAGeT-Brain and basic multi-atlas whole hippocampal segmentation using differing atlas and template library sizes, and registration and label fusion methods. The first experiment is a 10-fold validation (per parameter setting) over 60 subjects taken from the Alzheimer's Disease Neuroimaging Database (ADNI), and the second is a five-fold validation over 81 subjects having had a first episode of psychosis. In both cases, automated segmentations are compared with manual segmentations following the Pruessner-protocol. Using the best settings found from these experiments, we segment 246 images of the ADNI1:Complete 1Yr 1.5 T dataset and compare these with segmentations from existing automated and semi-automated methods: FSL FIRST, FreeSurfer, MAPER, and SNT. Finally, we conduct a leave-one-out cross-validation of hippocampal subfield segmentation in standard 3T T1-weighted images, using five high-resolution manually segmented atlases (Winterburn et al., 2013). RESULTS: In the ADNI cross-validation, using 9 atlases MAGeT-Brain achieves a mean Dice's Similarity Coefficient (DSC) score of 0.869 with respect to manual whole hippocampus segmentations, and also exhibits significantly lower variability in DSC scores than multi-atlas segmentation. In the younger, psychosis dataset, MAGeT-Brain achieves a mean DSC score of 0.892 and produces volumes which agree with manual segmentation volumes better than those produced by the FreeSurfer and FSL FIRST methods (mean difference in volume: 80 mm(3), 1600 mm(3), and 800 mm(3), respectively). Similarly, in the ADNI1:Complete 1Yr 1.5 T dataset, MAGeT-Brain produces hippocampal segmentations well correlated (r{$>$}0.85) with SNT semi-automated reference volumes within disease categories, and shows a conservative bias and a mean difference in volume of 250 mm(3) across the entire dataset, compared with FreeSurfer and FSL FIRST which both overestimate volume differences by 2600 mm(3) and 2800 mm(3) on average, respectively. Finally, MAGeT-Brain segments the CA1, CA4/DG and subiculum subfields on standard 3T T1-weighted resolution images with DSC overlap scores of 0.56, 0.65, and 0.58, respectively, relative to manual segmentations. CONCLUSION: We demonstrate that MAGeT-Brain produces consistent whole hippocampal segmentations using only 9 atlases, or fewer, with various hippocampal definitions, disease populations, and image acquisition types. Additionally, we show that MAGeT-Brain identifies hippocampal subfields in standard 3T T1-weighted images with overlap scores comparable to competing methods.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{planche_Cognitive_2016,
  title = {Cognitive {{Impairment}} in a {{Population-Based Study}} of {{Patients With Multiple Sclerosis}}: {{Differences Between Late Relapsing}}-{{Remitting}}, {{Secondary Progressive}} and {{Primary Progressive Multiple Sclerosis}}},
  shorttitle = {Cognitive {{Impairment}} in a {{Population-Based Study}} of {{Patients}} with {{Multiple Sclerosis}}},
  author = {Planche, V. and Gibelin, M. and Cregut, D. and Pereira, B. and Clavelou, P.},
  date = {2016-02},
  journaltitle = {Eur J Neurol},
  volume = {23},
  number = {2},
  pages = {282--289},
  issn = {13515101},
  doi = {10.1111/ene.12715},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/ene.12715},
  urldate = {2023-05-08},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,cognitive impairment,multiple sclerosis,neuropsy},
  annotation = {93 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{planche_Whitematternulled_2019,
  title = {White-{{Matter-Nulled MPRAGE}} at {{7T Reveals Thalamic Lesions}} and {{Atrophy}} of {{Specific Thalamic Nuclei}} in {{Multiple Sclerosis}}},
  author = {Planche, Vincent and Su, Jason H and Mournet, Sandy and Saranathan, Manojkumar and Dousset, Vincent and Han, May and Rutt, Brian K and Tourdias, Thomas},
  date = {2020-07},
  journaltitle = {Mult Scler},
  volume = {26},
  number = {8},
  pages = {987--992},
  issn = {1352-4585, 1477-0970},
  doi = {10.1177/1352458519828297},
  url = {http://journals.sagepub.com/doi/10.1177/1352458519828297},
  urldate = {2023-05-12},
  abstract = {Background:               Investigating the degeneration of specific thalamic nuclei in multiple sclerosis (MS) remains challenging.                                         Methods:               White-matter-nulled (WMn) MPRAGE, MP-FLAIR, and standard T1-weighted magnetic resonance imaging (MRI) were performed on MS patients ( n\,=\,15) and matched controls ( n\,=\,12). Thalamic lesions were counted in individual sequences and lesion contrast-to-noise ratio (CNR) was measured. Volumes of 12 thalamic nuclei were measured using an automatic segmentation pipeline specifically developed for WMn-MPRAGE.                                         Results:               WMn-MPRAGE showed more thalamic MS lesions ( n\,=\,35 in 9 out of 15 patients) than MP-FLAIR ( n\,=\,25) and standard T1 ( n\,=\,23), which was associated with significant improvement of CNR ( p\,{$<$}\,0.0001). MS patients had whole thalamus atrophy ( p\,=\,0.003) with lower volumes found for the anteroventral ( p\,{$<$}\,0.001), the pulvinar ( p\,{$<$}\,0.0001), and the habenular ( p\,=\,0.004) nuclei.                                         Conclusion:               WMn-MPRAGE and automatic thalamic segmentation can highlight thalamic MS lesions and measure patterns of focal thalamic atrophy.},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,multi-atlas segmentation,multiple sclerosis,Thalamic nuclei,ultra-high field magnetic resonance imaging,white-matter-nulled MPRAGE},
  annotation = {24 citations (Semantic Scholar/DOI) [2023-05-12]},
  file = {/Users/personal-macbook/Zotero/storage/3649JACJ/Planche et al. - 2020 - White-matter-nulled MPRAGE at 7T reveals thalamic .pdf}
}

@inproceedings{pmlr-v9-erhan10a,
  ids = {JMLR:v11:erhan10a,erhan_Why_2010,erhan_Why_2010a,erhan_Why_2010b},
  title = {Why {{Does Unsupervised Pre-Training Help Deep Learning}}?},
  booktitle = {Proc. {{Thirteen}}. {{Int}}. {{Conf}}. {{Artif}}. {{Intell}}. {{Stat}}.},
  author = {Erhan, Dumitru and Courville, Aaron and Bengio, Yoshua and Vincent, Pascal},
  editor = {Teh, Yee Whye and Titterington, Mike},
  date = {2010-05-13/2010-05-15},
  series = {Proceedings of Machine Learning Research},
  volume = {9},
  pages = {201--208},
  publisher = {{PMLR}},
  location = {{Chia Laguna Resort, Sardinia, Italy}},
  url = {https://proceedings.mlr.press/v9/erhan10a.html},
  abstract = {Much recent research has been devoted to learning algorithms for deep architectures such as Deep Belief Networks and stacks of auto-encoder variants with impressive results being obtained in several areas, mostly on vision and language datasets. The best results obtained on supervised learning tasks often involve an unsupervised learning component, usually in an unsupervised pre-training phase. The main question investigated here is the following: why does unsupervised pre-training work so well? Through extensive experimentation, we explore several possible explanations discussed in the literature including its action as a regularizer (Erhan et al. 2009) and as an aid to optimization (Bengio et al. 2007). Our results build on the work of Erhan et al. 2009, showing that unsupervised pre-training appears to play predominantly a regularization role in subsequent supervised training. However our results in an online setting, with a virtually unlimited data stream, point to a somewhat more nuanced interpretation of the roles of optimization and regularization in the unsupervised pre-training effect.},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/ZQH7CMQ9/Erhan et al. - Why Does Unsupervised Pre-training Help Deep Learn.pdf}
}

@article{pohl_ANATOMICAL_2004,
  title = {Anatomical {{Guided Segmentation With Non-Stationary Tissue Class Distributions}} in an {{Expectation-Maximization Framework}}},
  author = {Pohl, Kilian M. and Bouix, Sylvain and Kikinis, Ron and Grimson, W. Eric L.},
  date = {2004-04},
  journaltitle = {Proc. IEEE Int. Symp. Biomed. Imaging},
  volume = {2004},
  pages = {81--84},
  abstract = {High quality segmentation of brain MR images is a challenging task. To deal with this problem many automatic segmentation methods rely on atlas information of anatomical structures. We further investigate this line of research by introducing hierarchical representations of anatomical structures in an Expectation-Maximization framework. This new approach enables us to divide a complex segmentation scenario into less difficult sub-problems reducing the scenario's statistical complexity. We demonstrate the method's strength by segmenting a set of brain MR images into 31 different anatomical structures as well as comparing it to other methods.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{polap_MultiThreaded_2018,
  title = {Multi-{{Threaded Learning Control Mechanism}} for {{Neural Networks}}},
  author = {Po\l ap, Dawid and Wo\'zniak, Marcin and Wei, Wei and Dama\v{s}evi\v{c}ius, Robertas},
  date = {2018-10},
  journaltitle = {Future Generation Computer Systems},
  volume = {87},
  pages = {16--34},
  issn = {0167739X},
  doi = {10.1016/j.future.2018.04.050},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167739X18300931},
  urldate = {2022-12-28},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Back-propagation algorithm,Multi-threading,Neural networks},
  annotation = {44 citations (Semantic Scholar/DOI) [2022-12-28]}
}

@report{pop_DEEP_2018,
  title = {Deep {{Ensemble Bayesian Active Learning}}: {{Ad-Dressing}} the {{Mode Collapse Issue}} in {{Monte Carlo Dropout}} via {{Ensembles}}},
  author = {Pop, Remus and Fulop, Patric},
  date = {2018},
  abstract = {In image classification tasks, the ability of deep convolutional neural networks (CNNs) to deal with complex image data has proved to be unrivalled. Deep CNNs, however, require large amounts of labeled training data to reach their full potential. In specialized domains such as healthcare, labeled data can be difficult and expensive to obtain. One way to alleviate this problem is to rely on active learning, a learning technique that aims to reduce the amount of labelled data needed for a specific task while still delivering satisfactory performance. We propose a new active learning strategy designed for deep neural networks. This method improves upon the current state-of-the-art deep Bayesian active learning method, which suffers from the mode collapse problem. We correct for this deficiency by making use of the expressive power and statistical properties of model ensembles. Our proposed method manages to capture superior data uncertainty, which translates into improved classification performance. We demonstrate empirically that our ensemble method yields faster convergence of CNNs trained on the MNIST and CIFAR-10 datasets.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{postels_Practicality_2021,
  title = {On the {{Practicality}} of {{Deterministic Epistemic Uncertainty}}},
  author = {Postels, Janis and Segu, Mattia and Sun, Tao and Sieber, Luca and Gool, Luc Van and Yu, Fisher and Tombari, Federico},
  date = {2021-11-23},
  url = {https://openreview.net/forum?id=W3-hiLnUYl},
  urldate = {2022-07-04},
  abstract = {A set of novel approaches for estimating epistemic uncertainty in deep neural networks with a single forward pass has recently emerged as a valid alternative to Bayesian Neural Networks. On the...},
  eventtitle = {{{ICLR}}},
  langid = {english},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/HCTIF3UJ/Postels et al. - 2021 - On the Practicality of Deterministic Epistemic Unc.pdf}
}

@inproceedings{potapov_Universal_2014,
  title = {Universal {{Empathy}} and {{Ethical Bias}} for {{Artificial General Intelligence}}},
  booktitle = {J. {{Exp}}. {{Theor}}. {{Artif}}. {{Intell}}.},
  author = {Potapov, Alexey and Rodionov, Sergey},
  date = {2014},
  issn = {13623079},
  doi = {10.1080/0952813X.2014.895112},
  abstract = {Rational agents are usually built to maximise rewards. However, artificial general intelligence (AGI) agents can find undesirable ways of maximising any prior reward function. Therefore, value learning is crucial for safe AGI. We assume that generalised states of the world are valuable-not rewards themselves, and propose an extension of AIXI, in which rewards are used only to bootstrap hierarchical value learning. The modified AIXI agent is considered in the multi-agent environment, where other agents can be either humans or other mature agents, the values of which should be revealed and adopted by the infant AGI agent. A general framework for designing such empathic agent with ethical bias is proposed as an extension of the universal intelligence model as well. Moreover, we perform experiments in the simple Markov environment, which demonstrate feasibility of our approach to value learning in safe AGI. \textcopyright{} 2014 Taylor \& Francis.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,AIXI,empathy,multi-agent environment,representations,safe AGI}
}

@article{pourghassem_ContentBased_2008,
  title = {Content-{{Based Medical Image Classification Using}} a {{New Hierarchical Merging Scheme}}},
  author = {Pourghassem, Hossein and Ghassemian, Hassan},
  date = {2008-12-01},
  journaltitle = {Computerized Medical Imaging and Graphics},
  volume = {32},
  number = {8},
  pages = {651--661},
  issn = {0895-6111},
  doi = {10.1016/j.compmedimag.2008.07.006},
  url = {https://www.sciencedirect.com/science/article/pii/S0895611108000785},
  urldate = {2022-11-21},
  abstract = {Automatic medical image classification is a technique for assigning a medical image to a class among a number of image categories. Due to computational complexity, it is an important task in the content-based image retrieval (CBIR). In this paper, we propose a hierarchical medical image classification method including two levels using a perfect set of various shape and texture features. Furthermore, a tessellation-based spectral feature as well as a directional histogram has been proposed. In each level of the hierarchical classifier, using a new merging scheme and multilayer perceptron (MLP) classifiers (merging-based classification), homogenous (semantic) classes are created from overlapping classes in the database. The proposed merging scheme employs three measures to detect the overlapping classes: accuracy, miss-classified ratio, and dissimilarity. The first two measures realize a supervised classification method and the last one realizes an unsupervised clustering technique. In each level, the merging-based classification is applied to a merged class of the previous level and splits it to several classes. This procedure is progressive to achieve more classes. The proposed algorithm is evaluated on a database consisting of 9100 medical X-ray images of 40 classes. It provides accuracy rate of 90.83\% on 25 merged classes in the first level. If the correct class is considered within the best three matches, this value will increase to 97.9\%.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Content-based image retrieval,Medical X-ray image,Merging scheme,Merging-based hierarchical classification},
  annotation = {97 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/DVM6A5KW/Pourghassem and Ghassemian - 2008 - Content-based medical image classification using a.pdf;/Users/personal-macbook/Zotero/storage/RS74RK4W/S0895611108000785.html}
}

@article{powell_Registration_2008,
  title = {Registration and {{Machine Learning-Based Automated Segmentation}} of {{Subcortical}} and {{Cerebellar Brain Structures}}},
  author = {Powell, Stephanie and Magnotta, Vincent A. and Johnson, Hans and Jammalamadaka, Vamsi K. and Pierson, Ronald and Andreasen, Nancy C.},
  date = {2008-01},
  journaltitle = {Neuroimage},
  volume = {39},
  number = {1},
  pages = {238--247},
  doi = {10.1016/j.neuroimage.2007.05.063},
  abstract = {The large amount of imaging data collected in several ongoing multi-center studies requires automated methods to delineate brain structures of interest. We have previously reported on using artificial neural networks (ANN) to define subcortical brain structures. Here we present several automated segmentation methods using multidimensional registration. A direct comparison between template, probability, artificial neural network (ANN) and support vector machine (SVM)-based automated segmentation methods is presented. Three metrics for each segmentation method are reported in the delineation of subcortical and cerebellar brain regions. Results show that the machine learning methods outperform the template and probability-based methods. Utilization of these automated segmentation methods may be as reliable as manual raters and require no rater intervention.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Brain segmentation,Registration-based segmentatio}
}

@inproceedings{prasoon_Deep_2013,
  title = {Deep {{Feature Learning}} for {{Knee Cartilage Segmentation Using}} a {{Triplanar Convolutional Neural Network}}},
  booktitle = {Med. {{Image Comput}}. {{Comput}}.-{{Assist}}. {{Interv}}. \textendash{} {{MICCAI}} 2013},
  author = {Prasoon, Adhish and Petersen, Kersten and Igel, Christian and Lauze, Fran\c{c}ois and Dam, Erik and Nielsen, Mads},
  date = {2013},
  pages = {246--253},
  publisher = {{Springer Berlin Heidelberg}},
  abstract = {Segmentation of anatomical structures in medical images is often based on a voxel/pixel classification approach. Deep learning systems, such as convolutional neural networks (CNNs), can infer a hierarchical representation of images that fosters categorization. We propose a novel system for voxel classification integrating three 2D CNNs, which have a one-to-one association with the xy, yz and zx planes of 3D image, respectively. We applied our method to the segmentation of tibial cartilage in low field knee MRI scans and tested it on 114 unseen scans. Although our method uses only 2D features at a single scale, it performs better than a state-of-the-art method using 3D multi-scale features. In the latter approach, the features and the classifier have been carefully adapted to the problem at hand. That we were able to get better results by a deep learning architecture that autonomously learns the features from the images is the main insight of this study.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{price_Promise_2019,
  title = {The {{Promise}} of {{Artificial Intelligence}}},
  author = {Price, Sean},
  date = {2019},
  journaltitle = {Tex. Med.},
  eprint = {31613379},
  eprinttype = {pmid},
  issn = {19383223},
  doi = {10.7551/mitpress/12385.001.0001},
  abstract = {"Prepare Yourselves, Robots Will Soon Replace Doctors in Healthcare," screamed the headline in a 2017 Forbes magazine article. Media coverage like that makes it easy to see why artificial intelligence (AI) sounds like scary science fiction to some physicians.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{priya_Federated_2022,
  title = {A {{Federated Approach}} for {{Detecting}} the {{Chest Diseases Using Densenet}} for {{Multi-Label Classification}}},
  author = {Priya, K. V. and Peter, J. Dinesh},
  date = {2022-08},
  journaltitle = {Complex Intell. Syst.},
  volume = {8},
  number = {4},
  pages = {3121--3129},
  issn = {2199-4536, 2198-6053},
  doi = {10.1007/s40747-021-00474-y},
  url = {https://link.springer.com/10.1007/s40747-021-00474-y},
  urldate = {2022-11-21},
  abstract = {Multi-label disease classification algorithms help to predict various chronic diseases at an early stage. Diverse deep neural networks are applied for multi-label classification problems to foresee multiple mutually non-exclusive classes or diseases. We propose a federated approach for detecting the chest diseases using DenseNets for better accuracy in prediction of various diseases. Images of chest X-ray from the Kaggle repository is used as the dataset in the proposed model. This new model is tested with both sample and full dataset of chest X-ray, and it outperforms existing models in terms of various evaluation metrics. We adopted transfer learning approach along with the pre-trained network from scratch to improve performance. For this, we have integrated DenseNet121 to our framework. DenseNets have a few focal points as they help to overcome vanishing gradient issues, boost up the feature propagation and reuse and also to reduce the number of parameters. Furthermore, gradCAMS are used as visualization methods to visualize the affected parts on chest X-ray. Henceforth, the proposed architecture will help the prediction of various diseases from a single chest X-ray and furthermore direct the doctors and specialists for taking timely decisions.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Deep learning,Multi-label classification,Transfer learning},
  annotation = {1 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/X2GZDP5Y/Priya and Peter - 2022 - A federated approach for detecting the chest disea.pdf}
}

@article{pudil_Floating_1994,
  title = {Floating {{Search Methods}} in {{Feature Selection}}},
  author = {Pudil, P. and Novovi\v{c}ov\'a, J. and Kittler, J.},
  date = {1994-11},
  journaltitle = {Pattern Recognit. Lett.},
  volume = {15},
  number = {11},
  pages = {1119--1125},
  doi = {10.1016/0167-8655(94)90127-9},
  abstract = {Abstract Sequential search methods characterized by a dynamically changing number of features included or eliminated at each step, henceforth ``floating'' methods, are presented. They are shown to give very good results and to be computationally more effective than the branch and bound method.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Feature or,Feature selection,Pattern recognition},
  annotation = {3197 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{puonti_Fast_2016,
  title = {Fast and Sequence-Adaptive Whole-Brain Segmentation Using Parametric {{Bayesian}} Modeling},
  author = {Puonti, Oula and Iglesias, Juan Eugenio and Van Leemput, Koen},
  date = {2016-12},
  journaltitle = {NeuroImage},
  volume = {143},
  pages = {235--249},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2016.09.011},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811916304724},
  urldate = {2023-05-16},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Atlases,Bayesian modeling,MRI,Parametric models},
  annotation = {90 citations (Semantic Scholar/DOI) [2023-05-16]},
  file = {/Users/personal-macbook/Zotero/storage/WYRZB6LY/Puonti et al. - 2016 - Fast and sequence-adaptive whole-brain segmentatio.pdf}
}

@article{qi_Universal_2019,
  title = {Universal {{Dependency Parsing From Scratch}}},
  author = {Qi, Peng and Dozat, Timothy and Zhang, Yuhao and Manning, Christopher D.},
  date = {2019-01},
  abstract = {This paper describes Stanford's system at the CoNLL 2018 UD Shared Task. We introduce a complete neural pipeline system that takes raw text as input, and performs all tasks required by the shared task, ranging from tokenization and sentence segmentation, to POS tagging and dependency parsing. Our single system submission achieved very competitive performance on big treebanks. Moreover, after fixing an unfortunate bug, our corrected system would have placed the 2nd, 1st, and 3rd on the official evaluation metrics LAS,MLAS, and BLEX, and would have outperformed all submission systems on low-resource treebank categories on all metrics by a large margin. We further show the effectiveness of different model components through extensive ablation studies.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@inproceedings{qiao_Deep_2018,
  title = {Deep {{Co-Training}} for {{Semi-Supervised Image Recognition}}},
  booktitle = {Lect. {{Notes Comput}}. {{Sci}}.},
  author = {Qiao, Siyuan and Shen, Wei and Zhang, Zhishuai and Wang, Bo and Yuille, Alan},
  date = {2018},
  issn = {16113349},
  doi = {10.1007/978-3-030-01267-0_9},
  abstract = {In this paper, we study the problem of semi-supervised image recognition, which is to learn classifiers using both labeled and unlabeled images. We present Deep Co-Training, a deep learning based method inspired by the Co-Training framework. The original Co-Training learns two classifiers on two views which are data from different sources that describe the same instances. To extend this concept to deep learning, Deep Co-Training trains multiple deep neural networks to be the different views and exploits adversarial examples to encourage view difference, in order to prevent the networks from collapsing into each other. As a result, the co-trained networks provide different and complementary information about the data, which is necessary for the Co-Training framework to achieve good results. We test our method on SVHN, CIFAR-10/100 and ImageNet datasets, and our method outperforms the previous state-of-the-art methods by a large margin.},
  isbn = {978-3-030-01266-3},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Co-Training,Deep networks,Semi-supervised learning},
  annotation = {282 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{qiao_Sparsity_2010,
  title = {Sparsity {{Preserving Projections With Applications}} to {{Face Recognition}}},
  author = {Qiao, Lishan and Chen, Songcan and Tan, Xiaoyang},
  date = {2010-01},
  journaltitle = {Pattern Recognition},
  volume = {43},
  number = {1},
  pages = {331--341},
  issn = {00313203},
  doi = {10.1016/j.patcog.2009.05.005},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0031320309001964},
  urldate = {2022-12-28},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Compressive sensing,Dimensionality reduction,Face recognition,Sparse representation},
  annotation = {750 citations (Semantic Scholar/DOI) [2022-12-28]},
  file = {/Users/personal-macbook/Zotero/storage/IYXTRVQG/Qiao et al. - 2010 - Sparsity preserving projections with applications .pdf}
}

@article{qiu_Modeling_2019,
  title = {Modeling the {{Uncertainty}} in {{Electronic Health Records}}: {{A Bayesian Deep Learning Approach}}},
  author = {Qiu, Riyi and Jia, Yugang and Hadzikadic, Mirsad and Dulin, Michael and Niu, Xi and Wang, Xin},
  date = {2019-07},
  url = {http://arxiv.org/abs/1907.06162},
  abstract = {Deep learning models have exhibited superior performance in predictive tasks with the explosively increasing Electronic Health Records (EHR). However, due to the lack of transparency, behaviors of deep learning models are difficult to interpret. Without trustworthiness, deep learning models will not be able to assist in the real-world decision-making process of healthcare issues. We propose a deep learning model based on Bayesian Neural Networks (BNN) to predict uncertainty induced by data noise. The uncertainty is introduced to provide model predictions with an extra level of confidence. Our experiments verify that instances with high uncertainty are harmful to model performance. Moreover, by investigating the distributions of model prediction and uncertainty, we show that it is possible to identify a group of patients for timely intervention, such that decreasing data noise will benefit more on the prediction accuracy for these patients.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{racine_Healthcare_2019,
  title = {Healthcare {{Uses}} of {{Artificial Intelligence}}: {{Challenges}} and {{Opportunities}} for {{Growth}}},
  author = {Racine, Eric and Boehlen, Wren and Sample, Matthew},
  date = {2019},
  journaltitle = {Healthc. Manage. Forum},
  eprint = {31234654},
  eprinttype = {pmid},
  issn = {08404704},
  doi = {10.1177/0840470419843831},
  abstract = {Forms of Artificial Intelligence (AI), like deep learning algorithms and neural networks, are being intensely explored for novel healthcare applications in areas such as imaging and diagnoses, risk analysis, lifestyle management and monitoring, health information management, and virtual health assistance. Expected benefits in these areas are wide-ranging and include increased speed in imaging, greater insight into predictive screening, and decreased healthcare costs and inefficiency. However, AI-based clinical tools also create a host of situations wherein commonly-held values and ethical principles may be challenged. In this short column, we highlight three potentially problematic aspects of AI use in healthcare: (1) dynamic information and consent, (2) transparency and ownership, and (3) privacy and discrimination. We discuss their impact on patient/client, clinician, and health institution values and suggest ways to tackle this impact. We propose that AI-related ethical challenges may represent an opportunity for growth in organizations.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {33 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{radosavovic_Data_2018,
  title = {Data {{Distillation}}: {{Towards Omni-Supervised Learning}}},
  booktitle = {Proc. {{IEEE Comput}}. {{Soc}}. {{Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}.},
  author = {Radosavovic, Ilija and Dollar, Piotr and Girshick, Ross and Gkioxari, Georgia and He, Kaiming},
  date = {2018},
  issn = {10636919},
  doi = {10.1109/CVPR.2018.00433},
  abstract = {We investigate omni-supervised learning, a special regime of semi-supervised learning in which the learner exploits all available labeled data plus internet-scale sources of unlabeled data. Omni-supervised learning is lower-bounded by performance on existing labeled datasets, offering the potential to surpass state-of-the-art fully supervised methods. To exploit the omni-supervised setting, we propose data distillation, a method that ensembles predictions from multiple transformations of unlabeled data, using a single model, to automatically generate new training annotations. We argue that visual recognition models have recently become accurate enough that it is now possible to apply classic ideas about self-training to challenging real-world data. Our experimental results show that in the cases of human keypoint detection and general object detection, state-of-the-art models trained with data distillation surpass the performance of using labeled data from the COCO dataset alone.},
  isbn = {978-1-5386-6420-9},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {344 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{raffel_Backgroundoriented_2015,
  title = {Background-{{Oriented Schlieren}} ({{BOS}}) {{Techniques}}},
  author = {Raffel, Markus},
  date = {2015},
  journaltitle = {Exp. Fluids},
  issn = {07234864},
  doi = {10.1007/s00348-015-1927-5},
  abstract = {This article gives an overview of the background-oriented schlieren (BOS) technique, typical applications and literature in the field. BOS is an optical density visualization technique, belonging to the same family as schlieren photography, shadowgraphy or interferometry. In contrast to these older techniques, BOS uses correlation techniques on a background dot pattern to quantitatively characterize compressible and thermal flows with good spatial and temporal resolution. The main advantages of this technique, the experimental simplicity and the robustness of correlation-based digital analysis, mean that it is widely used, and variant versions are reviewed in the article. The advantages of each variant are reviewed, and further literature is provided for the reader.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{raffiee_Should_2014,
  title = {Should {{I Quit My Day Job}}?: {{A Hybrid Path}} to {{Entrepreneurship}}},
  author = {Raffiee, Joseph and Feng, Jie},
  date = {2014-08},
  journaltitle = {AMJ},
  volume = {57},
  number = {4},
  pages = {936--963},
  publisher = {{Academy of Management}},
  doi = {10.5465/amj.2012.0522},
  abstract = {Research suggests that the risk and uncertainty associated with entrepreneurial activity deters entry and contributes to the high rates of new business failure. In this study, we examine how the ability to reduce these factors by means of hybrid entrepreneurship?the process of starting a business while retaining a ?day job? in an existing organization?influences entrepreneurial entry and survival. Integrating insights from real options theory with logic from the individual differences literature, we hypothesize and find that individuals who are risk averse and have low core self-evaluation are more likely to enter hybrid entrepreneurship relative to full-time self-employment. In turn, we argue and find that hybrid entrepreneurs who subsequently enter full-time self-employment (i.e., quit their day job) have much higher rates of survival relative to individuals who enter full-time self-employment directly from paid employment. Adding support to our theory that the survival advantage is driven by a learning effect that takes place during hybrid entrepreneurship, we find that the decrease in exit hazard is stronger for individuals with prior entrepreneurial experience. Taken together, our findings suggest that individual characteristics may play a greater role in determining the process of how (rather than if) entrepreneurial entry occurs, and that the process of how entrepreneurial entry transpires has important implications for new business survival.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{raghu_Direct_2018,
  title = {Direct {{Uncertainty Prediction}} for {{Medical Second Opinions}}},
  author = {Raghu, Maithra and Blumer, Katy and Sayres, Rory and Obermeyer, Ziad and Kleinberg, Robert and Mullainathan, Sendhil and Kleinberg, Jon},
  date = {2018-07},
  abstract = {The issue of disagreements amongst human experts is a ubiquitous one in both machine learning and medicine. In medicine, this often corresponds to doctor disagreements on a patient diagnosis. In this work, we show that machine learning models can be trained to give uncertainty scores to data instances that might result in high expert disagreements. In particular, they can identify patient cases that would benefit most from a medical second opinion. Our central methodological finding is that Direct Uncertainty Prediction (DUP), training a model to predict an uncertainty score directly from the raw patient features, works better than Uncertainty Via Classification, the two-step process of training a classifier and postprocessing the output distribution to give an uncertainty score. We show this both with a theoretical result, and on extensive evaluations on a large scale medical imaging application.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{raghu_Direct_2018a,
  title = {Direct {{Uncertainty Prediction With Applications}} to {{Healthcare}}},
  author = {Raghu, Maithra and Blumer, Katy and Sayres, Rory and Obermeyer, Ziad and Mullainathan, Sendhil and Kleinberg, Jon},
  date = {2018-07},
  abstract = {Large labeled datasets for supervised learning are frequently constructed by assigning each instance to multiple human evaluators, and this leads to disagreement in the labels associated with a single instance. Here we consider the question of predicting the level of disagreement for a given instance, and we find an interesting phenomenon: direct prediction of uncertainty performs better than the two-step process of training a classifier and then using the classifier outputs to derive an uncertainty. We show stronger performance for predicting disagreement via this direct method both in a synthetic setting whose parameters we can fully control, and in a paradigmatic healthcare application involving multiple labels assigned by medical domain experts. We further show implications for allocating additional labeling effort toward instances with the greatest levels of predicted disagreement.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{raiszadeh_Proteomic_2012,
  title = {Proteomic {{Analysis}} of {{Eccrine Sweat}}: {{Implications}} for the {{Discovery}} of {{Schizophrenia Biomarker Proteins}}},
  author = {Raiszadeh, Michelle M. and Ross, Mark M. and Russo, Paul S. and Schaepper, Mary Ann and Zhou, Weidong and Deng, Jianghong and Ng, Daniel and Dickson, April and Dickson, Cindy and Strom, Monica and Osorio, Carolina and Soeprono, Thomas and Wulfkuhle, Julia D. and Petricoin, Emanuel F. and Liotta, Lance A. and Kirsch, Wolff M.},
  date = {2012},
  journaltitle = {J. Proteome Res.},
  issn = {15353893},
  doi = {10.1021/pr2007957},
  abstract = {Liquid chromatography-tandem mass spectrometry (LC-MS/MS) and multiple reaction monitoring mass spectrometry (MRM-MS) proteomics analyses were performed on eccrine sweat of healthy controls, and the results were compared with those from individuals diagnosed with schizophrenia (SZ). This is the first large scale study of the sweat proteome. First, we performed LC-MS/MS on pooled SZ samples and pooled control samples for global proteomics analysis. Results revealed a high abundance of diverse proteins and peptides in eccrine sweat. Most of the proteins identified from sweat samples were found to be different than the most abundant proteins from serum, which indicates that eccrine sweat is not simply a plasma transudate and may thereby be a source of unique disease-associated biomolecules. A second independent set of patient and control sweat samples were analyzed by LC-MS/MS and spectral counting to determine qualitative protein differential abundances between the control and disease groups. Differential abundances of selected proteins, initially determined by spectral counting, were verified by MRM-MS analyses. Seventeen proteins showed a differential abundance of approximately 2-fold or greater between the SZ pooled sample and the control pooled sample. This study demonstrates the utility of LC-MS/MS and MRM-MS as a viable strategy for the discovery and verification of potential sweat protein disease biomarkers. \textcopyright{} 2012 American Chemical Society.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{rajchl_NeuroNet_2018,
  title = {{{NeuroNet}}: {{Fast}} and {{Robust Reproduction}} of {{Multiple Brain Image Segmentation Pipelines}}},
  author = {Rajchl, Martin and Pawlowski, Nick and Rueckert, Daniel and Matthews, Paul M. and Glocker, Ben},
  date = {2018-06},
  abstract = {NeuroNet is a deep convolutional neural network mimicking multiple popular and state-of-the-art brain segmentation tools including FSL, SPM, and MALPEM. The network is trained on 5,000 T1-weighted brain MRI scans from the UK Biobank Imaging Study that have been automatically segmented into brain tissue and cortical and sub-cortical structures using the standard neuroimaging pipelines. Training a single model from these complementary and partially overlapping label maps yields a new powerful ``all-in-one'', multi-output segmentation tool. The processing time for a single subject is reduced by an order of magnitude compared to running each individual software package. We demonstrate very good reproducibility of the original outputs while increasing robustness to variations in the input data. We believe NeuroNet could be an important tool in large-scale population imaging studies and serve as a new standard in neuroscience by reducing the risk of introducing bias when choosing a specific software package.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{rajpurkar_CheXNet_2017,
  title = {{{CheXNet}}: {{Radiologist-Level Pneumonia Detection}} on {{Chest X-Rays With Deep Learning}}},
  author = {Rajpurkar, Pranav and Irvin, Jeremy and Zhu, Kaylie and Yang, Brandon and Mehta, Hershel and Duan, Tony and Ding, Daisy and Bagul, Aarti and Langlotz, Curtis and Shpanskaya, Katie and Lungren, Matthew P. and Ng, Andrew Y.},
  date = {2017-11},
  url = {https://arxiv.org/abs/1711.05225},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found},
  annotation = {1896 citations (Semantic Scholar/arXiv) [2023-05-08]}
}

@article{rajpurkar_Deep_2018,
  title = {Deep {{Learning}} for {{Chest Radiograph Diagnosis}}: {{A Retrospective Comparison}} of the {{CheXNeXt Algorithm}} to {{Practicing Radiologists}}},
  author = {Rajpurkar, Pranav and Irvin, Jeremy and Ball, Robyn L. and Zhu, Kaylie and Yang, Brandon and Mehta, Hershel and Duan, Tony and Ding, Daisy and Bagul, Aarti and Langlotz, Curtis P. and Patel, Bhavik N. and Yeom, Kristen W. and Shpanskaya, Katie and Blankenberg, Francis G. and Seekins, Jayne and Amrhein, Timothy J. and Mong, David A. and Halabi, Safwan S. and Zucker, Evan J. and Ng, Andrew Y. and Lungren, Matthew P.},
  date = {2018-11},
  journaltitle = {PLoS Med.},
  volume = {15},
  number = {11},
  pages = {e1002686},
  doi = {10.1371/journal.pmed.1002686},
  abstract = {BACKGROUND: Chest radiograph interpretation is critical for the detection of thoracic diseases, including tuberculosis and lung cancer, which affect millions of people worldwide each year. This time-consuming task typically requires expert radiologists to read the images, leading to fatigue-based diagnostic error and lack of diagnostic expertise in areas of the world where radiologists are not available. Recently, deep learning approaches have been able to achieve expert-level performance in medical image interpretation tasks, powered by large network architectures and fueled by the emergence of large labeled datasets. The purpose of this study is to investigate the performance of a deep learning algorithm on the detection of pathologies in chest radiographs compared with practicing radiologists. METHODS AND FINDINGS: We developed CheXNeXt, a convolutional neural network to concurrently detect the presence of 14 different pathologies, including pneumonia, pleural effusion, pulmonary masses, and nodules in frontal-view chest radiographs. CheXNeXt was trained and internally validated on the ChestX-ray8 dataset, with a held-out validation set consisting of 420 images, sampled to contain at least 50 cases of each of the original pathology labels. On this validation set, the majority vote of a panel of 3 board-certified cardiothoracic specialist radiologists served as reference standard. We compared CheXNeXt's discriminative performance on the validation set to the performance of 9 radiologists using the area under the receiver operating characteristic curve (AUC). The radiologists included 6 board-certified radiologists (average experience 12 years, range 4-28 years) and 3 senior radiology residents, from 3 academic institutions. We found that CheXNeXt achieved radiologist-level performance on 11 pathologies and did not achieve radiologist-level performance on 3 pathologies. The radiologists achieved statistically significantly higher AUC performance on cardiomegaly, emphysema, and hiatal hernia, with AUCs of 0.888 (95\% confidence interval [CI] 0.863-0.910), 0.911 (95\% CI 0.866-0.947), and 0.985 (95\% CI 0.974-0.991), respectively, whereas CheXNeXt's AUCs were 0.831 (95\% CI 0.790-0.870), 0.704 (95\% CI 0.567-0.833), and 0.851 (95\% CI 0.785-0.909), respectively. CheXNeXt performed better than radiologists in detecting atelectasis, with an AUC of 0.862 (95\% CI 0.825-0.895), statistically significantly higher than radiologists' AUC of 0.808 (95\% CI 0.777-0.838); there were no statistically significant differences in AUCs for the other 10 pathologies. The average time to interpret the 420 images in the validation set was substantially longer for the radiologists (240 minutes) than for CheXNeXt (1.5 minutes). The main limitations of our study are that neither CheXNeXt nor the radiologists were permitted to use patient history or review prior examinations and that evaluation was limited to a dataset from a single institution. CONCLUSIONS: In this study, we developed and validated a deep learning algorithm that classified clinically important abnormalities in chest radiographs at a performance level comparable to practicing radiologists. Once tested prospectively in clinical settings, the algorithm could have the potential to expand patient access to chest radiograph diagnostics.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {700 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{ram_Classification_2018,
  title = {Classification of {{Primary Cilia}} in {{Microscopy Images Using Convolutional Neural Random Forests}}},
  booktitle = {Proc. {{IEEE Southwest Symp}}. {{Image Anal}}. {{Interpret}}.},
  author = {Ram, Sundaresh and Majdi, Mohammed S. and Rodriguez, Jeffrey J. and Gao, Yang and Brooks, Heddwen L.},
  date = {2018-09},
  volume = {2018-April},
  pages = {89--92},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  doi = {10.1109/SSIAI.2018.8470320},
  abstract = {Accurate detection and classification of primary cilia in microscopy images is an essential and fundamental task for many biological studies including diagnosis of primary ciliary dyskinesia. Manual detection and classification of individual primary cilia by visual inspection is time consuming, and prone to induce subjective bias. However, automation of this process is challenging as well, due to clutter, bleed-through, imaging noise, and the similar characteristics of the non-cilia candidates present within the image. We propose a convolutional neural random forest classifier that combines a convolutional neural network with random decision forests to classify the primary cilia in fluorescence microscopy images. We compare the performance of the proposed classifier with that of an unsupervised k-means classifier and a supervised multi-layer perceptron classifier on real data consisting of 8 representative cilia images, containing more than 2300 primary cilia using precision/recall rates, ROC curves, AUC, and F{$\beta$}-score for classification accuracy. Results show that our proposed classifier achieves better classification accuracy.},
  isbn = {978-1-5386-6568-8},
  keywords = {\#nosource,⛔ No INSPIRE recid found,confocal microscopy,convolutional neural network,Image classification,primary cilia,random forests},
  annotation = {6 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@thesis{ram_dissertation_2017,
  type = {phdthesis},
  title = {Sparse {{Representations}} and {{Nonlinear Image Processing}} for {{Inverse Imaging Solutions}}},
  author = {Ram, S.},
  date = {2017},
  institution = {{Dept. Elect. Comput. Engg., Univ. Arizona}},
  location = {{Tucson, AZ}},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{ram_Three_2018,
  ids = {ram17,ram_ThreeDimensional_2018},
  title = {Three-{{Dimensional Segmentation}} of the {{Ex-Vivo Anterior Lamina Cribrosa From Second-Harmonic Imaging Microscopy}}},
  author = {Ram, Sundaresh and Danford, Forest and Howerton, Stephen and Rodriguez, Jeffrey J. and Geest, Jonathan P. Vande},
  date = {2018-07},
  journaltitle = {IEEE Trans. Biomed. Eng.},
  volume = {65},
  number = {7},
  pages = {1617--1629},
  issn = {0018-9294, 1558-2531},
  doi = {10.1109/TBME.2017.2674521},
  url = {https://ieeexplore.ieee.org/document/7862784/},
  urldate = {2023-06-03},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Graph cut segmentation,histogram thresholding,lamina cribrosa,volumetric data denoising,wavelet},
  annotation = {19 citations (Semantic Scholar/DOI) [2023-06-02]},
  file = {/Users/personal-macbook/Zotero/storage/A8B6J3YR/Ram et al. - 2018 - Three-Dimensional Segmentation of the Ex-Vivo Ante.pdf}
}

@inproceedings{ram_Vehicle_2016,
  ids = {ram16},
  title = {Vehicle {{Detection}} in {{Aerial Images Using Multiscale Structure Enhancement}} and {{Symmetry}}},
  booktitle = {2016 {{IEEE Int}}. {{Conf}}. {{Image Process}}. {{ICIP}}},
  author = {Ram, Sundaresh and Rodriguez, Jeffrey J.},
  date = {2016-09},
  pages = {3817--3821},
  publisher = {{IEEE}},
  location = {{Phoenix, AZ, USA}},
  doi = {10.1109/ICIP.2016.7533074},
  url = {http://ieeexplore.ieee.org/document/7533074/},
  urldate = {2023-06-03},
  eventtitle = {2016 {{IEEE International Conference}} on {{Image Processing}} ({{ICIP}})},
  isbn = {978-1-4673-9961-6},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {16 citations (Semantic Scholar/DOI) [2023-06-02]}
}

@inproceedings{ramien_Reg_2019,
  title = {Reg {{R-Cnn}}: {{Lesion Detection}} and {{Grading Under Noisy Labels}}},
  booktitle = {Lect. {{Notes Comput}}. {{Sci}}. {{Subser}}. {{Lect}}. {{Notes Artif}}. {{Intell}}. {{Lect}}. {{Notes Bioinforma}}.},
  author = {Ramien, Gregor N. and Jaeger, Paul F. and Kohl, Simon A. A. and Maier-Hein, Klaus H.},
  date = {2019},
  issn = {16113349},
  doi = {10.1007/978-3-030-32689-0_4},
  abstract = {For the task of concurrently detecting and categorizing objects, the medical imaging community commonly adopts methods developed on natural images. Current state-of-the-art object detectors are comprised of two stages: the first stage generates region proposals, the second stage subsequently categorizes them. Unlike in natural images, however, for anatomical structures of interest such as tumors, the appearance in the image (e.g., scale or intensity) links to a malignancy grade that lies on a continuous ordinal scale. While classification models discard this ordinal relation between grades by discretizing the continuous scale to an unordered bag of categories, regression models are trained with distance metrics, which preserve the relation. This advantage becomes all the more important in the setting of label confusions on ambiguous data sets, which is the usual case with medical images. To this end, we propose Reg R-CNN, which replaces the second-stage classification model of a current object detector with a regression model. We show the superiority of our approach on a public data set with 1026 patients and a series of toy experiments. Code will be available at github.com/MIC-DKFZ/RegRCNN.},
  isbn = {978-3-030-32688-3},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Lesion detection,Malignancy grading,Noisy labels}
}

@inproceedings{rangel_Characterization_2018,
  title = {Characterization and {{Calibration}} of a {{Stereo Gas Camera System}} for {{Obtaining Spatial Information}} of {{Gas Structures}}},
  booktitle = {2018 {{IEEE Sens}}. {{Appl}}. {{Symp}}. {{SAS}} 2018 - {{Proc}}.},
  author = {Rangel, Johannes and Kroll, Andreas},
  date = {2018},
  doi = {10.1109/SAS.2018.8336741},
  abstract = {The use of infrared cameras for gas visualization, also named gas cameras, has facilitated the search of escaped environmentally harmful gases in the petroleum and chemical industry, since such cameras allow the detection of gases in a remote way. One way to locate a gas cloud spatially is by setting up two gas cameras in a stereo arrangement and fusing their information. Since gas clouds are semi-transparent non-stationary textures in gas camera images, current methods for depth measurements from stereo visual systems may not succeed or be inaccurate. Furthermore, spatial jitter in the images originated by the internal cooling engine of a gas camera and the radiometric and temporal inaccuracies of the system can affect the performance of the reconstruction method. In order to calculate accurate spatial information with a stereo gas camera system, in this work a characterization of the geometric, radiometric and temporal inaccuracies of the system and a calibration procedure were carried out. After evaluating the obtained results by means of a case study, it has been shown that the location and spatial information of gas clouds can be achieved automatically through a calibration and spatial jitter compensation in the stereo images.},
  isbn = {978-1-5386-2092-2},
  keywords = {\#nosource,⛔ No INSPIRE recid found,camera calibration,gas imaging,infrared cameras,spatial jitter,stereo 3D reconstruction},
  annotation = {4 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{rangel_Obtaining_2019,
  title = {On {{Obtaining Reliable Spatial Information From Gas Structures With}} a {{Stereo Camera System}}},
  booktitle = {Proc. {{Int}}. {{Conf}}. {{Sens}}. {{Technol}}. {{ICST}}},
  author = {Rangel, Johannes and Kroll, Andreas},
  date = {2019},
  issn = {21568073},
  doi = {10.1109/ICSensT.2018.8603631},
  abstract = {Spotting and localizing unwanted harmful gas releases is of great interest for the maintenance of facilities in the chemical, oil, gas and biogas industry due to their economic impact and negative effect on the environment. In this regard, stereo gas camera systems have been proposed in the literature for obtaining spatiooral information from gas releases. These permit gas localization and tracking. Nevertheless, these works rely on a photo-consistency assumption that holds for most textured opaque objects in the visual spectrum but not necessarily for semi-transparent continuous textures such as gases. In this work, first, a detailed measuring model for gaining gas structure's spatial information with a stereo camera is proposed. A disparity calculation method and a quality measure is then implemented and tested for finding correspondences in stereo images of continuous textures. The proposed measuring model is tested and validated with the implemented disparity method and using synthetic and real stereo images sequences. The results indicate that the computed spatial information from gas structures approximates reliably the path-averaged and concentration-weighted gas position regarding the perspective of the stereo camera system.},
  isbn = {978-1-5386-5147-6},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{ranieri_Acute_2012,
  title = {Acute {{Respiratory Distress Syndrome}}: {{The Berlin Definition}}},
  author = {Ranieri, V. Marco and Rubenfeld, Gordon D. and Thompson, B. Taylor and Ferguson, Niall D. and Caldwell, Ellen and Fan, Eddy and Camporota, Luigi and Slutsky, Arthur S.},
  date = {2012},
  journaltitle = {JAMA - J. Am. Med. Assoc.},
  eprint = {22797452},
  eprinttype = {pmid},
  issn = {00987484},
  doi = {10.1001/jama.2012.5669},
  abstract = {The acute respiratory distress syndrome (ARDS) was defined in 1994 by the American-European Consensus Conference (AECC); since then, issues regarding the reliability and validity of this definition have emerged. Using a consensus process, a panel of experts convened in 2011 (an initiative of the European Society of Intensive Care Medicine endorsed by the American Thoracic Society and the Society of Critical Care Medicine) developed the Berlin Definition, focusing on feasibility, reliability, validity, and objective evaluation of its performance. A draft definition proposed 3 mutually exclusive categories of ARDS based on degree of hypoxemia: mild (200 mm Hg {$<$} PaO 2/FIO 2 {$\leq$} 300 mmHg), moderate (100mmHg {$<$} PaO 2/FIO 2 {$\leq$} 200mmHg), and severe (PaO 2/FIO 2 {$\leq$} 100mmHg) and 4 ancillary variables for severe ARDS: radiographic severity, respiratory system compliance ({$\leq$}40 mL/cm H 2O), positive endexpiratory pressure ({$\geq$}10 cm H 2O), and corrected expired volume per minute ({$\geq$}10 L/min). The draft Berlin Definition was empirically evaluated using patient-level meta-analysis of 4188 patients with ARDS from 4 multicenter clinical data sets and 269 patients with ARDS from 3 single-center data sets containing physiologic information. The 4 ancillary variables did not contribute to the predictive validity of severe ARDS for mortality and were removed from the definition. Using the Berlin Definition, stages of mild, moderate, and severe ARDS were associated with increased mortality (27\%;95\%CI, 24\%-30\%; 32\%;95\% CI, 29\%-34\%; and 45\%; 95\% CI, 42\%-48\%, respectively; P {$<$} .001) and increased median duration of mechanical ventilation in survivors (5 days; interquartile [IQR], 2-11; 7 days; IQR, 4-14; and 9 days; IQR, 5-17, respectively; P {$<$} .001). Compared with the AECC definition, the final Berlin Definition had better predictive validity for mortality, with an area under the receiver operating curve of 0.577 (95\% CI, 0.561-0.593) vs 0.536 (95\% CI, 0.520-0.553; P {$<$} .001). This updated and revised Berlin Definition for ARDS addresses a number of the limitations of the AECC definition. The approach of combining consensus discussions with empirical evaluation may serve as a model to create more accurate, evidence-based, critical illness syndrome definitions and to better inform clinical care, research, and health services planning. \textcopyright 2012 American Medical Association. All rights reserved.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {7572 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@thesis{ratner_Accelerating_2019,
  ids = {ratner_Accelerating_2019a},
  title = {Accelerating {{Machine Learning With Training Data Management}}},
  author = {Ratner, Alexander Jason},
  date = {2019},
  journaltitle = {Stanford},
  institution = {{Stanford}},
  issue = {August},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{ray_Novel_2005,
  title = {A {{Novel Approach}} to {{Fingerprint Pore Extraction}}},
  booktitle = {Proc. {{Thirty-Seventh Southeast}}. {{Symp}}. {{Syst}}. {{Theory}} 2005 {{SSST}} 05},
  author = {Ray, M. and Meenen, P. and Adhanii, R.},
  date = {2005},
  pages = {282--286},
  publisher = {{IEEE}},
  location = {{Tuskegee, AL, USA}},
  doi = {10.1109/SSST.2005.1460922},
  url = {http://ieeexplore.ieee.org/document/1460922/},
  urldate = {2022-12-29},
  eventtitle = {Proceedings of the {{Thirty-Seventh Southeastern Symposium}} on {{System Theory}} ({{SSST05}})},
  isbn = {978-0-7803-8808-6},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Biometrics,Fingerprints,Image Processing,Pores},
  annotation = {68 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{raykar_Learning_2010,
  title = {Learning {{From Crowds}}},
  author = {Raykar, Vikas C. and Yu, Shipeng and Zhao, Linda H. and Valadez, Gerardo Hermosillo and Florin, Charles and Bogoni, Luca and Moy, Linda and Raykar, C. and Valadez, Gerardo Hermosillo and Florin, Charles and Bogoni, Luca and Moy, Linda},
  date = {2010},
  journaltitle = {JMLR},
  volume = {11},
  number = {43},
  pages = {1297--1322},
  issn = {15324435},
  abstract = {For many supervised learning tasks it may be infeasible (or very expensive) to obtain objective and reliable labels. Instead, we can collect subjective (possibly noisy) labels from multiple experts or annotators. In practice, there is a substantial amount of disagreement among the annotators, and hence it is of great practical interest to address conventional supervised learning problems in this scenario. In this paper we describe a probabilistic approach for supervised learning when we have multiple annotators providing (possibly noisy) labels but no absolute gold standard. The proposed algorithm evaluates the different experts and also gives an estimate of the actual hidden labels. Experimental results indicate that the proposed method is superior to the commonly used majority voting baseline. \textcopyright{} 2010 Vikas C. Raykar, Shipeng Yu, Linda H. Zhao, Gerardo H. Valadez, Charles Florin, Luca Bogoni and Linda Moy.},
  langid = {english},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found,Computer Vision and Pattern Recognition (cs.CV),crowdsourcing,Crowdsourcing,FOS: Computer and information sciences,Human-Computer Interaction (cs.HC),Machine Learning (cs.LG),multiple annotators,Multiple annotators,multiple experts,Multiple experts,multiple teachers,Multiple teachers},
  file = {/Users/personal-macbook/Zotero/storage/GBI3K6PG/Raykar et al. - 2010 - Learning from Crowds.pdf}
}

@inproceedings{raykar_Supervised_2009,
  title = {Supervised {{Learning From Multiple Experts}}: {{Whom}} to {{Trust When Everyone Lies}} a {{Bit}}},
  shorttitle = {Supervised {{Learning}} from {{Multiple Experts}}},
  booktitle = {Proc. 26th {{Annu}}. {{Int}}. {{Conf}}. {{Mach}}. {{Learn}}. - {{ICML}} 09},
  author = {Raykar, Vikas C. and Yu, Shipeng and Zhao, Linda H. and Jerebko, Anna and Florin, Charles and Valadez, Gerardo Hermosillo and Bogoni, Luca and Moy, Linda},
  date = {2009},
  pages = {1--8},
  publisher = {{ACM Press}},
  location = {{Montreal, Quebec, Canada}},
  doi = {10.1145/1553374.1553488},
  url = {http://portal.acm.org/citation.cfm?doid=1553374.1553488},
  urldate = {2022-12-28},
  eventtitle = {The 26th {{Annual International Conference}}},
  isbn = {978-1-60558-516-1},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {365 citations (Semantic Scholar/DOI) [2022-12-28]},
  file = {/Users/personal-macbook/Zotero/storage/JQNTS33C/Raykar et al. - 2009 - Supervised learning from multiple experts whom to.pdf;/Users/personal-macbook/Zotero/storage/HY99QY6R/1553374.html}
}

@article{reagh_Dissociated_2014,
  title = {Dissociated {{Signals}} in {{Human Dentate Gyrus}} and {{CA3 Predict Different Facets}} of {{Recognition Memory}}},
  author = {Reagh, Zachariah M. and Watabe, Joseph and Ly, Maria and Murray, Elizabeth and Yassa, Michael A.},
  date = {2014-10},
  journaltitle = {J. Neurosci.},
  volume = {34},
  number = {40},
  pages = {13301--13313},
  doi = {10.1523/JNEUROSCI.2779-14.2014},
  abstract = {A wealth of evidence has implicated the hippocampus and surrounding medial temporal lobe cortices in support of recognition memory. However, the roles of the various subfields of the hippocampus are poorly understood. In this study, we concurrently varied stimulus familiarization and repetition to engage different facets of recognition memory. Using high-resolution fMRI (1.5 mm isotropic), we observed distinct familiarity and repetition-related recognition signal profiles in the dentate gyrus (DG)/CA3 subfield in human subjects. The DG/CA3 demonstrated robust response suppression with repetition and familiarity-related facilitation. Both of these discrete responses were predictive of different aspects of behavioral performance. Consistent with previous work, we observed novelty responses in CA1 consistent with ``match/mismatch detection,'' as well as mixed recognition signaling distributed across medial temporal lobe cortices. Additional analyses indicated that the repetition and familiarity-related signals in the DG/CA3 were strikingly dissociated along the hippocampal longitudinal axis and that activity in the posterior hippocampus was strongly correlated with the retrosplenial cortex. These data provide novel insight into the roles of hippocampal subfields in support of recognition memory and further provide evidence of a functional heterogeneity in the human DG/CA3, particularly along the longitudinal axis.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,CA3,dentate,fMRI,hippocampus,memory,recogniti},
  annotation = {30 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{redekop_UncertaintyBased_2021,
  title = {Uncertainty-{{Based Method}} for {{Improving Poorly Labeled Segmentation Datasets}}},
  booktitle = {2021 {{IEEE}} 18th {{Int}}. {{Symp}}. {{Biomed}}. {{Imaging ISBI}}},
  author = {Redekop, Ekaterina and Chernyavskiy, Alexey},
  date = {2021},
  pages = {1831--1835},
  publisher = {{IEEE}},
  doi = {10.1109/ISBI48211.2021.9434065},
  keywords = {⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/JYZ35CZ4/Redekop and Chernyavskiy - 2021 - Uncertainty-based method for improving poorly labe.pdf}
}

@inproceedings{redmon_YOLO9000_2017,
  title = {{{YOLO9000}}: {{Better}}, {{Faster}}, {{Stronger}}},
  shorttitle = {{{YOLO9000}}},
  booktitle = {{{IEEE Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}. {{CVPR}}},
  author = {Redmon, Joseph and Farhadi, Ali},
  date = {2017-07},
  pages = {6517--6525},
  publisher = {{IEEE}},
  location = {{Honolulu, HI}},
  doi = {10.1109/CVPR.2017.690},
  url = {http://ieeexplore.ieee.org/document/8100173/},
  urldate = {2022-11-21},
  eventtitle = {{{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-5386-0457-1},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {9405 citations (Semantic Scholar/DOI) [2022-11-21]},
  file = {/Users/personal-macbook/Zotero/storage/9D9EAVZQ/Redmon and Farhadi - 2017 - YOLO9000 Better, Faster, Stronger.pdf}
}

@article{reimer_Pupil_2016,
  title = {Pupil {{Fluctuations Track Rapid Changes}} in {{Adrenergic}} and {{Cholinergic Activity}} in {{Cortex}}},
  author = {Reimer, Jacob and McGinley, Matthew J. and Liu, Yang and Rodenkirch, Charles and Wang, Qi and McCormick, David A. and Tolias, Andreas S.},
  date = {2016},
  journaltitle = {Nat. Commun.},
  eprint = {27824036},
  eprinttype = {pmid},
  issn = {20411723},
  doi = {10.1038/ncomms13289},
  abstract = {Rapid variations in cortical state during wakefulness have a strong influence on neural and behavioural responses and are tightly coupled to changes in pupil size across species. However, the physiological processes linking cortical state and pupil variations are largely unknown. Here we demonstrate that these rapid variations, during both quiet waking and locomotion, are highly correlated with fluctuations in the activity of corticopetal noradrenergic and cholinergic projections. Rapid dilations of the pupil are tightly associated with phasic activity in noradrenergic axons, whereas longer-lasting dilations of the pupil, such as during locomotion, are accompanied by sustained activity in cholinergic axons. Thus, the pupil can be used to sensitively track the activity in multiple neuromodulatory transmitter systems as they control the state of the waking brain.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{ren_Faster_2015,
  ids = {ren_Faster_2015a},
  title = {Faster {{R-Cnn}}: {{Towards Real-Time Object Detection With Region Proposal Networks}}},
  shorttitle = {Faster R-Cnn},
  author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  date = {2015},
  journaltitle = {Adv. Neural Inf. Process. Syst.},
  volume = {28},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/QVFL8EEJ/Ren et al. - 2015 - Faster r-cnn Towards real-time object detection w.pdf;/Users/personal-macbook/Zotero/storage/N7EAD297/Ren et al. - 2015 - Faster r-cnn Towards real-time object detection w.html}
}

@article{ren_Interpretable_2021b,
  ids = {ren_Interpretable_2021,ren_Interpretable_2021a},
  title = {Interpretable {{Pneumonia Detection}} by {{Combining Deep Learning}} and {{Explainable Models With Multisource Data}}},
  author = {Ren, Hao and Wong, Aslan B. and Lian, Wanmin and Cheng, Weibin and Zhang, Ying and He, Jianwei and Liu, Qingfeng and Yang, Jiasheng and Zhang, Chen Jason and Wu, Kaishun and Zhang, Haodi},
  date = {2021},
  journaltitle = {IEEE Access},
  volume = {9},
  pages = {95872--95883},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2021.3090215},
  url = {https://ieeexplore.ieee.org/document/9458276/},
  urldate = {2023-05-08},
  keywords = {⛔ No INSPIRE recid found,Bayes methods,computer-aided diagnosis,interpretive medical-assisted diagnosis,large-scale annotated X-ray image dataset,Lung,Medical diagnostic imaging,medical image analysis,Pneumonia,Pulmonary diseases,Solid modeling,Training,X-ray imaging},
  annotation = {8 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/L8GGHA3M/Ren et al. - 2021 - Interpretable Pneumonia Detection by Combining Dee.pdf;/Users/personal-macbook/Zotero/storage/NXUS7G2L/Ren et al. - 2021 - Interpretable Pneumonia Detection by Combining Dee.pdf;/Users/personal-macbook/Zotero/storage/V5BQTX4I/Ren et al. - 2021 - Interpretable Pneumonia Detection by Combining Dee.pdf;/Users/personal-macbook/Zotero/storage/7WNI8FY8/9458276.html;/Users/personal-macbook/Zotero/storage/SMHCXE7N/9458276.html}
}

@article{renaud_Effects_1975,
  title = {Effects of 5,6-{{Dihydroxytryptamine}} on {{Tyrosine-Hydroxylase Activity}} in {{Central Catecholaminergic Neurons}} of the {{Rat}}},
  author = {Renaud, B. and Buda, M. and Lewis, B. D. and Pujol, J. F.},
  date = {1975-09-15},
  journaltitle = {Biochem Pharmacol},
  volume = {24},
  number = {18},
  eprint = {17},
  eprinttype = {pmid},
  pages = {1739--1742},
  issn = {0006-2952},
  doi = {10.1016/0006-2952(75)90018-0},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,{5,6-Dihydroxytryptamine},Animals,Brain,Catecholamines,Cerebral Cortex,Cisterna Magna,Corpus Striatum,In Vitro Techniques,Injections,Male,Neurons,Rats,{Rats, Inbred Strains},{Stimulation, Chemical},Substantia Nigra,Time Factors,Tryptamines,Tyrosine 3-Monooxygenase},
  annotation = {71 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{rialp_Phenomenon_2005,
  title = {The {{Phenomenon}} of {{Early Internationalizing Firms}}: {{What Do We Know After}} a {{Decade}} (1993\textendash 2003) of {{Scientific Inquiry}}?},
  author = {Rialp, Alex and Rialp, Josep and Knight, Gary A.},
  date = {2005-04},
  journaltitle = {Int. Bus. Rev.},
  volume = {14},
  number = {2},
  pages = {147--166},
  doi = {10.1016/j.ibusrev.2004.04.006},
  abstract = {With a view to increasing knowledge within the emergent field of international entrepreneurship, we examine 38 studies from the last decade that deal with international new ventures, global start-ups and born-global firms. The methodology used for this synthetic review allow us to analyze a large number of recent, purposefully chosen studies that are compared along the following criteria: (1) main objective and type of research; (2) theoretical framework/s of reference; (3) methodological issues and (4) main findings and/or conclusions. We seek to elucidate the most relevant benefits and contributions as well as potential drawbacks, limitations or major discrepancies found in the research activities conducted to date. Finally, some suggestions and implications are provided in the form of a new research model and future research directions.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Born-globalness,Global start-ups,Internati,INVs}
}

@inproceedings{ribeiro_Why_2016,
  title = {"{{Why Should I Trust You}}?" {{Explaining}} the {{Predictions}} of {{Any Classifier}}},
  booktitle = {Proc. {{ACM SIGKDD Int}}. {{Conf}}. {{Knowl}}. {{Discov}}. {{Data Min}}.},
  author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  date = {2016},
  doi = {10.1145/2939672.2939778},
  abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
  isbn = {978-1-4503-4232-2},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{riegler_OctNet_2017,
  title = {{{OctNet}}: {{Learning Deep 3D Representations}} at {{High Resolutions}}},
  shorttitle = {{{OctNet}}},
  booktitle = {2017 {{IEEE Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}. {{CVPR}}},
  author = {Riegler, Gernot and Ulusoy, Ali Osman and Geiger, Andreas},
  date = {2017-07},
  pages = {6620--6629},
  publisher = {{IEEE}},
  location = {{Honolulu, HI}},
  doi = {10.1109/CVPR.2017.701},
  url = {http://ieeexplore.ieee.org/document/8100184/},
  urldate = {2022-07-18},
  abstract = {We present OctNet, a representation for deep learning with sparse 3D data. In contrast to existing models, our representation enables 3D convolutional networks which are both deep and high resolution. Towards this goal, we exploit the sparsity in the input data to hierarchically partition the space using a set of unbalanced octrees where each leaf node stores a pooled feature representation. This allows to focus memory allocation and computation to the relevant dense regions and enables deeper networks without compromising resolution. We demonstrate the utility of our OctNet representation by analyzing the impact of resolution on several 3D tasks including 3D object classification, orientation estimation and point cloud labeling.},
  eventtitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-5386-0457-1},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/PMHQZJTA/Riegler et al. - 2017 - OctNet Learning Deep 3D Representations at High R.pdf}
}

@article{rikagrawal_Economics_2018,
  title = {The {{Economics}} of {{Artificial Intelligence}}: {{EBSCOhost}}},
  author = {Rik Agrawal, Ajay Kirkland},
  date = {2018},
  journaltitle = {McKinsey Q.},
  abstract = {The article deals with how artificial intelligence (AI) can transform the cost of prediction based on the views of Rotman School of Management professor Ajay Agrawal. In his book "Prediction Machines: The Simple Economics of Artificial Intelligence," Agrawal discusses the implications of AI for business. The increasing importance of data, judgment, and action to businesses is also discussed.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@inproceedings{rittner_Segmentation_2010,
  title = {Segmentation of {{Thalamic Nuclei Based}} on {{Tensorial Morphological Gradient}} of {{Diffusion Tensor Fields}}},
  booktitle = {2010 {{IEEE Int}}. {{Symp}}. {{Biomed}}. {{Imaging Nano Macro}}},
  author = {Rittner, Leticia and Lotufo, Roberto A. and Campbell, Jennifer and Pike, G. Bruce},
  date = {2010},
  pages = {1173--1176},
  publisher = {{IEEE}},
  location = {{Rotterdam, Netherlands}},
  doi = {10.1109/ISBI.2010.5490203},
  url = {http://ieeexplore.ieee.org/document/5490203/},
  urldate = {2023-05-12},
  eventtitle = {2010 {{IEEE International Symposium}} on {{Biomedical Imaging}}: {{From Nano}} to {{Macro}}},
  isbn = {978-1-4244-4125-9},
  keywords = {\#nosource,⛔ No INSPIRE recid found,biodiffusion,biomedical MRI,brain,image segmentati},
  annotation = {17 citations (Semantic Scholar/DOI) [2023-05-12]}
}

@article{rivas_Creating_2018,
  title = {Creating a {{Case}} for {{Digital Health}}},
  author = {Rivas, Homero},
  date = {2018},
  doi = {10.1007/978-3-319-61446-5_1},
  abstract = {The central paradigm in medicine is based on the patient-provider relationship. In these times, previously unheard diseases are being described every day while novel therapies for previously uncured diseases are introduced along with novel state-of-the-art diagnostic and therapeutic technologies. These developments alter the patient-physician relationship, which has remained largely unchanged for thousands of years. Digital Health represents an evolutionary adaptation of the art and science of medicine to pervasive information and communication technologies (ICTs). Without a doubt, this represents a phenomenal opportunity for us to scale access to care to any area in the world where connectivity may be available. This chapter reviews the ways that healthcare has evolved and its conceivable opportunities, challenges, and socioeconomic consequences.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {5 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{rizos_Average_2020,
  title = {Average {{Jane}}, {{Where Art Thou}}? \textendash{} {{Recent Avenues}} in {{Efficient Machine Learning Under Subjectivity Uncertainty}}},
  shorttitle = {Average {{Jane}}, {{Where Art Thou}}?},
  booktitle = {Inf. {{Process}}. {{Manag}}. {{Uncertain}}. {{Knowl}}.-{{Based Syst}}.},
  author = {Rizos, Georgios and Schuller, Bj\"orn W.},
  date = {2020},
  series = {Communications in {{Computer}} and {{Information Science}}},
  pages = {42--55},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-50146-4_4},
  abstract = {In machine learning tasks an actual `ground truth' may not be available. Then, machines often have to rely on human labelling of data. This becomes challenging the more subjective the learning task is, as human agreement can be low. To cope with the resulting high uncertainty, one could train individual models reflecting a single human's opinion. However, this is not viable, if one aims at mirroring the general opinion of a hypothetical `completely average person' \textendash{} the `average Jane'. Here, I summarise approaches to optimally learn efficiently in such a case. First, different strategies of reaching a single learning target from several labellers will be discussed. This includes varying labeller trustability and the case of time-continuous labels with potential dynamics. As human labelling is a labour-intensive endeavour, active and cooperative learning strategies can help reduce the number of labels needed. Next, sample informativeness can be exploited in teacher-based algorithms to additionally weigh data by certainty. In addition, multi-target learning of different labeller tracks in parallel and/or of the uncertainty can help improve the model robustness and provide an additional uncertainty measure. Cross-modal strategies to reduce uncertainty offer another view. From these and further recent strategies, I distil a number of future avenues to handle subjective uncertainty in machine learning. These comprise bigger, yet weakly labelled data processing basing amongst other on reinforcement learning, lifelong learning, and self-learning. Illustrative examples stem from the fields of Affective Computing and Digital Health \textendash{} both notoriously marked by subjectivity uncertainty.},
  isbn = {978-3-030-50146-4},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Active learning,Cooperative learning,Machine learning,Subjectivity,Uncertainty},
  annotation = {25 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/J24V9CJU/Rizos and Schuller - 2020 - Average Jane, Where Art Thou – Recent Avenues in .pdf}
}

@article{robinson_Academic_2001,
  title = {Academic {{Medical Centers}} and the {{Economics}} of {{Innovation}} in {{Health Care}}},
  author = {Robinson, James C.},
  date = {2001},
  journaltitle = {Future Acad. Med. Cent.},
  pages = {49--60},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@inproceedings{rodrigues_Pore_2019,
  title = {Pore {{Detection}} in {{Fingerprints Based}} on {{Image Subtraction}} and {{Anisotropic Diffusion Filtering}}},
  booktitle = {Proc. - 2018 {{IEEE Int}}. {{Conf}}. {{Syst}}. {{Man Cybern}}. {{SMC}} 2018},
  author = {Rodrigues, Emily S. and Borges, Vinicius R. P.},
  date = {2019},
  doi = {10.1109/SMC.2018.00355},
  abstract = {We describe a methodology for extracting and identifying pores in high resolution fingerprint digital images. The key strategy is based on an image subtraction between two fingerprint images with different smoothness levels. The anisotropic diffusion filter is employed to obtain such smoothed fingerprints, in which the pores are preserved in the first fingerprint, while the second one only presents ridges and valleys, but pores are blurred. The subtraction procedure results in a difference image, in which the pores are characterized by the lower magnitudes. After that, we perform a histogram equalization for enhancing pores and a global thresholding to obtain the pores as binary regions. Finally, such binary image is post-processed for removing false pore detections. Experiments were conducted using the PolyU HRF fingerprint image set and the results showed that the proposed methodology outperformed other filtered-based pore extraction methods considering the true and false pore detection rates.},
  isbn = {978-1-5386-6650-0},
  keywords = {\#nosource,⛔ No INSPIRE recid found,3rd level features,anisotropic diffusion,Fingerprints,pores}
}

@article{rohlfing_Evaluation_2004,
  title = {Evaluation of {{Atlas Selection Strategies}} for {{Atlas-Based Image Segmentation With Application}} to {{Confocal Microscopy Images}} of {{Bee Brains}}},
  author = {Rohlfing, Torsten and Brandt, Robert and Menzel, Randolf and Jr, Calvin R. Maurer},
  date = {2004-04},
  journaltitle = {Neuroimage},
  volume = {21},
  number = {4},
  pages = {1428--1442},
  doi = {10.1016/j.neuroimage.2003.11.010},
  abstract = {This paper evaluates strategies for atlas selection in atlas-based segmentation of three-dimensional biomedical images. Segmentation by intensity-based nonrigid registration to atlas images is applied to confocal microscopy images acquired from the brains of 20 bees. This paper evaluates and compares four different approaches for atlas image selection: registration to an individual atlas image (IND), registration to an average-shape atlas image (AVG), registration to the most similar image from a database of individual atlas images (SIM), and registration to all images from a database of individual atlas images with subsequent multi-classifier decision fusion (MUL). The MUL strategy is a novel application of multi-classifier techniques, which are common in pattern recognition, to atlas-based segmentation. For each atlas selection strategy, the segmentation performance of the algorithm was quantified by the similarity index (SI) between the automatic segmentation result and a manually generated gold standard. The best segmentation accuracy was achieved using the MUL paradigm, which resulted in a mean similarity index value between manual and automatic segmentation of 0.86 (AVG, 0.84; SIM, 0.82; IND, 0.81). The superiority of the MUL strategy over the other three methods is statistically significant (two-sided paired t test, P {$<$} 0.001). Both the MUL and AVG strategies performed better than the best possible SIM and IND strategies with optimal a posteriori atlas selection (mean similarity index for optimal SIM, 0.83; for optimal IND, 0.81). Our findings show that atlas selection is an important issue in atlas-based segmentation and that, in particular, multi-classifier techniques can substantially increase the segmentation accuracy.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {627 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{rolls_Computational_2010,
  title = {A {{Computational Theory}} of {{Episodic Memory Formation}} in the {{Hippocampus}}},
  author = {Rolls, Edmund T.},
  date = {2010-12},
  journaltitle = {Behavioural Brain Research},
  volume = {215},
  number = {2},
  pages = {180--196},
  issn = {01664328},
  doi = {10.1016/j.bbr.2010.03.027},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0166432810002135},
  urldate = {2023-05-08},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {242 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{romero_HIPS_2017,
  title = {{{HIPS}}: {{A New Hippocampus Subfield Segmentation Method}}},
  author = {Romero, Jos\'e E. and Coup\'e, Pierrick and Manj\'on, Jos\'e V.},
  date = {2017-12},
  journaltitle = {Neuroimage},
  volume = {163},
  pages = {286--295},
  doi = {10.1016/j.neuroimage.2017.09.049},
  abstract = {The importance of the hippocampus in the study of several neurodegenerative diseases such as Alzheimer's disease makes it a structure of great interest in neuroimaging. However, few segmentation methods have been proposed to measure its subfields due to its complex structure and the lack of high resolution magnetic resonance (MR) data. In this work, we present a new pipeline for automatic hippocampus subfield segmentation using two available hippocampus subfield delineation protocols that can work with both high and standard resolution data. The proposed method is based on multi-atlas label fusion technology that benefits from a novel multi-contrast patch match search process (using high resolution T1-weighted and T2-weighted images). The proposed method also includes as post-processing a new neural network-based error correction step to minimize systematic segmentation errors. The method has been evaluated on both high and standard resolution images and compared to other state-of-the-art methods showing better results in terms of accuracy and execution time.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {57 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{ronneberger_UNet_2015,
  ids = {ronneberger15,ronneberger_UNet_2015a},
  title = {U-{{Net}}: {{Convolutional Networks}} for {{Biomedical Image Segmentation}}},
  shorttitle = {U-{{Net}}},
  booktitle = {Med. {{Image Comput}}. {{Comput}}.-{{Assist}}. {{Interv}}. \textendash{} {{MICCAI}} 2015},
  author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  editor = {Navab, Nassir and Hornegger, Joachim and Wells, William M. and Frangi, Alejandro F.},
  date = {2015},
  volume = {9351},
  pages = {234--241},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-24574-4_28},
  url = {http://link.springer.com/10.1007/978-3-319-24574-4_28},
  urldate = {2023-01-11},
  isbn = {978-3-319-24573-7 978-3-319-24574-4},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/QXUE9VA2/Ronneberger et al. - 2015 - U-Net Convolutional Networks for Biomedical Image.pdf;/Users/personal-macbook/Zotero/storage/8AZ6F4ZF/978-3-319-24574-4_28.html}
}

@article{rosado-toro_Segmentation_2017,
  title = {Segmentation of the {{Right Ventricle}} in {{Four Chamber Cine Cardiac MR Images Using Polar Dynamic Programming}}},
  author = {Rosado-Toro, Jose A. and Abidov, Aiden and Altbach, Maria I. and Oliva, Isabel B. and Rodriguez, Jeffrey J. and Avery, Ryan J.},
  date = {2017},
  journaltitle = {Comput. Med. Imaging Graph.},
  eprint = {28886885},
  eprinttype = {pmid},
  issn = {18790771},
  doi = {10.1016/j.compmedimag.2017.08.002},
  abstract = {The four chamber plane is currently underutilized in the right ventricular segmentation community. Four chamber information can be useful to determine ventricular short axis stacks and provide a rough estimate of the right ventricle in short axis stacks. In this study, we develop and test a semi-automated technique for segmenting the right ventricle in four chamber cine cardiac magnetic resonance images. The three techniques that use minimum cost path algorithms were used. The algorithms are: Dijkstra's shortest path algorithm (Dijkstra), an A* algorithm that uses length, curvature and torsion into an active contour model (ALCT), and a variation of polar dynamic programming (PDP). The techniques are evaluated against the expert traces using 175 cardiac images from 7 patients. The evaluation first looks at mutual overlap metrics and then focuses on clinical measures such as fractional area change (FAC). The mean mutual overlap between the physician's traces ranged from 0.85 to 0.88. Using as reference physician 1{${'}$}s landmarks and traces (i.e., comparing the traces from physician 1 to the semi-automated segmentation using physician 1{${'}$}s landmarks), the PDP algorithm has a mean mutual overlap of 0.8970 compared to 0.8912 for ALCT and 0.8879 for Dijkstra. The mean mutual overlap between the BP regions generated by physician 1 and physician 2 landmarks are 0.9674, 0.9605 and 0.9531 for PDP, ALCT and Dijkstra, respectively. The FAC correlation coefficient between the physician's traces ranged from 0.73 to 0.93.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Four chamber right ventricle segmentation,Polar dynamic programming,Polar variance}
}

@inproceedings{rosenberg_Semisupervised_2005,
  title = {Semi-{{Supervised Self-Training}} of {{Object Detection Models}}},
  booktitle = {Proc. - {{Seventh IEEE Workshop Appl}}. {{Comput}}. {{Vis}}. {{WACV}} 2005},
  author = {Rosenberg, Chuck and Hebert, Martial and Schneiderman, Henry},
  date = {2005},
  doi = {10.1109/ACVMOT.2005.107},
  abstract = {The construction of appearance-based object detection systems is time-consuming and difficult because a large number of training examples must be collected and manually labeled in order to capture variations in object appearance. Semi-supervised training is a means for reducing the effort needed to prepare the training set by training the model with a small number of fully labeled examples and an additional set of unlabeled or weakly labeled examples. In this work we present a semi-supervised approach to framing object detection systems based on self-training. We implement our approach as a wrapper around the training process of an existing object detector and present empirical results. The key contributions of this empirical study is to demonstrate that a model trained in this manner can achieve results comparable to a model trained in the traditional manner using a much larger set of fully labeled data, and that a training data selection metric that is defined independently of the detector greatly outperforms a selection metric based on the detection confidence generated by the detector.},
  isbn = {0-7695-2271-8},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{rosset_Margin_,
  title = {Margin {{Maximizing Loss Functions}}},
  author = {Rosset, Saharon and Zhu, Ji and Hastie, Trevor},
  abstract = {Margin maximizing properties play an important role in the analysis of classi\textsterling -cation models, such as boosting and support vector machines. Margin maximiza-tion is theoretically interesting because it facilitates generalization error analysis, and practically interesting because it presents a clear geometric interpretation of the models being built. We formulate and prove a suf\textsterling cient condition for the solutions of regularized loss functions to converge to margin maximizing separa-tors, as the regularization vanishes. This condition covers the hinge loss of SVM, the exponential loss of AdaBoost and logistic regression loss. We also generalize it to multi-class classi\textsterling cation problems, and present margin maximizing multi-class versions of logistic regression and support vector machines.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@inproceedings{roth_Deeporgan_2015,
  title = {Deeporgan: {{Multi-Level Deep Convolutional Networks}} for {{Automated Pancreas Segmentation}}},
  booktitle = {Lect. {{Notes Comput}}. {{Sci}}.},
  author = {Roth, Holger R. and Lu, Le and Farag, Amal and Shin, Hoo Chang and Liu, Jiamin and Turkbey, Evrim B. and Summers, Ronald M.},
  date = {2015},
  issn = {16113349},
  doi = {10.1007/978-3-319-24553-9_68},
  abstract = {Automatic organ segmentation is an important yet challenging problem for medical image analysis. The pancreas is an abdominal organ with very high anatomical variability. This inhibits previous segmentation methods from achieving high accuracies, especially compared to other organs such as the liver, heart or kidneys. In this paper, we present a probabilistic bottom-up approach for pancreas segmentation in abdominal computed tomography (CT) scans, using multi-level deep convolutional networks (ConvNets). We propose and evaluate several variations of deep ConvNets in the context of hierarchical, coarse-tofine classification on image patches and regions, i.e. superpixels. We first present a dense labeling of local image patches via P-ConvNet and nearest neighbor fusion. Then we describe a regional ConvNet (R1-ConvNet) that samples a set of bounding boxes around each image superpixel at different scales of contexts in a ``zoom-out'' fashion. Our ConvNets learn to assign class probabilities for each superpixel region of being pancreas. Last, we study a stacked R2-ConvNet leveraging the joint space of CT intensities and the P-ConvNet dense probability maps. Both 3D Gaussian smoothing and 2D conditional random fields are exploited as structured predictions for post-processing. We evaluate on CT images of 82 patients in 4-fold cross-validation. We achieve a Dice Similarity Coefficient of 83.6{$\pm$}6.3\% in training and 71.8{$\pm$}10.7\% in testing.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {571 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{roth_New_2014,
  title = {A {{New}} 2.{{5D Representation}} for {{Lymph Node Detection Using Random Sets}} of {{Deep Convolutional Neural Network Observations}}},
  booktitle = {Med. {{Image Comput}}. {{Comput}}.-{{Assist}}. {{Interv}}. \textendash{} {{MICCAI}} 2014},
  author = {Roth, Holger R. and Lu, Le and Seff, Ari and Cherry, Kevin M. and Hoffman, Joanne and Wang, Shijun and Liu, Jiamin and Turkbey, Evrim and Summers, Ronald M.},
  editor = {Golland, Polina and Hata, Nobuhiko and Barillot, Christian and Hornegger, Joachim and Howe, Robert},
  date = {2014},
  volume = {8673},
  pages = {520--527},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-10404-1_65},
  url = {http://link.springer.com/10.1007/978-3-319-10404-1_65},
  urldate = {2023-05-08},
  isbn = {978-3-319-10403-4 978-3-319-10404-1},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/TS56RCLG/Roth et al. - 2014 - A New 2.5D Representation for Lymph Node Detection.pdf}
}

@article{roy_Bayesian_2019,
  title = {Bayesian {{QuickNAT}}: {{Model Uncertainty}} in {{Deep Whole-Brain Segmentation}} for {{Structure-Wise Quality Control}}},
  author = {Roy, Abhijit Guha and Conjeti, Sailesh and Navab, Nassir and Wachinger, Christian},
  date = {2019},
  journaltitle = {NeuroImage},
  eprint = {30926511},
  eprinttype = {pmid},
  issn = {10959572},
  doi = {10.1016/j.neuroimage.2019.03.042},
  abstract = {We introduce Bayesian QuickNAT for the automated quality control of whole-brain segmentation on MRI T1 scans. Next to the Bayesian fully convolutional neural network, we also present inherent measures of segmentation uncertainty that allow for quality control per brain structure. For estimating model uncertainty, we follow a Bayesian approach, wherein, Monte Carlo (MC) samples from the posterior distribution are generated by keeping the dropout layers active at test time. Entropy over the MC samples provides a voxel-wise model uncertainty map, whereas expectation over the MC predictions provides the final segmentation. Next to voxel-wise uncertainty, we introduce four metrics to quantify structure-wise uncertainty in segmentation for quality control. We report experiments on four out-of-sample datasets comprising of diverse age range, pathology and imaging artifacts. The proposed structure-wise uncertainty metrics are highly correlated with the Dice score estimated with manual annotation and therefore present an inherent measure of segmentation quality. In particular, the intersection over union over all the MC samples is a suitable proxy for the Dice score. In addition to quality control at scan-level, we propose to incorporate the structure-wise uncertainty as a measure of confidence to do reliable group analysis on large data repositories. We envisage that the introduced uncertainty metrics would help assess the fidelity of automated deep learning based segmentation methods for large-scale population studies, as they enable automated quality control and group analyses in processing large data repositories.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Brain segmentation,Deep learning,Group analysis,Model uncertainty,Quality control},
  annotation = {75 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{roy_Deep_2018,
  title = {A {{Deep Learning Framework}} for {{Brain Extraction}} in {{Humans}} and {{Animals With Traumatic Brain Injury}}},
  booktitle = {2018 {{IEEE}} 15th {{Int}}. {{Symp}}. {{Biomed}}. {{Imaging ISBI}} 2018},
  author = {Roy, Snehashis and Knutsen, Andrew and Korotcov, Alexandru and Bosomtwi, Asamoah and Dardzinski, Bernard and Butman, John A. and Pham, Dzung L.},
  date = {2018-04},
  pages = {687--691},
  publisher = {{IEEE}},
  location = {{Washington, DC}},
  doi = {10.1109/ISBI.2018.8363667},
  url = {https://ieeexplore.ieee.org/document/8363667/},
  urldate = {2022-12-29},
  eventtitle = {2018 {{IEEE}} 15th {{International Symposium}} on {{Biomedical Imaging}} ({{ISBI}} 2018)},
  isbn = {978-1-5386-3636-7},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {21 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{roy_TreeCNN_2020,
  title = {Tree-{{Cnn}}: {{A Hierarchical Deep Convolutional Neural Network}} for {{Incremental Learning}}},
  shorttitle = {Tree-{{Cnn}}},
  author = {Roy, Deboleena and Panda, Priyadarshini and Roy, Kaushik},
  date = {2020-01},
  journaltitle = {Neural Networks},
  volume = {121},
  pages = {148--160},
  issn = {08936080},
  doi = {10.1016/j.neunet.2019.09.010},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608019302710},
  urldate = {2022-11-21},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {129 citations (Semantic Scholar/DOI) [2022-11-21]},
  file = {/Users/personal-macbook/Zotero/storage/6MTNSLE3/Roy et al. - 2020 - Tree-CNN A hierarchical Deep Convolutional Neural.pdf;/Users/personal-macbook/Zotero/storage/XBCWRKC6/Roy et al. - 2020 - Tree-CNN A hierarchical Deep Convolutional Neural.pdf}
}

@thesis{ruder_Neural_2019,
  title = {Neural {{Transfer Learning}} for {{Natural Language Processing}}},
  author = {Ruder, Sebastian},
  date = {2019},
  journaltitle = {National University of Ireland},
  institution = {{National University of Ireland}},
  url = {http://ruder.io/thesis/neural_transfer_learning_for_nlp.pdf},
  abstract = {The current generation of neural network-based natural language processing models excels at learning from large amounts of labelled data. Given these capabilities, natural language processing is increasingly applied to new tasks, new domains, and new languages. Current models, however, are sensitive to noise and adversarial examples and prone to overfitting. This brittleness, together with the cost of attention, challenges the supervised learning paradigm. Transfer learning allows us to leverage knowledge acquired from related data in order to improve performance on a target task. Implicit transfer learning in the form of pretrained word representations has been a common component in natural language processing. In this dissertation, we argue that more explicit transfer learning is key to deal with the dearth of training data and to improve downstream performance of natural language processing models. We show experimental results transferring knowledge from related domains, tasks, and languages that support this hypothesis. We make several contributions to transfer learning for natural language processing: Firstly, we propose new methods to automatically select relevant data for supervised and unsupervised domain adaptation. Secondly, we propose two novel architectures that improve sharing in multi-task learning and outperform single-task learning as well as the state-of-the-art. Thirdly, we analyze the limitations of current models for unsupervised cross-lingual transfer and propose a method to mitigate them as well as a novel latent- variable cross-lingual word embedding model. Finally, we propose a framework based on fine-tuning language models for sequential transfer learning and analyze the adaptation phase.},
  pagetotal = {6053-6058},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{runyon_Dynamic_2019,
  title = {Dynamic {{Behavior}} of {{Cortisol}} and {{Cortisol Metabolites}} in {{Human Eccrine Sweat}}},
  author = {Runyon, J. Ray and Jia, Min and Goldstein, Michael R. and Skeath, Perry and Abrell, Leif and Chorover, Jon and Sternberg, Esther M.},
  date = {2019},
  journaltitle = {Int. J. Progn. Health Manag.},
  issn = {21532648},
  abstract = {The simultaneous measurement of cortisol with its downstream metabolites in human eccrine sweat is a sensitive approach to capture minute-to-minute stress responses. This study investigates exercise stress induced time dependent dynamic changes in cortisol, cortisone and downstream inactive cortisol metabolites in human eccrine sweat using a novel liquid chromatography-tandem mass spectrometry (LC-MS/MS) method. Cortisol and metabolite production (change in concentration over time) was measured in sweat at different time points during an administered exercise stress session with four healthy volunteers. Biomarker production plots were found to be highly individualized and sensitive to stress interventions such as exercise, and corresponded with stress response measures such as increases in heart rate. The LC-MS/MS method yielded baseline resolution between cortisol and cortisol metabolites with lower levels of detection and quantitation for each compound below 1 partper- billion (ppb). Cortisol and cortisol metabolites were found at concentrations ranging from 1 - 25 ppb in human eccrine sweat. They were also found to be stable in sweat with respect to temperature (37 C for up to 5 hours), pH (3- 9) and freeze/thaw cycles (up to 4) This indicates that changes in these biomarker concentrations and their rate of production are due to stress-related physiological enzyme activation, rather than passive degradation in sweat. The physiological status of enzyme activation is thus captured and preserved in human eccrine sweat samples. This is advantageous for the development of wearable devices and methodologies which can assess human health, stress, wellbeing and performance.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@inproceedings{russakovsky_Best_2015,
  title = {Best of {{Both Worlds}}: {{Human-Machine Collaboration}} for {{Object Annotation}}},
  shorttitle = {Best of {{Both Worlds}}},
  booktitle = {Proc. {{IEEE Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}.},
  author = {Russakovsky, Olga and Li, Li-Jia and Fei-Fei, Li},
  date = {2015},
  pages = {2121--2131},
  url = {https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Russakovsky_Best_of_Both_2015_CVPR_paper.html},
  urldate = {2022-12-28},
  eventtitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/PGJA5R3I/Russakovsky et al. - 2015 - Best of Both Worlds Human-Machine Collaboration f.pdf}
}

@inproceedings{russakovsky_Best_2015a,
  title = {Best of {{Both Worlds}}: {{Humanmachine Collaboration}} for {{Object Annotation}},},
  booktitle = {Proc. {{CVPR}}},
  author = {Russakovsky, O. and Li, L.-J. and Fei-Fei, L.},
  date = {2015},
  pages = {2121--2131},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{ruzzier_Relationship_2015,
  title = {On the {{Relationship Between Firm Size}}, {{Resources}}, {{Age}} at {{Entry}} and {{Internationalization}}: {{The Case}} of {{Slovenian SMEs}}},
  author = {Ruzzier, Mitja and Ruzzier, Maja Konecnik},
  date = {2015-01},
  journaltitle = {J. Bus. Econ. Manage.},
  volume = {16},
  number = {1},
  pages = {52--73},
  publisher = {{Taylor \& Francis}},
  doi = {10.3846/16111699.2012.745812},
  abstract = {AbstractExport marketing and international business literature support the view that firm size?a reflection of number of employees, and sales?is positively related to export intensity and is a distinguishing factor between internationalized and non-internationalized firms. According to the resource-based view heterogeneous resource profiles that enable firms to achieve competitive advantage in international markets may be also such differentiating factors. On the other hand, as a result of the process of globalization and the increasing number of born global firms, firm age at entry into foreign markets is becoming negatively related to internationalization. Our findings just partly confirm the trends above. Using a regression model on the selected sample of 247 Slovenian small and medium enterprises, we have confirmed the hypotheses that internationalized companies are significantly larger (in terms of sales) and have more specialized resources (human, organizational, and financial resources) than non-internationalized companies. Organizational and human resources and the number of employees were positively and significantly related, while the age of companies at the start of their international activities was negatively related, to the extent of companies? internationalization. Different implications and conclusions for researchers and entrepreneurs are derived.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{saad_ProbExplorer_,
  title = {{{ProbExplorer}}: {{Uncertainty-Guided Exploration}} and {{Editing}} of {{Probabilistic Medical Image Segmentation}}},
  author = {Saad, Ahmed and M\"oller, Torsten and Hamarneh, Ghassan},
  doi = {10.1111/j.1467-8659.2009.01691.x},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{saalmann_Intralaminar_2014,
  title = {Intralaminar and {{Medial Thalamic Influence}} on {{Cortical Synchrony}}, {{Information Transmission}} and {{Cognition}}},
  author = {Saalmann, Yuri B.},
  date = {2014-05-09},
  journaltitle = {Front. Syst. Neurosci.},
  volume = {8},
  issn = {1662-5137},
  doi = {10.3389/fnsys.2014.00083},
  url = {http://journal.frontiersin.org/article/10.3389/fnsys.2014.00083/abstract},
  urldate = {2023-05-08},
  keywords = {\#nosource,⛔ No INSPIRE recid found,anesthesia,attention,mediodorsal nucleus,memory},
  annotation = {241 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/B485TN9K/Saalmann - 2014 - Intralaminar and medial thalamic influence on cort.pdf}
}

@article{sabuncu_Generative_2010,
  title = {A {{Generative Model}} for {{Image Segmentation Based}} on {{Label Fusion}}},
  author = {Sabuncu, Mert R and Yeo, B T Thomas and Van Leemput, K and Fischl, Bruce and Golland, Polina},
  date = {2010-10},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {29},
  number = {10},
  pages = {1714--1729},
  issn = {0278-0062, 1558-254X},
  doi = {10.1109/TMI.2010.2050897},
  url = {http://ieeexplore.ieee.org/document/5487420/},
  urldate = {2023-05-08},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {503 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/75JT85NY/Sabuncu et al. - 2010 - A Generative Model for Image Segmentation Based on.pdf}
}

@article{sabuncu_Imagedriven_2009,
  title = {Image-{{Driven Population Analysis Through Mixture Modeling}}},
  author = {Sabuncu, Mert R. and Balci, Serdar K. and Shenton, Martha E. and Golland, Polina},
  date = {2009-09},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {28},
  number = {9},
  pages = {1473--1487},
  doi = {10.1109/TMI.2009.2017942},
  abstract = {We present iCluster, a fast and efficient algorithm that clusters a set of images while co-registering them using a parameterized, nonlinear transformation model. The output of the algorithm is a small number of template images that represent different modes in a population. This is in contrast with traditional, hypothesis-driven computational anatomy approaches that assume a single template to construct an atlas. We derive the algorithm based on a generative model of an image population as a mixture of deformable template images. We validate and explore our method in four experiments. In the first experiment, we use synthetic data to explore the behavior of the algorithm and inform a design choice on parameter settings. In the second experiment, we demonstrate the utility of having multiple atlases for the application of localizing temporal lobe brain structures in a pool of subjects that contains healthy controls and schizophrenia patients. Next, we employ iCluster to partition a data set of 415 whole brain MR volumes of subjects aged 18 through 96 years into three anatomical subgroups. Our analysis suggests that these subgroups mainly correspond to age groups. The templates reveal significant structural differences across these age groups that confirm previous findings in aging research. In the final experiment, we run iCluster on a group of 15 patients with dementia and 15 age-matched healthy controls. The algorithm produces two modes, one of which contains dementia patients only. These results suggest that the algorithm can be used to discover subpopulations that correspond to interesting structural or functional ``modes.''},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {92 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@thesis{sachan_Literate_2019,
  title = {Towards {{Literate Artificial Intelligence}}},
  author = {Sachan, Mrinmaya},
  date = {2019},
  journaltitle = {Carnegie Mellon University},
  institution = {{Carnegie Mellon University}},
  url = {https://pdfs.semanticscholar.org/25c5/6f52c528112da99d0ae7e559500ef7532d3a.pdf},
  abstract = {Standardized tests are often used to test students as they progress in the formal education system. These tests are widely available and measurable with clear evaluation procedures and metrics. Hence, these can serve as good tests for AI. We propose approaches for solving some of these tests. We broadly categorize these tests into two categories: open domain question answering tests such as reading comprehensions and elementary school science tests, and closed domain question answering tests such as intermediate or advanced math and science tests. We present alignment based approach with multi-task learning for the former. For closed domain tests, we propose a parsing to programs approach which can be seen as a natural language interface to expert systems. We also describe approaches for question generation based on instructional material in both open domain as well as closed domain settings. Finally, we show that we can improve both the question answering and question generation models by learning them jointly. This mechanism also allows us to leverage cheap unlabelled data for learning the two models. Our work can be easily applied for the social good in the education domain. We perform studies on human subjects who found our approaches useful as assistive tools in education.},
  issue = {June},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{salahieh_Direct_2015,
  title = {Direct {{Superresolution}} for {{Realistic Image Reconstruction}}},
  author = {Salahieh, Basel and Rodriguez, Jeffrey J. and Liang, Rongguang},
  date = {2015},
  journaltitle = {Opt. Express},
  issn = {1094-4087},
  doi = {10.1364/oe.23.026124},
  abstract = {Traditional superresolution techniques employ optimizers, priors, and regularizers to deliver stable, appealing restorations even though deviating from the real, ground-truth scene. We have developed a non-regularized superresolution algorithm that directly solves a fully-characterized multi-shift imaging reconstruction problem to achieve realistic restorations without being penalized by improper assumptions made in the inverse problem. An adaptive frequency-based filtering scheme is introduced to upper bound the reconstruction errors while still producing more fine details as compared with previous methods when inaccurate shift estimation, noise, and blurring scenarios are considered.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{salimans_Improved_2016,
  title = {Improved {{Techniques}} for {{Training GANs}}},
  booktitle = {Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.},
  author = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
  date = {2016},
  issn = {10495258},
  abstract = {We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21.3\%. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{salvador_Uncertainty_2021,
  title = {Uncertainty for {{Deep Image Classifiers}} on {{Out}} of {{Distribution Data}}.},
  author = {Salvador, Tiago and Iannantuono, Alexander and Oberman, Adam M.},
  date = {2021-03-05},
  url = {https://openreview.net/forum?id=JzG0n48hRf},
  urldate = {2022-07-04},
  abstract = {In addition to  achieving high accuracy, in many applications, it is important to  estimate the probability that a model prediction is correct. Predictive uncertainty is particularly important on...},
  langid = {english},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/UE2KFIXT/Salvador et al. - 2021 - Uncertainty for deep image classifiers on out of d.pdf;/Users/personal-macbook/Zotero/storage/HPXJ6CEV/forum.html}
}

@article{sapiro_Reconstruction_2010,
  title = {Reconstruction of the {{Orientation Distribution Function}} in {{Single-and Multiple-Shell Q-Ball Imaging Within Constant Solid Angle}}},
  author = {Sapiro, G. and Yacoub, E. and Ugurbil, K. and Harel, N.},
  date = {2010},
  journaltitle = {Magnetic},
  publisher = {{Wiley Online Library}},
  abstract = {Abstract q-Ball imaging is a high-angular-resolution diffusion imaging technique that has been proven very successful in resolving multiple intravoxel fiber orientations in MR images. The standard computation of the orientation distribution function (the probability of diffusion in a given direction) from q-ball data uses linear radial projection, neglecting the change in the volume element along each direction. This results in spherical distributions that are different from the true orientation distribution functions. For instance, they are neither \dbend},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{saranathan_Optimization_2015,
  title = {Optimization of {{White-Matter-Nulled Magnetization Prepared Rapid Gradient Echo}} ({{MP-RAGE}}) {{Imaging}}: {{Optimization}} of {{White-Matter-Nulled MP-RAGE Imaging}}},
  shorttitle = {Optimization of {{White-Matter-Nulled Magnetization Prepared Rapid Gradient Echo}} (Mp-{{Rage}}) {{Imaging}}},
  author = {Saranathan, Manojkumar and Tourdias, Thomas and Bayram, Ersin and Ghanouni, Pejman and Rutt, Brian K.},
  date = {2015-05},
  journaltitle = {Magn. Reson. Med},
  volume = {73},
  number = {5},
  pages = {1786--1794},
  issn = {07403194},
  doi = {10.1002/mrm.25298},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/mrm.25298},
  urldate = {2023-05-28},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {39 citations (Semantic Scholar/DOI) [2023-05-28]},
  file = {/Users/personal-macbook/Zotero/storage/6ZQF24LA/Saranathan et al. - 2015 - Optimization of white-matter-nulled magnetization .pdf}
}

@article{sassine_Positive_1975,
  title = {Positive {{Inotropic Effect}} of {{Insulin}} on {{Rabbit Auricle}} in {{Vitro}}},
  author = {Sassine, A. and Bourgeois, J. M. and Macabies, J.},
  date = {1975-12},
  journaltitle = {Arch Int Pharmacodyn Ther},
  volume = {218},
  number = {2},
  eprint = {2125},
  eprinttype = {pmid},
  pages = {196--201},
  issn = {0003-9780},
  abstract = {Water soluble pig insulin (4 x 10(-8) to 4 x 10(-7) g/ml) produced a marked and long-lasting increase in the contractile force of the rabbit auricle in vitro. Once the maximum effect for a given insulin concentration had been reached, addition of more insulin did not produce any further increase in inotropic effect. Insulin was without effect in reserpinized animals. Inhibition of cardiac beta-receptors by propranolol suppressed the positive inotropic effect of insulin. These findings support the hypothesis that insulin releases catecholamines from the myocardium.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Adrenergic beta-Antagonists,Animals,In Vitro Techniques,Insulin,Myocardial Contraction,Propranolol,Rabbits,Reserpine,{Stimulation, Chemical},Swine,Time Factors}
}

@article{sato_Biology_1989,
  title = {Biology of {{Sweat Glands}} and {{Their Disorders}}. {{I}}. {{Normal Sweat Gland Function}}},
  author = {Sato, K. and Kang, W. H. and Saga, K. and Sato, K. T.},
  date = {1989},
  journaltitle = {J. Am. Acad. Dermatol.},
  eprint = {2654204},
  eprinttype = {pmid},
  issn = {01909622},
  doi = {10.1016/S0190-9622(89)70063-3},
  abstract = {The basic mechanisms of sweat gland function and an updated review of some relatively common disorders of sweat secretion, are presented. Although sweat secretion and ductal absorption are basically biophysical and biologic cellular processes, a detailed description of the basic biophysical principles of membrane transport has been avoided to make the discussion more readable. The cited references will, however, help those readers primarily interested in the basic details of sweat gland function. Part I of this article includes a discussion of morphologic characteristics, central and peripheral nervous control of sweat secretion, neurotransmitters, intracellular mediators and stimulus secretion coupling, Na-K-Cl cotransport model for the ionic mechanism of sweat secretion, ingredients of sweat, ductal function, the pathogenesis of abnormal sweat gland function in cystic fibrosis, and the discovery of the apoeccrine sweat gland. Part II, to be published in the May issue of the Journal, reviews reports of all those major disorders of hyperhidrosis and hypohidrosis that have appeared in the literature during the past 10 years. It is hoped that this review will serve as a resource for clinicians who encounter puzzling disorders of sweating in their patients, as well as for investigators who wish to obtain a quick update on sweat gland function. \textcopyright{} 1989, American Academy of Dermatology Inc. All rights reserved.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {700 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{sauder_Context_2019,
  title = {Context {{Prediction}} for {{Unsupervised Deep Learning}} on {{Point Clouds}}},
  author = {Sauder, Jonathan and Sievers, Bjarne},
  date = {2019},
  journaltitle = {ArXiv},
  abstract = {This work proposes a novel method for unsupervised learning on raw point cloud data in which a neural network is trained to predict the spatial relationship between two point cloud segments and representations that capture semantic properties of the point cloud are learned. Point clouds provide a flexible and natural representation usable in countless applications such as robotics or self-driving cars. Recently, deep neural networks operating on raw point cloud data have shown promising results on supervised learning tasks such as object classification and semantic segmentation. While massive point cloud datasets can be captured using modern scanning technology, manually labelling such large 3D point clouds for supervised learning tasks is a cumbersome process. This necessitates effective unsupervised learning methods that can produce representations such that downstream tasks require significantly fewer annotated samples. We propose a novel method for unsupervised learning on raw point cloud data in which a neural network is trained to predict the spatial relationship between two point cloud segments. While solving this task, representations that capture semantic properties of the point cloud are learned. Our method outperforms previous unsupervised learning approaches in downstream object classification and segmentation tasks and performs on par with fully supervised methods.},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/Y7JMQQAK/Sauder and Sievers - 2019 - Context Prediction for Unsupervised Deep Learning .pdf}
}

@article{scheiner_Object_2021,
  title = {Object {{Detection}} for {{Automotive Radar Point Clouds}} \textendash{} {{A Comparison}}},
  author = {Scheiner, Nicolas and Kraus, Florian and Appenrodt, Nils and Dickmann, J\"urgen and Sick, Bernhard},
  date = {2021-11-16},
  journaltitle = {AI Perspectives},
  volume = {3},
  number = {1},
  pages = {6},
  issn = {2523-398X},
  doi = {10.1186/s42467-021-00012-z},
  url = {https://doi.org/10.1186/s42467-021-00012-z},
  urldate = {2022-07-19},
  abstract = {Automotive radar perception is an integral part of automated driving systems. Radar sensors benefit from their excellent robustness against adverse weather conditions such as snow, fog, or heavy rain. Despite the fact that machine-learning-based object detection is traditionally a camera-based domain, vast progress has been made for lidar sensors, and radar is also catching up. Recently, several new techniques for using machine learning algorithms towards the correct detection and classification of moving road users in automotive radar data have been introduced. However, most of them have not been compared to other methods or require next generation radar sensors which are far more advanced than current conventional automotive sensors. This article makes a thorough comparison of existing and novel radar object detection algorithms with some of the most successful candidates from the image and lidar domain. All experiments are conducted using a conventional automotive radar system. In addition to introducing all architectures, special attention is paid to the necessary point cloud preprocessing for all methods. By assessing all methods on a large and open real world data set, this evaluation provides the first representative algorithm comparison in this domain and outlines future research directions.},
  keywords = {⛔ No INSPIRE recid found,Automated driving,Automotive radar,Object detection,Vehicular perception},
  annotation = {4 citations (Semantic Scholar/DOI) [2022-07-20]},
  file = {/Users/personal-macbook/Zotero/storage/R6HGPVYP/Scheiner et al. - 2021 - Object detection for automotive radar point clouds.pdf;/Users/personal-macbook/Zotero/storage/5ZRERW8R/s42467-021-00012-z.html}
}

@article{schmidt_Disambiguating_2012,
  title = {Disambiguating the {{Similar}}: {{The Dentate Gyrus}} and {{Pattern Separation}}},
  author = {Schmidt, Brandy and Marrone, Diano F. and Markus, Etan J.},
  date = {2012-01},
  journaltitle = {Behav. Brain Res.},
  volume = {226},
  number = {1},
  pages = {56--65},
  doi = {10.1016/j.bbr.2011.08.039},
  abstract = {The human hippocampus supports the formation of episodic memory without confusing new memories with old ones. To accomplish this, the brain must disambiguate memories (i.e., accentuate the differences between experiences). There is convergent evidence linking pattern separation to the dentate gyrus. Damage to the dentate gyrus reduces an organism's ability to differentiate between similar objects. The dentate gyrus has tenfold more principle cells than its cortical input, allowing for a divergence in information flow. Dentate gyrus granule neurons also show a very different pattern of representing the environment than ``classic'' place cells in CA1 and CA3, or grid cells in the entorhinal cortex. More recently immediate early genes have been used to ``timestamp'' activity of individual cells throughout the dentate gyrus. These data indicate that the dentate gyrus robustly differentiates similar situations. The degree of differentiation is non-linear, with even small changes in input inducing a near maximal response in the dentate. Furthermore this differentiation occurs throughout the dentate gyrus longitudinal (dorsal-ventral) axis. Conversely, the data point to a divergence in information processing between the dentate gyrus suprapyramidal and infrapyramidal blades possibly related to differences in organization within these regions. The accumulated evidence from different approaches converges to support a role for the dentate gyrus in pattern separation. There are however inconsistencies that may require incorporation of neurogenesis and hippocampal microcircuits into the currents models. They also suggest different roles for the dentate gyrus suprapyramidal and infrapyramidal blades, and the responsiveness of CA3 to dentate input.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {173 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{schmoldt_Digitoxin_1975,
  title = {Digitoxin {{Metabolism}} by {{Rat Liver Microsomes}}},
  author = {Schmoldt, A. and Benthe, H. F. and Haberland, G.},
  date = {1975-09-01},
  journaltitle = {Biochem Pharmacol},
  volume = {24},
  number = {17},
  eprint = {10},
  eprinttype = {pmid},
  pages = {1639--1641},
  issn = {1873-2968},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Animals,{Chromatography, Thin Layer},Digitoxigenin,Digitoxin,Hydroxylation,In Vitro Techniques,Male,{Microsomes, Liver},NADP,Rats,Time Factors}
}

@article{schneider_Rethinking_2020,
  title = {Rethinking {{Drug Design}} in the {{Artificial Intelligence Era}}},
  author = {Schneider, Petra and Walters, W. Patrick and Plowright, Alleyn T. and Sieroka, Norman and Listgarten, Jennifer and Goodnow, Robert A. and Fisher, Jasmin and Jansen, Johanna M. and Duca, Jos\'e S. and Rush, Thomas S. and Zentgraf, Matthias and Hill, John Edward and Krutoholow, Elizabeth and Kohler, Matthias and Blaney, Jeff and Funatsu, Kimito and Luebkemann, Chris and Schneider, Gisbert},
  date = {2020},
  journaltitle = {Nat. Rev. Drug Discov.},
  eprint = {31801986},
  eprinttype = {pmid},
  issn = {14741784},
  doi = {10.1038/s41573-019-0050-3},
  abstract = {Artificial intelligence (AI) tools are increasingly being applied in drug discovery. While some protagonists point to vast opportunities potentially offered by such tools, others remain sceptical, waiting for a clear impact to be shown in drug discovery projects. The reality is probably somewhere in-between these extremes, yet it is clear that AI is providing new challenges not only for the scientists involved but also for the biopharma industry and its established processes for discovering and developing new medicines. This article presents the views of a diverse group of international experts on the `grand challenges' in small-molecule drug discovery with AI and the approaches to address them.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Computational chemistry,Drug development,Drug screening,Drug therapy,Small molecules}
}

@report{schroeder_National_2018,
  title = {National {{Survey}} on {{Distracted Driving Attitudes}} and {{Behaviors-2015}}},
  author = {Schroeder, Paul and Wilbur, Melanie and Pe\~na, Reyna},
  date = {2018},
  number = {DOT HS 812 461},
  institution = {{United States. National Highway Traffic Safety Administration}},
  location = {{Washington, DC}},
  url = {https://www.nhtsa.gov/sites/nhtsa.gov/files/documents/13123-2015_natl_survey_distracted_driving_031418_v5_tag.pdf},
  urldate = {2023-11-01},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/8ZWATR9V/Schroeder et al. - 2018 - National Survey on Distracted Driving Attitudes an.pdf}
}

@article{schultz_Segmenting_2011,
  title = {Segmenting {{Thalamic Nuclei}}: {{What Can We Gain From Hardi}}?},
  author = {Schultz, Thomas},
  date = {2011},
  journaltitle = {Med. Image Comput. Comput. Assist. Interv.},
  volume = {14},
  pages = {141--148},
  abstract = {The contrast provided by diffusion MRI has been exploited repeatedly for in vivo segmentations of thalamic nuclei. This paper systematically investigates the benefits of high-angular resolution (HARDI) data for this purpose. An empirical analysis of clustering stability reveals a clear advantage of acquiring HARDI data at b = 1000 s/mm2. However, based on stability arguments, as well as further visual and statistical evidence and theoretical insights about the impact of parameters, HARDI models such as the q-ball do not exhibit clear benefits over the standard diffusion tensor for thalamus segmentation at this b value.},
  issue = {Pt 2},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{seedat_MCUNet_2020,
  title = {{{McU-Net}}: {{A Framework Towards Uncertainty Representations}} for {{Decision Support System Patient Referrals}} in {{Healthcare Contexts}}},
  author = {Seedat, Nabeel},
  date = {2020-07},
  url = {https://arxiv.org/abs/2007.03995},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found},
  annotation = {2 citations (Semantic Scholar/arXiv) [2023-05-08]}
}

@inproceedings{sekuboyina_RelationalLearning_2021,
  title = {A {{Relational-Learning Perspective}} to {{Multi-Label Chest X-Ray Classification}}},
  booktitle = {18th {{Int}}. {{Symp}}. {{Biomed}}. {{Imaging ISBI}}},
  author = {Sekuboyina, Anjany and Onoro-Rubio, Daniel and Kleesiek, Jens and Malone, Brandon},
  date = {2021-04-13},
  pages = {1618--1622},
  publisher = {{IEEE}},
  location = {{Nice, France}},
  doi = {10.1109/ISBI48211.2021.9433786},
  url = {https://ieeexplore.ieee.org/document/9433786/},
  urldate = {2022-11-21},
  eventtitle = {18th {{International Symposium}} on {{Biomedical Imaging}} ({{ISBI}})},
  isbn = {978-1-66541-246-9},
  keywords = {⛔ No INSPIRE recid found,Annotations,Biomedical imaging,chest,knowledge graph,multi-label classification,radiographs,Radiography,relational learning,Uncertainty,X-ray imaging},
  annotation = {1 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/3BQZTWEL/Sekuboyina et al. - 2021 - A Relational-Learning Perspective To Multi-Label C.pdf;/Users/personal-macbook/Zotero/storage/P8M8URH2/Sekuboyina et al. - 2021 - A Relational-Learning Perspective To Multi-Label C.pdf;/Users/personal-macbook/Zotero/storage/5YQS4GA4/Sekuboyina et al. - 2021 - A Relational-Learning Perspective To Multi-Label C.html}
}

@article{sengupta_Application_2020,
  title = {Application of {{Deep Learning}} in {{Fundus Image Processing}} for {{Ophthalmic Diagnosis}} -- {{A Review}}},
  author = {Sengupta, Sourya and Singh, Amitojdeep and Leopold, Henry A. and Gulati, Tanmay and Lakshminarayanan, Vasudevan},
  date = {2020-01},
  journaltitle = {Artificial Intelligence in Medicine},
  volume = {102},
  eprint = {1812.07101},
  eprinttype = {arxiv},
  pages = {101758},
  issn = {09333657},
  doi = {10.1016/j.artmed.2019.101758},
  url = {http://arxiv.org/abs/1812.07101},
  urldate = {2021-11-05},
  abstract = {An overview of the applications of deep learning in ophthalmic diagnosis using retinal fundus images is presented. We also review various retinal image datasets that can be used for deep learning purposes. Applications of deep learning for segmentation of optic disk, blood vessels and retinal layer as well as detection of lesions are reviewed. Recent deep learning models for classification of diseases such as age-related macular degeneration, glaucoma,diabetic macular edema and diabetic retinopathy are also reported.},
  keywords = {⛔ No INSPIRE recid found,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  annotation = {37 citations (Semantic Scholar/arXiv) [2023-05-08] 73 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/CARV5KN3/Sengupta et al. - 2020 - Application of Deep Learning in Fundus Image Proce.pdf}
}

@article{seo_Flexible_2017,
  title = {Flexible {{Patch-Type Hydrochromic Polydiacetylene Sensor}} for {{Human Sweat Pore Mapping}}},
  author = {Seo, Minjeong and Park, Dong Hoon and Park, Bum Jun and Kim, Jong Man},
  date = {2017},
  journaltitle = {J. Appl. Polym. Sci.},
  issn = {10974628},
  doi = {10.1002/app.44419},
  abstract = {Owing to their stimulus-responsive colorimetric property, polydiacetylenes (PDAs) have been extensively investigated in the context of sensor applications. Incorporation of PDAs in matrix polymers can be utilized to add additional advantageous features into these sensors, like processability, mechanical flexibility, and mass production capability. In the current investigation, a new type of hydrochromic PDA sensor, which consists of a polydiacetylene-polyethylene oxide (PDA-PEO) composite film, was developed. The results of the study demonstrate that the hydrochromic film, which displays a blue-to-red color transition upon hydration, can be used to map human sweat secreting pores. The hygroscopic PEO component of the system enables local sweat to penetrate into the sensor film. The highly {$\pi$}-conjugated, imidazolium group containing PDA in the system functions as the hydrochromic material, which undergoes a blue-to-red transition and a corresponding fluorescence turn-on in response to contact with a nanoliter of sweat. In response to deposition of a fingerprint, water arising from individual sweat secreting pores promotes a change that leads to formation of a discrete fluorescence microdot pattern. The most important feature of the new sensor film is mechanical flexibility that gives it with the ability to be utilized to map sweat pores located on highly curved skin surfaces, such as those found on palms, soles, backs, and faces. Accordingly, this attribute offers critical advantages in cosmetics and biomedical applications because it enables recognition of active and inactive sweat pores on curved skin surfaces where rigid or paper-type sweat pore sensors are ineffective. \textcopyright{} 2016 Wiley Periodicals, Inc. J. Appl. Polym. Sci. 2017, 134, 44419.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,films,hydrochromic sensor,polydiacetylene,self-assembly,sweat pore mapping},
  annotation = {8 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{seyyed-kalantari_CheXclusion_2020,
  ids = {_CheXclusion_},
  title = {{{CheXclusion}}: {{Fairness Gaps}} in {{Deep Chest X-Ray Classifiers}}},
  shorttitle = {Chexclusion},
  booktitle = {Biocomput. 2021},
  author = {Seyyed-Kalantari, Laleh and Liu, Guanxiong and McDermott, Matthew and Chen, Irene Y. and Ghassemi, Marzyeh},
  date = {2020-11},
  pages = {232--243},
  publisher = {{WORLD SCIENTIFIC}},
  location = {{Kohala Coast, Hawaii, USA}},
  doi = {10.1142/9789811232701_0022},
  url = {https://www.worldscientific.com/doi/abs/10.1142/9789811232701_0022},
  urldate = {2023-05-09},
  eventtitle = {Pacific {{Symposium}} on {{Biocomputing}} 2021},
  isbn = {9789811232695 9789811232701},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {149 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/VZQ2MKFZ/Seyyed-Kalantari et al. - 2020 - CheXclusion Fairness gaps in deep chest X-ray cla.pdf;/Users/personal-macbook/Zotero/storage/KSCVHUMW/9789811232701_0022.html}
}

@thesis{shahri_APPLICATIONS_2015,
  title = {Applications of {{Machine Learning}} in {{Biology}} and {{Medicine}}},
  author = {Shahri, Saied Haidarian},
  date = {2015},
  journaltitle = {Wayne State University},
  institution = {{Wayne State University}},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{shakeri_Subcortical_2016,
  ids = {shakeri_subcorticalbrainstructuresegmentationusingfcnn_2016},
  title = {Sub-{{Cortical Brain Structure Segmentation Using F-CNN}}'s},
  booktitle = {2016 {{IEEE}} 13th {{Int}}. {{Symp}}. {{Biomed}}. {{Imaging ISBI}}},
  author = {Shakeri, Mahsa and Tsogkas, Stavros and Ferrante, Enzo and Lippe, Sarah and Kadoury, Samuel and Paragios, Nikos and Kokkinos, Iasonas},
  date = {2016-04},
  pages = {269--272},
  publisher = {{IEEE}},
  location = {{Prague}},
  doi = {10.1109/ISBI.2016.7493261},
  url = {https://ieeexplore.ieee.org/document/7493261/},
  urldate = {2023-05-12},
  eventtitle = {2016 {{IEEE}} 13th {{International Symposium}} on {{Biomedical Imaging}} ({{ISBI}})},
  isbn = {978-1-4799-2349-6},
  keywords = {\#nosource,⛔ No INSPIRE recid found,biomedical MRI,brain,Convolutional neural networks,image segmentation,Index Terms-Convolutional neural networks,Magnetic Resonance Imaging,Markov pro,Markov Random Fields,seman-tic segmentation,semantic segmentation,sub-cortical struc-tures,sub-cortical structures,thalamus},
  annotation = {112 citations (Semantic Scholar/DOI) [2023-05-12]},
  file = {/Users/personal-macbook/Zotero/storage/HEQX89P2/Shakeri et al. - 2016 - Sub-cortical brain structure segmentation using F-.pdf}
}

@article{shane_Promise_2007,
  title = {The {{Promise}} of {{Entrepreneurship}} as a {{Field}} of {{Research}}},
  author = {Shane, Scott and Venkataraman, Sankaran},
  date = {2007},
  journaltitle = {Entrep. Concepts Theory Perspect.},
  doi = {10.1007/978-3-540-48543-8_8},
  abstract = {To date, the phenomenon of entrepreneurship has lacked a conceptual framework. In this note we draw upon previous research conducted in the different social science disciplines and applied fields of business to create a conceptual framework for the field. With this framework we explain a set of empirical phenomena and predict a set of outcomes not explained or predicted by conceptual frameworks already in existence in other fields. \textcopyright{} 2007 Springer-Verlag Berlin Heidelberg.},
  isbn = {9783540485421},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{shankar_Generalizing_2018,
  title = {Generalizing {{Across Domains}} via {{Cross-Gradient Training}}},
  booktitle = {6th {{Int}}. {{Conf}}. {{Learn}}. {{Represent}}. {{ICLR}} 2018 - {{Conf}}. {{Track Proc}}.},
  author = {Shankar, Shiv and Piratla, Vihari and Chakrabarti, Soumen and Chaudhuri, Siddhartha and Jyothi, Preethi and Sarawagi, Sunita},
  date = {2018},
  abstract = {We present CROSSGRAD, a method to use multi-domain training data to learn a classifier that generalizes to new domains. CROSSGRAD does not need an adaptation phase via labeled or unlabeled data, or domain features in the new domain. Most existing domain adaptation methods attempt to erase domain signals using techniques like domain adversarial training. In contrast, CROSSGRAD is free to use domain signals for predicting labels, if it can prevent overfitting on training domains. We conceptualize the task in a Bayesian setting, in which a sampling step is implemented as data augmentation, based on domain-guided perturbations of input instances. CROSSGRAD parallelly trains a label and a domain classifier on examples perturbed by loss gradients of each other's objectives. This enables us to directly perturb inputs, without separating and re-mixing domain signals while making various distributional assumptions. Empirical evaluation on three different applications where this setting is natural establishes that (1) domain-guided perturbation provides consistently better generalization to unseen domains, compared to generic instance perturbation methods, and that (2) data augmentation is a more stable and accurate method than domain adversarial training.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{share_Review_1976,
  title = {Review of {{Drug Treatment}} for {{Down}}'s {{Syndrome Persons}}},
  author = {Share, J. B.},
  date = {1976-01},
  journaltitle = {Am J Ment Defic},
  volume = {80},
  number = {4},
  eprint = {2011},
  eprinttype = {pmid},
  pages = {388--393},
  issn = {0002-9351},
  abstract = {A review of drug treatment for Down's syndrome individuals was presented. Drugs used to modify behavior, as well as drugs used with the goal of affecting cognitive processes, were discussed. Some observations were offered as to the effectiveness of past and current drugs on Down's syndrome and some methodological problems relating to drug studies presented. There have not been any drugs that have demonstrated remarkable improvement in the status of Down's syndrome individuals that have been widely accepted as effective.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,5-Hydroxytryptophan,Amphetamines,Antipsychotic Agents,Behavior,Cell Transplantation,Cognition,Down Syndrome,Drug Evaluation,Enzyme Therapy,Glutamates,Humans,Minerals,Phenothiazines,Pituitary Hormones,Psychotropic Drugs,Research Design,Serotonin,Thyroid Hormones,Vitamins}
}

@article{sharifi_Deep_2021,
  ids = {sharifi_Deep_2021a},
  title = {Deep {{Learning}} on {{Ultrasound Images}} of {{Thyroid Nodules}}},
  author = {Sharifi, Yasaman and Bakhshali, Mohamad Amin and Dehghani, Toktam and DanaiAshgzari, Morteza and Sargolzaei, Mahdi and Eslami, Saeid},
  date = {2021-04-01},
  journaltitle = {Biocybernetics and Biomedical Engineering},
  volume = {41},
  number = {2},
  pages = {636--655},
  issn = {0208-5216},
  doi = {10.1016/j.bbe.2021.02.008},
  url = {https://www.sciencedirect.com/science/article/pii/S0208521621000152},
  urldate = {2022-05-16},
  abstract = {Due to safety, easy accessibility, noninvasively and cost-effectiveness of ultrasound imaging, this technology becomes one of the main contributors for analyzing thyroid nodules. However, interpretation of ultrasound images is a challenging task that subjects to the radiologist's prior medical knowledge and observational skills. There is a significant need for reliable, objective, and automated approaches for the meaningful assessment of ultrasound images. Many areas of machine learning including computer vision and image processing have been revolutionized by the recent advances in the field of deep learning. The current study systematically reviews the existing literatures and evaluates technical characteristics of the deep learning applications on the ultrasound images of thyroid nodules. In this review, all of the included studies have been published from 2017 to 2020 indicating the recent growing interest in the utilization of deep learning-based techniques for assessment of ultrasound images of thyroid nodules. Although deep learning has demonstrated potential for analyzing thyroid nodules' ultrasound images, this review highlights several existing barriers that need to be addressed in future works such as dealing with data limitation, generating public and valid datasets, and determining standard evaluation metrics. This survey outlines several methods (e.g., data augmentation and transfer learning) recently proposed to address similar challenges in other fields. Furthermore, to improve the diagnostic accuracy of the deep learning models, utilization of complementary information with multi-modal images are suggested. The protocol of this systematic review was registered in the PROSPERO database (CRD42020168346).},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Computer-assisted diagnosis,Deep learning,Medical diagnosis,Thyroid nodules,Ultrasonography},
  annotation = {10 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/5ZJR9C4U/Sharifi et al. - 2021 - Deep learning on ultrasound images of thyroid nodu.pdf;/Users/personal-macbook/Zotero/storage/HPQT4NEZ/Sharifi et al. - 2021 - Deep learning on ultrasound images of thyroid nodu.html}
}

@article{sharma_Internationalization_2003,
  title = {The {{Internationalization Process}} of {{Born Globals}}: {{A Network View}}},
  author = {Sharma, D. Deo and Blomstermo, Anders},
  date = {2003-12},
  journaltitle = {Int. Bus. Rev.},
  volume = {12},
  number = {6},
  pages = {739--753},
  doi = {10.1016/j.ibusrev.2003.05.002},
  abstract = {This paper attempts to make a contribution to the theory of development of the internationalization process of Born Globals. We propose that models emphasizing knowledge and networks are suitable for this purpose. The findings show that Born Globals possess international market knowledge before their first foreign market entry. The selection of foreign market entry mode is based on their existing knowledge and the knowledge supplied by their network ties.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Co-evolution,Reactive process,Referral}
}

@inproceedings{sheng_Get_2008,
  title = {Get {{Another Label}}? {{Improving Data Quality}} and {{Data Mining Using Multiple}}, {{Noisy Labelers}}},
  shorttitle = {Get {{Another Label}}?},
  booktitle = {Proc. 14th {{ACM SIGKDD Int}}. {{Conf}}. {{Knowl}}. {{Discov}}. {{Data Min}}.},
  author = {Sheng, Victor S. and Provost, Foster and Ipeirotis, Panagiotis G.},
  date = {2008},
  pages = {614--622},
  doi = {10.1145/1401890.1401965},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {1185 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/FJ96QHFU/Sheng et al. - 2008 - Get Another Label Improving Data Quality and Data.pdf}
}

@article{sheng_Majority_2019,
  title = {Majority {{Voting}} and {{Pairing With Multiple Noisy Labeling}}},
  author = {Sheng, Victor S. and Zhang, Jing and Gu, Bin and Wu, Xindong},
  date = {2019-07-01},
  journaltitle = {IEEE Trans. Knowl. Data Eng.},
  volume = {31},
  number = {7},
  pages = {1355--1368},
  issn = {1041-4347, 1558-2191, 2326-3865},
  doi = {10.1109/TKDE.2017.2659740},
  url = {https://ieeexplore.ieee.org/document/7835129/},
  urldate = {2022-12-28},
  keywords = {⛔ No INSPIRE recid found,classification,Crowdsourcing,Data models,data preprocessing,Labeling,Logistics,multiple noisy labels,Noise measurement,Training,Training data},
  annotation = {38 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/52AN3G8H/Sheng et al. - 2019 - Majority Voting and Pairing with Multiple Noisy La.pdf}
}

@book{sherman_Exploring_2001,
  title = {Exploring the {{Thalamus}}},
  author = {Sherman, S. Murray and Guillery, Ray W.},
  date = {2001-01},
  publisher = {{Elsevier}},
  abstract = {The thalamus is a group of cells placed centrally in the brain that serve a critical role in controlling how both sensory and motor signals are passed from one part of the cerebral cortex to another. Essentially, all information reaching the cerebral cortex and thus consciousness is relayed through the thalamus. The role of the thalamus in controlling the flow of information (such as visual, auditory, and motor) to the cortex has only recently begun to be understood. This book provides an in-depth look at the function of the thalamus and its role as relayer of information to the cerebral cortex. The authors explore how the thalamus controls messages that are passed to the cortex and they introduce the novel suggestion that the thalamus serves a critical role in controlling how messages pass from one part of the cortex to another. Exploring the Thalamus is a comprehensive, up-to-date reference for researchers. It discusses problems concerning the function and structure of the thalamus and concludes each chapter with thought-provoking questions regarding future research.Focuses on thalamocortical interrelationshipsDiscusses important problems concerning the function and structure of the thalamusConcludes each chapter with thought-provoking questions requiring future research},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{sheshadri_SQUARE_2013,
  title = {{{SQUARE}}: {{A Benchmark}} for {{Research}} on {{Computing Crowd Consensus}}},
  shorttitle = {{{SQUARE}}},
  author = {Sheshadri, Aashish and Lease, Matthew},
  date = {2013-11-03},
  journaltitle = {HCOMP},
  volume = {1},
  pages = {156--164},
  issn = {2769-1349, 2769-1330},
  doi = {10.1609/hcomp.v1i1.13088},
  url = {https://ojs.aaai.org/index.php/HCOMP/article/view/13088},
  urldate = {2022-12-28},
  abstract = {While many statistical consensus methods now exist, relatively little comparative benchmarking and integration of techniques has made it increasingly difficult to determine the current state-of-the-art, to evaluate the relative benefit of new methods, to understand where specific problems merit greater attention, and to measure field progress over time. To make such comparative evaluation easier for everyone, we present SQUARE, an open source shared task framework including benchmark datasets, defined tasks, standard metrics, and reference implementations with empirical results for several popular methods. In addition to measuring performance on a variety of public, real crowd datasets, the benchmark also varies supervision and noise by manipulating training size and labeling error. We envision SQUARE as dynamic and continually evolving, with new datasets and reference implementations being added according to community needs and interest. We invite community contributions and participation.},
  keywords = {⛔ No INSPIRE recid found,Aggregation,Benchmarking,Consensus,Crowdsourcing,Human Computation},
  annotation = {201 citations (Semantic Scholar/DOI) [2022-12-28]},
  file = {/Users/personal-macbook/Zotero/storage/99G9H6PX/Sheshadri and Lease - 2013 - SQUARE A Benchmark for Research on Computing Crow.pdf}
}

@article{shi_Hippocampal_2009,
  title = {Hippocampal {{Volume}} and {{Asymmetry}} in {{Mild Cognitive Impairment}} and {{Alzheimer}}'s {{Disease}}: {{Meta-Analyses}} of {{MRI Studies}}},
  author = {Shi, Feng and Liu, Bing and Zhou, Yuan and Yu, Chunshui and Jiang, Tianzi},
  date = {2009},
  journaltitle = {Hippocampus},
  volume = {19},
  number = {11},
  pages = {1055--1064},
  publisher = {{Wiley Online Library}},
  doi = {10.1002/hipo.20573},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {393 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{shin_Deep_2016,
  title = {Deep {{Convolutional Neural Networks}} for {{Computer-Aided Detection}}: {{CNN Architectures}}, {{Dataset Characteristics}} and {{Transfer Learning}}},
  author = {Shin, Hoo-Chang and Roth, Holger R. and Gao, Mingchen and Lu, Le and Xu, Ziyue and Nogues, Isabella and Yao, Jianhua and Mollura, Daniel and Summers, Ronald M.},
  date = {2016-05},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {35},
  number = {5},
  pages = {1285--1298},
  doi = {10.1109/TMI.2016.2528162},
  abstract = {Remarkable progress has been made in image recognition, primarily due to the availability of large-scale annotated datasets and deep convolutional neural networks (CNNs). CNNs enable learning data-driven, highly representative, hierarchical image features from sufficient training data. However, obtaining datasets as comprehensively annotated as ImageNet in the medical imaging domain remains a challenge. There are currently three major techniques that successfully employ CNNs to medical image classification: training the CNN from scratch, using off-the-shelf pre-trained CNN features, and conducting unsupervised CNN pre-training with supervised fine-tuning. Another effective method is transfer learning, i.e., fine-tuning CNN models pre-trained from natural image dataset to medical image tasks. In this paper, we exploit three important, but previously understudied factors of employing deep convolutional neural networks to computer-aided detection problems. We first explore and evaluate different CNN architectures. The studied models contain 5 thousand to 160 million parameters, and vary in numbers of layers. We then evaluate the influence of dataset scale and spatial image context on performance. Finally, we examine when and why transfer learning from pre-trained ImageNet (via fine-tuning) can be useful. We study two specific computer-aided detection (CADe) problems, namely thoraco-abdominal lymph node (LN) detection and interstitial lung disease (ILD) classification. We achieve the state-of-the-art performance on the mediastinal LN detection, and report the first five-fold cross-validation classification results on predicting axial CT slices with ILD categories. Our extensive empirical evaluation, CNN model analysis and valuable insights can be extended to the design of high performance CAD systems for other medical imaging tasks.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {753 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{shin_Learning_2016,
  title = {Learning to {{Read Chest X-Rays}}: {{Recurrent Neural Cascade Model}} for {{Automated Image Annotation}}},
  shorttitle = {Learning to {{Read Chest X-Rays}}},
  booktitle = {2016 {{IEEE Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}. {{CVPR}}},
  author = {Shin, Hoo-Chang and Roberts, Kirk and Lu, Le and Demner-Fushman, Dina and Yao, Jianhua and Summers, Ronald M},
  date = {2016-06},
  pages = {2497--2506},
  publisher = {{IEEE}},
  location = {{Las Vegas, NV, USA}},
  doi = {10.1109/CVPR.2016.274},
  url = {http://ieeexplore.ieee.org/document/7780643/},
  urldate = {2023-05-09},
  eventtitle = {2016 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-4673-8851-1},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {269 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/JU693ALU/Shin et al. - 2016 - Learning to Read Chest X-Rays Recurrent Neural Ca.pdf}
}

@inproceedings{shindjalova_Modeling_2014,
  title = {Modeling {{Data}} for {{Tilted Implants}} in {{Grafted With Bio-Oss Maxillary Sinuses Using Logistic Regression}}},
  author = {Shindjalova, R. and Prodanova, K. and Svechtarov, V.},
  date = {2014},
  pages = {58--62},
  location = {{Sozopol, Bulgaria}},
  doi = {10.1063/1.4902458},
  url = {http://aip.scitation.org/doi/abs/10.1063/1.4902458},
  urldate = {2023-01-11},
  eventtitle = {{{APPLICATIONS OF MATHEMATICS IN ENGINEERING AND ECONOMICS}} ({{AMEE}}'14)},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {37 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@online{shu_dirttapproachunsuperviseddomainadaptation_2018,
  ids = {shu_DIrtt_2018},
  title = {A {{DIRT-T Approach}} to {{Unsupervised Domain Adaptation}}},
  author = {Shu, Rui and Bui, Hung H. and Narui, Hirokazu and Ermon, Stefano},
  date = {2018},
  doi = {10.48550/ARXIV.1802.08735},
  url = {https://arxiv.org/abs/1802.08735},
  urldate = {2023-05-08},
  abstract = {Domain adaptation refers to the problem of leveraging labeled data in a source domain to learn an accurate model in a target domain where labels are scarce or unavailable. A recent approach for finding a common representation of the two domains is via domain adversarial training (Ganin \&amp; Lempitsky, 2015), which attempts to induce a feature extractor that matches the source and target feature distributions in some feature space. However, domain adversarial training faces two critical limitations: 1) if the feature extraction function has high-capacity, then feature distribution matching is a weak constraint, 2) in non-conservative domain adaptation (where no single classifier can perform well in both the source and target domains), training the model to do well on the source domain hurts performance on the target domain. In this paper, we address these issues through the lens of the cluster assumption, i.e., decision boundaries should not cross high-density data regions. We propose two novel and related models: 1) the Virtual Adversarial Domain Adaptation (VADA) model, which combines domain adversarial training with a penalty term that punishes the violation the cluster assumption; 2) the Decision-boundary Iterative Refinement Training with a Teacher (DIRT-T) model, which takes the VADA model as initialization and employs natural gradient steps to further minimize the cluster assumption violation. Extensive empirical results demonstrate that the combination of these two models significantly improve the state-of-the-art performance on the digit, traffic sign, and Wi-Fi recognition domain adaptation benchmarks.},
  pubstate = {preprint},
  version = {2},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,Machine Learning (cs.LG),Machine Learning (stat.ML)},
  annotation = {469 citations (Semantic Scholar/arXiv) [2023-05-08]}
}

@article{shuck_Personal_2002,
  title = {Personal {{Observations}} on the {{Cultural Evolution}} in {{Academic Surgery}}},
  author = {Shuck, Jerry M.},
  date = {2002-04},
  journaltitle = {Am. J. Surg.},
  volume = {183},
  number = {4},
  pages = {345--348},
  doi = {10.1016/S0002-9610(02)00814-0},
  abstract = {BACKGROUND: The changing environment in academic medical centers has had a major effect on the recruitment and the demographic characteristics of leadership positions in academic surgery. Categorization of ``cultures'' from the business model has been extrapolated into the academic surgical model. METHODS: The types of cultures in organizations according to Cameron and Quinnn at a school of management can be classified into four: clan culture, adhocracy culture, hierarchy, and market-driven culture. In addition, academic surgical chairmen were surveyed in 1981 and also 20 years later, 2001, by the author. This was done in an effort to determine whether there is a difference in the type of person being attracted to such positions and if there is demographic difference in academic chairmen over the two decades. RESULTS: The organizational profile of academic departments in 1980 is perceived to be more clan and adhocracy in type and less hierarchical and market driven. That has reversed itself dramatically two decades later with much of the energy of a department and structure based on hierarchy and the market. Also, in terms of the chairman, the mean age at the time of appointment in 1981 was 44 years and the mean age at time of appointment in 2001 was 49 years. In 1981 the years in grade was 9.4 years and in 201 it is 7.1 years. The new chairman is now older and will not serve as long as his/her predecessor. CONCLUSIONS: There clearly has been a cultural evolution in academic surgery over the past two decades. The chairman has different priorities than chairmen 20 years ago. The success of an academic department will depend upon the adaptation to this cultural evolution and the understanding of the chairman as to what the job really is.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{silberg_Tackling_2019,
  title = {Tackling {{Bias}} in {{Artificial Intelligence}} ({{And}} in {{Humans}}) {{McKinsey}}},
  author = {Silberg, Jake and Manyika, James},
  date = {2019},
  journaltitle = {Notes AI Front. Tackling Bias AI Hum.},
  abstract = {In order to avoid bias in artificial intelligence, fair and transparent decisions will be needed to build confidence in AI systems.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{silen_AcidBase_1975,
  title = {Acid-{{Base Balance}} in {{Amphibian Gastric Mucosa}}},
  author = {Silen, W. and Machen, T. E. and Forte, J. G.},
  date = {1975-09},
  journaltitle = {Am J Physiol},
  volume = {229},
  number = {3},
  eprint = {2015},
  eprinttype = {pmid},
  pages = {721--730},
  issn = {0002-9513},
  doi = {10.1152/ajplegacy.1975.229.3.721},
  abstract = {It has been established that H+ secretion can be maintained in frog stomach in the absence of exogenous CO2 by using a nutrient bathing fluid containing 25 mM H2PO4 (pH approximately equal to 4.5) or by lowering the pH of a nonbuffered nutrient solution to about 3.0-3.6. Exogenous CO2 in the presence of these nutrient solutions uniformly caused a marked decrease in H+ secretion, PD, adn short-circuit current (Isc) and an increase in transmucosal resistance (R). Elevation of nutrient [k+] to 83 mM reduced R significantly but transiently without change in H+ when nutrient pH less than 5.0, whereas R returned to base line and H+ increased when nutrient pH greater than 5.0. Acidification of the nutrient medium in the presence of exogenous CO2 results in inhibition of the secretory pump, probably by decreasing intracellular pH, and also interferes with conductance at the nutrient membrane. Removal of exogenous CO2 from standard bicarbonate nutrient solution reduced by 50\% the H+, PD, and Isc without change in R; K+-free nutrient solutions reverse these changes in Isc and PD but not in H+. The dropping PD and rising R induced by K+-free nutrient solutions in 5\% CO2 - 95\% O2 are returned toward normal by 100\% O2. Our findings support an important role for exogenous CO2 in maintaining normal acid-base balance in frog mucosa by acting as an acidifying agent.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Acid-Base Equilibrium,Animals,Anura,Bicarbonates,Carbon Dioxide,Electrophysiology,Gastric Mucosa,Hydrogen-Ion Concentration,Phosphates,Potassium,Rana catesbeiana,Solutions},
  annotation = {33 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{silva_Extensive_2021,
  title = {An {{Extensive Survey}} of {{Machine Learning Based Approaches}} on {{Automated Pathology Detection}} in {{Chest X-Rays}}},
  booktitle = {2021 28th {{Conf}}. {{Open Innov}}. {{Assoc}}. {{FRUCT}}},
  author = {Silva, Ravidu Suien Rammuni and Fernando, Pumudu},
  date = {2021-01},
  pages = {365--373},
  issn = {2305-7254},
  doi = {10.23919/FRUCT50888.2021.9347605},
  abstract = {Radiography is one of the most common and eminent medical imaging technologies in the world to date. Chest radiography is a very powerful and successful way of diagnosing thoracic diseases of humans. With the latest advancements and development in computer hardware, computer vision and especially with the publicly available large-scale datasets, machine learning based approaches on automated pathology detection in chest radiography have become increasingly popular among researchers. Our study conducts an extensive survey on existing machine learning approaches, its datasets and techniques on pathology detection in Chest X-Rays. The paper presents popular and publicly available labelled Chest X-Rays datasets with its specifications and discusses about the labellers, labelling methodologies used by them in a comprehensive discussion. Then, popular effective Image Processing techniques for Chest X-Rays images are presented. Then the paper further discusses about the current machine learning architectures used and portraits the effectiveness of Deep Convolutional Neural Networks for the purpose. Finally, the paper concludes with a discussion with gaps in current literature, unexplored areas and possible future with them in Machine Learning based automated pathology detection on Chest X-Rays.},
  eventtitle = {2021 28th {{Conference}} of {{Open Innovations Association}} ({{FRUCT}})},
  keywords = {⛔ No INSPIRE recid found,Diagnostic radiography,Labeling,Machine learning,Machine learning algorithms,Manuals,Pathology,X-rays},
  annotation = {2 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/NGVJL3QD/Silva and Fernando - 2021 - An Extensive Survey of Machine Learning Based Appr.pdf;/Users/personal-macbook/Zotero/storage/9BYBLM8U/9347605.html}
}

@article{silverstein_Most_2016,
  entrysubtype = {magazine},
  title = {Most of the {{World Doesn}}'t {{Have Access}} to {{X-Rays}}},
  author = {Silverstein, Jason},
  date = {2016-09-27T16:42:00Z},
  journaltitle = {The Atlantic},
  url = {https://www.theatlantic.com/health/archive/2016/09/radiology-gap/501803/},
  urldate = {2022-11-21},
  abstract = {One hospital in Boston has 126 radiologists. Liberia has two.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/2373ZXW4/501803.html;/Users/personal-macbook/Zotero/storage/WPUXYQLR/501803.html}
}

@online{simonyan_Very_2014,
  ids = {simonyan15},
  title = {Very {{Deep Convolutional Networks}} for {{Large-Scale Image Recognition}}},
  author = {Simonyan, Karen and Zisserman, Andrew},
  date = {2014},
  number = {1409.1556},
  eprint = {1409.1556},
  eprinttype = {arxiv},
  doi = {10.48550/ARXIV.1409.1556},
  url = {https://arxiv.org/abs/1409.1556},
  urldate = {2023-06-03},
  abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
  pubstate = {preprint},
  version = {6},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found,Computer Science - Computer Vision and Pattern Recognition,Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences},
  annotation = {9994 citations (Semantic Scholar/arXiv) [2023-06-02] 189 citations (INSPIRE 2023/6/2) 189 citations w/o self (INSPIRE 2023/6/2)},
  file = {/Users/personal-macbook/Zotero/storage/RDW3UQJI/Simonyan and Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.pdf;/Users/personal-macbook/Zotero/storage/PASQV49M/Simonyan and Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.html;/Users/personal-macbook/Zotero/storage/UVC4ZBDA/1409.html;/Users/personal-macbook/Zotero/storage/ZC5GMDXN/Simonyan and Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.html}
}

@online{simpson_largeannotatedmedicalimagedatasetdevelopmentevaluationsegmentationalgorithms_2019,
  ids = {simpson_Large_2019},
  title = {A {{Large Annotated Medical Image Dataset}} for the {{Development}} and {{Evaluation}} of {{Segmentation Algorithms}}},
  author = {Simpson, Amber L. and Antonelli, Michela and Bakas, Spyridon and Bilello, Michel and Farahani, Keyvan and family=Ginneken, given=Bram, prefix=van, useprefix=true and Kopp-Schneider, Annette and Landman, Bennett A. and Litjens, Geert and Menze, Bjoern and Ronneberger, Olaf and Summers, Ronald M. and Bilic, Patrick and Christ, Patrick F. and Do, Richard K. G. and Gollub, Marc and Golia-Pernicka, Jennifer and Heckers, Stephan H. and Jarnagin, William R. and McHugo, Maureen K. and Napel, Sandy and Vorontsov, Eugene and Maier-Hein, Lena and Cardoso, M. Jorge},
  date = {2019},
  doi = {10.48550/ARXIV.1902.09063},
  url = {https://arxiv.org/abs/1902.09063},
  urldate = {2023-05-08},
  abstract = {Semantic segmentation of medical images aims to associate a pixel with a label in a medical image without human initialization. The success of semantic segmentation algorithms is contingent on the availability of high-quality imaging data with corresponding labels provided by experts. We sought to create a large collection of annotated medical image datasets of various clinically relevant anatomies available under open source license to facilitate the development of semantic segmentation algorithms. Such a resource would allow: 1) objective assessment of general-purpose segmentation methods through comprehensive benchmarking and 2) open and free access to medical image data for any researcher interested in the problem domain. Through a multi-institutional effort, we generated a large, curated dataset representative of several highly variable segmentation tasks that was used in a crowd-sourced challenge - the Medical Segmentation Decathlon held during the 2018 Medical Image Computing and Computer Aided Interventions Conference in Granada, Spain. Here, we describe these ten labeled image datasets so that these data may be effectively reused by the research community.},
  pubstate = {preprint},
  version = {1},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,{FOS: Electrical engineering, electronic engineering, information engineering},Image and Video Processing (eess.IV)},
  annotation = {513 citations (Semantic Scholar/arXiv) [2023-05-08]}
}

@article{singhal_Review_2020,
  title = {A {{Review}} of {{Coronavirus Disease-2019}} ({{COVID-19}})},
  author = {Singhal, Tanu},
  date = {2020},
  journaltitle = {Indian J. Pediatr.},
  volume = {87},
  number = {4},
  eprint = {32166607},
  eprinttype = {pmid},
  pages = {281--286},
  publisher = {{The Indian Journal of Pediatrics}},
  issn = {09737693},
  doi = {10.1007/s12098-020-03263-6},
  abstract = {There is a new public health crises threatening the world with the emergence and spread of 2019 novel coronavirus (2019-nCoV) or the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The virus originated in bats and was transmitted to humans through yet unknown intermediary animals in Wuhan, Hubei province, China in December 2019. There have been around 96,000 reported cases of coronavirus disease 2019 (COVID-2019) and 3300 reported deaths to date (05/03/2020). The disease is transmitted by inhalation or contact with infected droplets and the incubation period ranges from 2 to 14 d. The symptoms are usually fever, cough, sore throat, breathlessness, fatigue, malaise among others. The disease is mild in most people; in some (usually the elderly and those with comorbidities), it may progress to pneumonia, acute respiratory distress syndrome (ARDS) and multi organ dysfunction. Many people are asymptomatic. The case fatality rate is estimated to range from 2 to 3\%. Diagnosis is by demonstration of the virus in respiratory secretions by special molecular tests. Common laboratory findings include normal/ low white cell counts with elevated C-reactive protein (CRP). The computerized tomographic chest scan is usually abnormal even in those with no symptoms or mild disease. Treatment is essentially supportive; role of antiviral agents is yet to be established. Prevention entails home isolation of suspected cases and those with mild illnesses and strict infection control measures at hospitals that include contact and droplet precautions. The virus spreads faster than its two ancestors the SARS-CoV and Middle East respiratory syndrome coronavirus (MERS-CoV), but has lower fatality. The global impact of this new epidemic is yet uncertain.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {2679 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{sinha_Certifying_2018,
  title = {Certifying {{Some Distributional Robustness With Principled Adversarial Training}}},
  booktitle = {6th {{Int}}. {{Conf}}. {{Learn}}. {{Represent}}.},
  author = {Sinha, Aman and Namkoong, Hongseok and Duchi, John and Volpi, Riccardo and Duchi, John},
  date = {2018-10},
  abstract = {Neural networks are vulnerable to adversarial examples and researchers have proposed many heuristic attack and defense mechanisms. We address this problem through the principled lens of distributionally robust optimization, which guarantees performance under adversarial input perturbations. By considering a Lagrangian penalty formulation of perturbing the underlying data distribution in a Wasserstein ball, we provide a training procedure that augments model parameter updates with worst-case perturbations of training data. For smooth losses, our procedure provably achieves moderate levels of robustness with little computational or statistical cost relative to empirical risk minimization. Furthermore, our statistical guarantees allow us to efficiently certify robustness for the population loss. For imperceptible perturbations, our method matches or outperforms heuristic approaches.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{small_Differential_1999,
  title = {Differential {{Regional Dysfunction}} of the {{Hippocampal Formation Among Elderly With Memory Decline}} and {{Alzheimer}}'s {{Disease}}},
  author = {Small, S. A. and Perera, G. M. and DeLaPaz, R. and Mayeux, R. and Stern, Y.},
  date = {1999-04},
  journaltitle = {Ann. Neurol.},
  volume = {45},
  number = {4},
  pages = {466--472},
  doi = {10.1002/1531-8249(199904)45:4<466::AID-ANA8>3.0.CO;2-Q},
  abstract = {The hippocampal formation is composed of separate anatomical regions interconnected to form a circuit, and investigating abnormal hippocampal function is most revealing at the level of these regions. Until recently, regional analysis of the hippocampal formation could be performed only in animals or in human postmortem tissue. Here, we report a method using functional magnetic resonance imaging that evaluates the hippocampal regions in vivo, and we use this method to study elderly with normal memory, with isolated memory decline, and with probable Alzheimer's disease (AD). Although age-related memory decline occurs commonly, the cause of this decline remains unknown, with disagreement as to whether this decline represents one or more etiologies. Analysis revealed two distinct patterns of regional dysfunction among elderly with isolated memory decline\textendash one pattern similar to that found in elders with AD, involving all hippocampal regions, and a second pattern with dysfunction restricted to only one hippocampal region, the subiculum. These results offer direct evidence of hippocampal dysfunction associated with memory decline in the elderly, and implicate both predementia AD and non-AD processes as possible underlying causes.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {334 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{small_Isolating_2014,
  title = {Isolating {{Pathogenic Mechanisms Embedded Within}} the {{Hippocampal Circuit Through Regional Vulnerability}}},
  author = {Small, Scott A.},
  date = {2014-10},
  journaltitle = {Neuron},
  volume = {84},
  number = {1},
  pages = {32--39},
  doi = {10.1016/j.neuron.2014.08.030},
  abstract = {Some of the most common and devastating disorders of the brain target the hippocampal formation. The hippocampal formation is a complex circuit of interconnected regions, and it is assumed that clues into the causes of these disorders are embedded within the circuit. Neuroimaging tools have been optimized to interrogate the malfunctioning hippocampal circuit, and by applying these tools to patients in the earliest stages of disease and to animal models, patterns of regional vulnerability have been established for Alzheimer's disease, schizophrenia, and cognitive aging. More recently, studies have begun deciphering the cellular and molecular reasons underlying regional dysfunction. Collectively, this information clarifies the pathophysiology of these disorders and informs on therapeutic strategies.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {42 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{small_Pathophysiological_2011,
  title = {A {{Pathophysiological Framework}} of {{Hippocampal Dysfunction}} in {{Ageing}} and {{Disease}}},
  author = {Small, Scott A. and Schobel, Scott A. and Buxton, Richard B. and Witter, Menno P. and Barnes, Carol A.},
  date = {2011-10},
  journaltitle = {Nat Rev Neurosci},
  volume = {12},
  number = {10},
  pages = {585--601},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/nrn3085},
  url = {http://www.nature.com/articles/nrn3085},
  urldate = {2023-05-08},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {767 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/5NQQFWTT/Small et al. - 2011 - A pathophysiological framework of hippocampal dysf.pdf}
}

@article{smith_Advances_2004,
  title = {Advances in {{Functional}} and {{Structural MR Image Analysis}} and {{Implementation}} as {{FSL}}},
  author = {Smith, Stephen M. and Jenkinson, Mark and Woolrich, Mark W. and Beckmann, Christian F. and Behrens, Timothy E. J. J. and Johansen-Berg, Heidi and Bannister, Peter R. and Luca, Marilena De and Drobnjak, Ivana and Flitney, David E. and Niazy, Rami K. and Saunders, James and Vickers, John and Zhang, Yongyue and Stefano, Nicola De and Brady, J. Michael and Matthews, Paul M. and Brady, J. Michael and Matthews, Paul M.},
  date = {2004-01},
  journaltitle = {NeuroImage},
  volume = {23},
  eprint = {15501092},
  eprinttype = {pmid},
  pages = {S208-S219},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2004.07.051},
  abstract = {The techniques available for the interrogation and analysis of neuroimaging data have a large influence in determining the flexibility, sensitivity, and scope of neuroimaging experiments. The development of such methodologies has allowed investigators to address scientific questions that could not previously be answered and, as such, has become an important research area in its own right. In this paper, we present a review of the research carried out by the Analysis Group at the Oxford Centre for Functional MRI of the Brain (FMRIB). This research has focussed on the development of new methodologies for the analysis of both structural and functional magnetic resonance imaging data. The majority of the research laid out in this paper has been implemented as freely available software tools within FMRIB's Software Library (FSL). \textcopyright{} 2004 Elsevier Inc. All rights reserved.},
  issue = {SUPPL. 1},
  keywords = {\#nosource,⛔ No INSPIRE recid found,FMRI,FSL,Structural MR image analysis},
  annotation = {9976 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{smith_Fast_2002,
  title = {Fast {{Robust Automated Brain Extraction}}},
  author = {Smith, Stephen M.},
  date = {2002-11},
  journaltitle = {Hum. Brain Mapp.},
  volume = {17},
  number = {3},
  pages = {143--155},
  doi = {10.1002/hbm.10062},
  abstract = {An automated method for segmenting magnetic resonance head images into brain and non-brain has been developed. It is very robust and accurate and has been tested on thousands of data sets from a wide variety of scanners and taken with a wide variety of MR sequences. The method, Brain Extraction Tool (BET), uses a deformable model that evolves to fit the brain's surface by the application of a set of locally adaptive model forces. The method is very fast and requires no preregistration or other pre-processing before being applied. We describe the new method and give examples of results and the results of extensive quantitative testing against ``gold-standard'' hand segmentations, and two other popular automated methods.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {9678 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{smith_Metal_1975,
  title = {Metal {{Substitutions Incarbonic Anhydrase}}: {{A Halide Ion Probe Study}}},
  shorttitle = {Metal Substitutions Incarbonic Anhydrase},
  author = {Smith, R. J. and Bryant, R. G.},
  date = {1975-10-27},
  journaltitle = {Biochem Biophys Res Commun},
  volume = {66},
  number = {4},
  eprint = {3},
  eprinttype = {pmid},
  pages = {1281--1286},
  issn = {0006-291X},
  doi = {10.1016/0006-291x(75)90498-2},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Animals,Binding Sites,Cadmium,Carbonic Anhydrases,Cattle,Humans,Hydrogen-Ion Concentration,Magnetic Resonance Spectroscopy,Mercury,Protein Binding,Protein Conformation,Zinc},
  annotation = {32 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{sogancioglu_Deep_2021,
  title = {Deep {{Learning}} for {{Chest X-Ray Analysis}}: {{A Survey}}},
  shorttitle = {Deep {{Learning}} for {{Chest X-ray Analysis}}},
  author = {Sogancioglu, Ecem and \c{C}alli, E. and Ginneken, B. and Leeuwen, K. G. V. and Murphy, K.},
  date = {2021},
  journaltitle = {Med. Image Anal},
  doi = {10.1016/j.media.2021.102125},
  abstract = {Semantic Scholar extracted view of "Deep Learning for Chest X-ray Analysis: A Survey" by Ecem Sogancioglu et al.},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {108 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/FWEB2DF7/Sogancioglu et al. - 2021 - Deep Learning for Chest X-ray Analysis A Survey.pdf}
}

@article{song_DualBranch_2022,
  title = {Dual-{{Branch Network}} via {{Pseudo-Label Training}} for {{Thyroid Nodule Detection}} in {{Ultrasound Image}}},
  author = {Song, Ruoning and Zhu, Chuang and Zhang, Long and Zhang, Tong and Luo, Yihao and Liu, Jun and Yang, Jie},
  date = {2022-01-29},
  journaltitle = {Appl Intell},
  issn = {1573-7497},
  doi = {10.1007/s10489-021-02967-2},
  url = {https://doi.org/10.1007/s10489-021-02967-2},
  urldate = {2022-05-16},
  abstract = {Automated nodule detection in the ultrasound image is essential for computer-aided thyroid tumor diagnosis. However, in the ultrasound image, the solid nodule has imaging characteristics similar to other tissues, making it challenging to detect such nodules. Therefore, we proposed a feature-enhanced dual-branch network (FDnet) to complete the nodule detection task by adding a semantic segmentation branch and a feature enhancement mechanism into the detection network. This design improves the target area's proposal score and suppresses the interference of similar tissues, which can reduce the false-positive rate of the proposed bounding box and finally obtain more reliable detection results. Additionally, to solve the lack of fine-grained mask information for semantic segmentation branch training in the actual scenario, we also proposed an iterative training strategy that combines the ground-truth boundary box with the branch results to generate a pseudo-label mask. Finally, we carried out various comparative experiments to verify the feasibility of the proposed network and training strategy. A series of experiments showed that FDnet could achieve competitive detection performance (mAP: 61.8/92.5/65.9), which metrics are better than the state-of-the-art detection methods. Besides, the performance using the pseudo-label mask training is also close to using the ground-truth mask in the public dataset, and the inference speed per image is also comparable to that of other networks both in the two datasets. This result shows that our method can improve the efficiency of thyroid nodule detection without fine-grained annotation, and the output result of the trained semantic segmentation branch can guide the further segmentation of nodule edge, which has practical clinical significance. We will release the source code and the public dataset at https://github.com/songruoning/Thyroid\_Solid\_Nodule.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Dual-branch network,Multi-task joint training,Pseudo-label mask,Thyroid nodule detection,Ultrasound image},
  annotation = {2 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/JSSHMY8N/Song et al. - 2022 - Dual-branch network via pseudo-label training for .pdf;/Users/personal-macbook/Zotero/storage/2ZE46C6J/Song et al. - 2022 - Dual-branch network via pseudo-label training for .html}
}

@article{sonner_Microfluidics_2015,
  title = {The {{Microfluidics}} of the {{Eccrine Sweat Gland}}, {{Including Biomarker Partitioning}}, {{Transport}}, and {{Biosensing Implications}}},
  author = {Sonner, Z. and Wilder, E. and Heikenfeld, J. and Kasting, G. and Beyette, F. and Swaile, D. and Sherman, F. and Joyce, J. and Hagen, J. and Kelley-Loughnane, N. and Naik, R.},
  date = {2015},
  journaltitle = {Biomicrofluidics},
  issn = {19321058},
  doi = {10.1063/1.4921039},
  abstract = {Non-invasive and accurate access of biomarkers remains a holy grail of the biomedical community. Human eccrine sweat is a surprisingly biomarker-rich fluid which is gaining increasing attention. This is especially true in applications of continuous bio-monitoring where other biofluids prove more challenging, if not impossible. However, much confusion on the topic exists as the microfluidics of the eccrine sweat gland has never been comprehensively presented and models of biomarker partitioning into sweat are either underdeveloped and/or highly scattered across literature. Reported here are microfluidic models for eccrine sweat generation and flow which are coupled with review of blood-to-sweat biomarker partition pathways, therefore providing insights such as how biomarker concentration changes with sweat flow rate. Additionally, it is shown that both flow rate and biomarker diffusion determine the effective sampling rate of biomarkers at the skin surface (chronological resolution). The discussion covers a broad class of biomarkers including ions (Na+, Cl-, K+, NH4+), small molecules (ethanol, cortisol, urea, and lactate), and even peptides or small proteins (neuropeptides and cytokines). The models are not meant to be exhaustive for all biomarkers, yet collectively serve as a foundational guide for further development of sweat-based diagnostics and for those beginning exploration of new biomarker opportunities in sweat.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{sonnhof_Inhibitory_1975,
  title = {Inhibitory {{Postsynaptic Actions}} of {{Taurine}}, {{GABA}} and {{Other Amino Acids}} on {{Motoneurons}} of the {{Isolated Frog Spinal Cord}}},
  author = {Sonnhof, U. and Grafe, P. and Krumnikl, J. and Linder, M. and Schindler, L.},
  date = {1975-12-19},
  journaltitle = {Brain Res},
  volume = {100},
  number = {2},
  eprint = {128},
  eprinttype = {pmid},
  pages = {327--341},
  issn = {0006-8993},
  doi = {10.1016/0006-8993(75)90486-2},
  abstract = {The actions of glycine, GABA, alpha-alanine, beta-alanine and taurine were studied by intracellular recordings from lumbar motoneurons of the isolated spinal cord of the frog. All amino acids tested produced a reduction in the amplitude of postsynaptic potentials, a blockade of the antidromic action potential and an increase of membrane conductance. Furthermore, membrane polarizations occurred, which were always in the same direction as the IPSP. All these effects indicate a postsynaptic inhibitory action of these amino acids. When the relative strength of different amino acids was compared, taurine had the strongest inhibitory potency, followed by beta-alanine, alpha-alanine, GABA and glycine. Topically applied strychnine and picrotoxin induced different changes of post-synaptic potentials, indicating that distinct inhibitory systems might be influenced by these two convulsants. Interactions with amino acids showed that picrotoxin seletively diminished the postsymaptic actions of GABA, while strychnine reduced the effects of taurine, glycine, alpha- and beta-alanine. But differences in the susceptibility of these amino acid actions to strychnine could be detected: the action of taurine was more sensitively blocked by strychnine compared with glycine, alpha- and beta-alanine. With regard to these results the importance of taurine and GABA as transmitters of postsynaptic inhibition on motoneurons in the spinal cord of the frog is discussed.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Alanine,Amino Acids,Animals,Anura,{Depression, Chemical},Drug Interactions,Evoked Potentials,gamma-Aminobutyric Acid,Glycine,Membrane Potentials,Motor Neurons,Neural Inhibition,Neurotransmitter Agents,Picrotoxin,Rana esculenta,Spinal Cord,Spinal Nerve Roots,Stereoisomerism,Strychnine,Synaptic Membranes,Taurine},
  annotation = {64 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/QBSQVV5E/Sonnhof et al. - 1975 - Inhibitory postsynaptic actions of taurine, GABA a.pdf}
}

@article{sorensen_Method_1948,
  ids = {sorensen_Method_1948a,sorenson_Method_1948},
  title = {A {{Method}} of {{Establishing Groups}} of {{Equal Amplitude}} in {{Plant Sociology Based}} on {{Similarity}} of {{Species Content}} and {{Its Application}} to {{Analyses}} of the {{Vegetation}} on {{Danish Commons}}},
  author = {Sorensen, Thorvald A.},
  date = {1948},
  journaltitle = {Biol. Skar.},
  volume = {5},
  pages = {1--34},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/NVH9WWSJ/1571417124651609984.html}
}

@article{spinks_Manual_2002,
  title = {Manual and {{Automated Measurement}} of the {{Whole Thalamus}} and {{Mediodorsal Nucleus Using Magnetic Resonance Imaging}}},
  author = {Spinks, Ruth and Magnotta, Vincent A. and Andreasen, Nancy C. and Albright, Karen C. and Ziebell, Steven and Nopoulos, Peggy and Cassell, Martin},
  date = {2002-10},
  journaltitle = {Neuroimage},
  volume = {17},
  number = {2},
  pages = {631--642},
  doi = {10.1006/nimg.2002.1185},
  abstract = {The thalamus is an important relay structure in the brain that may be relevant to a variety of brain diseases. It is divided into multiple subnuclei with different cortical connections. The medial dorsal (MD) nucleus is particularly important because it forms key connections with the prefrontal cortex. The current study reports precise and efficient methods for measuring the whole thalamus and the MD with MRI that have a high degree of interrater reliability. A multispectral image acquisition and novel image processing technique were used to improve structure visibility. The tricolor image assigns a color to each of the T1, T2, and PD weighted images, represented by red, green, and blue, respectively. The manually defined regions were then used to train an artificial neural network (ANN) to automatically define both the whole thalamus and the MD. The ANN provides an efficient automated method, making studies using larger sample sizes more feasible.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {58 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{srivastava_Computeraided_2008,
  title = {Computer-{{Aided Identification}} of {{Ovarian Cancer}} in {{Confocal Microendoscope Images}}},
  author = {Srivastava, Saurabh and Rodr\'iguez, Jeffrey J. and Rouse, Andrew R. and Brewer, Molly A. and Gmitro, Arthur F.},
  date = {2008},
  journaltitle = {J. Biomed. Opt.},
  issn = {10833668},
  doi = {10.1117/1.2907167},
  abstract = {The confocal microendoscope is an instrument for imaging the surface of the human ovary. Images taken with this instrument from normal and diseased tissue show significant differences in cellular distribution. A real-time computer-aided system to facilitate the identification of ovarian cancer is introduced. The cellular-level structure present in ex vivo confocal microendoscope images is modeled as texture. Features are extracted based on first-order statistics, spatial gray-level-dependence matrices, and spatial-frequency content. Selection of the features is performed using stepwise discriminant analysis, forward sequential search, a nonparametric method, principal component analysis, and a heuristic technique that combines the results of these other methods. The selected features are used for classification, and the performance of various machine classifiers is compared by analyzing areas under their receiver operating characteristic curves. The machine classifiers studied included linear discriminant analysis, quadratic discriminant analysis, and the k-nearest-neighbor algorithm. The results suggest it is possible to automatically identify pathology based on texture features extracted from confocal microendoscope images and that the machine performance is superior to that of a human observer.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {46 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{srivastava_Dropout_2014,
  title = {Dropout: {{A Simple Way}} to {{Prevent Neural Networks From Overfitting}}},
  author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Salakhutdinov, Ruslan and Sutskever, Ilya and Salakhutdinov, Ruslan},
  date = {2014},
  journaltitle = {J. Mach. Learn. Res.},
  volume = {15},
  number = {1},
  pages = {1929--1958},
  publisher = {{JMLR. org}},
  url = {https://www.researchgate.net/publication/286794765_Dropout_A_Simple_Way_to_Prevent_Neural_Networks_from_Overfitting},
  abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different "thinned" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found,deep learning,model combination,neural networks,regularization}
}

@article{statistics_Distracted_2017,
  title = {Distracted {{Driving}} 2015. ({{Traffic Safety Facts Research Note}}. {{Report No}}. {{DOT HS}} 812 381).},
  author = {family=Statistics, given=National Center, prefix=for, useprefix=false and {Analysis}},
  date = {2017},
  journaltitle = {Wash. DC Natl. Highw. Traffic Saf. Adm.},
  doi = {DOT HS 811 379},
  abstract = {HS 811 299), distraction is a specific type of inattention that occurs when drivers divert their attention from the driving task to focus on some other activity instead. The document describes distraction as a subset of inattention (which also includes fatigue, and physical and emotional conditions of the driver). However, while NHTSA may define the terms in this manner, inattention and distraction are often used inter-changeably or simultaneously in other material, including police crash reports. It is important that NHTSA and NHTSA's data users be aware of these differences in definitions. It is also important to acknowledge the inherent limitations in the data collection for distraction-affected crashes and the result-ing injuries and fatalities. The appendix of this document con-tains a table that describes the coding for distraction-affected crashes for FARS and GES as well as a discussion regarding limitations in the distracted driving data. Data Fatalities in Distraction-Affected Crashes In 2015, there were a total of 32,166 fatal crashes in the United States involving 48,613 drivers. As a result of those fatal crashes, 35,092 people were killed. In 2015, there were 3,196 fatal crashes that occurred on U.S. roadways that involved distraction (10\% of all fatal crashes). These crashes involved 3,263 distracted drivers, as some crashes involved more than one distracted driver. Distraction was reported for 7 percent (3,263 of 48,613) of the drivers involved in fatal crashes. In these distraction-affected crashes, 3,477 fatalities (10\% of overall fatalities) occurred. Table 1 pro-vides information on crashes, drivers, and fatalities involved in fatal distraction-affected crashes in 2015. Much attention across the country has been devoted to the dangers of using cell phones and other electronic devices while driving. In 2015, there were 442 fatal crashes reported to have involved cell phone use as a distraction (14\% of all fatal distraction-affected crashes). For these distraction-affected crashes, the police crash report stated that the driver was talk-ing on, listening to, or otherwise manipulating a cell phone},
  isbn = {DOT HS 811 737},
  keywords = {\#nosource,{$\warning$}️ Invalid DOI,⛔ No INSPIRE recid found}
}

@inproceedings{stearns_SNOMED_2001,
  title = {{{SNOMED Clinical Terms}}: {{Overview}} of the {{Development Process}} and {{Project Status}}.},
  shorttitle = {{{SNOMED}} Clinical Terms},
  booktitle = {Proc. {{AMIA Symp}}.},
  author = {Stearns, M. Q. and Price, C. and Spackman, K. A. and Wang, A. Y.},
  date = {2001},
  eprint = {11825268},
  eprinttype = {pmid},
  pages = {662--666},
  publisher = {{American Medical Informatics Association}},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2243297/},
  urldate = {2022-11-21},
  abstract = {Two large health care reference terminologies, SNOMED RT and Clinical Terms Version 3 , are in the process of being merged to form a comprehensive new work referred to as SNOMED Clinical Terms. The College of American Pathologists and the United Kingdom s National Health Service have entered into a collaborative agreement to develop this new work. Both organizations have extensive terminology development and maintenance experience. This paper discusses the process and status of SNOMED CT development and how the resources and expertise of both organizations are being used to develop this new terminological resource. The preliminary results of the merger process, including mapping, the merger of upper levels of each hierarchy, and attribute harmonization are also discussed.},
  pmcid = {PMC2243297},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/BKLHDJVW/Stearns et al. - 2001 - SNOMED clinical terms overview of the development.pdf;/Users/personal-macbook/Zotero/storage/MWJF8CFT/PMC2243297.html}
}

@article{stein_Functional_2000,
  title = {Functional {{Connectivity}} in the {{Thalamus}} and {{Hippocampus Studied With Functional Mr Imaging}}},
  author = {Stein, T. and Moritz, C. and Quigley, M. and Cordes, D. and Haughton, V. and Meyerand, E.},
  date = {2000-09},
  journaltitle = {AJNR Am. J. Neuroradiol.},
  volume = {21},
  number = {8},
  pages = {1397--1401},
  abstract = {BACKGROUND AND PURPOSE: With functional connectivity functional MR imaging, co-variance in signal intensity has been shown in functionally related regions of brain in participants instructed to perform no cognitive task. These changes are thought to represent synchronous fluctuations in blood flow, which imply neuronal connections between the regions. The purpose of this study was to map functional connectivity in subcortical nuclei with functional connectivity functional MR imaging. METHODS: Imaging data were acquired with an echo-planar sequence from six volunteers who performed no specific cognitive task. For functional connectivity functional MR imaging, a ``seed'' voxel or group of voxels was selected from the resting data set in the thalamus or in the hippocampus. Control voxels in gray matter presumed not to be eloquent cortex were also chosen. The correlation coefficient of the seed voxels and the control voxels with every other voxel in the resting data set was calculated. The voxels with correlation coefficients greater than or equal to 0.5 were mapped onto anatomic images for the functional connectivity functional MR images. The anatomic location of these voxels was determined by conventional parcellation methods. RESULTS: For each participant, functional connectivity functional MR imaging maps based on four seed voxels in the thalamus or hippocampus showed clusters of voxels in the ipsilateral and contralateral thalamus or hippocampus. For control voxels, few voxels in the hippocampus or thalamus showed significant correlation. Significantly more pixels in the ipsilateral hippocampus correlated with the seed voxel than in the contralateral hippocampus. The differences between numbers of functionally connected voxels in ipsilateral thalamus and those in contralateral thalamus were not significant. CONCLUSIONS: The thalamus and hippocampus show functional connectivity, presumably representing synchronous changes in blood flow.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found,thalamus}
}

@article{steriade_Functional_1988,
  title = {The {{Functional States}} of the {{Thalamus}} and the {{Associated Neuronal Interplay}}},
  author = {Steriade, M. and Llin\'as, R. R.},
  date = {1988-07},
  journaltitle = {Physiol. Rev.},
  volume = {68},
  number = {3},
  pages = {649--742},
  doi = {10.1152/physrev.1988.68.3.649},
  keywords = {\#nosource,⛔ No INSPIRE recid found,thalamus}
}

@article{stevens_Using_2007,
  title = {Using {{OWL}} to {{Model Biological Knowledge}}},
  author = {Stevens, Robert and Ega\~na Aranguren, Mikel and Wolstencroft, Katy and Sattler, Ulrike and Drummond, Nick and Horridge, Matthew and Rector, Alan},
  date = {2007-07},
  journaltitle = {International Journal of Human-Computer Studies},
  volume = {65},
  number = {7},
  pages = {583--594},
  issn = {10715819},
  doi = {10.1016/j.ijhcs.2007.03.006},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1071581907000444},
  urldate = {2022-11-21},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {107 citations (Semantic Scholar/DOI) [2022-11-20]}
}

@inproceedings{stojcsics_High_2018,
  title = {High {{Resolution 3D Thermal Imaging Using FLIR DUO R Sensor}}},
  booktitle = {{{INES}} 2018 - {{IEEE}} 22nd {{Int}}. {{Conf}}. {{Intell}}. {{Eng}}. {{Syst}}. {{Proc}}.},
  author = {Stojcsics, Daniel and Lovas, Istvan and Domozi, Zsolt and Molnar, Andras},
  date = {2018-11},
  pages = {000311--000316},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  doi = {10.1109/INES.2018.8523914},
  abstract = {With the spread of photogrammetry processes, photo-based 2D/3D reconstruction became general, in research as well as in the industry. Source images are taken using either a handheld camera or an automated camera fixed to the carrier, a UAV, then they are matched during post-processing. The price of digital microbolometer-based high-resolution (1 megapixel) thermal cameras is currently very high, but these, compared to RGB cameras (16-20 megapixel), are still considered to have very low-resolution, in this way employing photogrammetry in this present case is not feasible. In the article, a novel method developed by us is introduced which by using a low thermal resolution camera (FLIR DUO R), based on which a 3D thermal image can be produced with the help of a camera capable of dual imaging (RGB and Thermal). The work is illustrated using measurements, and post-production was conducted using the MATLAB software. The process is adequate for producing 3D thermal images taken using UAV devices.},
  isbn = {978-1-5386-1122-7},
  keywords = {\#nosource,⛔ No INSPIRE recid found,3D thermal imaging,FLIR,large scale point cloud,MATLAB,object reconstruction,photogrammetry},
  annotation = {8 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{stough_Automatic_2014,
  title = {Automatic {{Method}} for {{Thalamus Parcellation Using Multi-Modal Feature Classification}}},
  author = {Stough, Joshua V. and Glaister, Jeffrey and Ye, Chuyang and Ying, Sarah H. and Prince, Jerry L. and Carass, Aaron},
  date = {2014},
  journaltitle = {Med. Image Comput. Comput. Assist. Interv.},
  volume = {17},
  pages = {169--176},
  abstract = {Segmentation and parcellation of the thalamus is an important step in providing volumetric assessment of the impact of disease n brain structures. Conventionally, segmentation is carried out on T1-weighted magnetic resonance (MR) images and nuclear parcellation using diffusion weighted MR images. We present the first fully automatic method that incorporates both tissue contrasts and several derived fea-fractional anisotrophy, fiber orientation from the 5D Knutsson representation of the principal eigenvectors, and connectivity between the thalamus and the cortical lobes, as features. Combining these multiple information sources allows us to identify discriminating dimensions and thus parcellate the thalamic nuclei. A hierarchical random forest framework with a multidimensional feature per voxel, first distinguishes thalamus from background, and then separates each group of thalamic nuclei. Using a leave one out cross-validation on 12 subjects we have a mean Dice score of 0.805 and 0.799 for the left and right thalami, respectively. We also report overlap for the thalamic nuclear groups.},
  issue = {Pt 3},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@inproceedings{stough_Thalamic_2013,
  title = {Thalamic {{Parcellation From Multi-Modal Data Using Random Forest Learning}}},
  booktitle = {Proc. - {{Int}}. {{Symp}}. {{Biomed}}. {{Imaging}}},
  author = {Stough, Joshua V. and Ye, Chuyang and Ying, Sarah H. and Prince, Jerry L.},
  date = {2013},
  pages = {852--855},
  issn = {19457928},
  doi = {10.1109/ISBI.2013.6556609},
  abstract = {The thalamus sub-cortical gray matter structure consists of contiguous nuclei, each individually responsible for communication between various cerebral cortex and midbrain regions. These nuclei are differentially affected in neurodegenerative diseases such as multiple sclerosis and Alzheimer's. However thalamic parcellation of the nuclei, manual or automatic, is difficult given the limited contrast in any particular magnetic resonance (MR) modality. Several groups have had qualitative success differentiating nuclei based on spatial location and fiber orientation information in diffusion tensor imaging (DTI). In this paper, we extend these principles by combining these discriminating dimensions with structural MR and derived information, and by building random forest learners on the resultant multi-modal features. In training, we form a multi-dimensional feature per voxel, which we associate with a nucleus classification from a manual rater. Learners are trained to differentiate thalamus from background and thalamic nuclei from other nuclei. These learners inform the external forces of a multiple object level set model. Our cross-validated quantitative results on a set of twenty subjects show the efficacy and reproducibility of our results. \textcopyright{} 2013 IEEE.},
  isbn = {978-1-4673-6454-6},
  keywords = {\#nosource,⛔ No INSPIRE recid found,deformable models,Diffusion tensor imaging,machine learning,object segmentation,random forests}
}

@inproceedings{su_Active_2020,
  title = {Active {{Adversarial Domain Adaptation}}},
  booktitle = {Proc. - 2020 {{IEEE Winter Conf}}. {{Appl}}. {{Comput}}. {{Vis}}. {{WACV}} 2020},
  author = {Su, Jong Chyi and Tsai, Yi Hsuan and Sohn, Kihyuk and Liu, Buyu and Maji, Subhransu and Chandraker, Manmohan},
  date = {2020},
  doi = {10.1109/WACV45572.2020.9093390},
  abstract = {We propose an active learning approach for transferring representations across domains. Our approach, active adversarial domain adaptation (AADA), explores a duality between two related problems: adversarial domain alignment and importance sampling for adapting models across domains. The former uses a domain discriminative model to align domains, while the latter utilizes the model to weigh samples to account for distribution shifts. Specifically, our importance weight promotes unlabeled samples with large uncertainty in classification and diversity compared to la-beled examples, thus serving as a sample selection scheme for active learning. We show that these two views can be unified in one framework for domain adaptation and transfer learning when the source domain has many labeled examples while the target domain does not. AADA provides significant improvements over fine-tuning based approaches and other sampling methods when the two domains are closely related. Results on challenging domain adaptation tasks such as object detection demonstrate that the advantage over baseline approaches is retained even after hundreds of examples being actively annotated.},
  isbn = {978-1-72816-553-0},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {73 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{su_Deep_2017,
  title = {A {{Deep Learning Approach Towards Pore Extraction}} for {{High-Resolution Fingerprint Recognition}}},
  booktitle = {2017 {{IEEE Int}}. {{Conf}}. {{Acoust}}. {{Speech Signal Process}}. {{ICASSP}}},
  author = {Su, Hong-Ren and Chen, Kuang-Yu and Wong, Wei Jing and Lai, Shang-Hong},
  date = {2017-03},
  pages = {2057--2061},
  publisher = {{IEEE}},
  location = {{New Orleans, LA}},
  doi = {10.1109/ICASSP.2017.7952518},
  url = {http://ieeexplore.ieee.org/document/7952518/},
  urldate = {2022-12-29},
  eventtitle = {2017 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  isbn = {978-1-5090-4117-6},
  keywords = {\#nosource,⛔ No INSPIRE recid found,affine Fourier moment-matching,convolutional neural network,High-resolution fingerprint recognition,pore extraction},
  annotation = {26 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{su_Thalamus_2019,
  ids = {_PDF_a},
  title = {Thalamus {{Optimized Multi Atlas Segmentation}} ({{Thomas}}): {{Fast}}, {{Fully Automated Segmentation}} of {{Thalamic Nuclei From Structural Mri}}},
  author = {Su, Jason H. and Thomas, Francis T. and Kasoff, Willard S. and Tourdias, Thomas and Choi, Eun Young and Rutt, Brian K. and Saranathan, Manojkumar},
  date = {2019-07},
  journaltitle = {NeuroImage},
  volume = {194},
  pages = {272--282},
  publisher = {{Academic Press Inc.}},
  issn = {10959572},
  doi = {10.1016/j.neuroimage.2019.03.021},
  abstract = {The thalamus and its nuclei are largely indistinguishable on standard T1 or T2 weighted MRI. While diffusion tensor imaging based methods have been proposed to segment the thalamic nuclei based on the angular orientation of the principal diffusion tensor, these are based on echo planar imaging which is inherently limited in spatial resolution and suffers from distortion. We present a multi-atlas segmentation technique based on white-matter-nulled MP-RAGE imaging that segments the thalamus into 12 nuclei with computation times on the order of 10 min on a desktop PC; we call this method THOMAS (THalamus Optimized Multi Atlas Segmentation). THOMAS was rigorously evaluated on 7T MRI data acquired from healthy volunteers and patients with multiple sclerosis by comparing against manual segmentations delineated by a neuroradiologist, guided by the Morel atlas. Segmentation accuracy was very high, with uniformly high Dice indices: at least 0.85 for large nuclei like the pulvinar and mediodorsal nuclei and at least 0.7 even for small structures such as the habenular, centromedian, and lateral and medial geniculate nuclei. Volume similarity indices ranged from 0.82 for the smaller nuclei to 0.97 for the larger nuclei. Volumetry revealed that the volumes of the right anteroventral, right ventral posterior lateral, and both right and left pulvinar nuclei were significantly lower in MS patients compared to controls, after adjusting for age, sex and intracranial volume. Lastly, we evaluated the potential of this method for targeting the Vim nucleus for deep brain surgery and focused ultrasound thalamotomy by overlaying the Vim nucleus segmented from pre-operative data on post-operative data. The locations of the ablated region and active DBS contact corresponded well with the segmented Vim nucleus. Our fast, direct structural MRI based segmentation method opens the door for MRI guided intra-operative procedures like thalamotomy and asleep DBS electrode placement as well as for accurate quantification of thalamic nuclear volumes to follow progression of neurological disorders.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Multi-atlas segmentation,Thalamic nuclei,Thalamic parcellation,White matter nulled MP-RAGE}
}

@article{such_Extent_2017,
  title = {Extent of {{Diagnostic Agreement Among Medical Referrals}}},
  author = {Such, Monica Van and Lohr, Robert and Beckman, Thomas and Naessens, James M.},
  date = {2017},
  journaltitle = {J. Eval. Clin. Pract.},
  eprint = {28374457},
  eprinttype = {pmid},
  issn = {13652753},
  doi = {10.1111/jep.12747},
  abstract = {Rationale, aims and objectives: Diagnostic uncertainty is often encountered in a medical practice. Patients with ambiguous, uncertain, and undiagnosed problems are frequently referred for second opinions. Comparing referral diagnoses to final diagnoses provides an opportunity to determine how frequently final diagnoses vary and changes the direction of medical care. Methods: A retrospective study was done at a single academic medical center using a sample of 286 patients referred by physician assistants, nurse practitioners, and physicians from primary care practices from January 1, 2009 to December 31, 2010. Patients' referral and final diagnoses were compared and classified into 1 of 3 categories: referral diagnosis and final diagnosis the same, referral diagnosis better defined/refined, and referral diagnosis distinctly different from final diagnosis. Episode costs for the respective categories were calculated for the referral visit and services that occurred at our facility within the first 30 days. Results: In 12\% (36/286) of cases, referral diagnoses were the same as final diagnoses. Final diagnoses were better defined/refined in 66\% (188/286) of cases; but in 21\% of cases (62/286), final diagnoses were distinctly different than referral diagnoses. Total costs for cases in category 3 (different final diagnoses) were significantly higher than costs for cases in category 1 (P =.0001) and category 2 (P = {$<$}.0001). Conclusion: Referrals to advanced specialty care for undifferentiated problems are an essential component of patient care. Without adequate resources to handle undifferentiated diagnoses, a potential unintended consequence is misdiagnoses resulting in treatment delays and complications leading to more costly treatments.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,diagnostic uncertainty,face-to-face visit,provider referrals},
  annotation = {60 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{sudhyadhom_High_2009,
  title = {A {{High Resolution}} and {{High Contrast Mri}} for {{Differentiation}} of {{Subcortical Structures}} for {{DBS Targeting}}: {{The Fast Gray Matter Acquisition T1 Inversion Recovery}} ({{Fgatir}})},
  shorttitle = {A {{High Resolution}} and {{High Contrast Mri}} for {{Differentiation}} of {{Subcortical Structures}} for {{Dbs Targeting}}},
  author = {Sudhyadhom, Atchar and Haq, Ihtsham U. and Foote, Kelly D. and Okun, Michael S. and Bova, Frank J.},
  date = {2009-08},
  journaltitle = {NeuroImage},
  volume = {47},
  pages = {T44-T52},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2009.04.018},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811909003759},
  urldate = {2023-05-08},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Deep brain stimulation (DBS),High resolution,localization,Magnetic resolution imaging (MRI),Targeting},
  annotation = {180 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{sudre_Generalised_2017,
  title = {Generalised {{Dice Overlap}} as a {{Deep Learning Loss Function}} for {{Highly Unbalanced Segmentations}}},
  booktitle = {Lect. {{Notes Comput}}. {{Sci}}. {{Subser}}. {{Lect}}. {{Notes Artif}}. {{Intell}}. {{Lect}}. {{Notes Bioinforma}}.},
  author = {Sudre, Carole H. and Li, Wenqi and Vercauteren, Tom and Ourselin, Sebastien and Cardoso, M. Jorge},
  date = {2017},
  volume = {10553 LNCS},
  issn = {16113349},
  doi = {10.1007/978-3-319-67558-9_28},
  abstract = {Deep-learning has proved in recent years to be a powerful tool for image analysis and is now widely used to segment both 2D and 3D medical images. Deep-learning segmentation frameworks rely not only on the choice of network architecture but also on the choice of loss function. When the segmentation process targets rare observations, a severe class imbalance is likely to occur between candidate labels, thus resulting in sub-optimal performance. In order to mitigate this issue, strategies such as the weighted cross-entropy function, the sensitivity function or the Dice loss function, have been proposed. In this work, we investigate the behavior of these loss functions and their sensitivity to learning rate tuning in the presence of different rates of label imbalance across 2D and 3D segmentation tasks. We also propose to use the class re-balancing properties of the Generalized Dice overlap, a known metric for segmentation assessment, as a robust and accurate deep-learning loss function for unbalanced tasks.},
  isbn = {978-3-319-67557-2},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {1337 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{sun_Deep_2016,
  title = {Deep {{CORAL}}: {{Correlation Alignment}} for {{Deep Domain Adaptation}}},
  booktitle = {Lect. {{Notes Comput}}. {{Sci}}.},
  author = {Sun, Baochen and Saenko, Kate},
  date = {2016-07},
  issn = {16113349},
  doi = {10.1007/978-3-319-49409-8_35},
  abstract = {Deep neural networks are able to learn powerful representations from large quantities of labeled input data, however they cannot always generalize well across changes in input distributions. Domain adaptation algorithms have been proposed to compensate for the degradation in performance due to domain shift. In this paper, we address the case when the target domain is unlabeled, requiring unsupervised adaptation. CORAL [18] is a simple unsupervised domain adaptation method that aligns the second-order statistics of the source and target distributions with a linear transformation. Here, we extend CORAL to learn a nonlinear transformation that aligns correlations of layer activations in deep neural networks (Deep CORAL). Experiments on standard benchmark datasets show state-of-the-art performance. Our code is available at: https://github.com/VisionLearningGroup/CORAL.},
  isbn = {978-3-319-49408-1},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {1856 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{sun_Human_2015,
  ids = {_Human_},
  title = {Human {{Action Recognition Using Factorized Spatio-Temporal Convolutional Networks}}},
  booktitle = {2015 {{IEEE Int}}. {{Conf}}. {{Comput}}. {{Vis}}. {{ICCV}}},
  author = {Sun, Lin and Jia, Kui and Yeung, Dit-Yan and Shi, Bertram E.},
  date = {2015-12},
  pages = {4597--4605},
  publisher = {{IEEE}},
  location = {{Santiago, Chile}},
  doi = {10.1109/ICCV.2015.522},
  url = {http://ieeexplore.ieee.org/document/7410879/},
  urldate = {2023-05-14},
  eventtitle = {2015 {{IEEE International Conference}} on {{Computer Vision}} ({{ICCV}})},
  isbn = {978-1-4673-8391-2},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {508 citations (Semantic Scholar/DOI) [2023-05-14]},
  file = {/Users/personal-macbook/Zotero/storage/XR3XVMQ3/Sun et al. - 2015 - Human Action Recognition Using Factorized Spatio-T.pdf}
}

@inproceedings{swaminathan_Counterfactual_2015,
  title = {Counterfactual {{Risk Minimization}}: {{Learning From Logged Bandit Feedback}}},
  booktitle = {32nd {{Int}}. {{Conf}}. {{Mach}}. {{Learn}}. {{ICML}} 2015},
  author = {Swaminathan, Adith and Joachims, Thorsten},
  date = {2015},
  abstract = {We develop a learning principle and an efficient algorithm for batch learning from logged bandit feedback. This learning setting is ubiquitous in online systems (e.g., ad placement, web search, recommendation), where an algorithm makes a prediction (e.g., ad ranking) for a given input (e.g., query) and observes bandit feedback (e.g., user clicks on presented ads). We first address the counterfactual nature of the learning problem through propensity scoring. Next, we prove generalization error bounds that account for the variance of the propensity-weighted empirical risk estimator. These constructive bounds give rise to the Counterfactual Risk Minimization (CRM) principle. We show how CRM can be used to derive a new learning method-called Policy Optimizer for Exponential Models (POEM)-for learning stochastic linear rules for structured output prediction. We present a decomposition of the POEM objective that enables efficient stochastic gradient optimization. POEM is evaluated on several multi-label classification problems showing substantially improved robustness and generalization performance compared to the state-of-the-art.},
  isbn = {978-1-5108-1058-7},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{szegedy_Going_2015,
  title = {Going {{Deeper With Convolutions}}},
  booktitle = {Comput. {{Vis}}. {{Pattern Recognit}}. {{CVPR}}},
  author = {Szegedy, Christian and {Wei Liu} and {Yangqing Jia} and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  date = {2015-06},
  pages = {1--9},
  publisher = {{IEEE}},
  location = {{Boston, MA, USA}},
  doi = {10.1109/CVPR.2015.7298594},
  url = {http://ieeexplore.ieee.org/document/7298594/},
  urldate = {2022-11-21},
  eventtitle = {Computer {{Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-4673-6964-0},
  keywords = {⛔ No INSPIRE recid found,Computer architecture,Computer vision,Convolutional codes,Neural networks,Object detection,Sparse matrices,Visualization},
  annotation = {9995 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/7GLH38AQ/Szegedy et al. - 2015 - Going deeper with convolutions.pdf;/Users/personal-macbook/Zotero/storage/B6F8RVMP/7298594.html}
}

@inproceedings{szegedy_InceptionV4_2017,
  title = {Inception-{{V4}}, {{Inception-Resnet}} and the {{Impact}} of {{Residual Connections}} on {{Learning}}},
  booktitle = {Proc. {{AAAI Conf}}. {{Artif}}. {{Intell}}.},
  author = {Szegedy, Christian and Ioffe, Sergey and Vanhoucke, Vincent and Alemi, Alexander},
  date = {2017-02-12},
  volume = {31},
  doi = {10.1609/aaai.v31i1.11231},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/11231},
  urldate = {2023-01-11},
  abstract = {Very deep convolutional networks have been central to the largest advances in image recognition performance in recent years. One example is the Inception architecture that has been shown to achieve very good performance at relatively low computational cost. Recently, the introduction of residual connections in conjunction with a more traditional architecture has yielded state-of-the-art performance in the 2015 ILSVRC challenge; its performance was similar to the latest generation Inception-v3 network. This raises the question: Are there any benefits to combining Inception architectures with residual connections? Here we give clear empirical evidence that training with residual connections accelerates the training of Inception networks significantly. There is also some evidence of residual Inception networks outperforming similarly expensive Inception networks without residual connections by a thin margin. We also present several new streamlined architectures for both residual and nonresidual Inception networks. These variations improve the single-frame recognition performance on the ILSVRC 2012 classification task significantly. We further demonstrate how proper activation scaling stabilizes the training of very wide residual Inception networks. With an ensemble of three residual and one Inception-v4 networks, we achieve 3.08\% top-5 error on the test set of the ImageNet classification (CLS) challenge.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {9990 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/FFHWIKMB/Szegedy et al. - 2017 - Inception-v4, Inception-ResNet and the Impact of R.pdf}
}

@article{taha_Efficient_2015,
  title = {An {{Efficient Algorithm}} for {{Calculating}} the {{Exact Hausdorff Distance}}},
  author = {Taha, Abdel Aziz and Hanbury, Allan},
  date = {2015},
  journaltitle = {IEEE Trans. Pattern Anal. Mach. Intell.},
  issn = {01628828},
  doi = {10.1109/TPAMI.2015.2408351},
  abstract = {The Hausdorff distance (HD) between two point sets is a commonly used dissimilarity measure for comparing point sets and image segmentations. Especially when very large point sets are compared using the HD, for example when evaluating magnetic resonance volume segmentations, or when the underlying applications are based on time critical tasks, like motion detection, then the computational complexity of HD algorithms becomes an important issue. In this paper we propose a novel efficient algorithm for computing the exact Hausdorff distance. In a runtime analysis, the proposed algorithm is demonstrated to have nearly-linear complexity. Furthermore, it has efficient performance for large point set sizes as well as for large grid size; performs equally for sparse and dense point sets; and finally it is general without restrictions on the characteristics of the point set. The proposed algorithm is tested against the HD algorithm of the widely used national library of medicine insight segmentation and registration toolkit (ITK) using magnetic resonance volumes with extremely large size. The proposed algorithm outperforms the ITK HD algorithm both in speed and memory required. In an experiment using trajectories from a road network, the proposed algorithm significantly outperforms an HD algorithm based on R-Trees.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Algorithm,Computational Complexity,Evaluation,Hausdorff distance,Runtime Analysis},
  annotation = {215 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{taher_Systematic_2021,
  title = {A {{Systematic Benchmarking Analysis}} of {{Transfer Learning}} for {{Medical Image Analysis}}},
  author = {Taher, M. and Haghighi, Fatemeh and Feng, Ruibin and Gotway, M. and Liang, Jianming},
  date = {2021},
  journaltitle = {DART/FAIR@MICCAI},
  doi = {10.1007/978-3-030-87722-4_1},
  abstract = {A systematic study on the transferability of models pre-trained on iNat2021, the most recent large-scale fine-grained dataset, and 14 top self-supervised ImageNet models on 7 diverse medical tasks in comparison with the supervised ImageNet model. Transfer learning from supervised ImageNet models has been frequently used in medical image analysis. Yet, no large-scale evaluation has been conducted to benchmark the efficacy of newly-developed pre-training techniques for medical image analysis, leaving several important questions unanswered. As the first step in this direction, we conduct a systematic study on the transferability of models pre-trained on iNat2021, the most recent large-scale fine-grained dataset, and 14 top self-supervised ImageNet models on 7 diverse medical tasks in comparison with the supervised ImageNet model. Furthermore, we present a practical approach to bridge the domain gap between natural and medical images by continually (pre-)training supervised ImageNet models on medical images. Our comprehensive evaluation yields new insights: (1) pre-trained models on fine-grained data yield distinctive local representations that are more suitable for medical segmentation tasks, (2) self-supervised ImageNet models learn holistic features more effectively than supervised ImageNet models, and (3) continual pre-training can bridge the domain gap between natural and medical images. We hope that this large-scale open evaluation of transfer learning can direct the future research of deep learning for medical imaging. As open science, all codes and pre-trained models are available on our GitHub page https://github.com/JLiangLab/BenchmarkTransferLearning.},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {25 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/BZIK3B75/Taher et al. - 2021 - A Systematic Benchmarking Analysis of Transfer Lea.pdf}
}

@article{taieb_Uncertainty_,
  title = {Uncertainty {{Driven Multi-Loss Fully Convolutional Networks}} for {{Histopathology}}},
  author = {Taieb, A\textbackslash "\i cha Ben and Hamarneh, Ghassan},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{tajbakhsh_Convolutional_2016,
  title = {Convolutional {{Neural Networks}} for {{Medical Image Analysis}}: {{Full Training}} or {{Fine Tuning}}?},
  author = {Tajbakhsh, Nima and Shin, Jae Y. and Gurudu, Suryakanth R. and Hurst, R. Todd and Kendall, Christopher B. and Gotway, Michael B. and Liang, Jianming},
  date = {2016-05},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {35},
  number = {5},
  pages = {1299--1312},
  doi = {10.1109/TMI.2016.2535302},
  abstract = {Training a deep convolutional neural network (CNN) from scratch is difficult because it requires a large amount of labeled training data and a great deal of expertise to ensure proper convergence. A promising alternative is to fine-tune a CNN that has been pre-trained using, for instance, a large set of labeled natural images. However, the substantial differences between natural and medical images may advise against such knowledge transfer. In this paper, we seek to answer the following central question in the context of medical image analysis: Can the use of pre-trained deep CNNs with sufficient fine-tuning eliminate the need for training a deep CNN from scratch? To address this question, we considered four distinct medical imaging applications in three specialties (radiology, cardiology, and gastroenterology) involving classification, detection, and segmentation from three different imaging modalities, and investigated how the performance of deep CNNs trained from scratch compared with the pre-trained CNNs fine-tuned in a layer-wise manner. Our experiments consistently demonstrated that 1) the use of a pre-trained CNN with adequate fine-tuning outperformed or, in the worst case, performed as well as a CNN trained from scratch; 2) fine-tuned CNNs were more robust to the size of training sets than CNNs trained from scratch; 3) neither shallow tuning nor deep tuning was the optimal choice for a particular application; and 4) our layer-wise fine-tuning scheme could offer a practical way to reach the best performance for the application at hand based on the amount of available data.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Carotid intima-media thickness,computer-aided detection,convolutional neural networks,deep learning,fine-tuning,medical image analysis,polyp detection,pulmonary embolism detection,video quality assessment},
  annotation = {378 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{tajbakhsh_Embracing_2019,
  title = {Embracing {{Imperfect Datasets}}: {{A Review}} of {{Deep Learning Solutions}} for {{Medical Image Segmentation}}},
  author = {Tajbakhsh, Nima and Jeyaseelan, Laura and Li, Qian and Chiang, Jeffrey and Wu, Zhihao and Ding, Xiaowei},
  date = {2019-08},
  abstract = {The medical imaging literature has witnessed remarkable progress in high-performing segmentation models based on convolutional neural networks. Despite the new performance highs, the recent advanced segmentation models still require large, representative, and high quality annotated datasets. However, rarely do we have a perfect training dataset, particularly in the field of medical imaging, where data and annotations are both expensive to acquire. Recently, a large body of research has studied the problem of medical image segmentation with imperfect datasets, tackling two major dataset limitations: scarce annotations where only limited annotated data is available for training, and weak annotations where the training data has only sparse annotations, noisy annotations, or image-level annotations. In this article, we provide a detailed review of the solutions above, summarizing both the technical novelties and empirical results. We further compare the benefits and requirements of the surveyed methodologies and provide our recommended solutions to the problems of scarce and weak annotations. We hope this review increases the community awareness of the techniques to handle imperfect datasets.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{talamantes_Statistical_2007,
  title = {Statistical {{Modeling}} of {{Valley Fever Data}} in {{Kern County}}, {{California}}},
  author = {Talamantes, Jorge and Behseta, Sam and Zender, Charles S.},
  date = {2007-03},
  journaltitle = {Int. J. Biometeorol.},
  volume = {51},
  number = {4},
  pages = {307--313},
  doi = {10.1007/s00484-006-0065-4},
  abstract = {Coccidioidomycosis (valley fever) is a fungal infection found in the southwestern US, northern Mexico, and some places in Central and South America. The fungus that causes it (Coccidioides immitis) is normally soil-dwelling but, if disturbed, becomes air-borne and infects the host when its spores are inhaled. It is thus natural to surmise that weather conditions that foster the growth and dispersal of the fungus must have an effect on the number of cases in the endemic areas. We present here an attempt at the modeling of valley fever incidence in Kern County, California, by the implementation of a generalized auto regressive moving average (GARMA) model. We show that the number of valley fever cases can be predicted mainly by considering only the previous history of incidence rates in the county. The inclusion of weather-related time sequences improves the model only to a relatively minor extent. This suggests that fluctuations of incidence rates (about a seasonally varying background value) are related to biological and/or anthropogenic reasons, and not so much to weather anomalies.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{tan_Exploiting_2020,
  title = {Exploiting {{Uncertainties From Ensemble Learners}} to {{Improve Decision-Making}} in {{Healthcare AI}}},
  author = {Tan, Yingshui and Jin, Baihong and Yue, Xiangyu and Chen, Yuxin and Vincentelli, Alberto Sangiovanni},
  date = {2020-07},
  url = {http://arxiv.org/abs/2007.06063},
  abstract = {Ensemble learning is widely applied in Machine Learning (ML) to improve model performance and to mitigate decision risks. In this approach, predictions from a diverse set of learners are combined to obtain a joint decision. Recently, various methods have been explored in literature for estimating decision uncertainties using ensemble learning; however, determining which metrics are a better fit for certain decision-making applications remains a challenging task. In this paper, we study the following key research question in the selection of uncertainty metrics: when does an uncertainty metric outperforms another? We answer this question via a rigorous analysis of two commonly used uncertainty metrics in ensemble learning, namely ensemble mean and ensemble variance. We show that, under mild assumptions on the ensemble learners, ensemble mean is preferable with respect to ensemble variance as an uncertainty metric for decision making. We empirically validate our assumptions and theoretical results via an extensive case study: the diagnosis of referable diabetic retinopathy.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found},
  annotation = {4 citations (Semantic Scholar/arXiv) [2023-05-08]}
}

@inproceedings{tanno_Bayesian_2017,
  title = {Bayesian {{Image Quality Transfer With CNNs}}: {{Exploring Uncertainty}} in {{dMRI Super-Resolution}}},
  booktitle = {Med. {{Image Comput}}. {{Comput}}. {{Assist}}. {{Interv}}. - {{MICCAI}} 2017},
  author = {Tanno, Ryutaro and Worrall, Daniel E. and Ghosh, Aurobrata and Kaden, Enrico and Sotiropoulos, Stamatios N. and Criminisi, Antonio and Alexander, Daniel C.},
  date = {2017},
  pages = {611--619},
  publisher = {{Springer International Publishing}},
  doi = {10.1007/978-3-319-66182-7_70},
  abstract = {In this work, we investigate the value of uncertainty modelling in 3D super-resolution with convolutional neural networks (CNNs). Deep learning has shown success in a plethora of medical image transformation problems, such as super-resolution (SR) and image synthesis. However, the highly ill-posed nature of such problems results in inevitable ambiguity in the learning of networks. We propose to account for intrinsic uncertainty through a per-patch heteroscedastic noise model and for parameter uncertainty through approximate Bayesian inference in the form of variational dropout. We show that the combined benefits of both lead to the state-of-the-art performance SR of diffusion MR brain images in terms of errors compared to ground truth. We further show that the reduced error scores produce tangible benefits in downstream tractography. In addition, the probabilistic nature of the methods naturally confers a mechanism to quantify uncertainty over the super-resolved output. We demonstrate through experiments on both healthy and pathological brains the potential utility of such an uncertainty measure in the risk assessment of the super-resolved images for subsequent clinical use.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {129 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{tanno_Uncertainty_2019,
  title = {Uncertainty {{Quantification}} in {{Deep Learning}} for {{Safer Neuroimage Enhancement}}},
  author = {Tanno, Ryutaro and Worrall, Daniel and Kaden, Enrico and Ghosh, Aurobrata and Grussu, Francesco and Bizzi, Alberto and Sotiropoulos, Stamatios N. and Criminisi, Antonio and Alexander, Daniel C.},
  date = {2019-07},
  url = {https://arxiv.org/abs/1907.13418},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{tao_DomainWeighted_2019,
  title = {Domain-{{Weighted Majority Voting}} for {{Crowdsourcing}}},
  author = {Tao, Dapeng and Cheng, Jun and Yu, Zhengtao and Yue, Kun and Wang, Lizhen},
  date = {2019-01},
  journaltitle = {IEEE Trans. Neural Netw. Learning Syst.},
  volume = {30},
  number = {1},
  pages = {163--174},
  issn = {2162-237X, 2162-2388},
  doi = {10.1109/TNNLS.2018.2836969},
  url = {https://ieeexplore.ieee.org/document/8372965/},
  urldate = {2022-12-28},
  keywords = {⛔ No INSPIRE recid found,Crowdsourcing,domain knowledge,Labeling,Machine learning,Noise measurement,Reliability,Task analysis,theoretical guarantee,Training,weighted majority voting (MV)},
  annotation = {53 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/M7UB4YIS/Tao et al. - 2019 - Domain-Weighted Majority Voting for Crowdsourcing.pdf}
}

@article{tao_Label_2020,
  title = {Label {{Similarity-Based Weighted Soft Majority Voting}} and {{Pairing}} for {{Crowdsourcing}}},
  author = {Tao, Fangna and Jiang, Liangxiao and Li, Chaoqun},
  date = {2020-07-01},
  journaltitle = {Knowl Inf Syst},
  volume = {62},
  number = {7},
  pages = {2521--2538},
  issn = {0219-3116},
  doi = {10.1007/s10115-020-01475-y},
  abstract = {Crowdsourcing services provide an efficient and relatively inexpensive approach to obtain substantial amounts of labeled data by employing crowd workers. It is obvious that the labeling qualities of crowd workers directly affect the quality of the labeled data. However, existing label aggregation strategies seldom consider the differences in the quality of workers labeling different instances. In this paper, we argue that a single worker may even have different labeling qualities on different instances. Based on this premise, we propose four new strategies by assigning different weights to workers when labeling different instances. In our proposed strategies, we first use the similarity among worker labels to estimate the specific quality of the worker on different instances, and then we build a classifier to estimate the overall quality of the worker across all instances. Finally, we combine these two qualities to define the weight of the worker labeling a particular instance. Extensive experimental results show that our proposed strategies significantly outperform other existing state-of-the-art label aggregation strategies.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Crowdsourcing,Label aggregation,Label similarity,Overall quality,Specific quality},
  annotation = {27 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/23KINMIZ/Tao et al. - 2020 - Label Similarity-Based Weighted Soft Majority Voti.pdf}
}

@article{taras_Does_2016,
  title = {Does {{Country Equate With Culture}}? {{Beyond Geography}} in the {{Search}} for {{Cultural Boundaries}}},
  author = {Taras, Vas and Steel, Piers and Kirkman, Bradley L.},
  date = {2016-08},
  journaltitle = {Manag Int Rev},
  volume = {56},
  number = {4},
  pages = {455--487},
  publisher = {{Springer Berlin Heidelberg}},
  doi = {10.1007/s11575-016-0283-x},
  abstract = {Traditionally, cultures have been treated as though they reside exclusively within, or perfectly overlap with countries. Indeed, the terms ``country'' and ``culture'' are often used interchangeably. As evidence mounts for substantial within-country cultural variation, and often between-country similarities, the problem with equating country and culture becomes more apparent. To help resolve the country-culture conundrum, we evaluate the extent to which political boundaries are suitable for clustering cultures based on a meta-analysis of 558 studies that used Hofstede's (Culture's consequences: international differences in work-related values. Sage Publications, Beverly Hills, 1980) cultural values framework. The results reveal that approximately 80 \% of variation in cultural values resides within countries, confirming that country is often a poor proxy for culture. We also evaluate the relative suitability of other demographic and environmental characteristics, such as occupation, socio-economic status, wealth, freedom, globalization, and instability. Our results suggest that it may be more appropriate to talk about cultures of professions, socio-economic classes, and free versus oppressed societies, than about cultures of countries.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {0 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{tarvainen_Mean_2017,
  title = {Mean {{Teachers Are Better Role Models}}: {{Weight-Averaged Consistency Targets Improve Semi-Supervised Deep Learning Results}}},
  booktitle = {Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.},
  author = {Tarvainen, Antti and Valpola, Harri},
  date = {2017},
  issn = {10495258},
  abstract = {The recently proposed Temporal Ensembling has achieved state-of-the-art results in several semi-supervised learning benchmarks. It maintains an exponential moving average of label predictions on each training example, and penalizes predictions that are inconsistent with this target. However, because the targets change only once per epoch, Temporal Ensembling becomes unwieldy when learning large datasets. To overcome this problem, we propose Mean Teacher, a method that averages model weights instead of label predictions. As an additional benefit, Mean Teacher improves test accuracy and enables training with fewer labels than Temporal Ensembling. Without changing the network architecture, Mean Teacher achieves an error rate of 4.35\% on SVHN with 250 labels, outperforming Temporal Ensembling trained with 1000 labels. We also show that a good network architecture is crucial to performance. Combining Mean Teacher and Residual Networks, we improve the state of the art on CIFAR-10 with 4000 labels from 10.55\% to 6.28\%, and on ImageNet 2012 with 10\% of the labels from 35.24\% to 9.11\%.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@book{tassinarylgberntsongg_Handbook_2017,
  title = {Handbook of {{Psychophysiology}}},
  author = {Tassinary LG Berntson GG, Cacioppo JT},
  date = {2017},
  publisher = {{Cambridge University Press (CUP)}},
  issn = {0033-2917},
  doi = {10.1017/s0033291707001201},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{tatarchenko_Octree_2017,
  title = {Octree {{Generating Networks}}: {{Efficient Convolutional Architectures}} for {{High-Resolution 3D Outputs}}},
  shorttitle = {Octree {{Generating Networks}}},
  booktitle = {2017 {{IEEE Int}}. {{Conf}}. {{Comput}}. {{Vis}}. {{ICCV}}},
  author = {Tatarchenko, Maxim and Dosovitskiy, Alexey and Brox, Thomas},
  date = {2017-10},
  pages = {2107--2115},
  publisher = {{IEEE}},
  location = {{Venice}},
  doi = {10.1109/ICCV.2017.230},
  url = {http://ieeexplore.ieee.org/document/8237492/},
  urldate = {2022-07-18},
  eventtitle = {2017 {{IEEE International Conference}} on {{Computer Vision}} ({{ICCV}})},
  isbn = {978-1-5386-1032-9},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/2NQB4W7A/Tatarchenko et al. - 2017 - Octree Generating Networks Efficient Convolutiona.pdf}
}

@inproceedings{tation3dmrimages_2017,
  ids = {Yu_Yang_Chen_Qin_Heng_2017,yu_Volumetric_2017},
  title = {Volumetric {{ConvNets With Mixed Residual Connections}} for {{Automated Prostate Segmentation From 3D MR Images}}},
  booktitle = {Proc. {{AAAI Conf}}. {{Artif}}. {{Intell}}.},
  author = {Yu, Lequan and Yang, Xin and Chen, Hao and Qin, Jing and Heng, Pheng Ann},
  date = {2017-02-10},
  volume = {31},
  doi = {10.1609/aaai.v31i1.10510},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/10510},
  urldate = {2023-05-10},
  abstract = {Automated prostate segmentation from 3D MR images is very challenging due to large variations of prostate shape and indistinct prostate boundaries. We propose a novel volumetric convolutional neural network (ConvNet) with mixed residual connections to cope with this challenging problem.  Compared with previous methods, our volumetric ConvNet has two compelling advantages. First, it is implemented in a 3D manner and can fully exploit the 3D spatial contextual information of input data to perform efficient, precise and volume-to-volume prediction. Second and more important, the novel combination of residual connections (i.e., long and short) can greatly improve the training efficiency and discriminative capability of our network by enhancing the information propagation within the ConvNet both locally and globally. While the forward propagation of location information can improve the segmentation accuracy, the smooth backward propagation of gradient flow can accelerate the convergence speed and enhance the discrimination capability.  Extensive experiments on the open MICCAI PROMISE12 challenge dataset corroborated the effectiveness of the proposed volumetric ConvNet with mixed residual connections. Our method ranked the first in the challenge, outperforming other competitors by a large margin with respect to most of evaluation metrics. The proposed volumetric ConvNet is general enough and can be easily extended to other medical image analysis tasks, especially ones with limited training data.},
  eventtitle = {{{AAAI}}},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {300 citations (Semantic Scholar/DOI) [2023-05-09]},
  file = {/Users/personal-macbook/Zotero/storage/K7E6X9SW/Yu et al. - 2017 - Volumetric ConvNets with Mixed Residual Connection.pdf}
}

@article{tattersfield_Toman_2005,
  title = {Toman's {{Tuberculosis}}: {{Case Detection}}, {{Treatment}} and {{Monitoring}}. {{Questions}} and {{Answers}}, 2nd {{Edition}}},
  author = {Tattersfield, A.},
  date = {2005-01},
  journaltitle = {Occup Env. Med},
  volume = {62},
  number = {1},
  pages = {70},
  publisher = {{BMJ Publishing Group}},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{taylor_Automated_2018,
  title = {Automated {{Detection}} of {{Clinically-Significant Pneumothorax}} on {{Frontal Chest X-Rays Using Deep Convolutional Neural Networks}}},
  author = {Taylor, A. G. and Mielke, C. and Mongan, J.},
  date = {2018},
  journaltitle = {PLoS Med.},
  volume = {15},
  number = {11},
  pages = {e1002697},
  doi = {10.1371/journal.pmed.1002697},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {135 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{teixeira_Adaptive_2013,
  title = {On {{Adaptive Fingerprint Pore Extraction}}},
  booktitle = {Lect. {{Notes Comput}}. {{Sci}}. {{Subser}}. {{Lect}}. {{Notes Artif}}. {{Intell}}. {{Lect}}. {{Notes Bioinforma}}.},
  author = {Teixeira, Raoni Florentino Da Silva and Leite, Neucimar Jer\^onimo},
  date = {2013},
  issn = {03029743},
  doi = {10.1007/978-3-642-39094-4_9},
  abstract = {Pore extraction appears to play an important role in latent (or fragmentary) fingerprint examination and in applications involving large population or high security levels. In this paper, we introduce a novel pore extraction approach designed to deal with anisotropic fingerprint aspects, which can be used to detect both closed and open pores. The method combines the directional field information with a toggle mapping to estimate fingerprint ridges location. It has proved to be very robust to noise and, as we will show through some experiments, it outperforms well-known state-of-the-art methods. Although we illustrate its application only on a specific database, our approach is quite general, simple and can be easily extended to others image applications involving similar feature extraction. \textcopyright{} 2013 Springer-Verlag.},
  isbn = {978-3-642-39093-7},
  keywords = {\#nosource,⛔ No INSPIRE recid found,biometrics,directional field information,mathematical morphology,multi-scale image simplification,pore extraction}
}

@inproceedings{teixeira_Improving_2014,
  title = {Improving {{Pore Extraction}} in {{High Resolution Fingerprint Images Using Spatial Analysis}}},
  booktitle = {2014 {{IEEE Int}}. {{Conf}}. {{Image Process}}. {{ICIP}} 2014},
  author = {Teixeira, Raoni F. S. and Leite, Neucimar J.},
  date = {2014},
  doi = {10.1109/ICIP.2014.7026005},
  abstract = {Pore extraction appears to play an important role in high resolution partial fingerprint recognition and in applications involving large population or high security levels. In this paper, we introduce a novel pore extraction approach which takes into account a new relation concerning their spatial and photometric dependence. This relation is given locally by analyzing distinct pores according to their distance and contrast. We evaluate our approach on high resolution pore extraction database and in an application involving partial fingerprint alignment. The proposed segmentation has proved to be quite general, simple and can accurately extract fingerprint pores in real images with different ridge and valley widths. It is also very robust to noise and according to the considered experiments outperforms well-known state-of-art methods.},
  isbn = {978-1-4799-5751-4},
  keywords = {\#nosource,⛔ No INSPIRE recid found,biometrics,high-resolution fingerprint,partial fingerprints,pore detection,Pore extraction},
  annotation = {14 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{teng_Comparison_2001,
  ids = {inproceedings},
  title = {A {{Comparison}} of {{Noise Handling Techniques}}.},
  booktitle = {{{FLAIRS Conf}}.},
  author = {Teng, Choh-Man},
  date = {2001-01},
  pages = {269--273},
  abstract = {Imperfections in data can arise from many sources. The qual-ity of the data is of prime concern to any task that involves data analysis. It is crucial that we have a good understanding of data imperfections and the effects of various noise han-dling techniques. We study here a number of noise handling approaches, namely, robust algorithms that are tolerant of some amount of noise in the data, filtering that eliminates the noisy instances from the input, and polishing which corrects the noisy instances rather than removing them. We evaluated the performance of these approaches experimentally. The re-sults indicated that in addition to the traditional approach of avoiding overfitting, both filtering and polishing can be vi-able mechanisms for reducing the negative effects of noise. Polishing in particular showed significant improvement over the other two approaches in many cases, suggesting that even though noise correction adds considerable complexity to the task, it also recovers information not available with the other two approaches.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{teye_Bayesian_2018,
  title = {Bayesian {{Uncertainty Estimation}} for {{Batch Normalized Deep Networks}}},
  booktitle = {35th {{Int}}. {{Conf}}. {{Mach}}. {{Learn}}. {{ICML}} 2018},
  author = {Teye, Mattias and Azizpour, Hossein and Smith, Kevin},
  date = {2018},
  abstract = {We show that training a deep network using batch normalization is equivalent to approximate inference in Bayesian models. We further demonstrate that this finding allows us to make meaningful estimates of the model uncertainty using conventional architectures, without modifications to the network or the training procedure. Our approach is thoroughly validated by measuring the quality of uncertainty in a series of empirical experiments on different tasks. It outperforms baselines with strong statistical significance, and displays competitive performance with recent Bayesian approaches.},
  isbn = {978-1-5108-6796-3},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{thiagarajan_Calibrating_2020,
  title = {Calibrating {{Healthcare AI}}: {{Towards Reliable}} and {{Interpretable Deep Predictive Models}}},
  author = {Thiagarajan, Jayaraman J. and Sattigeri, Prasanna and Rajan, Deepta and Venkatesh, Bindya},
  date = {2020-04},
  url = {http://arxiv.org/abs/2004.14480},
  abstract = {The wide-spread adoption of representation learning technologies in clinical decision making strongly emphasizes the need for characterizing model reliability and enabling rigorous introspection of model behavior. While the former need is often addressed by incorporating uncertainty quantification strategies, the latter challenge is addressed using a broad class of interpretability techniques. In this paper, we argue that these two objectives are not necessarily disparate and propose to utilize prediction calibration to meet both objectives. More specifically, our approach is comprised of a calibration-driven learning method, which is also used to design an interpretability technique based on counterfactual reasoning. Furthermore, we introduce \textbackslash textit\{reliability plots\}, a holistic evaluation mechanism for model reliability. Using a lesion classification problem with dermoscopy images, we demonstrate the effectiveness of our approach and infer interesting insights about the model behavior.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found},
  annotation = {12 citations (Semantic Scholar/arXiv) [2023-05-08]}
}

@thesis{thomas_Fast_2017,
  title = {Fast {{Automatic Segmentation}} of {{Thalamic Nuclei}}},
  author = {Thomas, Francis Tyson and Bilgin, Ali and Saranathan, Manojkumar},
  date = {2017},
  institution = {{The University of Arizona}},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{thompson_Computational_2007,
  title = {Computational {{Anatomical Methods}} as {{Applied}} to {{Ageing}} and {{Dementia}}},
  author = {Thompson, P. M. and Apostolova, L. G.},
  date = {2007-12},
  journaltitle = {Br. J. Radiol.},
  volume = {80 Spec No},
  pages = {S78--91},
  abstract = {The cellular hallmarks of Alzheimer's disease (AD) accumulate in the living brain up to 30 years before the characteristic symptoms of dementia can be identified. Brain changes in AD are difficult to distinguish from those in normal ageing, and this has led to the development of powerful computational methods to extract statistical information on the brain changes that are characteristic of AD, mild cognitive impairment (MCI) and different dementia subtypes. Time-lapse maps can be built to show how the disease spreads in the brain, and where treatment affects the disease trajectory. Here, we review three computational approaches to map brain deficits in AD: cortical thickness maps, tensor-based morphometry and hippocampal/ventricular surface modelling. Anatomical structures, modelled as three-dimensional geometrical surfaces, are mathematically combined across subjects for group or interval comparisons. Mathematical concepts from computational surface modelling, fluid mechanics and multivariate statistics are exploited to distinguish disease from normal variations in brain structure. These methods yield insight into the dynamics of AD and MCI, showing where brain changes correlate with cognitive or behavioural changes such as language dysfunction or apathy. We describe cortical and hippocampal changes that distinguish dementia subtypes (such as Lewy-body dementia, HIV-associated dementia and AD), and we describe brain changes that predict recovery or decline in those at risk. Finally, we indicate which computational methods are powerful enough to track dementia in clinical trials, on the basis of their efficiency and sensitivity to early change, and the detail in the measures they provide.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{thornton_Letter_1975,
  title = {Letter: {{Duration}} of {{Action}} of {{AH8165}}},
  shorttitle = {Letter},
  author = {Thornton, J. A. and Harrison, M. J.},
  date = {1975-09},
  journaltitle = {Br J Anaesth},
  volume = {47},
  number = {9},
  eprint = {28},
  eprinttype = {pmid},
  pages = {1033},
  issn = {0007-0912},
  doi = {10.1093/bja/47.9.1033},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,{Dose-Response Relationship, Drug},Hemodynamics,Humans,Pyridinium Compounds,Time Factors},
  annotation = {5 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{thorpe_Speed_1996,
  title = {Speed of {{Processing}} in the {{Human Visual System}}},
  author = {Thorpe, S. and Fize, D. and Marlot, C.},
  date = {1996-06},
  journaltitle = {Nature},
  volume = {381},
  number = {6582},
  pages = {520--522},
  doi = {10.1038/381520a0},
  abstract = {How long does it take for the human visual system to process a complex natural image? Subjectively, recognition of familiar objects and scenes appears to be virtually instantaneous, but measuring this processing time experimentally has proved difficult. Behavioural measures such as reaction times can be used, but these include not only visual processing but also the time required for response execution. However, event-related potentials (ERPs) can sometimes reveal signs of neural processing well before the motor output. Here we use a go/no-go categorization task in which subjects have to decide whether a previously unseen photograph, flashed on for just 20 ms, contains an animal. ERP analysis revealed a frontal negativity specific to no-go trials that develops roughly 150 ms after stimulus onset. We conclude that the visual processing needed to perform this highly demanding task can be achieved in under 150 ms.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{thyreau_Segmentation_2018,
  title = {Segmentation of the {{Hippocampus}} by {{Transferring Algorithmic Knowledge}} for {{Large Cohort Processing}}},
  author = {Thyreau, Benjamin and Sato, Kazunori and Fukuda, Hiroshi and Taki, Yasuyuki},
  date = {2018-01},
  journaltitle = {Med. Image Anal.},
  volume = {43},
  pages = {214--228},
  doi = {10.1016/j.media.2017.11.004},
  abstract = {The hippocampus is a particularly interesting target for neuroscience research studies due to its essential role within the human brain. In large human cohort studies, bilateral hippocampal structures are frequently identified and measured to gain insight into human behaviour or genomic variability in neuropsychiatric disorders of interest. Automatic segmentation is performed using various algorithms, with FreeSurfer being a popular option. In this manuscript, we present a method to segment the bilateral hippocampus using a deep-learned appearance model. Deep convolutional neural networks (ConvNets) have shown great success in recent years, due to their ability to learn meaningful features from a mass of training data. Our method relies on the following key novelties: (i) we use a wide and variable training set coming from multiple cohorts (ii) our training labels come in part from the output of the FreeSurfer algorithm, and (iii) we include synthetic data and use a powerful data augmentation scheme. Our method proves to be robust, and it has fast inference ({$<$}30s total per subject), with trained model available online (https://github.com/bthyreau/hippodeep). We depict illustrative results and show extensive qualitative and quantitative cohort-wide comparisons with FreeSurfer. Our work demonstrates that deep neural-network methods can easily encode, and even improve, existing anatomical knowledge, even when this knowledge exists in algorithmic form.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{tian_MaxMargin_2019,
  title = {Max-{{Margin Majority Voting}} for {{Learning From Crowds}}},
  author = {Tian, Tian and Zhu, Jun and Qiaoben, You},
  date = {2019-10-01},
  journaltitle = {IEEE Trans. Pattern Anal. Mach. Intell.},
  volume = {41},
  number = {10},
  pages = {2480--2494},
  issn = {0162-8828, 2160-9292, 1939-3539},
  doi = {10.1109/TPAMI.2018.2860987},
  url = {https://ieeexplore.ieee.org/document/8423686/},
  urldate = {2022-12-20},
  keywords = {⛔ No INSPIRE recid found,Bayes methods,crowdsourcing,Crowdsourcing,Labeling,Max-margin learning,Maximum likelihood estimation,Noise measurement,online learning,regularized Bayesian inference,Task analysis},
  annotation = {90 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/2FV4BIEK/Tian et al. - 2019 - Max-Margin Majority Voting for Learning from Crowd.pdf}
}

@article{tjoa_Survey_2021,
  ids = {tjoa_Survey_2019},
  title = {A {{Survey}} on {{Explainable Artificial Intelligence}} ({{XAI}}): {{Toward Medical XAI}}},
  shorttitle = {A {{Survey}} on {{Explainable Artificial Intelligence}} ({{XAI}})},
  author = {Tjoa, Erico and Guan, Cuntai},
  date = {2021-11},
  journaltitle = {IEEE Trans. Neural Netw. Learning Syst.},
  volume = {32},
  number = {11},
  pages = {4793--4813},
  issn = {2162-237X, 2162-2388},
  doi = {10.1109/TNNLS.2020.3027314},
  url = {https://ieeexplore.ieee.org/document/9233366/},
  urldate = {2023-05-08},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {653 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/78HIIYGI/Tjoa and Guan - 2021 - A Survey on Explainable Artificial Intelligence (X.pdf}
}

@inproceedings{tomasi_Bilateral_1998,
  title = {Bilateral {{Filtering}} for {{Gray}} and {{Color Images}}},
  booktitle = {Proc. {{IEEE Int}}. {{Conf}}. {{Comput}}. {{Vis}}.},
  author = {Tomasi, C. and Manduchi, R.},
  date = {1998},
  doi = {10.1109/iccv.1998.710815},
  abstract = {Bilateral filtering smooths images while preserving edges, by means of a nonlinear combination of nearby image values. The method is noniterative, local, and simple. It combines gray levels or colors based on both their geometric closeness and their photometric similarity, and prefers near values to distant values in both domain and range. In contrast with filters that operate on the three bands of a color image separately, a bilateral filter can enforce the perceptual metric underlying the CIE-Lab color space, and smooth colors and preserve edges in a way that is tuned to human perception. Also, in contrast with standard filtering, bilateral filtering produces no phantom colors along edges in color images, and reduces phantom colors where they appear in the original image.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {8901 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@online{tomczack_learnestimatelabelsuncertaintyqualityassurance_2019,
  ids = {tomczack_Learn_2019},
  title = {Learn to {{Estimate Labels Uncertainty}} for {{Quality Assurance}}},
  author = {Tomczack, Agnieszka and Navab, Nassir and Albarqouni, Shadi},
  date = {2019},
  doi = {10.48550/ARXIV.1909.08058},
  url = {https://arxiv.org/abs/1909.08058},
  urldate = {2023-05-08},
  abstract = {Deep Learning sets the state-of-the-art in many challenging tasks showing outstanding performance in a broad range of applications. Despite its success, it still lacks robustness hindering its adoption in medical applications. Modeling uncertainty, through Bayesian Inference and Monte-Carlo dropout, has been successfully introduced for better understanding the underlying deep learning models. Yet, another important source of uncertainty, coming from the inter-observer variability, has not been thoroughly addressed in the literature. In this paper, we introduce labels uncertainty which better suits medical applications and show that modeling such uncertainty together with epistemic uncertainty is of high interest for quality control and referral systems.},
  pubstate = {preprint},
  version = {1},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found,Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences},
  annotation = {6 citations (Semantic Scholar/arXiv) [2023-05-08]}
}

@article{tome_Lifting_2017,
  title = {Lifting {{From}} the {{Deep}}: {{Convolutional 3D Pose Estimation From}} a {{Single Image}}},
  author = {Tome, Denis and Russell, Chris and Agapito, Lourdes},
  date = {2017-01},
  abstract = {We propose a unified formulation for the problem of 3D human pose estimation from a single raw RGB image that reasons jointly about 2D joint estimation and 3D pose reconstruction to improve both tasks. We take an integrated approach that fuses probabilistic knowledge of 3D human pose with a multi-stage CNN architecture and uses the knowledge of plausible 3D landmark locations to refine the search for better 2D locations. The entire process is trained end-to-end, is extremely efficient and obtains state- of-the-art results on Human3.6M outperforming previous approaches both on 2D and 3D errors.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{tompson_Joint_2014,
  title = {Joint {{Training}} of a {{Convolutional Network}} and a {{Graphical Model}} for {{Human Pose Estimation}}},
  author = {Tompson, Jonathan and Jain, Arjun and LeCun, Yann and Bregler, Christoph},
  date = {2014-06},
  abstract = {This paper proposes a new hybrid architecture that consists of a deep Convolutional Network and a Markov Random Field. We show how this architecture is successfully applied to the challenging problem of articulated human pose estimation in monocular images. The architecture can exploit structural domain constraints such as geometric relationships between body joint locations. We show that joint training of these two model paradigms improves performance and allows us to significantly outperform existing state-of-the-art techniques.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@inproceedings{tongxiao_Learning_2015,
  ids = {xiao_Learning_2015},
  title = {Learning {{From Massive Noisy Labeled Data}} for {{Image Classification}}},
  booktitle = {2015 {{IEEE Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}. {{CVPR}}},
  author = {{Tong Xiao} and {Tian Xia} and {Yi Yang} and {Chang Huang} and {Xiaogang Wang}},
  date = {2015-06},
  pages = {2691--2699},
  publisher = {{IEEE}},
  location = {{Boston, MA, USA}},
  doi = {10.1109/CVPR.2015.7298885},
  url = {http://ieeexplore.ieee.org/document/7298885/},
  urldate = {2023-05-08},
  eventtitle = {2015 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-4673-6964-0},
  keywords = {\#nosource,⛔ No INSPIRE recid found,clothing,computer vision,convolution,image classif},
  annotation = {832 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@book{topol_DEEP_2019,
  title = {{{DEEP MEDICINE}}: {{How Artificial Intelligence Can Make Healthcare Human Again}}},
  author = {Topol, Eric},
  date = {2019},
  journaltitle = {Perspectives on Science and Christian Faith},
  abstract = {First edition. "Despite having access to more resources than ever, our doctors are overloaded with demands for their time and expertise. In Deep Medicine, leading physician Eric Topol shows how artificial intelligence can help. Natural-language processing can record our doctor's notes, make sense of our medical histories, and read more deeply into the scientific literature than any human ever could. Deep-learning algorithms \textendash{} applied to wearable sensors, genomic information, blood work, scans, and all of our medical data \textendash{} can create bespoke treatment plans. And virtual medical assistants, powered by personalized AI, can provide us with coaching to promote our health, shape our diet, and even prevent illness. Bust most importantly, by freeing physicians from the tasks that interfere with human connection, AI will give doctors the gift of time \textendash{} to restore the care in healthcare. Innovative, provocative, and hopeful, Deep Medicine shows us how the awesome power of AI can make medicine better, and reveals the paradox that machines can make humans healthier \textendash{} and more human"\textendash{} Introduction to deep medicine \textendash{} Shallow medicine \textendash{} Medical diagnosis \textendash{} The skinny on deep learning \textendash{} Deep liabilities \textendash{} Doctors and patterns \textendash{} Clinicians without patterns \textendash{} Mental health \textendash{} AI and health systems \textendash{} Deep discovery \textendash{} Deep diet \textendash{} The virtual medical assistant \textendash{} Deep empathy.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{topol_Highperformance_2019,
  title = {High-{{Performance Medicine}}: {{The Convergence}} of {{Human}} and {{Artificial Intelligence}}},
  author = {Topol, Eric J.},
  date = {2019-01},
  journaltitle = {Nat. Med.},
  volume = {25},
  number = {1},
  eprint = {30617339},
  eprinttype = {pmid},
  pages = {44--56},
  publisher = {{Nature Publishing Group}},
  issn = {1546170X},
  doi = {10.1038/s41591-018-0300-7},
  url = {https://doi.org/10.1038/s41591-018-0300-7},
  abstract = {The use of artificial intelligence, and the deep-learning subtype in particular, has been enabled by the use of labeled big data, along with markedly enhanced computing power and cloud storage, across all sectors. In medicine, this is beginning to have an impact at three levels: for clinicians, predominantly via rapid, accurate image interpretation; for health systems, by improving workflow and the potential for reducing medical errors; and for patients, by enabling them to process their own data to promote health. The current limitations, including bias, privacy and security, and lack of transparency, along with the future directions of these applications will be discussed in this article. Over time, marked improvements in accuracy, productivity, and workflow will likely be actualized, but whether that will be used to improve the patient\textendash doctor relationship or facilitate its erosion remains to be seen.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Health care,Machine learning},
  annotation = {2311 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{toshev_DeepPose_2013,
  title = {{{DeepPose}}: {{Human Pose Estimation}} via {{Deep Neural Networks}}},
  author = {Toshev, Alexander and Szegedy, Christian},
  date = {2013-12},
  abstract = {We propose a method for human pose estimation based on Deep Neural Networks (DNNs). The pose estimation is formulated as a DNN-based regression problem towards body joints. We present a cascade of such DNN regressors which results in high precision pose estimates. The approach has the advantage of reasoning about pose in a holistic fashion and has a simple but yet powerful formulation which capitalizes on recent advances in Deep Learning. We present a detailed empirical analysis with state-of-art or better performance on four academic benchmarks of diverse real-world images.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{tourdias_Visualization_2014,
  title = {Visualization of {{Intra-Thalamic Nuclei With Optimized White-Matter-Nulled Mprage}} at {{7T}}},
  author = {Tourdias, Thomas and Saranathan, Manojkumar and Levesque, Ives R. and Su, Jason and Rutt, Brian K.},
  date = {2014-01},
  journaltitle = {NeuroImage},
  volume = {84},
  pages = {534--545},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2013.08.069},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811913009348},
  urldate = {2023-05-10},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,7T,Anterior ventral nucleus,AV,CM,CNR,COM,CS,Thalamic nuclei,Thalamus,Ultra high field,White matter nulled MPRAGE},
  annotation = {107 citations (Semantic Scholar/DOI) [2023-05-09]},
  file = {/Users/personal-macbook/Zotero/storage/BU33X4NU/Tourdias et al. - 2014 - Visualization of intra-thalamic nuclei with optimi.pdf}
}

@article{toyoda_Random_2008,
  title = {Random {{Field Model}} for {{Integration}} of {{Local Information}} and {{Global Information}}},
  author = {Toyoda, Takahiro and Hasegawa, Osamu},
  date = {2008-08},
  journaltitle = {IEEE Trans. Pattern Anal. Mach. Intell.},
  volume = {30},
  number = {8},
  pages = {1483--1489},
  doi = {10.1109/TPAMI.2008.105},
  abstract = {This paper presents a proposal of a general framework that explicitly models local information and global information in a conditional random field. The proposed method extracts global image features as well as local ones and uses them to predict the scene of the input image. Scene-based top-down information is generated based on the predicted scene. It represents a global spatial configuration of labels and category compatibility over an image. Incorporation of the global information helps to resolve local ambiguities and achieves locally and globally consistent image recognition. In spite of the model's simplicity, the proposed method demonstrates good performance in image labeling of two datasets.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{tran_Learning_2014,
  title = {Learning {{Spatiotemporal Features With 3D Convolutional Networks}}},
  author = {Tran, Du and Bourdev, Lubomir and Fergus, Rob and Torresani, Lorenzo and Paluri, Manohar},
  date = {2014-12},
  abstract = {We propose a simple, yet effective approach for spatiotemporal feature learning using deep 3-dimensional convolutional networks (3D ConvNets) trained on a large scale supervised video dataset. Our findings are three-fold: 1) 3D ConvNets are more suitable for spatiotemporal feature learning compared to 2D ConvNets; 2) A homogeneous architecture with small 3x3x3 convolution kernels in all layers is among the best performing architectures for 3D ConvNets; and 3) Our learned features, namely C3D (Convolutional 3D), with a simple linear classifier outperform state-of-the-art methods on 4 different benchmarks and are comparable with current best methods on the other 2 benchmarks. In addition, the features are compact: achieving 52.8\% accuracy on UCF101 dataset with only 10 dimensions and also very efficient to compute due to the fast inference of ConvNets. Finally, they are conceptually very simple and easy to train and use.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{traynor_Reproducibility_2010,
  title = {Reproducibility of {{Thalamic Segmentation Based}} on {{Probabilistic Tractography}}},
  author = {Traynor, Catherine and Heckemann, Rolf A. and Hammers, Alexander and O'Muircheartaigh, Jonathan and Crum, William R. and Barker, Gareth J. and Richardson, Mark P.},
  date = {2010-08},
  journaltitle = {Neuroimage},
  volume = {52},
  number = {1},
  pages = {69--85},
  doi = {10.1016/j.neuroimage.2010.04.024},
  abstract = {Reliable identification of thalamic nuclei is required to improve targeting of electrodes used in Deep Brain Stimulation (DBS), and for exploring the role of thalamus in health and disease. A previously described method using probabilistic tractography to segment the thalamus based on connections to cortical target regions was implemented. Both within- and between-subject reproducibility were quantitatively assessed by the overlap of the resulting segmentations; the effect of two different numbers of target regions (6 and 31) on reproducibility of the segmentation results was also investigated. Very high reproducibility was observed when a single dataset was processed multiple times using different starting conditions. Thalamic segmentation was also very reproducible when multiple datasets from the same subject were processed using six cortical target regions. Within-subject reproducibility was reduced when the number of target regions was increased, particularly in medial and posterior regions of the thalamus. A large degree of overlap in segmentation results from different subjects was obtained, particularly in thalamic regions classified as connecting to frontal, parietal, temporal and pre-central cortical target regions.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{traynor_Segmentation_2011,
  title = {Segmentation of the {{Thalamus}} in {{MRI Based}} on {{T1}} and {{T2}}},
  author = {Traynor, Catherine R. and Barker, Gareth J. and Crum, William R. and Williams, Steve C. R. and Richardson, Mark P.},
  date = {2011-06},
  journaltitle = {Neuroimage},
  volume = {56},
  number = {3},
  pages = {939--950},
  doi = {10.1016/j.neuroimage.2011.01.083},
  abstract = {Reliable identification of thalamic nuclei is required to improve positioning of electrodes in Deep Brain Stimulation (DBS), and to allow the role of individual thalamic nuclei in health and disease to be fully investigated. In this work, a previously proposed method for identifying sub-regions within the thalamus based on differences in their T1 and T2 values is explored in detail. The effect on the segmentation of T1 and T2 dependence weighted against priors for spatial position and extent was investigated. When T1 and T2 dependence was highly weighted, good distinction between identified regions was obtained in T1/T2 feature-space, but no contiguous anatomically distinct regions were identified within the thalamus. Incorporating spatial priors was necessary to ensure anatomically distinct regions were defined. Optimal values for segmentation parameters were obtained by assessing performance on a 'synthetic thalamus'. Using these optimum input parameters, within- and between-subjects reproducibility was assessed. Good reproducibility was obtained when six regions were specified to be identified in the thalamus. The six regions identified were similar in the majority of the normal subject group. However, intriguingly these regions were different from those obtained in the same subjects using a well-known connectivity-based segmentation technique. This method shows promise to identify intrathalamic structures on the basis of T1 and T2 signal. A comprehensive characterisation of thalamic nuclei may require a fully multi-modal approach.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{tripathi_Morphology_2015,
  title = {Morphology of {{Human Sweat Ducts Observed}} by {{Optical Coherence Tomography}} and {{Their Frequency}} of {{Resonance}} in the {{Terahertz Frequency Region}}},
  author = {Tripathi, Saroj R. and Miyata, Eisuke and Ishai, Paul Ben and Kawase, Kodo},
  date = {2015},
  journaltitle = {Sci. Rep.},
  eprint = {25766116},
  eprinttype = {pmid},
  issn = {20452322},
  doi = {10.1038/srep09071},
  abstract = {It is crucial to understand the various biological effects induced by terahertz (THz) electromagnetic waves with the rapid development of electronic and photonic devices operating in the THz frequency region. The presence of sweat glands plays an important role in THz wave interactions with human skin. We investigated the morphological features of sweat ducts using optical coherence tomography (OCT) to further understand such phenomena. We observed remarkable features of the ducts, such as their clear helical structure. The intersubject and intrasubject variations in the diameter of sweat ducts were considerably smaller than the variations in other structural parameters, such as length and number of turns. Based on the sweat duct dimensions and THz dielectric properties of skin measured using terahertz time-domain spectroscopy (THz-TDS), we calculated the resonating frequency of the sweat duct under the assumption of it functioning as a helical antenna. Here, we show that the resonance frequency in the axial mode of operation lies in the THz wave region with a centre frequency of 0.44 {$\pm$} 0.07 THz. We expect that these findings will further our understanding of the various health consequences of the interaction of THz waves with human beings.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@report{troyanskaya_Artificial_,
  title = {Artificial {{Intelligence}} and {{Cancer}}},
  author = {Troyanskaya, Olga and Trajanoski, Zlatko and Carpenter, Anne and Thrun, Sebastian and Razavian, Narges and Oliver, Nuria},
  url = {www.nature.com/natcancer},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{tsai_Adversarial_2019,
  title = {Adversarial {{Learning}} of {{Label Dependency}}: {{A Novel Framework}} for {{Multi-Class Classification}}},
  shorttitle = {Adversarial {{Learning}} of {{Label Dependency}}},
  booktitle = {Int. {{Conf}}. {{Acoust}}. {{Speech Signal Process}}. {{ICASSP}}},
  author = {Tsai, Che-Ping and Lee, Hung-Yi},
  date = {2019-05},
  pages = {3847--3851},
  publisher = {{IEEE}},
  location = {{Brighton, United Kingdom}},
  doi = {10.1109/ICASSP.2019.8682549},
  url = {https://ieeexplore.ieee.org/document/8682549/},
  urldate = {2022-11-21},
  eventtitle = {International {{Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  isbn = {978-1-4799-8131-1},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {6 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/XUWR9JUU/Tsai and Lee - 2019 - Adversarial Learning of Label Dependency A Novel .pdf}
}

@inproceedings{tsai_Learning_2018,
  title = {Learning to {{Adapt Structured Output Space}} for {{Semantic Segmentation}}},
  booktitle = {Proc. {{IEEE Comput}}. {{Soc}}. {{Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}.},
  author = {Tsai, Yi Hsuan and Hung, Wei Chih and Schulter, Samuel and Sohn, Kihyuk and Yang, Ming Hsuan and Chandraker, Manmohan},
  date = {2018},
  issn = {10636919},
  doi = {10.1109/CVPR.2018.00780},
  abstract = {Convolutional neural network-based approaches for semantic segmentation rely on supervision with pixel-level ground truth, but may not generalize well to unseen image domains. As the labeling process is tedious and labor intensive, developing algorithms that can adapt source ground truth labels to the target domain is of great interest. In this paper, we propose an adversarial learning method for domain adaptation in the context of semantic segmentation. Considering semantic segmentations as structured outputs that contain spatial similarities between the source and target domains, we adopt adversarial learning in the output space. To further enhance the adapted model, we construct a multi-level adversarial network to effectively perform output space domain adaptation at different feature levels. Extensive experiments and ablation study are conducted under various domain adaptation settings, including synthetic-to-real and cross-city scenarios. We show that the proposed method performs favorably against the state-of-the-art methods in terms of accuracy and visual quality.},
  isbn = {978-1-5386-6420-9},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {1039 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{tsang_Enhanced_2010,
  title = {Enhanced {{Surveillance}} of {{Coccidioidomycosis}}, {{Arizona}}, {{USA}}, 2007-2008},
  author = {Tsang, Clarisse A. and Anderson, Shoana M. and Imholte, Sara B. and Erhart, Laura M. and Chen, Sanny and Park, Benjamin J. and Christ, Cara and Komatsu, Kenneth K. and Chiller, Tom and Sunenshine, Rebecca H.},
  date = {2010-11},
  journaltitle = {Emerg. Infect. Dis.},
  volume = {16},
  number = {11},
  pages = {1738--1744},
  doi = {10.3201/eid1611.100475},
  abstract = {Coccidioidomycosis is endemic to the southwestern United States; 60\% of nationally reported cases occur in Arizona. Although the Council of State and Territorial Epidemiologists case definition for coccidioidomycosis requires laboratory and clinical criteria, Arizona uses only laboratory criteria. To validate this case definition and characterize the effects of coccidioidomycosis in Arizona, we interviewed every tenth case-patient with coccidioidomycosis reported during January 2007-February 2008. Of 493 patients interviewed, 44\% visited the emergency department, and 41\% were hospitalized. Symptoms lasted a median of 120 days. Persons aware of coccidioidomycosis before seeking healthcare were more likely to receive an earlier diagnosis than those unaware of the disease (p = 0.04) and to request testing for Coccidioides spp. (p = 0.05). These findings warrant greater public and provider education. Ninety-five percent of patients interviewed met the Council of State and Territorial Epidemiologists clinical case definition, validating the Arizona laboratory-based case definition for surveillance in a coccidiodomycosis-endemic area.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {108 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{tsoumakas_MultiLabel_2007,
  title = {Multi-Label Classification: An Overview},
  shorttitle = {Multi-Label Classification},
  author = {Tsoumakas, Grigorios and Katakis, Ioannis},
  date = {2007-07-01},
  journaltitle = {Int. J. Data Warehous. Min.},
  volume = {3},
  number = {3},
  pages = {1--13},
  issn = {1548-3924, 1548-3932},
  doi = {10.4018/jdwm.2007070101},
  url = {https://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/jdwm.2007070101},
  urldate = {2022-11-21},
  abstract = {Multi-label classification methods are increasingly required by modern applications, such as protein function classification, music categorization, and semantic scene classification. This article introduces the task of multi-label classification, organizes the sparse related literature into a structured presentation and performs comparative experimental results of certain multilabel classification methods. It also contributes the definition of concepts for the quantification of the multi-label nature of a data set.},
  langid = {ng},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {2460 citations (Semantic Scholar/DOI) [2022-11-21]}
}

@inproceedings{tu_MultiLabel_2018,
  title = {Multi-{{Label Answer Aggregation Based}} on {{Joint Matrix Factorization}}},
  booktitle = {2018 {{IEEE Int}}. {{Conf}}. {{Data Min}}. {{ICDM}}},
  author = {Tu, Jinzheng and Yu, Guoxian and Domeniconi, Carlotta and Wang, Jun and Xiao, Guoqiang and Guo, Maozu},
  date = {2018-11},
  pages = {517--526},
  publisher = {{IEEE}},
  location = {{Singapore}},
  doi = {10.1109/ICDM.2018.00067},
  url = {https://ieeexplore.ieee.org/document/8594876/},
  urldate = {2023-03-29},
  eventtitle = {2018 {{IEEE International Conference}} on {{Data Mining}} ({{ICDM}})},
  isbn = {978-1-5386-9159-5},
  keywords = {⛔ No INSPIRE recid found,Correlation,Crowdsourcing,{Crowdsourcing, Multi-Label Learning, Joint Matrix Factorization, Spammers},Image annotation,Labeling,Noise measurement,Reliability,Task analysis},
  file = {/Users/personal-macbook/Zotero/storage/7E9J3I3V/Tu et al. - 2018 - Multi-Label Answer Aggregation Based on Joint Matr.pdf}
}

@inproceedings{tung_Multiatlas_2013,
  title = {Multi-{{Atlas Based Neointima Segmentation}} in {{Intravascular Coronary OCT}}},
  booktitle = {2013 {{IEEE}} 10th {{Int}}. {{Symp}}. {{Biomed}}. {{Imaging}}},
  author = {Tung, K. P. and Bei, W. J. and Shi, W. Z. and Wang, H. Y. and Tong, T. and Silva, R. De and Edwards, E. and Rueckert, D.},
  date = {2013-04},
  pages = {1280--1283},
  abstract = {Neointima thickening plays a decisive role in coronary restenosis after stenting. The aim of this study is to detect neointima tissue in intravascular optical coherence tomography (IVOCT) sequences. We developed a multi-atlas based segmentation method to detect neointima without stent struts locations. The atlases are selected by measurements of stenosis and a similarity metric. The probability map is then used to estimate neointima label in the unseen image. To account for the registration errors, a patch-based label fusion approach is applied. Validation is performed using 18 typical in-vivo IVOCT sequences. The comparison against manual expert segmentation and other fusion approaches demonstrates that the proposed neointima identification is robust and accurate.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,diseases,image fusion,image registration,image seg}
}

@inproceedings{tzeng_Adversarial_2017,
  title = {Adversarial {{Discriminative Domain Adaptation}}},
  booktitle = {Proc. - 30th {{IEEE Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}. {{CVPR}} 2017},
  author = {Tzeng, Eric and Hoffman, Judy and Saenko, Kate and Darrell, Trevor},
  date = {2017},
  doi = {10.1109/CVPR.2017.316},
  abstract = {Adversarial learning methods are a promising approach to training robust deep networks, and can generate complex samples across diverse domains. They can also improve recognition despite the presence of domain shift or dataset bias: recent adversarial approaches to unsupervised domain adaptation reduce the difference between the training and test domain distributions and thus improve generalization performance. However, while generative adversarial networks (GANs) show compelling visualizations, they are not optimal on discriminative tasks and can be limited to smaller shifts. On the other hand, discriminative approaches can handle larger domain shifts, but impose tied weights on the model and do not exploit a GAN-based loss. In this work, we first outline a novel generalized framework for adversarial adaptation, which subsumes recent state-of-the-art approaches as special cases, and use this generalized view to better relate prior approaches. We then propose a previously unexplored instance of our general framework which combines discriminative modeling, untied weight sharing, and a GAN loss, which we call Adversarial Discriminative Domain Adaptation (ADDA). We show that ADDA is more effective yet considerably simpler than competing domainadversarial methods, and demonstrate the promise of our approach by exceeding state-of-the-art unsupervised adaptation results on standard domain adaptation tasks as well as a difficult cross-modality object classification task.},
  isbn = {978-1-5386-0457-1},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {3484 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{tzeng_Deep_2014,
  title = {Deep {{Domain Confusion}}: {{Maximizing}} for {{Domain Invariance}}},
  author = {Tzeng, Eric and Hoffman, Judy and Zhang, Ning and Saenko, Kate and Darrell, Trevor},
  date = {2014-12},
  abstract = {Recent reports suggest that a generic supervised deep CNN model trained on a large-scale dataset reduces, but does not remove, dataset bias on a standard benchmark. Fine-tuning deep models in a new domain can require a significant amount of data, which for many applications is simply not available. We propose a new CNN architecture which introduces an adaptation layer and an additional domain confusion loss, to learn a representation that is both semantically meaningful and domain invariant. We additionally show that a domain confusion metric can be used for model selection to determine the dimension of an adaptation layer and the best position for the layer in the CNN architecture. Our proposed adaptation method offers empirical performance which exceeds previously published results on a standard benchmark visual domain adaptation task.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{uhlmann_FlyLimbTracker_2017,
  title = {{{FlyLimbTracker}}: {{An Active Contour Based Approach}} for {{Leg Segment Tracking}} in {{Unmarked}}, {{Freely Behaving Drosophila}}},
  author = {Uhlmann, Virginie and Ramdya, Pavan and Delgado-Gonzalo, Ricard and Benton, Richard and Unser, Michael},
  date = {2017-04},
  journaltitle = {PLoS One},
  volume = {12},
  number = {4},
  pages = {e0173433},
  doi = {10.1371/journal.pone.0173433},
  abstract = {Understanding the biological underpinnings of movement and action requires the development of tools for quantitative measurements of animal behavior. Drosophila melanogaster provides an ideal model for developing such tools: the fly has unparalleled genetic accessibility and depends on a relatively compact nervous system to generate sophisticated limbed behaviors including walking, reaching, grooming, courtship, and boxing. Here we describe a method that uses active contours to semi-automatically track body and leg segments from video image sequences of unmarked, freely behaving D. melanogaster. We show that this approach yields a more than 6-fold reduction in user intervention when compared with fully manual annotation and can be used to annotate videos with low spatial or temporal resolution for a variety of locomotor and grooming behaviors. FlyLimbTracker, the software implementation of this method, is open-source and our approach is generalizable. This opens up the possibility of tracking leg movements in other species by modifications of underlying active contour models.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {36 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@incollection{university_2016_,
  title = {From 2016 to 2018, {{He Was}} a {{Post-Doctoral Fellow}}},
  author = {University, Washington and St. Louis, M.O. and {U.S.A.}},
  publisher = {{Inc}},
  location = {{San Diego, CA, USA}},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{upadhyay_Robustness_2021,
  title = {Robustness via {{Uncertainty-Aware Cycle Consistency}}},
  author = {Upadhyay, Uddeshya and Chen, Yanbei and Akata, Zeynep},
  date = {2021-10-22},
  url = {https://openreview.net/forum?id=PYcdGhnZQJh},
  urldate = {2022-07-04},
  abstract = {We introduce uncertainty estimation in unpaired image translation to make it more robust},
  eventtitle = {Advances in {{Neural Information Processing Systems}}},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/Q3VYAKW5/Upadhyay et al. - 2021 - Robustness via Uncertainty-aware Cycle Consistency.pdf;/Users/personal-macbook/Zotero/storage/J3ZDYFIU/forum.html}
}

@inproceedings{ushani_Learning_2017,
  title = {A {{Learning Approach}} for {{Real-Time Temporal Scene Flow Estimation From Lidar Data}}},
  booktitle = {2017 {{IEEE Int}}. {{Conf}}. {{Robot}}. {{Autom}}. {{ICRA}}},
  author = {Ushani, Arash K. and Wolcott, Ryan W. and Walls, Jeffrey M. and Eustice, Ryan M.},
  date = {2017-05},
  pages = {5666--5673},
  publisher = {{IEEE}},
  location = {{Singapore, Singapore}},
  doi = {10.1109/ICRA.2017.7989666},
  url = {http://ieeexplore.ieee.org/document/7989666/},
  urldate = {2023-05-08},
  eventtitle = {2017 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  isbn = {978-1-5090-4633-1},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {57 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@online{ustalov_learning_2021,
  ids = {ustalov_GeneralPurpose_2021,ustalov_Learning_2021},
  title = {Learning {{From Crowds With Crowd-Kit}}},
  author = {Ustalov, Dmitry and Pavlichenko, Nikita and Tseitlin, Boris},
  date = {2021},
  doi = {10.48550/ARXIV.2109.08584},
  url = {https://arxiv.org/abs/2109.08584},
  urldate = {2023-05-10},
  abstract = {Quality control is a crux of crowdsourcing. While most means for quality control are organizational and imply worker selection, golden tasks, and post-acceptance, computational quality control techniques allow parameterizing the whole crowdsourcing process of workers, tasks, and labels, inferring and revealing relationships between them. In this paper, we present Crowd-Kit, a general-purpose crowdsourcing computational quality control toolkit. It provides efficient implementations in Python of computational quality control algorithms for crowdsourcing, including data quality estimators and truth inference methods. We focus on aggregation methods for all the major annotation tasks, from the categorical annotation in which latent label assumption is met to more complex tasks like image and sequence aggregation. We perform an extensive evaluation of our toolkit on several datasets of different natures, enabling benchmarking computational quality control methods in a uniform, systematic, and reproducible way using the same codebase. We release our code and data under an open-source license at https://github.com/Toloka/crowd-kit.},
  pubstate = {preprint},
  version = {3},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found,Computer Science - Human-Computer Interaction,Computer Science - Software Engineering,FOS: Computer and information sciences,G.4,Human-Computer Interaction (cs.HC),Software Engineering (cs.SE)},
  annotation = {0 citations (Semantic Scholar/arXiv) [2023-05-09]},
  file = {/Users/personal-macbook/Zotero/storage/PG2K9X63/Ustalov et al. - 2021 - A General-Purpose Crowdsourcing Computational Qual.pdf}
}

@article{vaillancourt_Deep_2003,
  title = {Deep {{Brain Stimulation}} of the {{Vim Thalamic Nucleus Modifies Several Features}} of {{Essential Tremor}}},
  author = {Vaillancourt, D. E. and Sturman, M. M. and Metman, L. Verhagen and Bakay, R. A. E. and Corcos, D. M.},
  date = {2003-10},
  journaltitle = {Neurology},
  volume = {61},
  number = {7},
  pages = {919--925},
  doi = {10.1212/01.WNL.0000086371.78447.D2},
  abstract = {BACKGROUND: Pharmacologic interventions (e.g., beta blockers) and thalamic lesions have failed to alter the pathophysiology of essential tremor (ET) beyond a reduction in tremor amplitude. Deep brain stimulation (DBS) of the ventral intermediate (VIM) nucleus of the thalamus successfully reduces tremor rating scores. It is unknown how VIM DBS alters the pathophysiologic characteristics of ET. OBJECTIVE: To determine the effects of VIM DBS on the neurophysiologic characteristics of ET. METHODS: Hand tremor and EMG activity of forearm extensor and flexor muscles were recorded in six patients with ET ON-DBS and OFF-DBS and from six age- and sex-matched control subjects. Hand tremor was assessed across different inertial loads. The amplitude, frequency, regularity, and tremor-EMG coherence were analyzed. RESULTS: VIM DBS reduced the amplitude, increased the frequency, decreased the regularity, and reduced the 1 to 8 Hz tremor-EMG coherence of ET. ON-DBS, patients with ET had greater tremor amplitude, lower frequency, more regularity, and greater tremor-EMG coherence compared to control subjects. CONCLUSIONS: Whereas pharmacologic and thalamic lesions have previously failed to change characteristics of ET beyond amplitude reduction, VIM DBS modified multiple features of ET. The changes in ET after VIM DBS provide strong evidence for clinical efficacy.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {105 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{vaneeden_Relationship_2012,
  title = {The {{Relationship Between Lung Inflammation}} and {{Cardiovascular Disease}}},
  author = {Van Eeden, Stephan and Leipsic, Jonathon and Paul Man, S. F. and Sin, Don D.},
  date = {2012-07-01},
  journaltitle = {Am J Respir Crit Care Med},
  volume = {186},
  number = {1},
  pages = {11--16},
  issn = {1073-449X, 1535-4970},
  doi = {10.1164/rccm.201203-0455PP},
  url = {https://www.atsjournals.org/doi/10.1164/rccm.201203-0455PP},
  urldate = {2022-12-01},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {152 citations (Semantic Scholar/DOI) [2022-12-01]}
}

@inproceedings{vapnik_Principles_1991,
  title = {Principles of {{Risk Minimization}} for {{Learning Theory}}},
  booktitle = {Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.},
  author = {Vapnik, V.},
  date = {1991},
  volume = {4},
  publisher = {{Morgan-Kaufmann}},
  url = {https://proceedings.neurips.cc/paper/1991/file/ff4d5fbbafdf976cfdc032e3bde78de5-Paper.pdf},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/FSRK95RI/Vapnik - Principles of Risk Minimization for Learning Theor.pdf}
}

@article{varon_Noise_2015,
  title = {Noise {{Level Estimation}} for {{Model Selection}} in {{Kernel PCA Denoising}}},
  author = {Varon, Carolina and Alzate, Carlos and Suykens, Johan A. K.},
  date = {2015-11},
  journaltitle = {IEEE Trans. Neural Netw. Learning Syst.},
  volume = {26},
  number = {11},
  pages = {2650--2663},
  issn = {2162-237X, 2162-2388},
  doi = {10.1109/TNNLS.2015.2388696},
  url = {http://ieeexplore.ieee.org/document/7012106/},
  urldate = {2022-12-28},
  keywords = {⛔ No INSPIRE recid found,Eigenvalues and eigenfunctions,Estimation,Kernel,Kernel principal component analysis (kPCA),least squares support vector machines (LS-SVMs),Noise,Noise level,noise level estimation,Noise reduction,Principal component analysis,unsupervised learning,unsupervised learning.},
  annotation = {33 citations (Semantic Scholar/DOI) [2022-12-28]},
  file = {/Users/personal-macbook/Zotero/storage/XXL7JJZH/Varon et al. - 2015 - Noise Level Estimation for Model Selection in Kern.pdf}
}

@article{vassal_Direct_2012,
  title = {Direct {{Stereotactic Targeting}} of the {{Ventrointermediate Nucleus}} of the {{Thalamus Based}} on {{Anatomic}} 1.5-{{T MRI Mapping}} with a {{White Matter Attenuated Inversion Recovery}} ({{WAIR}}) {{Sequence}}},
  author = {Vassal, Fran\c{c}ois and Coste, J\'er\^ome and Derost, Philippe and Mendes, Vivien and Gabrillargues, Jean and Nuti, Christophe and Durif, Franck and Lemaire, Jean-Jacques},
  date = {2012-10},
  journaltitle = {Brain Stimulation},
  volume = {5},
  number = {4},
  pages = {625--633},
  issn = {1935861X},
  doi = {10.1016/j.brs.2011.10.007},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1935861X1100163X},
  urldate = {2023-05-28},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Deep brain stimulation,Direct targeting,Thalamus,Tremor,Ventrointermediate nucleus},
  annotation = {65 citations (Semantic Scholar/DOI) [2023-05-28]},
  file = {/Users/personal-macbook/Zotero/storage/YNUVJGNB/Vassal et al. - 2012 - Direct stereotactic targeting of the ventrointerme.pdf}
}

@inproceedings{vedula_ThreeDimensional_1999,
  title = {Three-{{Dimensional Scene Flow}}},
  booktitle = {7th {{Int}}. {{Conf}}. {{Comput}}. {{Vis}}.},
  author = {Vedula, Sundar and Baker, Simon and Yz, Peter Rander and Collins, Robert and Kanade, Takeo},
  date = {1999},
  doi = {10.1109/ICCV.1999.790293},
  abstract = {Scene flow is the three-dimensional motion field of points in the world, just as optical flow is the two-dimensional motion field of points in an image. Any optical flow is simply the projection of the scene flow onto the image plane of a camera. In this paper, we present a framework for the computation of dense, non-rigid scene flow from optical flow. Our approach leads to straightforward linear algorithms and a classification of the task into three major scenarios: (1) complete instantaneous knowledge of the scene structure, (2) knowledge only of correspondence information, and (3) no knowledge of the scene structure. We also show that multiple estimates of the normal flow cannot be used to estimate dense scene flow directly without some form of smoothing or regularization.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{vedula_Threedimensional_2005,
  title = {Three-{{Dimensional Scene Flow}}},
  author = {Vedula, Sundar and Baker, Simon and Rander, Peter and Collins, Robert and Kanade, Takeo and Yz, Peter Rander and Collins, Robert and Kanade, Takeo},
  date = {2005},
  journaltitle = {IEEE Trans. Pattern Anal. Mach. Intell.},
  eprint = {15747803},
  eprinttype = {pmid},
  issn = {01628828},
  doi = {10.1109/TPAMI.2005.63},
  abstract = {Just as optical flow is the two-dimensional motion of points in an image, scene flow is the three-dimensional motion of points in the world. The fundamental difficulty with optical flow is that only the normal flow can be computed directly from the image measurements, without some form of smoothing or regularization. In this paper, we begin by showing that the same fundamental limitation applies to scene flow; however, many cameras are used to image the scene. There are then two choices when computing scene flow: 1) perform the regularization in the images or 2) perform the regularization on the surface of the object in the scene. In this paper, we choose to compute scene flow using regularization in the images. We describe three algorithms, the first two for computing scene flow from optical flows and the third for constraining scene structure from the inconsistencies in multiple optical flows. \textcopyright{} 2005 IEEE.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Normal flow,Optical flow,Scene flow,The brightness constancy constraint,Three-dimensional dense nonrigid motion,Three-dimensional normal flow}
}

@article{veeraraghavan_SUF30316_2015,
  title = {{{SU-F-303-16}}: {{Multi-Atlas}} and {{Learning Based Segmentation}} of {{Head}} and {{Neck Normal Structures From Multi-Parametric MRI}}},
  author = {Veeraraghavan, H. and Tyagi, N. and Hunt, M. and Lee, N. and Deasy, J.},
  date = {2015-06},
  journaltitle = {Med. Phys.},
  volume = {42},
  pages = {3541},
  doi = {10.1118/1.4925243},
  abstract = {Purpose: To generate automatic segmentation of head and neck normal structures from multi?parametric MR Dixon images. Materials and Method: We present a multi?atlas based registration combined with machine learning?based segmentation of head and neck structures from MR T1 FFE based mdixon images. All the images were acquired using a 3T Phillips MR scanner. 6 patients; 3 in atlas and 3 in testing were used. The individual mdixon images were registered to corresponding images from the multi?atlas using affine and B?spline deformable registration using the open?source software Plastimatch. Second, the best?aligned image pairs were automatically extracted through automatic landmark generation and matching. Scale Invariant Feature Transform (SIFT) features were used to generate the landmarks. The segmentation labels were propagated from the best matching atlas. A random forest (RF) classifier trained with K=10 fold cross validation using the MR mdixon and Haralick textures computed on the same images from the multi?atlas refined the segmentation. Finally, the generated segmentations were smoothed using Markov Random Field and morphological post?processing. Results: The patients used in the analysis displayed anatomical variations owing to dental implants and disease. We evaluated the segmentations generated by our method by computing dice overlap scores with manually generated segmentations. Our method resulted in an accuracy ranging between 0.5 to 0.73 for the various structures, namely, bone, right and left parotid, right and left submandibular glands. The algorithm selected registrations closely agreed with the visual comparison of the image registrations. Conclusions: We developed a fully automatic method for normal structures segmentation that combines multi?atlas based registration with machine learning from multi parametric MRI. Our method quantifies the accuracy of registrations by using automatic landmark extraction. Accurate, automatic volumetric segmentation of normal structures is essential for MR?based treatment planning.},
  issue = {6Part26},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{verbaeten_Ensemble_2003,
  title = {Ensemble {{Methods}} for {{Noise Elimination}} in {{Classification Problems}}},
  author = {Verbaeten, Sofie and Assche, Anneleen Van},
  date = {2003},
  journaltitle = {Lect. Notes Comput. Sci. Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinforma.},
  issn = {16113349},
  doi = {10.1007/3-540-44938-8_32},
  abstract = {Ensemble methods combine a set of classifiers to construct a new classifier that is (often) more accurate than any of its component classifiers. In this paper, we use ensemble methods to identify noisy training examples. More precisely, we consider the problem of mislabeled training examples in classification tasks, and address this problem by pre-processing the training set, i.e. by identifying and removing outliers from the training set. We study a number of filter techniques that are based on well-known ensemble methods like cross-validated committees, bagging and boosting. We evaluate these techniques in an Inductive Logic Programming setting and use a first order decision tree algorithm to construct the ensembles. \textcopyright{} Springer-Verlag Berlin Heidelberg 2003.},
  isbn = {3540403698},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {174 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{verghese_Renal_2009,
  ids = {verghese09},
  title = {Renal {{Primary Cilia Lengthen}} after {{Acute Tubular Necrosis}}},
  author = {Verghese, Elizabeth and Ricardo, Sharon D. and Weidenfeld, Raphael and Zhuang, Junli and Hill, Prudence A. and Langham, Robyn G. and Deane, James A.},
  date = {2009-10},
  journaltitle = {J. Am. Soc. Nephrol.},
  volume = {20},
  number = {10},
  pages = {2147--2153},
  issn = {1046-6673},
  doi = {10.1681/ASN.2008101105},
  url = {https://journals.lww.com/00001751-200910000-00012},
  urldate = {2023-06-03},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {106 citations (Semantic Scholar/DOI) [2023-06-02]}
}

@article{vernooij_Prevalence_2008,
  title = {Prevalence and {{Risk Factors}} of {{Cerebral Microbleeds}}: {{The Rotterdam Scan Study}}},
  author = {Vernooij, M. W. and family=Lugt, given=A., prefix=van der, useprefix=false and Ikram, M. A. and Wielopolski, P. A. and Niessen, W. J. and Hofman, A. and Krestin, G. P. and Breteler, M. M. B.},
  date = {2008-04},
  journaltitle = {Neurology},
  volume = {70},
  number = {14},
  pages = {1208--1214},
  doi = {10.1212/01.wnl.0000307750.41970.d9},
  abstract = {BACKGROUND: Cerebral microbleeds are focal deposits of hemosiderin that can be visualized with MRI. Little is known on their prevalence in the general population and on their etiology. It has been suggested that, in analogy to spontaneous intracranial hemorrhage, the etiology of microbleeds differs according to their location in the brain, with lobar microbleeds being caused by cerebral amyloid angiopathy and deep or infratentorial microbleeds resulting from hypertension and atherosclerosis. We investigated the prevalence of and risk factors for microbleeds in the general population aged 60 years and older. METHODS: This study is based on 1,062 persons (mean age 69.6 years) from the population-based Rotterdam Scan Study. MRI was performed at 1.5 T and included a sequence optimized to increase the conspicuity of microbleeds. We assessed the relation of APOE genotype, cardiovascular risk factors, and markers of small vessel disease to the presence and location of microbleeds with multiple logistic regression. RESULTS: Overall prevalence of cerebral microbleeds was high and increased with age from 17.8\% in persons aged 60-69 years to 38.3\% in those over 80 years. APOE epsilon 4 carriers had significantly more often strictly lobar microbleeds than noncarriers. In contrast, cardiovascular risk factors and presence of lacunar infarcts and white matter lesions were associated with microbleeds in a deep or infratentorial location but not in a lobar location. CONCLUSION: The prevalence of cerebral microbleeds is high. Our data support the hypothesis that strictly lobar microbleeds are related to cerebral amyloid angiopathy, whereas microbleeds in a deep or infratentorial location result from hypertensive or atherosclerotic microangiopathy.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@incollection{victor_Sheng_2003,
  title = {Sheng ({{SM}}'14) {{Received}} the {{Master}}'s {{Degree}} in {{Computer Science From}} the {{University}} of {{New}}},
  author = {Victor, S.},
  date = {2003},
  publisher = {{NB, Canada, in}},
  location = {{Brunswick, Fredericton}},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{vidas_3D_2013,
  title = {{{3D Thermal Mapping}} of {{Building Interiors Using}} an {{RGB-D}} and {{Thermal Camera}}},
  booktitle = {2013 {{IEEE Int}}. {{Conf}}. {{Robot}}. {{Autom}}.},
  author = {Vidas, Stephen and Moghadam, Peyman and Bosse, Michael},
  date = {2013-05},
  pages = {2311--2318},
  publisher = {{IEEE}},
  location = {{Karlsruhe}},
  doi = {10.1109/ICRA.2013.6630890},
  url = {http://ieeexplore.ieee.org/document/6630890/},
  urldate = {2022-12-29},
  eventtitle = {2013 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  isbn = {978-1-4673-5643-5 978-1-4673-5641-1},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {137 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{vogel_3D_2011,
  title = {{{3D Scene Flow Estimation With}} a {{Rigid Motion Prior}}},
  booktitle = {2011 {{Int}}. {{Conf}}. {{Comput}}. {{Vis}}.},
  author = {Vogel, Christoph and Schindler, Konrad and Roth, Stefan},
  date = {2011-11},
  pages = {1291--1298},
  publisher = {{IEEE}},
  location = {{Barcelona, Spain}},
  doi = {10.1109/ICCV.2011.6126381},
  url = {http://ieeexplore.ieee.org/document/6126381/},
  urldate = {2022-12-29},
  eventtitle = {2011 {{IEEE International Conference}} on {{Computer Vision}} ({{ICCV}})},
  isbn = {978-1-4577-1102-2 978-1-4577-1101-5 978-1-4577-1100-8},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {97 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{volpi_Adversarial_2018,
  title = {Adversarial {{Feature Augmentation}} for {{Unsupervised Domain Adaptation}}},
  booktitle = {Proc. {{IEEE Comput}}. {{Soc}}. {{Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}.},
  author = {Volpi, Riccardo and Morerio, Pietro and Savarese, Silvio and Murino, Vittorio},
  date = {2018},
  issn = {10636919},
  doi = {10.1109/CVPR.2018.00576},
  abstract = {Recent works showed that Generative Adversarial Networks (GANs) can be successfully applied in unsupervised domain adaptation, where, given a labeled source dataset and an unlabeled target dataset, the goal is to train powerful classifiers for the target samples. In particular, it was shown that a GAN objective function can be used to learn target features indistinguishable from the source ones. In this work, we extend this framework by (i) forcing the learned feature extractor to be domain-invariant, and (ii) training it through data augmentation in the feature space, namely performing feature augmentation. While data augmentation in the image space is a well established technique in deep learning, feature augmentation has not yet received the same level of attention. We accomplish it by means of a feature generator trained by playing the GAN minimax game against source features. Results show that both enforcing domain-invariance and performing feature augmentation lead to superior or comparable performance to state-of-the-art results in several unsupervised domain adaptation benchmarks.},
  isbn = {978-1-5386-6420-9},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {193 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{vovk_Review_2007,
  title = {A {{Review}} of {{Methods}} for {{Correction}} of {{Intensity Inhomogeneity}} in {{MRI}}},
  author = {Vovk, Uro and Pernus, Franjo and Likar, Botjan},
  date = {2007},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {26},
  number = {3},
  pages = {405--421},
  publisher = {{IEEE}},
  doi = {10.1109/TMI.2006.891486},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {864 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{wachinger_DeepNAT_2018,
  title = {{{DeepNAT}}: {{Deep Convolutional Neural Network}} for {{Segmenting Neuroanatomy}}},
  shorttitle = {{{DeepNAT}}},
  author = {Wachinger, Christian and Reuter, Martin and Klein, Tassilo},
  date = {2018-04},
  journaltitle = {NeuroImage},
  volume = {170},
  pages = {434--445},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2017.02.035},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811917301465},
  urldate = {2023-05-08},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Brain segmentation,Conditional random field,Conv},
  annotation = {295 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/52YNSMJ2/Wachinger et al. - 2018 - DeepNAT Deep convolutional neural network for seg.pdf}
}

@article{wagner_Steven_2010,
  title = {Steven {{Bird}}, {{Ewan Klein}} and {{Edward Loper}}: {{Natural Language Processing With Python}}, {{Analyzing Text With}} the {{Natural Language Toolkit}}},
  author = {Wagner, Wiebke},
  date = {2010-12},
  journaltitle = {Lang. Resour. Eval.},
  volume = {44},
  number = {4},
  pages = {421--424},
  doi = {10.1007/s10579-010-9124-x},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{wallis_How_2019,
  title = {How {{Artificial Intelligence Will Change Medicine}}},
  author = {Wallis, Claudia},
  date = {2019},
  journaltitle = {Nature},
  eprint = {31853072},
  eprinttype = {pmid},
  issn = {14764687},
  doi = {10.1038/d41586-019-03845-1},
  abstract = {[Figure not available: see fulltext.].},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Computer science,Health care},
  annotation = {28 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{wang_Aleatoric_2019,
  title = {Aleatoric {{Uncertainty Estimation With Test-Time Augmentation}} for {{Medical Image Segmentation With Convolutional Neural Networks}}},
  author = {Wang, Guotai and Li, Wenqi and Aertsen, Michael and Deprest, Jan and Ourselin, S\'ebastien and Vercauteren, Tom},
  date = {2019-04},
  journaltitle = {Neurocomputing},
  volume = {338},
  pages = {34--45},
  issn = {09252312},
  doi = {10.1016/j.neucom.2019.01.103},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0925231219301961},
  urldate = {2022-12-29},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Convolutional neural networks,Data augmentation,Medical image segmentation,Uncertainty estimation},
  annotation = {328 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/A5A8HHW2/Wang et al. - 2019 - Aleatoric uncertainty estimation with test-time au.pdf}
}

@article{wang_Automatic_2019,
  title = {Automatic {{Brain Tumor Segmentation Based}} on {{Cascaded Convolutional Neural Networks With Uncertainty Estimation}}},
  author = {Wang, Guotai and Li, Wenqi and Ourselin, S\'ebastien and Vercauteren, Tom},
  date = {2019},
  journaltitle = {Front. Comput. Neurosci.},
  issn = {16625188},
  doi = {10.3389/fncom.2019.00056},
  abstract = {Automatic segmentation of brain tumors from medical images is important for clinical assessment and treatment planning of brain tumors. Recent years have seen an increasing use of convolutional neural networks (CNNs) for this task, but most of them use either 2D networks with relatively low memory requirement while ignoring 3D context, or 3D networks exploiting 3D features while with large memory consumption. In addition, existing methods rarely provide uncertainty information associated with the segmentation result. We propose a cascade of CNNs to segment brain tumors with hierarchical subregions from multi-modal Magnetic Resonance images (MRI), and introduce a 2.5D network that is a trade-off between memory consumption, model complexity and receptive field. In addition, we employ test-time augmentation to achieve improved segmentation accuracy, which also provides voxel-wise and structure-wise uncertainty information of the segmentation result. Experiments with BraTS 2017 dataset showed that our cascaded framework with 2.5D CNNs was one of the top performing methods (second-rank) for the BraTS challenge. We also validated our method with BraTS 2018 dataset and found that test-time augmentation improves brain tumor segmentation accuracy and that the resulting uncertainty information can indicate potential mis-segmentations and help to improve segmentation accuracy.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,brain tumor segmentation,convolutional neural network,data augmentation,deep learning,uncertainty},
  annotation = {135 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{wang_Automatic_2019a,
  title = {Automatic {{Brain Tumor Segmentation Using Convolutional Neural Networks With Test-Time Augmentation}}},
  booktitle = {Lect. {{Notes Comput}}. {{Sci}}.},
  author = {Wang, Guotai and Li, Wenqi and Ourselin, S\'ebastien and Vercauteren, Tom},
  date = {2019},
  issn = {16113349},
  doi = {10.1007/978-3-030-11726-9_6},
  abstract = {Automatic brain tumor segmentation plays an important role for diagnosis, surgical planning and treatment assessment of brain tumors. Deep convolutional neural networks (CNNs) have been widely used for this task. Due to the relatively small data set for training, data augmentation at training time has been commonly used for better performance of CNNs. Recent works also demonstrated the usefulness of data augmentation at test time, in addition to training time, for achieving more robust predictions. We investigate how test-time augmentation can improve CNNs' performance for brain tumor segmentation. We used different underpinning network structures and augmented the image by 3D rotation, flipping, scaling and adding random noise at both training and test time. Experiments with BraTS 2018 training and validation set show that test-time augmentation can achieve higher segmentation accuracy and obtain uncertainty estimation of the segmentation results.},
  isbn = {978-3-030-11725-2},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Brain tumor,Convolutional neural network,Data augmentation,Segmentation},
  annotation = {97 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{wang_Binge_2017,
  title = {Binge {{Watching}}: {{Scaling Affordance Learning From Sitcoms}}},
  shorttitle = {Binge {{Watching}}},
  booktitle = {2017 {{IEEE Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}. {{CVPR}}},
  author = {Wang, Xiaolong and Girdhar, Rohit and Gupta, Abhinav},
  date = {2017-07},
  pages = {3366--3375},
  publisher = {{IEEE}},
  location = {{Honolulu, HI}},
  doi = {10.1109/CVPR.2017.359},
  url = {http://ieeexplore.ieee.org/document/8099842/},
  urldate = {2023-05-08},
  eventtitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-5386-0457-1},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {58 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/RJEGMPEC/Wang et al. - 2017 - Binge Watching Scaling Affordance Learning from S.pdf}
}

@article{wang_Changes_2003,
  title = {Changes in {{Hippocampal Volume}} and {{Shape Across Time Distinguish Dementia}} of the {{Alzheimer Type From Healthy Aging}}?},
  author = {Wang, Lei and Swank, Jeffrey S. and Glick, Irena E. and Gado, Mokhtar H. and Miller, Michael I. and Morris, John C. and Csernansky, John G.},
  date = {2003-10},
  journaltitle = {Neuroimage},
  volume = {20},
  number = {2},
  pages = {667--682},
  doi = {10.1016/S1053-8119(03)00361-6},
  abstract = {Rates of hippocampal volume loss have been shown to distinguish subjects with dementia of the Alzheimer type (DAT) from nondemented controls (Jack et al., 2000). In this study, we obtained magnetic resonance scans in 18 subjects with very mild DAT (CDR 0.5) and 26 age-matched nondemented controls (CDR 0) 2 years apart. Large-deformation high-dimensional brain mapping was used to quantify and compare changes in hippocampal shape as well as volume in the two groups of subjects. Hippocampal volume loss over time was significantly greater in the CDR 0.5 subjects (left = 8.3\%, right = 10.2\%) than in the CDR 0 subjects (left = 4.0\%, right = 5.5\%) (ANOVA, F = 7.81, P = 0.0078). We used singular-value decomposition and logistic regression models to quantify hippocampal shape change across time within individuals, and this shape change in the CDR 0.5 and CDR 0 subjects was found to be significantly different (Wilks's \${$\lambda\$$}, P = 0.014). Further, at baseline, CDR 0.5 subjects, in comparison to CDR 0 subjects, showed inward deformation over 38\% of the hippocampal surface; after 2 years this difference grew to 47\%. Also, within the CDR 0 subjects, shape change between baseline and follow-up was largely confined to the head of the hippocampus and subiculum, while in the CDR 0.5 subjects, shape change involved the lateral body of the hippocampus as well as the head region and subiculum. These results suggest that different patterns of hippocampal shape change in time as well as different rates of hippocampal volume loss distinguish very mild DAT from healthy aging.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {266 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{wang_ChestXRay8_2017,
  title = {{{ChestX-Ray8}}: {{Hospital-Scale Chest X-Ray Database}} and {{Benchmarks}} on {{Weakly-Supervised Classification}} and {{Localization}} of {{Common Thorax Diseases}}},
  shorttitle = {{{ChestX-Ray8}}},
  booktitle = {2017 {{IEEE Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}. {{CVPR}}},
  author = {Wang, Xiaosong and Peng, Yifan and Lu, Le and Lu, Zhiyong and Bagheri, Mohammadhadi and Summers, Ronald M.},
  date = {2017-07},
  pages = {3462--3471},
  publisher = {{IEEE}},
  location = {{Honolulu, HI}},
  doi = {10.1109/CVPR.2017.369},
  url = {http://ieeexplore.ieee.org/document/8099852/},
  urldate = {2023-04-02},
  eventtitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-5386-0457-1},
  keywords = {⛔ No INSPIRE recid found,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition},
  annotation = {2515 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/SMTPXR84/Wang et al. - 2017 - ChestX-Ray8 Hospital-Scale Chest X-Ray Database a.pdf}
}

@article{wang_Clinical_2020,
  title = {Clinical {{Characteristics}} of 138 {{Hospitalized Patients With}} 2019 {{Novel Coronavirus-Infected Pneumonia}} in {{Wuhan}}, {{China}}},
  author = {Wang, Dawei and Hu, Bo and Hu, Chang and Zhu, Fangfang and Liu, Xing and Zhang, Jing and Wang, Binbin and Xiang, Hui and Cheng, Zhenshun and Xiong, Yong and Zhao, Yan and Li, Yirong and Wang, Xinghuan and Peng, Zhiyong},
  date = {2020},
  journaltitle = {JAMA - J. Am. Med. Assoc.},
  eprint = {32031570},
  eprinttype = {pmid},
  issn = {15383598},
  doi = {10.1001/jama.2020.1585},
  abstract = {Importance: In December 2019, novel coronavirus (2019-nCoV)-infected pneumonia (NCIP) occurred in Wuhan, China. The number of cases has increased rapidly but information on the clinical characteristics of affected patients is limited. Objective: To describe the epidemiological and clinical characteristics of NCIP. Design, Setting, and Participants: Retrospective, single-center case series of the 138 consecutive hospitalized patients with confirmed NCIP at Zhongnan Hospital of Wuhan University in Wuhan, China, from January 1 to January 28, 2020; final date of follow-up was February 3, 2020. Exposures: Documented NCIP. Main Outcomes and Measures: Epidemiological, demographic, clinical, laboratory, radiological, and treatment data were collected and analyzed. Outcomes of critically ill patients and noncritically ill patients were compared. Presumed hospital-related transmission was suspected if a cluster of health professionals or hospitalized patients in the same wards became infected and a possible source of infection could be tracked. Results: Of 138 hospitalized patients with NCIP, the median age was 56 years (interquartile range, 42-68; range, 22-92 years) and 75 (54.3\%) were men. Hospital-associated transmission was suspected as the presumed mechanism of infection for affected health professionals (40 [29\%]) and hospitalized patients (17 [12.3\%]). Common symptoms included fever (136 [98.6\%]), fatigue (96 [69.6\%]), and dry cough (82 [59.4\%]). Lymphopenia (lymphocyte count, 0.8 \texttimes{} 109/L [interquartile range \{IQR\}, 0.6-1.1]) occurred in 97 patients (70.3\%), prolonged prothrombin time (13.0 seconds [IQR, 12.3-13.7]) in 80 patients (58\%), and elevated lactate dehydrogenase (261 U/L [IQR, 182-403]) in 55 patients (39.9\%). Chest computed tomographic scans showed bilateral patchy shadows or ground glass opacity in the lungs of all patients. Most patients received antiviral therapy (oseltamivir, 124 [89.9\%]), and many received antibacterial therapy (moxifloxacin, 89 [64.4\%]; ceftriaxone, 34 [24.6\%]; azithromycin, 25 [18.1\%]) and glucocorticoid therapy (62 [44.9\%]). Thirty-six patients (26.1\%) were transferred to the intensive care unit (ICU) because of complications, including acute respiratory distress syndrome (22 [61.1\%]), arrhythmia (16 [44.4\%]), and shock (11 [30.6\%]). The median time from first symptom to dyspnea was 5.0 days, to hospital admission was 7.0 days, and to ARDS was 8.0 days. Patients treated in the ICU (n = 36), compared with patients not treated in the ICU (n = 102), were older (median age, 66 years vs 51 years), were more likely to have underlying comorbidities (26 [72.2\%] vs 38 [37.3\%]), and were more likely to have dyspnea (23 [63.9\%] vs 20 [19.6\%]), and anorexia (24 [66.7\%] vs 31 [30.4\%]). Of the 36 cases in the ICU, 4 (11.1\%) received high-flow oxygen therapy, 15 (41.7\%) received noninvasive ventilation, and 17 (47.2\%) received invasive ventilation (4 were switched to extracorporeal membrane oxygenation). As of February 3, 47 patients (34.1\%) were discharged and 6 died (overall mortality, 4.3\%), but the remaining patients are still hospitalized. Among those discharged alive (n = 47), the median hospital stay was 10 days (IQR, 7.0-14.0). Conclusions and Relevance: In this single-center case series of 138 hospitalized patients with confirmed NCIP in Wuhan, China, presumed hospital-related transmission of 2019-nCoV was suspected in 41\% of patients, 26\% of patients received ICU care, and mortality was 4.3\%.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {9989 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{wang_Deep_2018,
  title = {Deep {{Visual Domain Adaptation}}: {{A Survey}}},
  author = {Wang, Mei and Deng, Weihong},
  date = {2018},
  journaltitle = {Neurocomputing},
  issn = {18728286},
  doi = {10.1016/j.neucom.2018.05.083},
  abstract = {Deep domain adaptation has emerged as a new learning technique to address the lack of massive amounts of labeled data. Compared to conventional methods, which learn shared feature subspaces or reuse important source instances with shallow representations, deep domain adaptation methods leverage deep networks to learn more transferable representations by embedding domain adaptation in the pipeline of deep learning. There have been comprehensive surveys for shallow domain adaptation, but few timely reviews the emerging deep learning based methods. In this paper, we provide a comprehensive survey of deep domain adaptation methods for computer vision applications with four major contributions. First, we present a taxonomy of different deep domain adaptation scenarios according to the properties of data that define how two domains are diverged. Second, we summarize deep domain adaptation approaches into several categories based on training loss, and analyze and compare briefly the state-of-the-art methods under these categories. Third, we overview the computer vision applications that go beyond image classification, such as face recognition, semantic segmentation and object detection. Fourth, some potential deficiencies of current methods and several future directions are highlighted.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Computer vision applications,Deep domain adaptation,Deep networks,Transfer learning},
  annotation = {1279 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{wang_Deep_2021,
  ids = {wang_Deep_2021a},
  title = {Deep {{High-Resolution Representation Learning}} for {{Visual Recognition}}},
  author = {Wang, Jingdong and Sun, Ke and Cheng, Tianheng and Jiang, Borui and Deng, Chaorui and Zhao, Yang and Liu, Dong and Mu, Yadong and Tan, Mingkui and Wang, Xinggang and Liu, Wenyu and Xiao, Bin},
  date = {2021-10-01},
  journaltitle = {IEEE Trans. Pattern Anal. Mach. Intell.},
  volume = {43},
  number = {10},
  pages = {3349--3364},
  issn = {0162-8828, 2160-9292, 1939-3539},
  doi = {10.1109/TPAMI.2020.2983686},
  url = {https://ieeexplore.ieee.org/document/9052469/},
  urldate = {2022-05-16},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {1560 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/BVY59UYK/Wang et al. - 2021 - Deep High-Resolution Representation Learning for V.pdf}
}

@article{wang_Deep_2021b,
  title = {Deep {{Learning}} in {{Medical Ultrasound Image Analysis}}: {{A Review}}},
  shorttitle = {Deep {{Learning}} in {{Medical Ultrasound Image Analysis}}},
  author = {Wang, Yu and Ge, Xinke and Ma, He and Qi, Shouliang and Zhang, Guanjing and Yao, Yudong},
  date = {2021},
  journaltitle = {IEEE Access},
  volume = {9},
  pages = {54310--54324},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2021.3071301},
  abstract = {Ultrasound (US) is one of the most widely used imaging modalities in medical diagnosis. It has the advantages of real-time, low cost, noninvasive nature, and easy to operate. However, it also has the unique disadvantages of strong artifacts and noise and high dependence on the experience of doctors. In order to overcome the shortcomings of ultrasound diagnosis and help doctor improve the accuracy and efficiency of diagnosis, many computer aided diagnosis (CAD) systems have been developed. In recent years, deep learning has achieved great success in computer vision with its unique advantages. In the aspect of medical US image analysis, deep learning has also been exploited for its great potential and more and more researchers apply it to CAD systems. In this paper, we first introduce the deep learning models commonly used in medical US image analysis; Second, we review the data preprocessing methods of medical US images, including data augmentation, denoising, and enhancement; Finally, we analyze the applications of deep learning in medical US imaging tasks (such as image classification, object detection, and image reconstruction).},
  eventtitle = {{{IEEE Access}}},
  keywords = {⛔ No INSPIRE recid found,Biomedical imaging,Deep learning,Feature extraction,Image analysis,Medical diagnostic imaging,medical ultrasound image analysis,Task analysis,Ultrasonic imaging,ultrasound image preprocessing},
  annotation = {15 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/CXN2CYA9/Wang et al. - 2021 - Deep Learning in Medical Ultrasound Image Analysis.pdf;/Users/personal-macbook/Zotero/storage/74HN5RG3/9395635.html;/Users/personal-macbook/Zotero/storage/K22I93GC/9395635.html}
}

@article{wang_DeepLearning_2021,
  title = {A {{Deep-Learning Pipeline}} for the {{Diagnosis}} and {{Discrimination}} of {{Viral}}, {{Non-Viral}} and {{Covid-19 Pneumonia From Chest X-Ray Images}}},
  author = {Wang, Guangyu and Liu, Xiaohong and Shen, Jun and Wang, Chengdi and Li, Zhihuan and Ye, Linsen and Wu, Xingwang and Chen, Ting and Wang, Kai and Zhang, Xuan and Zhou, Zhongguo and Yang, Jian and Sang, Ye and Deng, Ruiyun and Liang, Wenhua and Yu, Tao and Gao, Ming and Wang, Jin and Yang, Zehong and Cai, Huimin and Lu, Guangming and Zhang, Lingyan and Yang, Lei and Xu, Wenqin and Wang, Winston and Olvera, Andrea and Ziyar, Ian and Zhang, Charlotte and Li, Oulan and Liao, Weihua and Liu, Jun and Chen, Wen and Chen, Wei and Shi, Jichan and Zheng, Lianghong and Zhang, Longjiang and Yan, Zhihan and Zou, Xiaoguang and Lin, Guiping and Cao, Guiqun and Lau, Laurance L. and Mo, Long and Liang, Yong and Roberts, Michael and Sala, Evis and Sch\"onlieb, Carola-Bibiane and Fok, Manson and Lau, Johnson Yiu-Nam and Xu, Tao and He, Jianxing and Zhang, Kang and Li, Weimin and Lin, Tianxin},
  date = {2021-04-15},
  journaltitle = {Nat Biomed Eng},
  volume = {5},
  number = {6},
  pages = {509--521},
  issn = {2157-846X},
  doi = {10.1038/s41551-021-00704-1},
  url = {https://www.nature.com/articles/s41551-021-00704-1},
  urldate = {2022-12-29},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {67 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/TQNFV7EH/Wang et al. - 2021 - A deep-learning pipeline for the diagnosis and dis.pdf}
}

@article{wang_Dynamic_2019,
  title = {Dynamic {{Graph CNN}} for {{Learning}} on {{Point Clouds}}},
  author = {Wang, Yue and Sun, Yongbin and Liu, Ziwei and Sarma, Sanjay E. and Bronstein, Michael M. and Solomon, Justin},
  date = {2019},
  journaltitle = {ACM Trans. Graph.},
  eprint = {null},
  eprinttype = {pmid},
  doi = {10.1145/3326362},
  abstract = {Point clouds provide a flexible geometric representation suitable for countless applications in computer graphics; they also comprise the raw output of most 3D data acquisition devices. While hand-designed features on point clouds have long been proposed in graphics and vision, however, the recent overwhelming success of convolutional neural networks (CNNs) for image analysis suggests the value of adapting insight from CNN to the point cloud world. Point clouds inherently lack topological information, so designing a model to recover topology can enrich the representation power of point clouds. To this end, we propose a new neural network module dubbed EdgeConv suitable for CNN-based high-level tasks on point clouds, including classification and segmentation. EdgeConv acts on graphs dynamically computed in each layer of the network. It is differentiable and can be plugged into existing architectures. Compared to existing modules operating in extrinsic space or treating each point independently, EdgeConv has several appealing properties: It incorporates local neighborhood information; it can be stacked applied to learn global shape properties; and in multi-layer systems affinity in feature space captures semantic characteristics over potentially long distances in the original embedding. We show the performance of our model on standard benchmarks, including ModelNet40, ShapeNetPart, and S3DIS.},
  pmcid = {null},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {3282 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/NS7TA6A4/Wang et al. - 2019 - Dynamic Graph CNN for Learning on Point Clouds.pdf}
}

@article{wang_Factor_2010,
  title = {Factor {{Analysis}} for {{Cross-Platform Tumor Classification Based}} on {{Gene Expression Profiles}}},
  author = {Wang, Shu-Lin and Gui, Jie and Li, Xueling},
  date = {2010-02-01},
  journaltitle = {J CIRCUIT SYST COMP},
  volume = {19},
  number = {01},
  pages = {243--258},
  publisher = {{World Scientific Publishing Co.}},
  issn = {0218-1266},
  doi = {10.1142/S0218126610006074},
  url = {https://www.worldscientific.com/doi/abs/10.1142/S0218126610006074},
  urldate = {2021-11-16},
  abstract = {Previous studies on tumor classification based on feature extraction from gene expression profiles (GEP) were proven to be effective, but some of such methods lack biomedical meaning to some extent. To deal with this problem, we proposed a novel feature extraction method whose experimental results are of biomedical interpretability and helpful for gaining insight into the structure analysis of gene expression dataset. This method first applied rank sum test to roughly select a set of informative genes and then adopted factor analysis to extract latent factors for tumor classification. Experiments on three pairs of cross-platform tumor datasets indicated that the proposed method can obviously improve the performance of cross-platform classification and only several latent factors, which can represent a large number of informative genes, would obtain very high predictive accuracy on test set. The results also suggested that the classification model trained on one dataset can successfully predict another tumor dataset with the same tumor subtype obtained on different experimental platforms.},
  keywords = {⛔ No INSPIRE recid found,cross-platform analysis,factor analysis,Feature extraction,gene expression profiles,tumor classification},
  annotation = {12 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/XTUGED7Q/Wang et al. - 2010 - Factor Analysis for Cross-Platform Tumor Classific.pdf}
}

@article{wang_Interactive_2018,
  title = {Interactive {{Medical Image Segmentation Using Deep Learning With Image-Specific Fine Tuning}}},
  author = {Wang, Guotai and Li, Wenqi and Zuluaga, Maria A. and Pratt, Rosalind and Patel, Premal A. and Aertsen, Michael and Doel, Tom and David, Anna L. and Deprest, Jan and Ourselin, Sebastien and Vercauteren, Tom},
  date = {2018},
  journaltitle = {IEEE Trans. Med. Imaging},
  eprint = {29969407},
  eprinttype = {pmid},
  issn = {1558254X},
  doi = {10.1109/TMI.2018.2791721},
  abstract = {Convolutional neural networks (CNNs) have achieved state-of-the-art performance for automatic medical image segmentation. However, they have not demonstrated sufficiently accurate and robust results for clinical use. In addition, they are limited by the lack of image-specific adaptation and the lack of generalizability to previously unseen object classes (a.k.a. zero-shot learning). To address these problems, we propose a novel deep learning-based interactive segmentation framework by incorporating CNNs into a bounding box and scribble-based segmentation pipeline. We propose image-specific fine tuning to make a CNN model adaptive to a specific test image, which can be either unsupervised (without additional user interactions) or supervised (with additional scribbles). We also propose a weighted loss function considering network and interaction-based uncertainty for the fine tuning. We applied this framework to two applications: 2-D segmentation of multiple organs from fetal magnetic resonance (MR) slices, where only two types of these organs were annotated for training and 3-D segmentation of brain tumor core (excluding edema) and whole brain tumor (including edema) from different MR sequences, where only the tumor core in one MR sequence was annotated for training. Experimental results show that: 1) our model is more robust to segment previously unseen objects than state-of-the-art CNNs; 2) image-specific fine tuning with the proposed weighted loss function significantly improves segmentation accuracy; and 3) our method leads to accurate results with fewer user interactions and less user time than traditional interactive segmentation methods.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,brain tumor,convolutional neural network,fetal MRI,fine-tuning,Interactive image segmentation},
  annotation = {124 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{wang_Label_2019,
  title = {A {{Label Embedding Method}} for {{Multi-Label Classification}} via {{Exploiting Local Label Correlations}}},
  booktitle = {Neural {{Inf}}. {{Process}}.},
  author = {Wang, Xidong and Li, Jun and Xu, Jianhua},
  editor = {Gedeon, Tom and Wong, Kok Wai and Lee, Minho},
  date = {2019},
  volume = {1143},
  pages = {168--180},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-36802-9_19},
  url = {http://link.springer.com/10.1007/978-3-030-36802-9_19},
  urldate = {2022-11-21},
  isbn = {978-3-030-36801-2 978-3-030-36802-9},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Dimensionality reduction,Global recoverability,Label correlation,Local recoverability,Multi-label learning},
  annotation = {2 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/R45CG3P3/Wang et al. - 2019 - A Label Embedding Method for Multi-label Classific.pdf}
}

@article{wang_Multiatlas_2014,
  title = {Multi-{{Atlas Segmentation}} of {{Subcortical Brain Structures}} via the {{AutoSeg Software Pipeline}}},
  author = {Wang, Jiahui and Vachet, Clement and Rumple, Ashley and Gouttard, Sylvain and Ouziel, Cl\'ementine and Perrot, Emilie and Du, Guangwei and Huang, Xuemei and Gerig, Guido and Styner, Martin},
  date = {2014-02},
  journaltitle = {Front. Neuroinform.},
  volume = {8},
  pages = {7},
  abstract = {Automated segmenting and labeling of individual brain anatomical regions, in MRI are challenging, due to the issue of individual structural variability. Although atlas-based segmentation has shown its potential for both tissue and structure segmentation, due to the inherent natural variability as well as disease-related changes in MR appearance, a single atlas image is often inappropriate to represent the full population of datasets processed in a given neuroimaging study. As an alternative for the case of single atlas segmentation, the use of multiple atlases alongside label fusion techniques has been introduced using a set of individual ``atlases'' that encompasses the expected variability in the studied population. In our study, we proposed a multi-atlas segmentation scheme with a novel graph-based atlas selection technique. We first paired and co-registered all atlases and the subject MR scans. A directed graph with edge weights based on intensity and shape similarity between all MR scans is then computed. The set of neighboring templates is selected via clustering of the graph. Finally, weighted majority voting is employed to create the final segmentation over the selected atlases. This multi-atlas segmentation scheme is used to extend a single-atlas-based segmentation toolkit entitled AutoSeg, which is an open-source, extensible C++ based software pipeline employing BatchMake for its pipeline scripting, developed at the Neuro Image Research and Analysis Laboratories of the University of North Carolina at Chapel Hill. AutoSeg performs N4 intensity inhomogeneity correction, rigid registration to a common template space, automated brain tissue classification based skull-stripping, and the multi-atlas segmentation. The multi-atlas-based AutoSeg has been evaluated on subcortical structure segmentation with a testing dataset of 20 adult brain MRI scans and 15 atlas MRI scans. The AutoSeg achieved mean Dice coefficients of 81.73\% for the subcortical structures.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found,atlas,brain,Insight Toolkit,MRI,registration}
}

@inproceedings{wang_Regressionbased_2011,
  title = {Regression-{{Based Label Fusion}} for {{Multi-Atlas Segmentation}}},
  booktitle = {{{CVPR}} 2011},
  author = {Wang, H. and Suh, J. W. and Das, S. and Pluta, J. and Altinay, M. and Yushkevich, P.},
  date = {2011-06},
  pages = {1113--1120},
  abstract = {Automatic segmentation using multi-atlas label fusion has been widely applied in medical image analysis. To simplify the label fusion problem, most methods implicitly make a strong assumption that the segmentation errors produced by different atlases are uncorrelated. We show that violating this assumption significantly reduces the efficiency of multi-atlas segmentation. To address this problem, we propose a regression-based approach for label fusion. Our experiments on segmenting the hippocampus in magnetic resonance images (MRI) show significant improvement over previous label fusion techniques.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,biomedical MRI,image fusion,image segmentation,med}
}

@inproceedings{wang_Trading_2015,
  title = {Trading {{Interpretability}} for {{Accuracy}}: {{Oblique Treed Sparse Additive Models}}},
  booktitle = {Proc. {{ACM SIGKDD Int}}. {{Conf}}. {{Knowl}}. {{Discov}}. {{Data Min}}.},
  author = {Wang, Jialei and Fujimaki, Ryohei and Motohashi, Yosuke},
  date = {2015-08},
  volume = {2015-August},
  pages = {1245--1254},
  publisher = {{Association for Computing Machinery}},
  doi = {10.1145/2783258.2783407},
  url = {http://dl.acm.org/citation.cfm?doid=2783258.2783407},
  abstract = {Model interpretability has been recognized to play a key role in practical data mining. Interpretable models provide significant insights on data and model behaviors and may convince end-users to employ certain models. In return for these advantages, however, there is generally a sacrifice in accuracy, i.e., flexibility of model representation (e.g., linear, rule-based, etc.) and model complexity needs to be restricted in order for users to be able to understand the results. This paper proposes oblique treed sparse additive models (OT-SpAMs). Our main focus is on developing a model which sacrifices a certain degree of interpretability for accuracy but achieves entirely sufficient accuracy with such fully non-linear models as kernel support vector machines (SVMs). OT-SpAMs are instances of region-specific predictive models. They divide feature spaces into regions with sparse oblique tree splitting and assign local sparse additive experts to individual regions. In order to maintain OT-SpAM interpretability, we have to keep the overall model structure simple, and this produces simultaneous model selection issues for sparse oblique region structures and sparse local experts. We address this problem by extending factorized asymptotic Bayesian inference. We demonstrate, on simulation, benchmark, and real world datasets that, in terms of accuracy, OT-SpAMs outperform state-of-the-art interpretable models and perform competitively with kernel SVMs, while still providing results that are highly understandable.},
  isbn = {978-1-4503-3664-2},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Interpretable model,Model selection,Sparseness}
}

@inproceedings{wang_Uncertainty_2022,
  title = {Uncertainty {{Estimation}} and {{Calibration With Finite-State Probabilistic RNNs}}},
  author = {Wang, Cheng and Lawrence, Carolin and Niepert, Mathias},
  date = {2022-02-10},
  url = {https://openreview.net/forum?id=9EKHN1jOlA},
  urldate = {2022-07-04},
  abstract = {Uncertainty quantification is crucial for building reliable and trustable machine learning systems. We propose to estimate uncertainty in recurrent neural networks (RNNs) via stochastic discrete...},
  eventtitle = {International {{Conference}} on {{Learning Representations}}},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/SISU4RJ4/Wang et al. - 2022 - Uncertainty Estimation and Calibration with Finite.pdf;/Users/personal-macbook/Zotero/storage/TWKTXVGU/forum.html}
}

@online{wang_Wisdom_2020,
  title = {Wisdom of {{Committees}}: {{An Overlooked Approach}} to {{Faster}} and {{More Accurate Models}}},
  shorttitle = {Wisdom of {{Committees}}},
  author = {Wang, Xiaofang and Kondratyuk, Dan and Christiansen, Eric and Kitani, Kris M. and Alon, Yair and Eban, Elad},
  date = {2020},
  doi = {10.48550/ARXIV.2012.01988},
  url = {https://arxiv.org/abs/2012.01988},
  urldate = {2023-05-03},
  abstract = {Committee-based models (ensembles or cascades) construct models by combining existing pre-trained ones. While ensembles and cascades are well-known techniques that were proposed before deep learning, they are not considered a core building block of deep model architectures and are rarely compared to in recent literature on developing efficient models. In this work, we go back to basics and conduct a comprehensive analysis of the efficiency of committee-based models. We find that even the most simplistic method for building committees from existing, independently pre-trained models can match or exceed the accuracy of state-of-the-art models while being drastically more efficient. These simple committee-based models also outperform sophisticated neural architecture search methods (e.g., BigNAS). These findings hold true for several tasks, including image classification, video classification, and semantic segmentation, and various architecture families, such as ViT, EfficientNet, ResNet, MobileNetV2, and X3D. Our results show that an EfficientNet cascade can achieve a 5.4x speedup over B7 and a ViT cascade can achieve a 2.3x speedup over ViT-L-384 while being equally accurate.},
  pubstate = {preprint},
  version = {6},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences},
  annotation = {15 citations (Semantic Scholar/arXiv) [2023-05-02]}
}

@article{warfield_Simultaneous_2004,
  title = {Simultaneous {{Truth}} and {{Performance Level Estimation}} ({{STAPLE}}): {{An Algorithm}} for the {{Validation}} of {{Image Segmentation}}},
  shorttitle = {Simultaneous {{Truth}} and {{Performance Level Estimation}} ({{STAPLE}})},
  author = {Warfield, S.K. and Zou, K.H. and Wells, W.M.},
  date = {2004-07},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {23},
  number = {7},
  pages = {903--921},
  issn = {0278-0062},
  doi = {10.1109/TMI.2004.828354},
  url = {http://ieeexplore.ieee.org/document/1309714/},
  urldate = {2023-01-27},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {1850 citations (Semantic Scholar/DOI) [2023-01-26]},
  file = {/Users/personal-macbook/Zotero/storage/55ETMTQH/Warfield et al. - 2004 - Simultaneous Truth and Performance Level Estimatio.pdf}
}

@online{website_insurer_2013,
  ids = {_Insurer_2013},
  title = {Insurer {{Analyzes Top}} 10 {{Driving Distractions Involved}} in {{Fatal Car Crashes}}},
  date = {2013-04-04T16:25:22+00:00},
  url = {https://www.insurancejournal.com/news/national/2013/04/04/287259.htm},
  urldate = {2023-05-14},
  abstract = {Of the more than 65,000 people in the U.S. killed in car crashes over the past two years, one in 10 were in crashes where at least one of the drivers was},
  langid = {american},
  organization = {{Insurance Journal}},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/4RXNZYDI/287259.html}
}

@article{wedel_Stereoscopic_2011,
  title = {Stereoscopic {{Scene Flow Computation}} for {{3D Motion Understanding}}},
  author = {Wedel, Andreas and Brox, Thomas and Vaudrey, Tobi and Rabe, Clemens and Franke, Uwe and Cremers, Daniel},
  date = {2011},
  journaltitle = {Int. J. Comput. Vis.},
  issn = {09205691},
  doi = {10.1007/s11263-010-0404-0},
  url = {http://www.springerlink.com/content/028362k33p1560u5/fulltext.pdf},
  abstract = {Building upon recent developments in optical flow and stereo matching estimation, we propose a variational framework for the estimation of stereoscopic scene flow, i.e., the motion of points in the three-dimensional world from stereo image sequences. The proposed algorithm takes into account image pairs from two consecutive times and computes both depth and a 3D motion vector associated with each point in the image. In contrast to previous works, we partially decouple the depth estimation from the motion estimation, which has many practical advantages. The variational formulation is quite flexible and can handle both sparse or dense disparity maps. The proposed method is very efficient; with the depth map being computed on an FPGA, and the scene flow computed on the GPU, the proposed algorithm runs at frame rates of 20 frames per second on QVGA images (320\texttimes 240 pixels). Furthermore, we present solutions to two important problems in scene flow estimation: violations of intensity consistency between input images, and the uncertainty measures for the scene flow result. \textcopyright{} 2010 Springer Science+Business Media, LLC.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,3D motion,3D reconstruction,Motion segmentation,Scene flow,Structure from motion}
}

@article{wei_Convolutional_2016,
  title = {Convolutional {{Pose Machines}}},
  author = {Wei, Shih-En and Ramakrishna, Varun and Kanade, Takeo and Sheikh, Yaser},
  date = {2016-01},
  abstract = {Pose Machines provide a sequential prediction framework for learning rich implicit spatial models. In this work we show a systematic design for how convolutional networks can be incorporated into the pose machine framework for learning image features and image-dependent spatial models for the task of pose estimation. The contribution of this paper is to implicitly model long-range dependencies between variables in structured prediction tasks such as articulated pose estimation. We achieve this by designing a sequential architecture composed of convolutional networks that directly operate on belief maps from previous stages, producing increasingly refined estimates for part locations, without the need for explicit graphical model-style inference. Our approach addresses the characteristic difficulty of vanishing gradients during training by providing a natural learning objective function that enforces intermediate supervision, thereby replenishing back-propagated gradients and conditioning the learning procedure. We demonstrate state-of-the-art performance and outperform competing methods on standard benchmarks including the MPII, LSP, and FLIC datasets.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{wei_Ensemble_2020a,
  ids = {wei_Ensemble_2020},
  title = {Ensemble {{Deep Learning Model}} for {{Multicenter Classification}} of {{Thyroid Nodules}} on {{Ultrasound Images}}},
  author = {Wei, Xi and Gao, Ming and Yu, Ruiguo and Liu, Zhiqiang and Gu, Qing and Liu, Xun and Zheng, Zhiming and Zheng, Xiangqian and Zhu, Jialin and Zhang, Sheng},
  date = {2020-06-18},
  journaltitle = {Med Sci Monit},
  volume = {26},
  eprint = {32555130},
  eprinttype = {pmid},
  pages = {e926096},
  issn = {1643-3750},
  doi = {10.12659/MSM.926096},
  abstract = {BACKGROUND Thyroid nodules are extremely common and typically diagnosed with ultrasound whether benign or malignant. Imaging diagnosis assisted by Artificial Intelligence has attracted much attention in recent years. The aim of our study was to build an ensemble deep learning classification model to accurately differentiate benign and malignant thyroid nodules. MATERIAL AND METHODS Based on current advanced methods of image segmentation and classification algorithms, we proposed an ensemble deep learning classification model for thyroid nodules (EDLC-TN) after precise localization. We compared diagnostic performance with four other state-of-the-art deep learning algorithms and three ultrasound radiologists according to ACR TI-RADS criteria. Finally, we demonstrated the general applicability of EDLC-TN for diagnosing thyroid cancer using ultrasound images from multi medical centers. RESULTS The method proposed in this paper has been trained and tested on a thyroid ultrasound image dataset containing 26 541 images and the accuracy of this method could reach 98.51\%. EDLC-TN demonstrated the highest value for area under the curve, sensitivity, specificity, and accuracy among five state-of-the-art algorithms. Combining EDLC-TN with models and radiologists could improve diagnostic accuracy. EDLC-TN achieved excellent diagnostic performance when applied to ultrasound images from another independent hospital. CONCLUSIONS Based on ensemble deep learning, the proposed approach in this paper is superior to other similar existing methods of thyroid classification, as well as ultrasound radiologists. Moreover, our network represents a generalized platform that potentially can be applied to medical images from multiple medical centers.},
  langid = {english},
  pmcid = {PMC7325553},
  keywords = {⛔ No INSPIRE recid found,{Adenocarcinoma, Follicular},Adenoma,Adolescent,Adult,Aged,{Aged, 80 and over},{Carcinoma, Neuroendocrine},Deep Learning,Female,{Goiter, Nodular},Granuloma,Humans,{Image Interpretation, Computer-Assisted},Male,Middle Aged,{Thyroid Cancer, Papillary},{Thyroid Carcinoma, Anaplastic},Thyroid Neoplasms,Thyroid Nodule,Ultrasonography,Young Adult},
  annotation = {14 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/6S2LWHN7/Wei et al. - 2020 - Ensemble Deep Learning Model for Multicenter Class.pdf}
}

@book{wei-skillern_Entrepreneurship_2007,
  title = {Entrepreneurship in the {{Social Sector}}},
  author = {Wei-Skillern, Jane and Austin, James E. and Leonard, Herman and Stevenson, Howard},
  date = {2007-05},
  publisher = {{SAGE}},
  abstract = {``Entrepreneurship in the Social Sector provides an excellent overview of the many tools available to the entrepreneur to advance his or her mission, and it discusses many of the problems that organizations and their managers encounter at different points of a growth process.''\textemdash NONPROFIT AND VOLUNTARY SECTOR QUARTERLYWritten for students and practitioners, this unique text, with Harvard cases, provides detailed analysis and frameworks for achieving maximum impact through social entrepreneurship. Entrepreneurship in the Social Sector enables readers to attain an in depth understanding of the distinctive characteristics of the social enterprise context and organizations. The authors offer tools to develop the knowledge to pursue social entrepreneurship more strategically and achieve mission impact more efficiently, effectively, and sustainably. Key Features Spans a range of social enterprise activity:Examples are included across multiple and varied contexts from the nonprofit, business, and government sectors.Offers Harvard Business School case studies: Through these cases, the critical components of social entrepreneurship are addressed including start-up, funding, growth, alliances and collaboration, and performance measurement.Presents cutting edge social enterprise research: Detailed analysis and frameworks introduce the key themes and ideas that are illustrated through the cases at the end of each chapter.Provides US and international coverage: Since social entrepreneurship is a growing field in the US and abroad, a number of case studies set in international settings are included.Intended AudienceThe text is designed as a core or supplementary text for advanced undergraduate and graduate courses such as Social Entrepreneurship or Non-Profit Entrepreneurship in the departments of business, management, marketing, and public policy.``The emerging field of social entrepreneurship has been crying out for a definitive textbook. With clarity, insight, and a strong practical orientation, the authors of Entrepreneurship in the Social Sector have set the gold standard for many years to come.'' \textemdash Professor J. Gregory Dees, Duke University``This is so much more than a casebook! Entrepreneurship in the Social Sector offers a grounded and insightful conceptualization of the key challenges and fundamental processes of social entrepreneurship. It also presents practical frameworks for analyzing both, across a wide range of organizations. This book should be on the shelf of every aspiring and successful social entrepreneur.'' \textemdash James A. Phills, Jr., Stanford University},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{welinder_Multidimensional_2010,
  title = {The {{Multidimensional Wisdom}} of {{Crowds}}},
  booktitle = {Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.},
  author = {Welinder, Peter and Branson, Steve and Perona, Pietro and Belongie, Serge},
  date = {2010},
  volume = {23},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2010/file/0f9cafd014db7a619ddb4276af0d692c-Paper.pdf},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/ZMTNK7YW/Welinder et al. - 2010 - The Multidimensional Wisdom of Crowds.pdf;/Users/personal-macbook/Zotero/storage/8NDLFI9D/0f9cafd014db7a619ddb4276af0d692c-Abstract.html}
}

@article{weng_Can_2017,
  title = {Can {{Machine-Learning Improve Cardiovascular Risk Prediction Using Routine Clinical Data}}?},
  author = {Weng, Stephen F. and Reps, Jenna and Kai, Joe and Garibaldi, Jonathan M. and Qureshi, Nadeem},
  date = {2017},
  journaltitle = {PLoS ONE},
  eprint = {28376093},
  eprinttype = {pmid},
  issn = {19326203},
  doi = {10.1371/journal.pone.0174944},
  abstract = {Background: Current approaches to predict cardiovascular risk fail to identify many people who would benefit from preventive treatment, while others receive unnecessary intervention. Machine-learning offers opportunity to improve accuracy by exploiting complex interactions between risk factors. We assessed whether machine-learning can improve cardiovascular risk prediction. Methods: Prospective cohort study using routine clinical data of 378,256 patients from UK family practices, free from cardiovascular disease at outset. Four machine-learning algorithms (random forest, logistic regression, gradient boosting machines, neural networks) were compared to an established algorithm (American College of Cardiology guidelines) to predict first cardiovascular event over 10-years. Predictive accuracy was assessed by area under the 'receiver operating curve' (AUC); and sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV) to predict 7.5\% cardiovascular risk (threshold for initiating statins). Findings: 24,970 incident cardiovascular events (6.6\%) occurred. Compared to the established risk prediction algorithm (AUC 0.728, 95\% CI 0.723-0.735), machine-learning algorithms improved prediction: random forest +1.7\% (AUC 0.745, 95\% CI 0.739-0.750), logistic regression +3.2\% (AUC 0.760, 95\% CI 0.755-0.766), gradient boosting +3.3\% (AUC 0.761, 95\% CI 0.755-0.766), neural networks +3.6\% (AUC 0.764, 95\% CI 0.759-0.769). The highest achieving (neural networks) algorithm predicted 4,998/7,404 cases (sensitivity 67.5\%, PPV 18.4\%) and 53,458/75,585 non-cases (specificity 70.7\%, NPV 95.7\%), correctly predicting 355 (+7.6\%) more patients who developed cardiovascular disease compared to the established algorithm. Conclusions: Machine-learning significantly improves accuracy of cardiovascular risk prediction, increasing the number of patients identified who could benefit from preventive treatment, while avoiding unnecessary treatment of others.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {715 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{wenjiabai_Probabilistic_2013,
  ids = {bai_Probabilistic_2013},
  title = {A {{Probabilistic Patch-Based Label Fusion Model}} for {{Multi-Atlas Segmentation With Registration Refinement}}: {{Application}} to {{Cardiac Mr Images}}},
  shorttitle = {A {{Probabilistic Patch-Based Label Fusion Model}} for {{Multi-Atlas Segmentation}} with {{Registration Refinement}}},
  author = {{Wenjia Bai} and {Wenzhe Shi} and O'Regan, D. P. and {Tong Tong} and {Haiyan Wang} and Jamil-Copley, S. and Peters, N. S. and Rueckert, D.},
  date = {2013-07},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {32},
  number = {7},
  pages = {1302--1315},
  issn = {0278-0062, 1558-254X},
  doi = {10.1109/TMI.2013.2256922},
  url = {http://ieeexplore.ieee.org/document/6494647/},
  urldate = {2023-05-08},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {202 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/Q28YLG98/Wenjia Bai et al. - 2013 - A Probabilistic Patch-Based Label Fusion Model for.pdf}
}

@inproceedings{whitehill_Whose_2009,
  title = {Whose {{Vote Should Count More}}: {{Optimal Integration}} of {{Labels From Labelers}} of {{Unknown Expertise}}},
  shorttitle = {Whose {{Vote Should Count More}}},
  booktitle = {Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.},
  author = {Whitehill, Jacob and Wu, Ting-fan and Bergsma, Jacob and Movellan, Javier and Ruvolo, Paul},
  date = {2009},
  volume = {22},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2009/file/f899139df5e1059396431415e770c6dd-Paper.pdf},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/IJBYV7LA/Whitehill et al. - 2009 - Whose vote should count more Optimal integration .pdf;/Users/personal-macbook/Zotero/storage/D7Q8KUBE/f899139df5e1059396431415e770c6dd-Abstract.html}
}

@article{wiegell_Automatic_2003,
  title = {Automatic {{Segmentation}} of {{Thalamic Nuclei From Diffusion Tensor Magnetic Resonance Imaging}}},
  author = {Wiegell, Mette R and Tuch, David S and Larsson, Henrik B.W and Wedeen, Van J},
  date = {2003-06},
  journaltitle = {NeuroImage},
  volume = {19},
  number = {2},
  pages = {391--401},
  issn = {10538119},
  doi = {10.1016/S1053-8119(03)00044-2},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811903000442},
  urldate = {2023-05-12},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {277 citations (Semantic Scholar/DOI) [2023-05-12]}
}

@article{willyard_Can_2019,
  title = {Can {{AI Fix Medical Records}}?},
  author = {Willyard, Cassandra},
  date = {2019},
  journaltitle = {Nature},
  eprint = {31853075},
  eprinttype = {pmid},
  issn = {14764687},
  doi = {10.1038/d41586-019-03848-y},
  abstract = {Digitized patient charts were supposed to revolutionize medical practice. Artificial intelligence could help unlock their potential. [Figure not available: see fulltext.].},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Computer science,Health care},
  annotation = {7 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{wilson_Survey_2020,
  title = {A {{Survey}} of {{Unsupervised Deep Domain Adaptation}}},
  author = {Wilson, Garrett and Cook, Diane J.},
  date = {2020},
  journaltitle = {ACM Trans. Intell. Syst. Technol.},
  issn = {2157-6904},
  doi = {10.1145/3400066},
  abstract = {Deep learning has produced state-of-the-art results for a variety of tasks. While such approaches for supervised learning have performed well, they assume that training and testing data are drawn from the same distribution, which may not always be the case. As a complement to this challenge, single-source unsupervised domain adaptation can handle situations where a network is trained on labeled data from a source domain and unlabeled data from a related but different target domain with the goal of performing well at test-time on the target domain. Many single-source and typically homogeneous unsupervised deep domain adaptation approaches have thus been developed, combining the powerful, hierarchical representations from deep learning with domain adaptation to reduce reliance on potentially-costly target data labels. This survey will compare these approaches by examining alternative methods, the unique and common elements, results, and theoretical insights. We follow this with a look at application areas and open research directions.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {395 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{wiltschko_Mapping_2015,
  title = {Mapping {{Sub-Second Structure}} in {{Mouse Behavior}}},
  author = {Wiltschko, Alexander~B. and Johnson, Matthew~J. and Iurilli, Giuliano and Peterson, Ralph~E. and Katon, Jesse~M. and Pashkovski, Stan~L. and Abraira, Victoria~E. and Adams, Ryan~P. and Datta, Sandeep~Robert},
  date = {2015-12},
  journaltitle = {Neuron},
  volume = {88},
  number = {6},
  pages = {1121--1135},
  issn = {08966273},
  doi = {10.1016/j.neuron.2015.11.031},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627315010375},
  urldate = {2023-05-08},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {496 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/VAGKTRWN/Wiltschko et al. - 2015 - Mapping Sub-Second Structure in Mouse Behavior.pdf}
}

@inproceedings{winn_Object_2006,
  ids = {winn2006object,winn_objectclassrecognitionglance_2006},
  title = {Object {{Class Recognition}} at a {{Glance}}},
  booktitle = {Proc. {{IEEE Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}.},
  author = {Winn, John and Criminisi, Antonio},
  date = {2006},
  pages = {1082--1090},
  publisher = {{IEEE}},
  url = {https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/Criminisi_cvpr2006_video.pdf},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/PLREW99K/Winn and Criminisi - 2006 - Object Class Recognition at a Glance.pdf;/Users/personal-macbook/Zotero/storage/XJ7X9ISU/Winn and Criminisi - 2006 - Object class recognition at a glance.pdf}
}

@article{winzeck_ISLES_2018,
  title = {{{ISLES}} 2016 and 2017-{{Benchmarking Ischemic Stroke Lesion Outcome Prediction Based}} on {{Multispectral MRI}}},
  author = {Winzeck, Stefan and Hakim, Arsany and McKinley, Richard and Pinto, Jos\'e A. A. D. S. R. and Alves, Victor and Silva, Carlos and Pisov, Maxim and Krivov, Egor and Belyaev, Mikhail and Monteiro, Miguel and Oliveira, Arlindo and Choi, Youngwon and Paik, Myunghee Cho and Kwon, Yongchan and Lee, Hanbyul and Kim, Beom Joon and Won, Joong-Ho and Islam, Mobarakol and Ren, Hongliang and Robben, David and Suetens, Paul and Gong, Enhao and Niu, Yilin and Xu, Junshen and Pauly, John M. and Lucas, Christian and Heinrich, Mattias P. and Rivera, Luis C. and Castillo, Laura S. and Daza, Laura A. and Beers, Andrew L. and Arbelaezs, Pablo and Maier, Oskar and Chang, Ken and Brown, James M. and Kalpathy-Cramer, Jayashree and Zaharchuk, Greg and Wiest, Roland and Reyes, Mauricio},
  date = {2018-09-13},
  journaltitle = {Front. Neurol.},
  volume = {9},
  pages = {679},
  issn = {1664-2295},
  doi = {10.3389/fneur.2018.00679},
  url = {https://www.frontiersin.org/article/10.3389/fneur.2018.00679/full},
  urldate = {2023-04-06},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {116 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/ZD6PL2A2/Winzeck et al. - 2018 - ISLES 2016 and 2017-Benchmarking Ischemic Stroke L.pdf}
}

@article{wisse_Hippocampal_2014,
  title = {Hippocampal {{Subfield Volumes}} at {{7T}} in {{Early Alzheimer}}'s {{Disease}} and {{Normal Aging}}},
  author = {Wisse, Laura E. M. and Biessels, Geert Jan and Heringa, Sophie M. and Kuijf, Hugo J. and Koek, Dineke (H ) L. and Luijten, Peter R. and Geerlings, Mirjam I.},
  date = {2014-09},
  journaltitle = {Neurobiol. Aging},
  volume = {35},
  number = {9},
  pages = {2039--2045},
  doi = {10.1016/j.neurobiolaging.2014.02.021},
  abstract = {We compared hippocampal subfield and entorhinal cortex (ERC) volumes between patients with mild cognitive impairment (MCI), Alzheimer's disease (AD), and controls without cognitive impairment. Additionally, we investigated the relation between age and hippocampal subfields and ERC in controls. We performed ultra-high field 0.7 mm3 7Tesla magnetic resonance imaging in 16 patients with amnestic MCI, 9 with AD, and 29 controls. ERC, subiculum, cornu ammonis (CA)1, CA2, CA3, and dentate gyrus (DG)\&CA4 were traced on T2-weighted images. Analyses of covariance, adjusted for age, sex, and intracranial volume showed that compared with controls and patients with MCI, patients with AD had significantly smaller ERC, subiculum, CA1, CA3, and DG\&CA4 volumes. Trend analyses revealed similar associations between ERC and hippocampal subfields and diagnostic group. Older age was significantly associated with smaller CA1 and DG\&CA4 volumes. In conclusion, almost all hippocampal subfields and ERC show volume reductions in patients with AD compared with controls and patients with MCI. Future, larger studies should determine which subfields are affected earliest in the disease process and what mechanisms underlie the volume loss.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,7Tesla,Alzheimer disease,Hippocampal subfields},
  annotation = {128 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{wolf_Mathematical_2018,
  title = {Mathematical {{Foundations}} of {{Supervised Learning}} ({{Growing Lecture Notes}})},
  author = {Wolf, Michael M.},
  date = {2018},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@inproceedings{wolterink_Deep_2017,
  title = {Deep {{MR}} to {{CT Synthesis Using Unpaired Data}}},
  booktitle = {Lect. {{Notes Comput}}. {{Sci}}. {{Subser}}. {{Lect}}. {{Notes Artif}}. {{Intell}}. {{Lect}}. {{Notes Bioinforma}}.},
  author = {Wolterink, Jelmer M. and Dinkla, Anna M. and Savenije, Mark H. F. and Seevinck, Peter R. and family=Berg, given=Cornelis A. T., prefix=van den, useprefix=false and I\v{s}gum, Ivana},
  date = {2017},
  issn = {16113349},
  doi = {10.1007/978-3-319-68127-6_2},
  abstract = {MR-only radiotherapy treatment planning requires accurate MR-to-CT synthesis. Current deep learning methods for MR-to-CT synthesis depend on pairwise aligned MR and CT training images of the same patient. However, misalignment between paired images could lead to errors in synthesized CT images. To overcome this, we propose to train a generative adversarial network (GAN) with unpaired MR and CT images. A GAN consisting of two synthesis convolutional neural networks (CNNs) and two discriminator CNNs was trained with cycle consistency to transform 2D brain MR image slices into 2D brain CT image slices and vice versa. Brain MR and CT images of 24 patients were analyzed. A quantitative evaluation showed that the model was able to synthesize CT images that closely approximate reference CT images, and was able to outperform a GAN model trained with paired MR and CT images.},
  isbn = {978-3-319-68126-9},
  keywords = {\#nosource,⛔ No INSPIRE recid found,CT synthesis,Deep learning,Generative adversarial networks,Radiotherapy,Treatment planning},
  annotation = {500 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{wolz_LEAP_2010,
  title = {{{LEAP}}: {{Learning Embeddings}} for {{Atlas Propagation}}},
  shorttitle = {{{LEAP}}},
  author = {Wolz, Robin and Aljabar, Paul and Hajnal, Joseph V. and Hammers, Alexander and Rueckert, Daniel},
  date = {2010-01},
  journaltitle = {NeuroImage},
  volume = {49},
  number = {2},
  pages = {1316--1325},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2009.09.069},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811909010684},
  urldate = {2023-05-08},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {246 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/ZLRRWU6E/Wolz et al. - 2010 - LEAP Learning embeddings for atlas propagation.pdf}
}

@article{woodward_Thalamocortical_2012,
  title = {Thalamocortical {{Dysconnectivity}} in {{Schizophrenia}}},
  author = {Woodward, Neil D. and Karbasforoushan, Haleh and Heckers, Stephan},
  date = {2012-10},
  journaltitle = {Am. J. Psychiatry},
  volume = {169},
  number = {10},
  pages = {1092--1099},
  doi = {10.1176/appi.ajp.2012.12010056},
  abstract = {OBJECTIVE: The thalamus and cerebral cortex are connected via topographically organized, reciprocal connections. Previous studies have revealed thalamic abnormalities in schizophrenia; however, it is not known whether thalamocortical networks are differentially affected in the disorder. To explore this possibility, the authors examined functional connectivity in intrinsic low-frequency blood-oxygen-level-dependent (BOLD) signal fluctuations between major divisions of the cortex and thalamus using resting-state functional MRI (fMRI). METHOD: Seventy-seven healthy subjects and 62 patients with schizophrenia underwent resting-state fMRI. To identify functional subdivisions of the thalamus, the authors parceled the cortex into six regions of interest: the prefrontal cortex, motor cortex/supplementary motor area, somatosensory cortex, temporal lobe, posterior parietal cortex, and occipital lobe. Mean BOLD time series were extracted for each region of interest and entered into a seed-based functional connectivity analysis. RESULTS: Consistent with previous reports, activity in distinct cortical areas correlated with specific, largely nonoverlapping regions of the thalamus in both healthy comparison subjects and schizophrenia patients. Direct comparison between groups revealed reduced prefrontal-thalamic connectivity and increased motor/somatosensory-thalamic connectivity in schizophrenia. The changes in connectivity were unrelated to local gray matter content within the thalamus and to antipsychotic medication dosage. No differences were observed in temporal, posterior parietal, or occipital cortex connectivity with the thalamus. CONCLUSIONS: These findings establish differential abnormalities of thalamocortical networks in schizophrenia. The etiology of schizophrenia may disrupt the development of prefrontal-thalamic connectivity and refinement of somatomotor connectivity with the thalamus that occurs during brain maturation.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{woznitza_Immediate_2018,
  title = {Immediate {{Reporting}} of {{Chest X-Rays Referred From General Practice}} by {{Reporting Radiographers}}: {{A Single Centre Feasibility Study}}},
  shorttitle = {Immediate {{Reporting}} of {{Chest X-Rays Referred}} from {{General Practice}} by {{Reporting Radiographers}}},
  author = {Woznitza, N. and Piper, K. and Rowe, S. and Bhowmik, A.},
  date = {2018-05},
  journaltitle = {Clin Radiol},
  volume = {73},
  number = {5},
  eprint = {29246588},
  eprinttype = {pmid},
  pages = {507.e1-507.e8},
  issn = {0009-9260},
  doi = {10.1016/j.crad.2017.11.016},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5903871/},
  urldate = {2022-11-21},
  abstract = {\textbullet{}               Early lung cancer diagnosis is often limited by insufficient radiology capacity.                                         \textbullet{}               It is feasible to introduce immediate reporting of chest X-rays from general practice by radiographers.                                         \textbullet{}               Time to diagnosis of lung cancer can be significantly shortened with immediate chest X-ray reporting.},
  pmcid = {PMC5903871},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {20 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/4UWWMJYE/Woznitza et al. - 2018 - Immediate reporting of chest X-rays referred from .pdf}
}

@inproceedings{wu_Active_2018,
  title = {Active {{Learning With Noise Modeling}} for {{Medical Image Annotation}}},
  booktitle = {2018 {{IEEE}} 15th {{Int}}. {{Symp}}. {{Biomed}}. {{Imaging ISBI}} 2018},
  author = {Wu, J. and Ruan, S. and Lian, C. and Mutic, S. and Anastasio, M. A. and Li, H.},
  date = {2018-04},
  pages = {298--301},
  abstract = {Active learning is an effective solution to select informative training datasets (examples) from which a pre-defined classifier learns for optimizing its performance. It has been widely applied for information extraction, classification, and filtering. Most existing active learning methods do not consider image noise separately to guide the selection of informative examples, which might lead to sub-optimal annotation. Due to the intrinsic presence of noise in images, large amount of images, and varied imaging modalities, using active learning for medical image annotation is an even more challenging task. In this study, we develop a novel low-rank modeling-based multi-label active learning (LRMMAL) method for effective medical image annotation. Different to those traditional active learning methods, the LRMMAL method innovatively measures image noise and combines it with the measures of example label uncertainty and label correlation into a new sampling process to determine most informative examples for annotation. Experimental results on thoracic CT images and comparisons with other four multi-label active learning methods illustrate the superior performance of the LRMMAL method.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,computerised tomography,image classification,learn}
}

@thesis{wu_Degrees_M13,
  title = {Degrees in {{Computer Science From Soochow University}}, {{Suzhou}}, {{China}}, in 2004 and 2012, {{Respectively}}},
  author = {Wu, Jian},
  year = {(M'13)},
  pagetotal = {received},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{wu_MultiLabel_2020,
  title = {Multi-{{Label Active Learning Algorithms}} for {{Image Classification}}: {{Overview}} and {{Future Promise}}},
  shorttitle = {Multi-{{Label Active Learning Algorithms}} for {{Image Classification}}},
  author = {Wu, Jian and Sheng, Victor S. and Zhang, Jing and Li, Hua and Dadakova, Tetiana and Swisher, Christine Leon and Cui, Zhiming and Zhao, Pengpeng},
  date = {2020-07},
  journaltitle = {ACM Comput. Surv.},
  volume = {53},
  number = {2},
  pages = {1--35},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3379504},
  url = {https://dl.acm.org/doi/10.1145/3379504},
  urldate = {2021-11-16},
  abstract = {Image classification is a key task in image understanding, and multi-label image classification has become a popular topic in recent years. However, the success of multi-label image classification is closely related to the way of constructing a training set. As active learning aims to construct an effective training set through iteratively selecting the most informative examples to query labels from annotators, it was introduced into multi-label image classification. Accordingly, multi-label active learning is becoming an important research direction. In this work, we first review existing multi-label active learning algorithms for image classification. These algorithms can be categorized into two top groups from two aspects respectively: sampling and annotation. The most important component of multi-label active learning is to design an effective sampling strategy that actively selects the examples with the highest informativeness from an unlabeled data pool, according to various information measures. Thus, different informativeness measures are emphasized in this survey. Furthermore, this work also makes a deep investigation on existing challenging issues and future promises in multi-label active learning with a focus on four core aspects: example dimension, label dimension, annotation, and application extension.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/HUL37KA7/Wu et al. - 2020 - Multi-Label Active Learning Algorithms for Image C.pdf}
}

@article{wu_PointConv_,
  title = {{{PointConv}}: {{Deep Convolutional Networks}} on {{3D Point Clouds}}},
  author = {Wu, Wenxuan and Qi, Zhongang and Fuxin, Li},
  pages = {10},
  doi = {10.1109/CVPR.2019.00985},
  abstract = {Unlike images which are represented in regular dense grids, 3D point clouds are irregular and unordered, hence applying convolution on them can be difficult. In this paper, we extend the dynamic filter to a new convolution operation, named PointConv. PointConv can be applied on point clouds to build deep convolutional networks. We treat convolution kernels as nonlinear functions of the local coordinates of 3D points comprised of weight and density functions. With respect to a given point, the weight functions are learned with multi-layer perceptron networks and density functions through kernel density estimation. The most important contribution of this work is a novel reformulation proposed for efficiently computing the weight functions, which allowed us to dramatically scale up the network and significantly improve its performance. The learned convolution kernel can be used to compute translation-invariant and permutation-invariant convolution on any point set in the 3D space. Besides, PointConv can also be used as deconvolution operators to propagate features from a subsampled point cloud back to its original resolution. Experiments on ModelNet40, ShapeNet, and ScanNet show that deep convolutional neural networks built on PointConv are able to achieve state-of-the-art on challenging semantic segmentation benchmarks on 3D point clouds. Besides, our experiments converting CIFAR-10 into a point cloud showed that networks built on PointConv can match the performance of convolutional networks in 2D images of a similar structure.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/RBR72W4M/Wu et al. - PointConv Deep Convolutional Networks on 3D Point.pdf}
}

@article{wu_Recent_2020a,
  ids = {wu_Recent_2020},
  title = {Recent {{Advances}} in {{Deep Learning}} for {{Object Detection}}},
  author = {Wu, Xiongwei and Sahoo, Doyen and Hoi, Steven C. H.},
  date = {2020-07-05},
  journaltitle = {Neurocomputing},
  volume = {396},
  pages = {39--64},
  issn = {0925-2312},
  doi = {10.1016/j.neucom.2020.01.085},
  url = {https://www.sciencedirect.com/science/article/pii/S0925231220301430},
  urldate = {2022-05-16},
  abstract = {Object detection is a fundamental visual recognition problem in computer vision and has been widely studied in the past decades. Visual object detection aims to find objects of certain target classes with precise localization in a given image and assign each object instance a corresponding class label. Due to the tremendous successes of deep learning based image classification, object detection techniques using deep learning have been actively studied in recent years. In this paper, we give a comprehensive survey of recent advances in visual object detection with deep learning. By reviewing a large body of recent related work in literature, we systematically analyze the existing object detection frameworks and organize the survey into three major parts: (i) detection components, (ii) learning strategies, and (iii) applications \& benchmarks. In the survey, we cover a variety of factors affecting the detection performance in detail, such as detector architectures, feature learning, proposal generation, sampling strategies, etc. Finally, we discuss several future directions to facilitate and spur future research for visual object detection with deep learning.},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Deep convolutional neural networks,Deep learning,Object detection},
  annotation = {241 citations (Semantic Scholar/DOI) [2022-07-18]},
  file = {/Users/personal-macbook/Zotero/storage/JJESQVRI/Wu et al. - 2020 - Recent advances in deep learning for object detect.pdf;/Users/personal-macbook/Zotero/storage/LH7H5M99/Wu et al. - 2020 - Recent advances in deep learning for object detect.html;/Users/personal-macbook/Zotero/storage/SHMT22U3/Wu et al. - 2020 - Recent advances in deep learning for object detect.html}
}

@inproceedings{xia_3D_2020,
  title = {{{3D Semi-Supervised Learning With Uncertainty-Aware Multi-View Co-Training}}},
  booktitle = {2020 {{IEEE Winter Conf}}. {{Appl}}. {{Comput}}. {{Vis}}. {{WACV}}},
  author = {Xia, Yingda and Liu, Fengze and Yang, Dong and Cai, Jinzheng and Yu, Lequan and Zhu, Zhuotun and Xu, Daguang and Yuille, Alan and Roth, Holger},
  date = {2020-03},
  pages = {3635--3644},
  publisher = {{IEEE}},
  location = {{Snowmass Village, CO, USA}},
  doi = {10.1109/WACV45572.2020.9093608},
  url = {https://ieeexplore.ieee.org/document/9093608/},
  urldate = {2022-12-29},
  eventtitle = {2020 {{IEEE Winter Conference}} on {{Applications}} of {{Computer Vision}} ({{WACV}})},
  isbn = {978-1-72816-553-0},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {88 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/DEUQQAAW/Xia et al. - 2020 - 3D Semi-Supervised Learning with Uncertainty-Aware.pdf}
}

@article{xia_Uncertaintyaware_2020,
  title = {Uncertainty-{{Aware Multi-View Co-Training}} for {{Semi-Supervised Medical Image Segmentation}} and {{Domain Adaptation}}},
  author = {Xia, Yingda and Yang, Dong and Yu, Zhiding and Liu, Fengze and Cai, Jinzheng and Yu, Lequan and Zhu, Zhuotun and Xu, Daguang and Yuille, Alan and Roth, Holger},
  date = {2020-10},
  journaltitle = {Med. Image Anal.},
  volume = {65},
  pages = {101766},
  issn = {13618423},
  doi = {10.1016/j.media.2020.101766},
  abstract = {Although having achieved great success in medical image segmentation, deep learning-based approaches usually require large amounts of well-annotated data, which can be extremely expensive in the field of medical image analysis. Unlabeled data, on the other hand, is much easier to acquire. Semi-supervised learning and unsupervised domain adaptation both take the advantage of unlabeled data, and they are closely related to each other. In this paper, we propose uncertainty-aware multi-view co-training (UMCT), a unified framework that addresses these two tasks for volumetric medical image segmentation. Our framework is capable of efficiently utilizing unlabeled data for better performance. We firstly rotate and permute the 3D volumes into multiple views and train a 3D deep network on each view. We then apply co-training by enforcing multi-view consistency on unlabeled data, where an uncertainty estimation of each view is utilized to achieve accurate labeling. Experiments on the NIH pancreas segmentation dataset and a multi-organ segmentation dataset show state-of-the-art performance of the proposed framework on semi-supervised medical image segmentation. Under unsupervised domain adaptation settings, we validate the effectiveness of this work by adapting our multi-organ segmentation model to two pathological organs from the Medical Segmentation Decathlon Datasets. Additionally, we show that our UMCT-DA model can even effectively handle the challenging situation where labeled source data is inaccessible, demonstrating strong potentials for real-world applications.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Domain adaptation,Segmentation,Semi-supervised learning,Uncertainty estimation}
}

@inproceedings{xianfan_Multiple_2008,
  ids = {fan_Multiple_2008},
  title = {A {{Multiple Geometric Deformable Model Framework}} for {{Homeomorphic}} 3d {{Medical Image Segmentation}}},
  booktitle = {2008 {{IEEE Comput}}. {{Soc}}. {{Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}. {{Workshop}}},
  author = {{Xian Fan} and Bazin, Pierre-Louis and Bogovic, John and {Ying Bai} and Prince, Jerry L.},
  date = {2008-06},
  pages = {1--7},
  publisher = {{IEEE}},
  location = {{Anchorage, AK, USA}},
  doi = {10.1109/CVPRW.2008.4563013},
  url = {http://ieeexplore.ieee.org/document/4563013/},
  urldate = {2023-05-08},
  eventtitle = {2008 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition Workshops}} ({{CVPR Workshops}})},
  isbn = {978-1-4244-2339-2},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {15 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/F8ZYEM4V/Xian Fan et al. - 2008 - A multiple geometric deformable model framework fo.pdf}
}

@article{xiang_Deep_2018,
  title = {Deep {{Embedding Convolutional Neural Network}} for {{Synthesizing CT Image From T1-Weighted MR Image}}},
  author = {Xiang, Lei and Wang, Qian and Nie, Dong and Zhang, Lichi and Jin, Xiyao and Qiao, Yu and Shen, Dinggang},
  date = {2018},
  journaltitle = {Med. Image Anal.},
  issn = {13618423},
  doi = {10.1016/j.media.2018.03.011},
  abstract = {Recently, more and more attention is drawn to the field of medical image synthesis across modalities. Among them, the synthesis of computed tomography (CT) image from T1-weighted magnetic resonance (MR) image is of great importance, although the mapping between them is highly complex due to large gaps of appearances of the two modalities. In this work, we aim to tackle this MR-to-CT synthesis task by a novel deep embedding convolutional neural network (DECNN). Specifically, we generate the feature maps from MR images, and then transform these feature maps forward through convolutional layers in the network. We can further compute a tentative CT synthesis from the midway of the flow of feature maps, and then embed this tentative CT synthesis result back to the feature maps. This embedding operation results in better feature maps, which are further transformed forward in DECNN. After repeating this embedding procedure for several times in the network, we can eventually synthesize a final CT image in the end of the DECNN. We have validated our proposed method on both brain and prostate imaging datasets, by also comparing with the state-of-the-art methods. Experimental results suggest that our DECNN (with repeated embedding operations) demonstrates its superior performances, in terms of both the perceptive quality of the synthesized CT image and the run-time cost for synthesizing a CT image.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Deep convolutional neural network,Embedding block,Image synthesis},
  annotation = {115 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{xiao_Multimodal_2016,
  title = {Multimodal {{7T Imaging}} of {{Thalamic Nuclei}} for {{Preclinical Deep Brain Stimulation Applications}}},
  author = {Xiao, YiZi and Zitella, Laura M. and Duchin, Yuval and Teplitzky, Benjamin A. and Kastl, Daniel and Adriany, Gregor and Yacoub, Essa and Harel, Noam and Johnson, Matthew D.},
  date = {2016-06-10},
  journaltitle = {Front. Neurosci.},
  volume = {10},
  issn = {1662-453X},
  doi = {10.3389/fnins.2016.00264},
  url = {http://journal.frontiersin.org/Article/10.3389/fnins.2016.00264/abstract},
  urldate = {2023-05-28},
  keywords = {\#nosource,⛔ No INSPIRE recid found,diffusion weighted imaging,Diffusion weighted imaging,fiber tractography,Fiber tractography,hi,High-field imaging,Susceptibility weighted imaging,Thalamus},
  annotation = {24 citations (Semantic Scholar/DOI) [2023-05-28]},
  file = {/Users/personal-macbook/Zotero/storage/24QSHX7E/Xiao et al. - 2016 - Multimodal 7T Imaging of Thalamic Nuclei for Precl.pdf}
}

@inproceedings{xuan_Segmentation_1995,
  title = {Segmentation of {{Magnetic Resonance Brain Image}}: {{Integrating Region Growing}} and {{Edge Detection}}},
  booktitle = {Image {{Process}}. 1995 {{Proc}}. {{Int}}. {{Conf}}. {{On}}},
  author = {Xuan, Jianhua and Adali, T\"ulay and Wang, Yue},
  date = {1995},
  volume = {3},
  pages = {544--547},
  publisher = {{IEEE}},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@inproceedings{yan_Weakly_2018,
  title = {Weakly {{Supervised Deep Learning}} for {{Thoracic Disease Classification}} and {{Localization}} on {{Chest X-Rays}}},
  booktitle = {Int. {{Conf}}. {{Bioinforma}}. {{Comput}}. {{Biol}}. {{Health Inform}}.},
  author = {Yan, Chaochao and Yao, Jiawen and Li, Ruoyu and Xu, Zheng and Huang, Junzhou},
  date = {2018-08-15},
  pages = {103--110},
  publisher = {{ACM}},
  location = {{Washington DC USA}},
  doi = {10.1145/3233547.3233573},
  url = {https://dl.acm.org/doi/10.1145/3233547.3233573},
  urldate = {2022-11-21},
  eventtitle = {International {{Conference}} on {{Bioinformatics}}, {{Computational Biology}} and {{Health Informatics}}},
  isbn = {978-1-4503-5794-4},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {83 citations (Semantic Scholar/DOI) [2022-11-21]},
  file = {/Users/personal-macbook/Zotero/storage/8TWMHU22/Yan et al. - 2018 - Weakly Supervised Deep Learning for Thoracic Disea.pdf}
}

@article{yang_Design_2011,
  title = {Design of a 3-{{D Infrared Imaging System Using Structured Light}}},
  author = {Yang, Rongqian and Chen, Yazhu},
  date = {2011-02},
  journaltitle = {IEEE Trans. Instrum. Meas.},
  volume = {60},
  number = {2},
  pages = {608--617},
  issn = {00189456},
  doi = {10.1109/TIM.2010.2051614},
  abstract = {Two-dimensional infrared thermography (IRT) is widely used in various domains and can be extended to more applications if the spatial information of the temperature distribution is provided to form three-dimensional (3-D) thermography. A 3-D infrared (IR) imaging system based on structured light is designed to acquire the 3-D surface temperature distribution. The projector, color camera, and IR camera must be geometrically calibrated. However, few studies have been conducted on this topic, and conventional calibration techniques cannot be directly applied to such calibration because the IR camera is sensitive only to thermal information and cannot capture visible calibration patterns. Hence, three calibration patterns are designed, and corresponding calibration methods are proposed to calibrate this system effectively and accurately. Experimental results show that this system has high spatial accuracy and can effectively obtain the temperature distribution of a 3-D surface. \textcopyright{} 2006 IEEE.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,3-D infrared imaging,Camera calibration,infrared thermography (IRT),structured light,temperature distribution},
  annotation = {49 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{yang_Ethics_2020,
  title = {The {{Ethics}} of {{Artificial Intelligence}}},
  author = {Yang, Chun-Soo},
  date = {2020},
  journaltitle = {Leg. Stud. Inst. Chosun Univ.},
  issn = {17381363},
  doi = {10.18189/isicu.2020.27.1.73},
  abstract = {The last two decades have been witness to considerable progress in the administration of artificial nutrition and hydration (ANH). This can be used to sustain life in various patient groups that would have previously succumbed to the effects of malnutrition. The complexity of these clinical cases often causes healthcare professionals great anxiety, as the decision to initiate or withdraw ANH has significant emotional, ethical and resource implications. These difficult decisions require considerable deliberation, balancing the judgements and values of patients, their families and carers, and even the cultural beliefs of society at large. This short article looks at the application of contemporary medical ethical principles for guiding decisions and discusses the implications of the Mental Capacity Act, with particular relevance to ANH.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@inproceedings{yang_Learn_2019,
  title = {Learn to {{Be Uncertain}}: {{Leveraging Uncertain Labels}} in {{Chest X-Rays With Bayesian Neural Networks}}},
  booktitle = {{{IEEE Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}. {{CVPR Workshop}}},
  author = {Yang, Hao-Yu and Yang, Junling and Pan, Yue and Cao, Kunlin and Song, Qi and Gao, Feng and Yin, Youbing},
  date = {2019},
  abstract = {Communication of uncertainty is important for both radiology reports and deep neural networks (DNNs). For ra-diologists, conveying diagnostic uncertainty in the written report is a challenging and yet inevitable task. On the other hand, while deep learning models have shown compelling potentials in disease classification and lesion detection, applications of DNNs in the medical domain should provide a quantitative measurement of prediction confidence for risk management purposes. In this paper, we investigate the relationship between uncertainty in diagnostic chest x-ray radiology reports and uncertainty estimation of corresponding DNN models using Bayesian approaches. Two sampling methods, Bernoulli and Gaussian dropout have been tested. Our results show that the incorporation of uncertainty labels during model training results in higher predic-tive variance for uncertain cases at test time. The uncertain cases are inherently difficult to diagnose for human readers, which often needs a further psychical examination to confirm. Returning uncertain predictions on these cases will prevent the DNN model from making over-confident mistakes .},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{yang_Neural_2017,
  title = {Neural {{Multi-Atlas Label Fusion}}: {{Application}} to {{Cardiac MR Images}}},
  author = {Yang, Heran and Sun, Jian and Li, Huibin and Wang, Lisheng and Xu, Zongben},
  date = {2017-09},
  abstract = {Multi-atlas segmentation approach is one of the most widely-used image segmentation techniques in biomedical applications. There are two major challenges in this category of methods, i.e., atlas selection and label fusion. In this paper, we propose a novel multi-atlas segmentation method that formulates multi-atlas segmentation in a deep learning framework for better solving these challenges. The proposed method, dubbed deep fusion net (DFN), is a deep architecture that integrates a feature extraction subnet and a non-local patch-based label fusion (NL-PLF) subnet in a single network. The network parameters are learned by end-to-end training strategy for automatically learning deep features that enable optimal performance in a NL-PLF framework. Besides, the learned deep features are further utilized in defining a similarity measure for atlas selection. We evaluate our proposed method on two public cardiac MR databases of SATA-13 and LV-09 for left ventricle segmentation, and our learned DFNs with extracted deep features for atlas selection at testing phase achieve state-of-the-art accuracies, e.g., 0.833 in averaged Dice metric (ADM) on SATA-13 database and 0.95 in ADM for epicardium segmentation on LV-09 database. Besides, our method is robust to the cross-database evaluation, e.g., the DFN learned on LV-09 database achieves 0.815 in ADM on SATA-13 database. We also test our proposed method on Cardiac Atlas Project (CAP) testing set of MICCAI 2013 SATA Segmentation Challenge, and our method achieves 0.815 in Dice metric, ranking as the highest result on this dataset.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@online{yao_learningdiagnosescratchexploitingdependencieslabels_2017,
  ids = {yao_Learning_2017a,yao_Learning_2017b},
  title = {Learning to {{Diagnose From Scratch}} by {{Exploiting Dependencies Among Labels}}},
  author = {Yao, Li and Poblenz, Eric and Dagunts, Dmitry and Covington, Ben and Bernard, Devon and Lyman, Kevin},
  date = {2017},
  doi = {10.48550/ARXIV.1710.10501},
  url = {https://arxiv.org/abs/1710.10501},
  urldate = {2022-12-15},
  abstract = {The field of medical diagnostics contains a wealth of challenges which closely resemble classical machine learning problems; practical constraints, however, complicate the translation of these endpoints naively into classical architectures. Many tasks in radiology, for example, are largely problems of multi-label classification wherein medical images are interpreted to indicate multiple present or suspected pathologies. Clinical settings drive the necessity for high accuracy simultaneously across a multitude of pathological outcomes and greatly limit the utility of tools which consider only a subset. This issue is exacerbated by a general scarcity of training data and maximizes the need to extract clinically relevant features from available samples -- ideally without the use of pre-trained models which may carry forward undesirable biases from tangentially related tasks. We present and evaluate a partial solution to these constraints in using LSTMs to leverage interdependencies among target labels in predicting 14 pathologic patterns from chest x-rays and establish state of the art results on the largest publicly available chest x-ray dataset from the NIH without pre-training. Furthermore, we propose and discuss alternative evaluation metrics and their relevance in clinical practice.},
  pubstate = {preprint},
  version = {2},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found,Computer Science - Computer Vision and Pattern Recognition,Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences},
  annotation = {275 citations (Semantic Scholar/arXiv) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/MYSI4J28/Papers with code.png;/Users/personal-macbook/Zotero/storage/ZKMAHB2Q/Yao et al. - 2018 - Learning to diagnose from scratch by exploiting de.pdf;/Users/personal-macbook/Zotero/storage/8PLNGEEY/arXiv.org web link.html;/Users/personal-macbook/Zotero/storage/9FXQX4WR/1710.html;/Users/personal-macbook/Zotero/storage/AA6XWSGV/Papers with code web link.html;/Users/personal-macbook/Zotero/storage/TLGVL567/1710.html}
}

@article{yao_Quality_2019,
  title = {Quality of {{Uncertainty Quantification}} for {{Bayesian Neural Network Inference}}},
  author = {Yao, Jiayu and Pan, Weiwei and Ghosh, Soumya and Doshi-Velez, Finale},
  date = {2019-06},
  url = {http://arxiv.org/abs/1906.09686},
  abstract = {Bayesian Neural Networks (BNNs) place priors over the parameters in a neural network. Inference in BNNs, however, is difficult; all inference methods for BNNs are approximate. In this work, we empirically compare the quality of predictive uncertainty estimates for 10 common inference methods on both regression and classification tasks. Our experiments demonstrate that commonly used metrics (e.g. test log-likelihood) can be misleading. Our experiments also indicate that inference innovations designed to capture structure in the posterior do not necessarily produce high quality posterior approximations.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{yap_MultiLabel_2021,
  title = {Multi-{{Label Classification}} and {{Label Dependence}} in in {{Silico Toxicity Prediction}}},
  author = {Yap, Xiu Huan and Raymer, Michael},
  date = {2021-08-01},
  journaltitle = {Toxicology in Vitro},
  volume = {74},
  pages = {105157},
  issn = {0887-2333},
  doi = {10.1016/j.tiv.2021.105157},
  url = {https://www.sciencedirect.com/science/article/pii/S0887233321000825},
  urldate = {2022-06-23},
  abstract = {Most computational predictive models are specifically trained for a single toxicity endpoint and lack the ability to learn dependencies between endpoints, such as those targeting similar biological pathways. In this study, we compare the performance of 3 multi-label classification (MLC) models, namely Classifier Chains (CC), Label Powersets (LP) and Stacking (SBR), against independent classifiers (Binary Relevance) on Tox21 challenge data. Also, we develop a novel label dependence measure that shows full range of values, even at low prior probabilities, for the purpose of data-driven label partitioning. Using Logistic Regression as the base classifier and random label partitioning (k~=~3), CC show statistically significant improvements in model performance using Hamming and multi-label accuracy scores (p{$<$}0.05), while SBR show significant improvements in multi-label accuracy scores. The weights in the Logistic Regression and Stacking models are positively associated with label dependencies, suggesting that learning label dependence is a key contributor to improving model performance. An original quantitative measure of label dependency is combined with the Louvain community detection method to learn label partitioning using a data-driven process. The resulting MLCs with learned label partitioning were generally found to be non-inferior to their corresponding random or no label partitioning counterparts. Additionally, using the Random Forest classifier in a 10-fold stratified cross validation Stacking model, we find that the top-performing stacking model out-performs the corresponding base model in 11 out of 12 Tox21 labels. Taken together, these results suggest that MLC models could potentially boost the performance of current single-endpoint predictive models and that label partitioning learning may be used in place of random label partitionings.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Label dependence,Multi-label classification,Tox21,Toxicity prediction},
  file = {/Users/personal-macbook/Zotero/storage/UID2GAT9/Yap and Raymer - 2021 - Multi-label classification and label dependence in.pdf;/Users/personal-macbook/Zotero/storage/GF2S45JM/multi-label-classification-and-label-dependence-0Gmzk3g9.html}
}

@article{yassa_Highresolution_2010,
  title = {High-{{Resolution Structural}} and {{Functional MRI}} of {{Hippocampal CA3}} and {{Dentate Gyrus}} in {{Patients With Amnestic Mild Cognitive Impairment}}},
  author = {Yassa, Michael A. and Stark, Shauna M. and Bakker, Arnold and Albert, Marilyn S. and Gallagher, Michela and Stark, Craig E. L.},
  date = {2010-07},
  journaltitle = {Neuroimage},
  volume = {51},
  number = {3},
  pages = {1242--1252},
  doi = {10.1016/j.neuroimage.2010.03.040},
  abstract = {Functional magnetic resonance imaging (fMRI) studies have observed hyperactivity in the hippocampal region in individuals with Mild Cognitive Impairment (MCI). However, the actual source of such hyperactivity is not well understood. Studies of aged rats observed similar hyperactive signals in the CA3 region of the hippocampus that correlated with spatial memory deficits and, in particular, with their ability to represent novel environments as being distinct from familiar ones (pattern separation). In this study, we tested the hypothesis that patients with amnestic MCI (aMCI) have deficits in pattern separation, along with hyperactive fMRI BOLD activity in the CA3 region of the hippocampus. We used high-resolution fMRI during a continuous recognition task designed to emphasize pattern separation. We conducted hippocampal subfield-level region of interest analyses to test for dysfunctional activity in aMCI patients. We found that patients showed impaired performance on trials that taxed their pattern separation abilities. We also observed hyperactive BOLD signals in the CA3/dentate and hypoactive signals in the entorhinal cortex during the separation condition. In a high-resolution morphometric analysis of hippocampal subfields, aMCI patients also had smaller CA3/dentate and CA1 volumes (no difference in the subiculum). The CA3/dentate region bilaterally also exhibited the largest shape deformations in aMCI patients, suggesting that this locus is affected early in the course of the disease. These findings suggest that structural and functional changes in the CA3/dentate region of the hippocampus contribute to the deficits in episodic memory that are observed in patients with aMCI. The functional hyperactivity may be evidence for a dysfunctional encoding mechanism, consistent with the predictions of computational models of hippocampal learning.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {411 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{ye_Parcellation_2013,
  title = {Parcellation of the {{Thalamus Using Diffusion Tensor Images}} and a {{Multi-Object Geometric Deformable Model}}},
  author = {Ye, Chuyang and Bogovic, John A. and Ying, Sarah H. and Prince, Jerry L.},
  editor = {Ourselin, Sebastien and Haynor, David R.},
  date = {2013-03-13},
  pages = {866909},
  location = {{Lake Buena Vista (Orlando Area), Florida, USA}},
  doi = {10.1117/12.2006119},
  url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2006119},
  urldate = {2023-05-12},
  eventtitle = {{{SPIE Medical Imaging}}},
  keywords = {\#nosource,⛔ No INSPIRE recid found,5D Knutsson space,DTI,multiple object geometric},
  annotation = {9 citations (Semantic Scholar/DOI) [2023-05-12]},
  file = {/Users/personal-macbook/Zotero/storage/W9BHD8QC/Ye et al. - 2013 - Parcellation of the thalamus using diffusion tenso.pdf}
}

@thesis{yin_More_2019,
  title = {Towards {{More Scalable}} and {{Robust Machine Learning}}},
  author = {Yin, Dong},
  date = {2019},
  journaltitle = {Berkeley},
  institution = {{Berkeley}},
  url = {http://www2.eecs.berkeley.edu/Pubs/TechRpts/2019/EECS-2019-175.html},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{yin_Truth_2020,
  title = {Truth {{Inference With}} a {{Deep Clustering-Based Aggregation Model}}},
  author = {Yin, Li'ang and Liu, Yunfei and Zhang, Weinan and Yu, Yong},
  date = {2020},
  journaltitle = {IEEE Access},
  volume = {8},
  pages = {16662--16675},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.2964484},
  url = {https://ieeexplore.ieee.org/document/8950460/},
  urldate = {2022-12-28},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {5 citations (Semantic Scholar/DOI) [2022-12-28]},
  file = {/Users/personal-macbook/Zotero/storage/BFZXYXER/Yin et al. - 2020 - Truth Inference With a Deep Clustering-Based Aggre.pdf;/Users/personal-macbook/Zotero/storage/TNGBBZB3/Yin et al. - 2020 - Truth Inference With a Deep Clustering-Based Aggre.pdf}
}

@article{yosinski_How_2014,
  title = {How {{Transferable Are Features}} in {{Deep Neural Networks}}?},
  author = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  date = {2014},
  journaltitle = {Adv. Neural Inf. Process. Syst.},
  volume = {27},
  pages = {3320--3328},
  issn = {10495258},
  abstract = {Many deep neural networks trained on natural images exhibit a curious phenomenon in common: on the first layer they learn features similar to Gabor filters and color blobs. Such first-layer features appear not to be specific to a particular dataset or task, but general in that they are applicable to many datasets and tasks. Features must eventually transition from general to specific by the last layer of the network, but this transition has not been studied extensively. In this paper we experimentally quantify the generality versus specificity of neurons in each layer of a deep convolutional neural network and report a few surprising results. Trans-ferability is negatively affected by two distinct issues: (1) the specialization of higher layer neurons to their original task at the expense of performance on the target task, which was expected, and (2) optimization difficulties related to splitting networks between co-adapted neurons, which was not expected. In an example network trained on ImageNet, we demonstrate that either of these two issues may dominate, depending on whether features are transferred from the bottom, middle, or top of the network. We also document that the transferability of features decreases as the distance between the base task and target task increases, but that transferring features even from distant tasks can be better than using random features. A final surprising result is that initializing a network with transferred features from almost any number of layers can produce a boost to generalization that lingers even after fine-tuning to the target dataset.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{young_Susceptibilityenhanced_2009,
  title = {Susceptibility-{{Enhanced}} 3-{{Tesla T1-Weighted Spoiled Gradient Echo}} of the {{Midbrain Nuclei}} for {{Guidance}} of {{Deep Brain Stimulation Implantation}}},
  author = {Young, Geoffrey S. and Feng, Feng and Shen, Hao and Chen, Nan-Kuei},
  date = {2009-10},
  journaltitle = {Neurosurgery},
  volume = {65},
  number = {4},
  pages = {809--815},
  doi = {10.1227/01.NEU.0000345354.21320.D1},
  abstract = {Surgical planning for deep brain stimulation implantation procedures requires T1-weighted imaging (T1WI) for stereotactic navigation. Because the subthalamic nucleus, the main target for deep brain stimulation, and other midbrain nuclei cannot be visualized on the stereotactic guidance T1WI, additional T2-weighted imaging (T2WI) is generally obtained and registered to the T1WI for surgical targeting. Surgical planning based on the registration of the 2 data sets is subject to error resulting from inconsistent geometric distortions and any subject movement between the 2 scans. In this article, we propose a new method to produce susceptibility-enhanced, contrast-optimized T1-weighted 3-dimensional spoiled gradient recalled acquisition in steady state images with enhanced contrast for midbrain nuclei within the volumetric T1WI data set itself, eliminating the need for additional T2WI. The scan parameters of 3-dimensional spoiled gradient recalled acquisition in steady state are chosen in a way that T1WI can be obtained from conventional magnitude reconstruction and images with improved contrast between midbrain nuclei and surrounding tissues can be produced from the same data by performing susceptibility-weighted imaging reconstruction on a chosen region of interest. In addition, our preliminary experience suggests that the resulting contrast between the midbrain nuclei is superior to the current state-of-the-art fast spin echo T2WI in depicting the subthalamic nucleus as distinct from the substantia nigra pars reticulata and clear depiction of the nucleus ventrointermedius externus of thalamus.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{yovel_Virtual_2007,
  title = {Virtual {{Definition}} of {{Neuronal Tissue}} by {{Cluster Analysis}} of {{Multi-Parametric Imaging}} ({{Virtual-Dot-Com Imaging}})},
  author = {Yovel, Yossi and Assaf, Yaniv},
  date = {2007-03},
  journaltitle = {Neuroimage},
  volume = {35},
  number = {1},
  pages = {58--69},
  doi = {10.1016/j.neuroimage.2006.08.055},
  abstract = {Individual mapping of cerebral, morphological, functionally related structures using MRI was carried out using a new multi-contrast acquisition and analysis framework, called virtual-dot-com imaging. So far, conventional anatomical MRI has been able to provide gross segmentation of gray/white matter boundaries and a few sub-cortical structures. By combining a handful of imaging contrasts mechanisms (T1, T2, magnetization transfer, T2* and proton density), we were able to further segment sub-cortical tissue to its sub-nuclei arrangement, a segmentation that is difficult based on conventional, single-contrast MRI. Using an automatic four-step image and signal processing algorithm, we segmented the thalamus to at least 7 sub-nuclei with high similarity across subjects and high statistical significance within subjects (p{$<$}0.0001). The identified sub-nuclei resembled the known anatomical arrangement of the thalamus given in various atlases. Each cluster was characterized by a unique MRI contrast fingerprint. With this procedure, the weighted proportions of the different cellular compartments could be estimated, a property available to date only by histological analysis. Each sub-nucleus could be characterized in terms of normalized MRI contrast and compared to other sub-nuclei. The different weights of the contrasts (T1/T2/T2*/PD/MT, etc.) for each sub-nuclei cluster might indicate the intra-cluster morphological arrangement of the tissue that it represents. The implications of this methodology are far-ranging, from non-invasive, in vivo, individual mapping of histologically distinct brain areas to automatic identification of pathological processes.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{yu_Architectures_2019,
  title = {Architectures and {{Accuracy}} of {{Artificial Neural Network}} for {{Disease Classification From Omics Data}}},
  author = {Yu, Hui and Samuels, David C. and Zhao, Ying-Yong and Guo, Yan},
  date = {2019-03},
  journaltitle = {BMC Genomics},
  volume = {20},
  number = {1},
  pages = {167},
  abstract = {BACKGROUND: Deep learning has made tremendous successes in numerous artificial intelligence applications and is unsurprisingly penetrating into various biomedical domains. High-throughput omics data in the form of molecular profile matrices, such as transcriptomes and metabolomes, have long existed as a valuable resource for facilitating diagnosis of patient statuses/stages. It is timely imperative to compare deep learning neural networks against classical machine learning methods in the setting of matrix-formed omics data in terms of classification accuracy and robustness. RESULTS: Using 37 high throughput omics datasets, covering transcriptomes and metabolomes, we evaluated the classification power of deep learning compared to traditional machine learning methods. Representative deep learning methods, Multi-Layer Perceptrons (MLP) and Convolutional Neural Networks (CNN), were deployed and explored in seeking optimal architectures for the best classification performance. Together with five classical supervised classification methods (Linear Discriminant Analysis, Multinomial Logistic Regression, Na\{\textbackslash "\i\}ve Bayes, Random Forest, Support Vector Machine), MLP and CNN were comparatively tested on the 37 datasets to predict disease stages or to discriminate diseased samples from normal samples. MLPs achieved the highest overall accuracy among all methods tested. More thorough analyses revealed that single hidden layer MLPs with ample hidden units outperformed deeper MLPs. Furthermore, MLP was one of the most robust methods against imbalanced class composition and inaccurate class labels. CONCLUSION: Our results concluded that shallow MLPs (of one or two hidden layers) with ample hidden neurons are sufficient to achieve superior and robust classification performance in exploiting numerical matrix-formed omics data for diagnosis purpose. Specific observations regarding optimal network width, class imbalance tolerance, and inaccurate labeling tolerance will inform future improvement of neural network applications on functional genomics data.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found,Artificial neural network,Cancer diagnosis,Deep}
}

@article{yu_artificialintelligencehealthcare_2018,
  ids = {yu_Artificial_2018},
  title = {Artificial {{Intelligence}} in {{Healthcare}}},
  author = {Yu, Kun-Hsing and Beam, Andrew L. and Kohane, Isaac S.},
  date = {2018-10-10},
  journaltitle = {Nat Biomed Eng},
  volume = {2},
  number = {10},
  pages = {719--731},
  issn = {2157-846X},
  doi = {10.1038/s41551-018-0305-z},
  url = {https://www.nature.com/articles/s41551-018-0305-z},
  urldate = {2023-05-10},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Computational models,Machine learning,Predictive medicine},
  annotation = {1096 citations (Semantic Scholar/DOI) [2023-05-09]}
}

@article{yu_Highprecision_2020,
  title = {High-{{Precision Camera Pose Estimation}} and {{Optimization}} in a {{Large-Scene 3D Reconstruction System}}},
  author = {Yu, Lei and Fu, Xiaofan and Xu, Haonan and Fei, Shumin},
  date = {2020-05},
  journaltitle = {Meas. Sci. Technol.},
  volume = {31},
  number = {8},
  pages = {085401},
  publisher = {{IOP Publishing}},
  issn = {0957-0233},
  doi = {10.1088/1361-6501/AB816C},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {8 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{yu_MultiScale_2015,
  title = {Multi-{{Scale Context Aggregation}} by {{Dilated Convolutions}}},
  author = {Yu, Fisher and Koltun, Vladlen},
  date = {2015-11},
  abstract = {State-of-the-art models for semantic segmentation are based on adaptations of convolutional networks that had originally been designed for image classification. However, dense prediction and image classification are structurally different. In this work, we develop a new convolutional network module that is specifically designed for dense prediction. The presented module uses dilated convolutions to systematically aggregate multi-scale contextual information without losing resolution. The architecture is based on the fact that dilated convolutions support exponential expansion of the receptive field without loss of resolution or coverage. We show that the presented context module increases the accuracy of state-of-the-art semantic segmentation systems. In addition, we examine the adaptation of image classification networks to dense prediction and show that simplifying the adapted network can increase accuracy.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{yuan_DDDASbased_2015,
  title = {{{DDDAS-based Information-Aggregation}} for {{Crowd Dynamics Modeling With UAVs}} and {{UGVs}}},
  author = {Yuan, Yifei and Wang, Zhenrui and Li, Mingyang and Son, Young Jun and Liu, Jian},
  date = {2015},
  journaltitle = {Front. Robot. AI},
  issn = {22969144},
  doi = {10.3389/frobt.2015.00008},
  abstract = {Unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs) collaboratively play important roles in crowd tracking for applications such as border patrol and crowd surveillance. Dynamic data-driven application systems (DDDAS) paradigm has been developed for these applications to take advantage of real-time monitoring data. In the DDDAS paradigm, one crucial step in crowd surveillance is crowd dynamics modeling, which is based on multi-resolution crowd observation data collected from both UAVs and UGVs. Data collected from UAVs capture global crowd motion but have low resolution while those from UGVs have high resolution information of local crowd motion. This paper proposes an information-aggregation approach for crowd dynamics modeling by incorporating multi-resolution data, where a grid-based method is developed to model crowd motion with UAVs' low-resolution global perception, and an autoregressive model is employed to model individuals' motion based on UGVs' detailed perception. A simulation experiment is provided to illustrate and demonstrate the effectiveness of the proposed approach.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Crowd tracking,DDDAS,Grid-based,Multi-resolution data,Surveillance,UAVs and UGVs},
  annotation = {8 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{yuan_LargeScale_2021,
  title = {Large-{{Scale Robust Deep AUC Maximization}}: {{A New Surrogate Loss}} and {{Empirical Studies}} on {{Medical Image Classification}}},
  shorttitle = {Large-{{Scale Robust Deep Auc Maximization}}},
  author = {Yuan, Zhuoning and Yan, Yan and Sonka, Milan and Yang, Tianbao},
  date = {2021},
  pages = {3040--3049},
  publisher = {{IEEE}},
  url = {https://openaccess.thecvf.com/content/ICCV2021/html/Yuan_Large-Scale_Robust_Deep_AUC_Maximization_A_New_Surrogate_Loss_and_ICCV_2021_paper.html},
  urldate = {2022-11-21},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  langid = {english},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,FOS: Mathematics,Machine Learning (cs.LG),Machine Learning (stat.ML),Mathematics - Optimization and Control,Optimization and Control (math.OC),Statistics - Machine Learning},
  file = {/Users/personal-macbook/Zotero/storage/GVCR8REW/Yuan et al. - 2021 - Large-scale Robust Deep AUC Maximization A New Su.pdf;/Users/personal-macbook/Zotero/storage/U9CRCM4D/Yuan et al. - 2021 - Large-Scale Robust Deep AUC Maximization A New Su.pdf;/Users/personal-macbook/Zotero/storage/4C99RM5L/2012.html;/Users/personal-macbook/Zotero/storage/VM5GNNJB/Yuan_Large-Scale_Robust_Deep_AUC_Maximization_A_New_Surrogate_Loss_and_ICCV_2021_paper.html}
}

@article{yuan_Robust_2020,
  title = {Robust {{Deep AUC Maximization}}: {{A New Surrogate Loss}} and {{Empirical Studies}} on {{Medical Image Classification}}},
  shorttitle = {Robust {{Deep AUC Maximization}}},
  author = {Yuan, Zhuoning and Yan, Yan and Sonka, M. and Yang, Tianbao},
  date = {2020},
  journaltitle = {undefined},
  url = {https://www.semanticscholar.org/paper/Robust-Deep-AUC-Maximization%3A-A-New-Surrogate-Loss-Yuan-Yan/32004efe5f295c8e1f1525728d274ae9e4ac839a},
  urldate = {2022-07-04},
  abstract = {This work proposes a new margin-based surrogate loss function for the A UC score (named as the AUC margin loss) that is more robust than the commonly used AUC square loss, while enjoying the same advantage in terms of large-scale stochastic optimization. Deep AUC Maximization (DAM) is a paradigm for learning a deep neural network by maximizing the AUC score of the model on a dataset. Most previous works of AUC maximization focus on the perspective of optimization by designing efficient stochastic algorithms, and studies on generalization performance of DAM on difficult tasks are missing. In this work, we aim to make DAM more practical for interesting real-world applications (e.g., medical image classification). First, we propose a new margin-based surrogate loss function for the AUC score (named as the AUC margin loss). It is more robust than the commonly used AUC square loss, while enjoying the same advantage in terms of large-scale stochastic optimization. Second, we conduct empirical studies of our DAM method on difficult medical image classification tasks, namely classification of chest x-ray images for identifying many threatening diseases and classification of images of skin lesions for identifying melanoma. Our DAM method has achieved great success on these difficult tasks, i.e., the 1st place on Stanford CheXpert competition (by the paper submission date) and Top 1\% rank (rank 33 out of 3314 teams) on Kaggle 2020 Melanoma classification competition. We also conduct extensive ablation studies to demonstrate the advantages of the new AUC margin loss over the AUC square loss on benchmark datasets. To the best of our knowledge, this is the first work that makes DAM succeed on large-scale medical image datasets.},
  langid = {english},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/62RZZASZ/32004efe5f295c8e1f1525728d274ae9e4ac839a.html}
}

@article{yun_Fructooligosaccharides_1996,
  title = {Fructooligosaccharides\textemdash{{Occurrence}}, {{Preparation}}, and {{Application}}},
  author = {Yun, Jong Won},
  date = {1996-08},
  journaltitle = {Enzyme and Microbial Technology},
  volume = {19},
  number = {2},
  pages = {107--117},
  issn = {01410229},
  doi = {10.1016/0141-0229(95)00188-3},
  url = {https://linkinghub.elsevier.com/retrieve/pii/0141022995001883},
  urldate = {2023-05-08},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {480 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{yushkevich_Automated_2015,
  title = {Automated {{Volumetry}} and {{Regional Thickness Analysis}} of {{Hippocampal Subfields}} and {{Medial Temporal Cortical Structures}} in {{Mild Cognitive Impairment}}: {{Automatic Morphometry}} of {{MTL Subfields}} in {{Mci}}},
  shorttitle = {Automated {{Volumetry}} and {{Regional Thickness Analysis}} of {{Hippocampal Subfields}} and {{Medial Temporal Cortical Structures}} in {{Mild Cognitive Impairment}}},
  author = {Yushkevich, Paul A. and Pluta, John B. and Wang, Hongzhi and Xie, Long and Ding, Song-Lin and Gertje, Eske C. and Mancuso, Lauren and Kliot, Daria and Das, Sandhitsu R. and Wolk, David A.},
  date = {2015-01},
  journaltitle = {Hum. Brain Mapp.},
  volume = {36},
  number = {1},
  pages = {258--287},
  issn = {10659471},
  doi = {10.1002/hbm.22627},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/hbm.22627},
  urldate = {2023-05-10},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Alzheimer's disease,biomarker,Brodmann area 35},
  annotation = {400 citations (Semantic Scholar/DOI) [2023-05-09]},
  file = {/Users/personal-macbook/Zotero/storage/XKS6VTVX/Yushkevich et al. - 2015 - Automated volumetry and regional thickness analysi.pdf}
}

@article{yushkevich_Nearly_2010,
  title = {Nearly {{Automatic Segmentation}} of {{Hippocampal Subfields}} in in {{Vivo Focal T2-Weighted MRI}}},
  author = {Yushkevich, Paul A. and Wang, Hongzhi and Pluta, John and Das, Sandhitsu R. and Craige, Caryne and Avants, Brian B. and Weiner, Michael W. and Mueller, Susanne},
  date = {2010-12},
  journaltitle = {Neuroimage},
  volume = {53},
  number = {4},
  pages = {1208--1224},
  doi = {10.1016/j.neuroimage.2010.06.040},
  abstract = {We present and evaluate a new method for automatically labeling the subfields of the hippocampal formation in focal 0.4 \$\textbackslash times\$ 0.5 \$\textbackslash times\$ 2.0mm(3) resolution T2-weighted magnetic resonance images that can be acquired in the routine clinical setting with under 5 min scan time. The method combines multi-atlas segmentation, similarity-weighted voting, and a novel learning-based bias correction technique to achieve excellent agreement with manual segmentation. Initial partitioning of MRI slices into hippocampal 'head', 'body' and 'tail' slices is the only input required from the user, necessitated by the nature of the underlying segmentation protocol. Dice overlap between manual and automatic segmentation is above 0.87 for the larger subfields, CA1 and dentate gyrus, and is competitive with the best results for whole-hippocampus segmentation in the literature. Intraclass correlation of volume measurements in CA1 and dentate gyrus is above 0.89. Overlap in smaller hippocampal subfields is lower in magnitude (0.54 for CA2, 0.62 for CA3, 0.77 for subiculum and 0.79 for entorhinal cortex) but comparable to overlap between manual segmentations by trained human raters. These results support the feasibility of subfield-specific hippocampal morphometry in clinical studies of memory and neurodegenerative disease.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{yushkevich_Quantitative_2015,
  title = {Quantitative {{Comparison}} of 21 {{Protocols}} for {{Labeling Hippocampal Subfields}} and {{Parahippocampal Subregions}} in in {{Vivo MRI}}: {{Towards}} a {{Harmonized Segmentation Protocol}}},
  author = {Yushkevich, Paul A. and Amaral, Robert S. C. and Augustinack, Jean C. and Bender, Andrew R. and Bernstein, Jeffrey D. and Boccardi, Marina and Bocchetta, Martina and Burggren, Alison C. and Carr, Valerie A. and Chakravarty, M. Mallar and Ch\'etelat, Ga\"el and Daugherty, Ana M. and Davachi, Lila and Ding, Song-Lin and Ekstrom, Arne and Geerlings, Mirjam I. and Hassan, Abdul and Huang, Yushan and Iglesias, J. Eugenio and Joie, Renaud La and Kerchner, Geoffrey A. and LaRocque, Karen F. and Libby, Laura A. and Malykhin, Nikolai and Mueller, Susanne G. and Olsen, Rosanna K. and Palombo, Daniela J. and Parekh, Mansi B. and Pluta, John B. and Preston, Alison R. and Pruessner, Jens C. and Ranganath, Charan and Raz, Naftali and Schlichting, Margaret L. and Schoemaker, Dorothee and Singh, Sachi and Stark, Craig E. L. and Suthana, Nanthia and Tompary, Alexa and Turowski, Marta M. and Leemput, Koen Van and Wagner, Anthony D. and Wang, Lei and Winterburn, Julie L. and Wisse, Laura E. M. and Yassa, Michael A. and Zeineh, Michael M. and Group (HSG), Hippocampal Subfields},
  date = {2015-05},
  journaltitle = {Neuroimage},
  volume = {111},
  pages = {526--541},
  doi = {10.1016/j.neuroimage.2015.01.004},
  abstract = {OBJECTIVE: An increasing number of human in vivo magnetic resonance imaging (MRI) studies have focused on examining the structure and function of the subfields of the hippocampal formation (the dentate gyrus, CA fields 1-3, and the subiculum) and subregions of the parahippocampal gyrus (entorhinal, perirhinal, and parahippocampal cortices). The ability to interpret the results of such studies and to relate them to each other would be improved if a common standard existed for labeling hippocampal subfields and parahippocampal subregions. Currently, research groups label different subsets of structures and use different rules, landmarks, and cues to define their anatomical extents. This paper characterizes, both qualitatively and quantitatively, the variability in the existing manual segmentation protocols for labeling hippocampal and parahippocampal substructures in MRI, with the goal of guiding subsequent work on developing a harmonized substructure segmentation protocol. METHOD: MRI scans of a single healthy adult human subject were acquired both at 3 T and 7 T. Representatives from 21 research groups applied their respective manual segmentation protocols to the MRI modalities of their choice. The resulting set of 21 segmentations was analyzed in a common anatomical space to quantify similarity and identify areas of agreement. RESULTS: The differences between the 21 protocols include the region within which segmentation is performed, the set of anatomical labels used, and the extents of specific anatomical labels. The greatest overall disagreement among the protocols is at the CA1/subiculum boundary, and disagreement across all structures is greatest in the anterior portion of the hippocampal formation relative to the body and tail. CONCLUSIONS: The combined examination of the 21 protocols in the same dataset suggests possible strategies towards developing a harmonized subfield segmentation protocol and facilitates comparison between published studies.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,CA1,CA2,CA3,Dentate gyrus,Entorhinal cortex,H}
}

@article{yushkevich_Userguided_2006,
  title = {User-{{Guided 3D Active Contour Segmentation}} of {{Anatomical Structures}}: {{Significantly Improved Efficiency}} and {{Reliability}}},
  author = {Yushkevich, Paul A. and Piven, Joseph and Hazlett, Heather Cody and Smith, Rachel Gimpel and Ho, Sean and Gee, James C. and Gerig, Guido},
  date = {2006-07},
  journaltitle = {Neuroimage},
  volume = {31},
  number = {3},
  pages = {1116--1128},
  doi = {10.1016/j.neuroimage.2006.01.015},
  abstract = {Active contour segmentation and its robust implementation using level set methods are well-established theoretical approaches that have been studied thoroughly in the image analysis literature. Despite the existence of these powerful segmentation methods, the needs of clinical research continue to be fulfilled, to a large extent, using slice-by-slice manual tracing. To bridge the gap between methodological advances and clinical routine, we developed an open source application called ITK-SNAP, which is intended to make level set segmentation easily accessible to a wide range of users, including those with little or no mathematical expertise. This paper describes the methods and software engineering philosophy behind this new tool and provides the results of validation experiments performed in the context of an ongoing child autism neuroimaging study. The validation establishes SNAP intrarater and interrater reliability and overlap error statistics for the caudate nucleus and finds that SNAP is a highly reliable and efficient alternative to manual tracing. Analogous results for lateral ventricle segmentation are provided.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{zahr_Sensitivity_2020,
  title = {Sensitivity of {{Ventrolateral Posterior Thalamic Nucleus}} to {{Back Pain}} in {{Alcoholism}} and {{CD4 Nadir}} in {{HIV}}},
  author = {Zahr, Natalie M. and Sullivan, Edith V. and Pohl, Kilian M. and Pfefferbaum, Adolf and Saranathan, Manojkumar},
  date = {2020},
  journaltitle = {Hum. Brain Mapp.},
  eprint = {31785046},
  eprinttype = {pmid},
  issn = {10970193},
  doi = {10.1002/hbm.24880},
  abstract = {Volumes of thalamic nuclei are differentially affected by disease-related processes including alcoholism and human immunodeficiency virus (HIV) infection. This MRI study included 41 individuals diagnosed with alcohol use disorders (AUD, 12 women), 17 individuals infected with HIV (eight women), and 49 healthy controls (24 women) aged 39 to 75 years. A specialized, high-resolution acquisition protocol enabled parcellation of five thalamic nuclei: anterior [anterior ventral (AV)], posterior [pulvinar (Pul)], medial [mediodorsal (MD)], and ventral [including ventral lateral posterior (VLp) and ventral posterior lateral (VPl)]. An omnibus mixed-model approach solving for volume considered the ``fixed effects'' of nuclei, diagnosis, and their interaction while covarying for hemisphere, sex, age, and supratentorial volume (svol). The volume by diagnosis interaction term was significant; the effects of hemisphere and sex were negligible. Follow-up mixed-model tests thus evaluated the combined (left + right) volume of each nucleus separately for effects of diagnosis while controlling for age and svol. Only the VLp showed diagnoses effects and was smaller in the AUD (p =.04) and HIV (p =.0003) groups relative to the control group. In the AUD group, chronic back pain (p =.008) and impaired deep tendon ankle reflex (p =.0005) were associated with smaller VLp volume. In the HIV group, lower CD4 nadir (p =.008) was associated with smaller VLp volume. These results suggest that the VLp is differentially sensitive to disease processes associated with AUD and HIV.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,alcoholism,in vivo,pain,sensorimotor,thalamic nuclei}
}

@inproceedings{zalud_Fusion_2013,
  title = {Fusion of {{Thermal Imaging}} and {{CCD Camera-Based Data}} for {{Stereovision Visual Telepresence}}},
  booktitle = {2013 {{IEEE Int}}. {{Symp}}. {{Saf}}. {{Secur}}. {{Rescue Robot}}. {{SSRR}} 2013},
  author = {Zalud, Ludek and Kocmanova, Petra},
  date = {2013},
  doi = {10.1109/SSRR.2013.6719344},
  abstract = {The aim of this paper is to describe the fusion of data acquired from a CCD camera and a thermal imager. The fusion is realized by means of spatial data from a TOF camera to ensure 'natural' representation of a robot's environment; thus, the thermal and color-related data are comprised in one stereo image presented to a binocular, head-mounted display. The data acquisition is performed using a sensor head, which is placed on an Orpheus-X3 robot; both the head and the robot were developed by our working group. The head contains five matrix sensors: a pair of CCD cameras, a pair of thermal imagers, and one TOF camera. After the geometrical calibration of each sensor, the positions of the sensors in 6DOFs are computed. The corresponding data from the CCD camera and the thermal imager are subsequently determined via homogeneous and perspective transformations. The result consists in an image containing aligned data from the CCD camera and the thermal imager for each eye. \textcopyright{} 2013 IEEE.},
  isbn = {978-1-4799-0880-6},
  keywords = {\#nosource,⛔ No INSPIRE recid found,CCD camera,data fusion,mobile robot,reconnaissance,thermal imager},
  annotation = {27 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{zech_Variable_2018,
  title = {Variable {{Generalization Performance}} of a {{Deep Learning Model}} to {{Detect Pneumonia}} in {{Chest Radiographs}}: {{A Cross-Sectional Study}}},
  author = {Zech, John R. and Badgeley, Marcus A. and Liu, Manway and Costa, Anthony B. and Titano, Joseph J. and Oermann, Eric Karl},
  date = {2018-11},
  journaltitle = {PLoS Med.},
  volume = {15},
  number = {11},
  pages = {e1002683},
  doi = {10.1371/journal.pmed.1002683},
  abstract = {BACKGROUND: There is interest in using convolutional neural networks (CNNs) to analyze medical imaging to provide computer-aided diagnosis (CAD). Recent work has suggested that image classification CNNs may not generalize to new data as well as previously believed. We assessed how well CNNs generalized across three hospital systems for a simulated pneumonia screening task. METHODS AND FINDINGS: A cross-sectional design with multiple model training cohorts was used to evaluate model generalizability to external sites using split-sample validation. A total of 158,323 chest radiographs were drawn from three institutions: National Institutes of Health Clinical Center (NIH; 112,120 from 30,805 patients), Mount Sinai Hospital (MSH; 42,396 from 12,904 patients), and Indiana University Network for Patient Care (IU; 3,807 from 3,683 patients). These patient populations had an age mean (SD) of 46.9 years (16.6), 63.2 years (16.5), and 49.6 years (17) with a female percentage of 43.5\%, 44.8\%, and 57.3\%, respectively. We assessed individual models using the area under the receiver operating characteristic curve (AUC) for radiographic findings consistent with pneumonia and compared performance on different test sets with DeLong's test. The prevalence of pneumonia was high enough at MSH (34.2\%) relative to NIH and IU (1.2\% and 1.0\%) that merely sorting by hospital system achieved an AUC of 0.861 (95\% CI 0.855-0.866) on the joint MSH-NIH dataset. Models trained on data from either NIH or MSH had equivalent performance on IU (P values 0.580 and 0.273, respectively) and inferior performance on data from each other relative to an internal test set (i.e., new data from within the hospital system used for training data; P values both {$<$}0.001). The highest internal performance was achieved by combining training and test data from MSH and NIH (AUC 0.931, 95\% CI 0.927-0.936), but this model demonstrated significantly lower external performance at IU (AUC 0.815, 95\% CI 0.745-0.885, P = 0.001). To test the effect of pooling data from sites with disparate pneumonia prevalence, we used stratified subsampling to generate MSH-NIH cohorts that only differed in disease prevalence between training data sites. When both training data sites had the same pneumonia prevalence, the model performed consistently on external IU data (P = 0.88). When a 10-fold difference in pneumonia rate was introduced between sites, internal test performance improved compared to the balanced model (10\$\textbackslash times\$ MSH risk P {$<$} 0.001; 10\$\textbackslash times\$ NIH P = 0.002), but this outperformance failed to generalize to IU (MSH 10\$\textbackslash times\$ P {$<$} 0.001; NIH 10\$\textbackslash times\$ P = 0.027). CNNs were able to directly detect hospital system of a radiograph for 99.95\% NIH (22,050/22,062) and 99.98\% MSH (8,386/8,388) radiographs. The primary limitation of our approach and the available public data is that we cannot fully assess what other factors might be contributing to hospital system-specific biases. CONCLUSION: Pneumonia-screening CNNs achieved better internal than external performance in 3 out of 5 natural comparisons. When models were trained on pooled data from sites with different pneumonia prevalence, they performed better on new pooled data from these sites but not on external data. CNNs robustly identified hospital system and department within a hospital, which can have large differences in disease burden and may confound predictions.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{zeineh_Dynamics_2003,
  title = {Dynamics of the {{Hippocampus During Encoding}} and {{Retrieval}} of {{Face-Name Pairs}}},
  author = {Zeineh, Michael M. and Engel, Stephen A. and Thompson, Paul M. and Bookheimer, Susan Y.},
  date = {2003-01},
  journaltitle = {Science},
  volume = {299},
  number = {5606},
  pages = {577--580},
  doi = {10.1126/science.1077775},
  abstract = {The medial temporal lobe (MTL) is critical in forming new memories, but how subregions within the MTL carry out encoding and retrieval processes in humans is unknown. Using new high-resolution functional magnetic resonance imaging (fMRI) acquisition and analysis methods, we identified mnemonic properties of different subregions within the hippocampal circuitry as human subjects learned to associate names with faces. The cornu ammonis (CA) fields 2 and 3 and the dentate gyrus were active relative to baseline only during encoding, and this activity decreased as associations were learned. Activity in the subiculum showed the same temporal decline, but primarily during retrieval. Our results demonstrate that subdivisions within the hippocampus make distinct contributions to new memory formation.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {486 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{zelikovski_Mesoappendicular_1975,
  title = {Meso-{{Appendicular Testis}}},
  author = {Zelikovski, A. and Abu-Dalu, J. and Urca, I.},
  date = {1975-10},
  journaltitle = {Br J Urol},
  volume = {47},
  number = {5},
  eprint = {122},
  eprinttype = {pmid},
  pages = {579},
  issn = {0007-1331},
  doi = {10.1111/j.1464-410x.1975.tb06266.x},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Adult,Appendicitis,Appendix,Cryptorchidism,Humans,Male},
  annotation = {2 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@thesis{zhan_AIassisted_2018,
  title = {Towards {{AI-assisted Healthcare}}: {{System Design}} and {{Deployment}} for {{Machine Learning Based Clinical Decision Support}}},
  author = {Zhan, Andong},
  date = {2018},
  journaltitle = {Johns Hopkins University},
  institution = {{Johns Hopkins University}},
  url = {https://jscholarship.library.jhu.edu/handle/1774.2/59992},
  abstract = {Over the last decade, American hospitals have adopted electronic health records (EHRs) widely. In the next decade, incorporating EHRs with clinical decision support (CDS) together into the process of medicine has the potential to change the way medicine has been practiced and advance the quality of patient care. It is a unique opportunity for machine learning (ML), with its ability to process massive datasets beyond the scope of human capability, to provide new clinical insights that aid physicians in planning and delivering care, ultimately leading to better outcomes, lower costs of care, and increased patient satisfaction. However, applying ML-based CDS has to face steep system and application challenges. No open platform is there to support ML and domain experts to develop, deploy, and monitor ML-based CDS; and no end-to-end solution is available for machine learning algorithms to consume heterogenous EHRs and deliver CDS in real-time. Build ML-based CDS from scratch can be expensive and time-consuming. In this dissertation, CDS-Stack, an open cloud-based platform, is introduced to help ML practitioners to deploy ML-based CDS into healthcare practice. The CDS-Stack integrates various components into the infrastructure for the development, deployment, and monitoring of the ML-based CDS. It provides an ETL engine to transform heterogenous EHRs, either historical or online, into a common data model (CDM) in parallel so that ML algorithms can directly consume health data for training or prediction. It introduces both pull and push-based online CDS pipelines to deliver CDS in real-time. The CDS-Stack has been adopted by Johns Hopkins Medical Institute (JHMI) to deliver a sepsis early warning score since November 2017 and begins to show promising results. Furthermore, we believe CDS-Stack can be extended to outpatients too. A case study of outpatient CDS has been conducted which utilizes smartphones and machine learning to quantify the severity of Parkinson disease. In this study, a mobile Parkinson disease severity score (mPDS) is generated using a novel machine learning approach. The results show it can detect response to dopaminergic therapy, correlate strongly with traditional rating scales, and capture intraday symptom fluctuation.},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@report{zhang_Apply_2016,
  type = {CS 229 Project Reports},
  title = {Apply and {{Compare Different Classical Image Classification Method}}: {{Detect Distracted Driver}}},
  shorttitle = {Apply and {{Compare Different Classical Image Classification Method}}},
  author = {Zhang, Ben},
  date = {2016},
  institution = {{Stanford}},
  url = {http://cs229.stanford.edu/proj2016/report/Zhang- DetectDistractedDriver-report.pdf},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/VM7IZ6W5/Zhang-DetectDistractedDriver-report.pdf}
}

@article{zhang_Automatic_2017,
  title = {Automatic {{Thalamus Segmentation From Magnetic Resonance Images Using Multiple Atlases Level Set Framework}} ({{MALSF}})},
  author = {Zhang, Minghui and Lu, Zhentai and Feng, Qianjin and Zhang, Yu},
  date = {2017-06},
  journaltitle = {Sci. Rep.},
  volume = {7},
  number = {1},
  pages = {4274},
  abstract = {In this paper, we present an original multiple atlases level set framework (MALSF) for automatic, accurate and robust thalamus segmentation in magnetic resonance images (MRI). The contributions of the MALSF method are twofold. First, the main technical contribution is a novel label fusion strategy in the level set framework. Label fusion is achieved by seeking an optimal level set function that minimizes energy functional with three terms: label fusion term, image based term, and regularization term. This strategy integrates shape prior, image information and the regularity of the thalamus. Second, we use propagated labels from multiple registration methods with different parameters to take full advantage of the complementary information of different registration methods. Since different registration methods and different atlases can yield complementary information, multiple registration and multiple atlases can be incorporated into the level set framework to improve the segmentation performance. Experiments have shown that the MALSF method can improve the segmentation accuracy for the thalamus. Compared to ground truth segmentation, the mean Dice metrics of our method are 0.9239 and 0.9200 for left and right thalamus.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{zhang_CEKA_2015,
  title = {{{CEKA}}: {{A Tool}} for {{Mining}} the {{Wisdom}} of {{Crowds}}},
  author = {Zhang, Jing and Sheng, Victor S. and Nicholson, Bryce A. and Wu, Xindong},
  date = {2015},
  journaltitle = {J. Mach. Learn. Res.},
  volume = {16},
  number = {88},
  pages = {2853--2858},
  url = {http://jmlr.org/papers/v16/zhang15a.html},
  abstract = {CEKA is a software package for developers and researchers to mine the wisdom of crowds. It makes the entire knowledge discovery procedure much easier, including analyzing qualities of workers, simulating labeling behaviors, inferring true class labels of instances, filtering and correcting mislabeled instances (noise), building learning models and evaluating them. It integrates a set of state-of-the-art inference algorithms, a set of general noise handling algorithms, and abundant functions for model training and evaluation. CEKA is written in Java with core classes being compatible with the well-known machine learning tool WEKA, which makes the utilization of the functions in WEKA much easier.},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/JHKLQQ2Q/Zhang et al. - 2015 - CEKA A Tool for Mining the Wisdom of Crowds.pdf}
}

@article{zhang_Crowdsourced_2019,
  title = {Crowdsourced {{Label Aggregation Using Bilayer Collaborative Clustering}}},
  author = {Zhang, Jing and Sheng, Victor S. and Wu, Jian},
  date = {2019-10},
  journaltitle = {IEEE Trans. Neural Netw. Learning Syst.},
  volume = {30},
  number = {10},
  pages = {3172--3185},
  issn = {2162-237X, 2162-2388},
  doi = {10.1109/TNNLS.2018.2890148},
  url = {https://ieeexplore.ieee.org/document/8626164/},
  urldate = {2022-12-28},
  abstract = {With online crowdsourcing platforms, labels can be acquired at relatively low costs from massive nonexpert workers. To improve the quality of labels obtained from these imperfect crowdsourced workers, we usually let different workers provide labels for the same instance. Then, the true labels for all instances are estimated from these multiple noisy labels. This traditional general-purpose label aggregation process, solely relying on the collected noisy labels, cannot significantly improve the accuracy of integrated labels under a low labeling quality circumstance. This paper proposes a novel bilayer collaborative clustering (BLCC) method for the label aggregation in crowdsourcing. BLCC first generates the conceptual-level features for the instances from their multiple noisy labels and infers the initially integrated labels by performing clustering on the conceptual-level features. Then, it performs another clustering on the physical-level features to form the estimations of the true labels on the physical layer. The clustering results on both layers can facilitate in tracking the changes in the uncertainties of the instances. Finally, the initially integrated labels that are likely to be wrongly inferred on the conceptual layer can be addressed using the estimated labels on the physical layer. The clustering processes on both layers can keep providing guidance information for each other in the multiple label remedy rounds. The experimental results on 12 real-world crowdsourcing data sets show that the performance of the proposed method in terms of accuracy is better than that of the state-of-the-art methods.},
  keywords = {⛔ No INSPIRE recid found,Clustering,Collaboration,crowdsourcing,Crowdsourcing,Feature extraction,label aggregation,label noise handling,Labeling,Noise measurement,Probabilistic logic,Reliability,truth inference},
  annotation = {20 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/KDZ4GYVR/Zhang et al. - 2019 - Crowdsourced Label Aggregation Using Bilayer Colla.pdf}
}

@article{zhang_Deep_2015,
  title = {Deep {{Convolutional Neural Networks}} for {{Multi-Modality Isointense Infant Brain Image Segmentation}}},
  author = {Zhang, Wenlu and Li, Rongjian and Deng, Houtao and Wang, Li and Lin, Weili and Ji, Shuiwang and Shen, Dinggang},
  date = {2015-03},
  journaltitle = {Neuroimage},
  volume = {108},
  pages = {214--224},
  doi = {10.1016/j.neuroimage.2014.12.061},
  abstract = {The segmentation of infant brain tissue images into white matter (WM), gray matter (GM), and cerebrospinal fluid (CSF) plays an important role in studying early brain development in health and disease. In the isointense stage (approximately 6-8 months of age), WM and GM exhibit similar levels of intensity in both T1 and T2 MR images, making the tissue segmentation very challenging. Only a small number of existing methods have been designed for tissue segmentation in this isointense stage; however, they only used a single T1 or T2 images, or the combination of T1 and T2 images. In this paper, we propose to use deep convolutional neural networks (CNNs) for segmenting isointense stage brain tissues using multi-modality MR images. CNNs are a type of deep models in which trainable filters and local neighborhood pooling operations are applied alternatingly on the raw input images, resulting in a hierarchy of increasingly complex features. Specifically, we used multi-modality information from T1, T2, and fractional anisotropy (FA) images as inputs and then generated the segmentation maps as outputs. The multiple intermediate layers applied convolution, pooling, normalization, and other operations to capture the highly nonlinear mappings between inputs and outputs. We compared the performance of our approach with that of the commonly used segmentation methods on a set of manually segmented isointense stage brain images. Results showed that our proposed model significantly outperformed prior methods on infant brain tissue segmentation. In addition, our results indicated that integration of multi-modality images led to significant performance improvement.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Convolutional neural networks,Deep learning,Imag},
  annotation = {684 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{zhang_Differential_2018,
  title = {Differential {{Evolution Based Weighted Majority Voting}} for {{Crowdsourcing}}},
  booktitle = {{{PRICAI}} 2018 {{Trends Artif}}. {{Intell}}.},
  author = {Zhang, Hao and Jiang, Liangxiao and Xu, Wenqiang},
  date = {2018},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {11013},
  pages = {228--236},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-97310-4_26},
  url = {http://link.springer.com/10.1007/978-3-319-97310-4_26},
  urldate = {2022-12-28},
  abstract = {With the rapid development of crowdsourcing learning, inferring (integrating) truth labels from multiple noisy label sets, it is also called label integration, has been a hot research topic. And many methods have been proposed for label integration. However, due to the variable uncertainty of crowdsourced labelers, inferring truth labels from multiple noisy label sets still faces great challenges. In this paper we transform the label integration problem into an optimization problem, and exploit a differential evolution-based weighted majority voting method, simply DEWMV, for label integration. DEWMV searches and weights the voting quality of each label through the designed differential evolution (DE) algorithm. In DEWMV, we define three fitness functions, including the uncertainty of the integration label, the uncertainty of the class member probability and the hybrid uncertainty, to search the optimal voting quality for each label. By theoretically analyzing their effectiveness, we choose the hybrid uncertainty as the final fitness function for DEWMV. The experimental results on 14 real-world datasets show that DEWMV is superior to standard majority voting (MV) and all the other state-of-the-art label integration methods used to compare.},
  isbn = {978-3-319-97310-4},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Crowdsourcing,Differential evolution,Label integration,Label quality,Multiple noisy labels},
  annotation = {9 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/R7XTGWXQ/openurl.pdf}
}

@inproceedings{zhang_Dive_,
  title = {Dive {{Into Deep Learning}}},
  author = {Zhang, Aston; and Lipton, Zack; and Li, Mu; and Smola, Alex},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@incollection{zhang_Generalized_2019,
  ids = {zhang_Generalized_2019a},
  title = {A {{Generalized Approach}} to {{Determine Confident Samples}} for {{Deep Neural Networks}} on {{Unseen Data}}},
  booktitle = {Uncertainty for {{Safe Utilization}} of {{Machine Learning}} in {{Medical Imaging}} and {{Clinical Image-Based Procedures}}},
  author = {Zhang, Min and Leung, Kevin H. and Ma, Zili and Wen, Jin and Avinash, Gopal},
  editor = {Greenspan, Hayit and Tanno, Ryutaro and Erdt, Marius and Arbel, Tal and Baumgartner, Christian and Dalca, Adrian and Sudre, Carole H. and Wells, William M. and Drechsler, Klaus and Linguraru, Marius George and Oyarzun Laura, Cristina and Shekhar, Raj and Wesarg, Stefan and Gonz\'alez Ballester, Miguel \'Angel},
  date = {2019},
  volume = {11840},
  pages = {65--74},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-32689-0_7},
  url = {http://link.springer.com/10.1007/978-3-030-32689-0_7},
  urldate = {2023-05-08},
  isbn = {978-3-030-32688-3 978-3-030-32689-0},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Confident samples,Deep neural network,Feature extraction,Outlier detection}
}

@inproceedings{zhang_Imbalanced_2013,
  title = {Imbalanced {{Multiple Noisy Labeling}} for {{Supervised Learning}}},
  booktitle = {Proc. {{AAAI Conf}}. {{Artif}}. {{Intell}}.},
  author = {Zhang, Jing and Wu, Xindong and Sheng, Victor},
  date = {2013-06-29},
  volume = {27},
  pages = {1651--1652},
  doi = {10.1609/aaai.v27i1.8530},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/8530},
  urldate = {2022-12-28},
  abstract = {When labeling objects via Internet-based outsourcing systems, the labelers may have bias, because they lack expertise, dedication and personal preference. These reasons cause Imbalanced Multiple Noisy Labeling. To deal with the imbalance labeling issue, we propose an agnostic algorithm PLAT (Positive LAbel frequency Threshold) which does not need any information about quality of labelers and underlying class distribution. Simulations on eight real-world datasets with different underlying class distributions demonstrate that PLAT not only effectively deals with the imbalanced multiple noisy labeling problem that off-the-shelf agnostic methods cannot cope with, but also performs nearly the same as majority voting under the circumstances that labelers have no bias.},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {5 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/JDTVPEHK/Zhang et al. - 2013 - Imbalanced Multiple Noisy Labeling for Supervised .pdf}
}

@article{zhang_Improving_2018,
  title = {Improving {{Crowdsourced Label Quality Using Noise Correction}}},
  author = {Zhang, Jing and Sheng, Victor S. and Li, Tao and Wu, Xindong},
  date = {2018-05},
  journaltitle = {IEEE Trans. Neural Netw. Learning Syst.},
  volume = {29},
  number = {5},
  pages = {1675--1688},
  issn = {2162-237X, 2162-2388},
  doi = {10.1109/TNNLS.2017.2677468},
  url = {http://ieeexplore.ieee.org/document/7885126/},
  urldate = {2022-12-28},
  keywords = {⛔ No INSPIRE recid found,Algorithm design and analysis,Crowdsourcing,ground truth inference,Inference algorithms,label integration,label noise correction,label quality,Labeling,Noise measurement,Prediction algorithms,Predictive models},
  annotation = {63 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/PSVQS4GQ/Zhang et al. - 2018 - Improving Crowdsourced Label Quality Using Noise C.pdf}
}

@inproceedings{zhang_INPREM_2020,
  title = {{{INPREM}}: {{An Interpretable}} and {{Trustworthy Predictive Model}} for {{Healthcare}}},
  author = {Zhang, Xianli and Qian, Buyue and Cao, Shilei and Li, Yang and Chen, Hang and Zheng, Yefeng and Davidson, Ian},
  date = {2020},
  doi = {10.1145/3394486.3403087},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {25 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{zhang_Label_2017,
  title = {Label {{Aggregation}} for {{Crowdsourcing With Bi-Layer Clustering}}},
  booktitle = {Proc. 40th {{Int}}. {{ACM SIGIR Conf}}. {{Res}}. {{Dev}}. {{Inf}}. {{Retr}}.},
  author = {Zhang, Jing and Sheng, Victor S. and Li, Tao},
  date = {2017-08-07},
  series = {{{SIGIR}} '17},
  pages = {921--924},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3077136.3080679},
  url = {https://doi.org/10.1145/3077136.3080679},
  urldate = {2021-11-02},
  abstract = {This paper proposes a novel general label aggregation method for both binary and multi-class labeling in crowdsourcing, namely Bi-Layer Clustering (BLC), which clusters two layers of features - the conceptual-level and the physical-level features - to infer true labels of instances. BLC first clusters the instances using the conceptual-level features extracted from their multiple noisy labels and then performs clustering again using the physical-level features. It can facilitate tracking the uncertainty changes of the instances, so that the integrated labels that are likely to be falsely inferred on the conceptual layer can be easily corrected using the estimated labels on the physical layer. Experimental results on two real-world crowdsourcing data sets show that BLC outperforms seven state-of-the-art methods.},
  isbn = {978-1-4503-5022-8},
  keywords = {⛔ No INSPIRE recid found,clustering,crowdsourcing,inference,label aggregation},
  annotation = {11 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/MDHXYC9I/Zhang et al. - 2017 - Label Aggregation for Crowdsourcing with Bi-Layer .pdf}
}

@article{zhang_MultiClass_2016,
  title = {Multi-{{Class Ground Truth Inference}} in {{Crowdsourcing With Clustering}}},
  author = {Zhang, Jing and Sheng, Victor S. and Wu, Jian and Wu, Xindong},
  date = {2016-04-01},
  journaltitle = {IEEE Trans. Knowl. Data Eng.},
  volume = {28},
  number = {4},
  pages = {1080--1085},
  issn = {1041-4347},
  doi = {10.1109/TKDE.2015.2504974},
  url = {http://ieeexplore.ieee.org/document/7345572/},
  urldate = {2022-12-28},
  keywords = {⛔ No INSPIRE recid found,Clustering,Clustering algorithms,{clustering,},Computer science,Crowdsourcing,EM algorithm,ground truth inference,Inference algorithms,Labeling,Maximum likelihood estimation,multi-class labeling,Noise measurement},
  annotation = {59 citations (Semantic Scholar/DOI) [2022-12-28]},
  file = {/Users/personal-macbook/Zotero/storage/8Q38UTNF/Zhang et al. - 2016 - Multi-Class Ground Truth Inference in Crowdsourcin.pdf}
}

@inproceedings{zhang_MultiLabel_2010,
  title = {Multi-{{Label Learning}} by {{Exploiting Label Dependency}}},
  booktitle = {16th {{ACM SIGKDD Int}}. {{Conf}}. {{Knowl}}. {{Discov}}. {{Data Min}}.},
  author = {Zhang, Min-Ling and Zhang, Kun},
  date = {2010},
  pages = {999},
  publisher = {{ACM Press}},
  location = {{Washington, DC, USA}},
  doi = {10.1145/1835804.1835930},
  url = {http://dl.acm.org/citation.cfm?doid=1835804.1835930},
  urldate = {2022-11-21},
  eventtitle = {16th {{ACM SIGKDD}} International Conference},
  isbn = {978-1-4503-0055-1},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,bayesian network,machine learning,multi-label learning},
  annotation = {412 citations (Semantic Scholar/DOI) [2022-11-21]},
  file = {/Users/personal-macbook/Zotero/storage/KA4XLK8X/Zhang and Zhang - 2010 - Multi-label learning by exploiting label dependenc.pdf}
}

@inproceedings{zhang_multilabelinferencecrowdsourcing_2018,
  title = {Multi-{{Label Inference}} for {{Crowdsourcing}}},
  booktitle = {Proc. 24th {{ACM SIGKDD Int}}. {{Conf}}. {{Knowl}}. {{Discov}}. {{Data Min}}.},
  author = {Zhang, Jing and Wu, Xindong},
  date = {2018-07-19},
  pages = {2738--2747},
  publisher = {{ACM}},
  location = {{London United Kingdom}},
  doi = {10.1145/3219819.3219958},
  eventtitle = {Knowledge {{Discovery}} and {{Data Mining}}},
  isbn = {978-1-4503-5552-0},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Crowdsourcing,label aggregation,Maximum likelihood estimation,mixture models,probabilistic graphical models},
  annotation = {30 citations (Semantic Scholar/DOI) [2022-12-28]},
  file = {/Users/personal-macbook/Zotero/storage/SLWJBGI7/Zhang and Wu - 2018 - Multi-Label Inference for Crowdsourcing.pdf}
}

@inproceedings{zhang_MultiModal_2020,
  title = {Multi-{{Modal Multi-Label Emotion Detection With Modality}} and {{Label Dependence}}},
  booktitle = {Conf. {{Empir}}. {{Methods Nat}}. {{Lang}}. {{Process}}. {{EMNLP}}},
  author = {Zhang, Dong and Ju, Xincheng and Li, Junhui and Li, Shoushan and Zhu, Qiaoming and Zhou, Guodong},
  date = {2020},
  pages = {3584--3593},
  publisher = {{Association for Computational Linguistics}},
  location = {{Online}},
  doi = {10.18653/v1/2020.emnlp-main.291},
  url = {https://www.aclweb.org/anthology/2020.emnlp-main.291},
  urldate = {2022-11-21},
  eventtitle = {Conference on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {11 citations (Semantic Scholar/DOI) [2022-11-21]},
  file = {/Users/personal-macbook/Zotero/storage/7NZXLM5J/Zhang et al. - 2020 - Multi-modal Multi-label Emotion Detection with Mod.pdf;/Users/personal-macbook/Zotero/storage/IW2HXFWF/5d386dbb-05f3-3685-846c-a665b237fb4a.html}
}

@inproceedings{zhang_Multiple_2019,
  title = {Multiple {{Noisy Label Distribution Propagation}} for {{Crowdsourcing}}},
  booktitle = {Proc. {{Twenty-Eighth Int}}. {{Jt}}. {{Conf}}. {{Artif}}. {{Intell}}.},
  author = {Zhang, Hao and Jiang, Liangxiao and Xu, Wenqiang},
  date = {2019-08},
  pages = {1473--1479},
  publisher = {{International Joint Conferences on Artificial Intelligence Organization}},
  location = {{Macao, China}},
  doi = {10.24963/ijcai.2019/204},
  url = {https://www.ijcai.org/proceedings/2019/204},
  urldate = {2022-12-29},
  abstract = {Crowdsourcing services provide a fast, efficient, and cost-effective means of obtaining large labeled data for supervised learning. Ground truth inference, also called label integration, designs proper aggregation strategies to infer the unknown true label of each instance from the multiple noisy label set provided by ordinary crowd workers. However, to the best of our knowledge, nearly all existing label integration methods focus solely on the multiple noisy label set itself of the individual instance while totally ignoring the intercorrelation among multiple noisy label sets of different instances. To solve this problem, a multiple noisy label distribution propagation (MNLDP) method is proposed in this study. MNLDP first transforms the multiple noisy label set of each instance into its multiple noisy label distribution and then propagates its multiple noisy label distribution to its nearest neighbors. Consequently, each instance absorbs a fraction of the multiple noisy label distributions from its nearest neighbors and yet simultaneously maintains a fraction of its own original multiple noisy label distribution. Promising experimental results on simulated and real-world datasets validate the effectiveness of our proposed method.},
  eventtitle = {Twenty-{{Eighth International Joint Conference}} on {{Artificial Intelligence}} \{\vphantom\}{{IJCAI-19}}\vphantom\{\}},
  isbn = {978-0-9992411-4-1},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {16 citations (Semantic Scholar/DOI) [2022-12-28]}
}

@article{zhang_Review_2014,
  title = {A {{Review}} on {{Multi-Label Learning Algorithms}}},
  author = {Zhang, Min Ling and Zhou, Zhi Hua},
  date = {2014-08},
  journaltitle = {IEEE Trans. Knowl. Data Eng.},
  volume = {26},
  number = {8},
  pages = {1819--1837},
  issn = {1041-4347},
  doi = {10.1109/TKDE.2013.39},
  url = {http://ieeexplore.ieee.org/document/6471714/},
  urldate = {2023-05-28},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {2291 citations (Semantic Scholar/DOI) [2023-05-28]}
}

@inproceedings{zhang_Spectral_2014,
  title = {Spectral {{Methods Meet EM}}: {{A Provably Optimal Algorithm}} for {{Crowdsourcing}}},
  booktitle = {Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.},
  author = {Zhang, Yuchen and Chen, Xi and Zhou, Dengyong and Jordan, Michael I},
  date = {2014},
  volume = {27},
  pages = {1260--1268},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2014/file/788d986905533aba051261497ecffcbb-Paper.pdf},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{zhang_Spectral_2016,
  title = {Spectral {{Methods Meet EM}}: {{A Provably Optimal Algorithm}} for {{Crowdsourcing}}},
  shorttitle = {Spectral {{Methods Meet Em}}},
  author = {Zhang, Yuchen and Chen, Xi and Zhou, Dengyong and Jordan, Michael I.},
  date = {2016},
  journaltitle = {JMLR},
  volume = {17},
  number = {1},
  pages = {3537--3580},
  publisher = {{JMLR. org}},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/HE9DRM96/Zhang et al. - 2014 - Spectral methods meet EM A provably optimal algor.pdf;/Users/personal-macbook/Zotero/storage/MVHZ5VQC/Zhang et al. - 2016 - Spectral methods meet EM A provably optimal algor.pdf;/Users/personal-macbook/Zotero/storage/N7A5HRK6/788d986905533aba051261497ecffcbb-Abstract.html}
}

@article{zhang_Transfer_2020,
  title = {Transfer {{Adaptation Learning}}: {{A Decade Survey}}},
  shorttitle = {Transfer {{Adaptation Learning}}},
  author = {Zhang, Lei and Gao, Xinbo},
  date = {2020-11-21},
  journaltitle = {ArXiv190304687 Cs},
  eprint = {1903.04687},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1903.04687},
  urldate = {2021-11-09},
  abstract = {The world we see is ever-changing and it always changes with people, things, and the environment. Domain is referred to as the state of the world at a certain moment. A research problem is characterized as transfer adaptation learning (TAL) when it needs knowledge correspondence between different moments/domains. Conventional machine learning aims to find a model with the minimum expected risk on test data by minimizing the regularized empirical risk on the training data, which, however, supposes that the training and test data share similar joint probability distribution. TAL aims to build models that can perform tasks of target domain by learning knowledge from a semantic related but distribution different source domain. It is an energetic research filed of increasing influence and importance, which is presenting a blowout publication trend. This paper surveys the advances of TAL methodologies in the past decade, and the technical challenges and essential problems of TAL have been observed and discussed with deep insights and new perspectives. Broader solutions of transfer adaptation learning being created by researchers are identified, i.e., instance re-weighting adaptation, feature adaptation, classifier adaptation, deep network adaptation and adversarial adaptation, which are beyond the early semi-supervised and unsupervised split. The survey helps researchers rapidly but comprehensively understand and identify the research foundation, research status, theoretical limitations, future challenges and under-studied issues (universality, interpretability, and credibility) to be broken in the field toward universal representation and safe applications in open-world scenarios.},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found,Computer Science - Computer Vision and Pattern Recognition,Computer Vision,Distribution Discrepancy,Domain Adaptation,Transfer Learning},
  file = {/Users/personal-macbook/Zotero/storage/A6XIRCSJ/Zhang and Gao - 2020 - Transfer Adaptation Learning A Decade Survey.pdf}
}

@inproceedings{zhang_Understanding_2021,
  title = {Understanding {{Intrinsic Robustness Using Label Uncertainty}}},
  booktitle = {Int. {{Conf}}. {{Learn}}. {{Represent}}.},
  author = {Zhang, Xiao and Evans, David},
  date = {2021},
  doi = {10.48550/arxiv.2107.03250},
  keywords = {⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/BMLCPFM7/Zhang and Evans - 2021 - Understanding Intrinsic Robustness Using Label Unc.pdf}
}

@article{zhao_Adaptive_2010,
  title = {Adaptive {{Fingerprint Pore Modeling}} and {{Extraction}}},
  author = {Zhao, Qijun and Zhang, David and Zhang, Lei and Luo, Nan},
  date = {2010},
  journaltitle = {Pattern Recognit.},
  issn = {00313203},
  doi = {10.1016/j.patcog.2010.02.016},
  abstract = {Sweat pores on fingerprints have proven to be discriminative features and have recently been successfully employed in automatic fingerprint recognition systems (AFRS), where the extraction of fingerprint pores is a critical step. Most of the existing pore extraction methods detect pores by using a static isotropic pore model; however, their detection accuracy is not satisfactory due to the limited approximation capability of static isotropic models to various types of pores. This paper presents a dynamic anisotropic pore model to describe pores more accurately by using orientation and scale parameters. An adaptive pore extraction method is then developed based on the proposed dynamic anisotropic pore model. The fingerprint image is first partitioned into well-defined, ill-posed, and background blocks. According to the dominant ridge orientation and frequency on each foreground block, a local instantiation of appropriate pore model is obtained. Finally, the pores are extracted by filtering the block with the adaptively generated pore model. Extensive experiments are performed on the high resolution fingerprint databases we established. The results demonstrate that the proposed method can detect pores more accurately and robustly, and consequently improve the fingerprint recognition accuracy of pore-based AFRS. \textcopyright{} 2010 Elsevier Ltd. All rights reserved.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Automatic fingerprint recognition,Biometrics,Pore extraction,Pore models},
  annotation = {129 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{zhao_Automatic_2022a,
  ids = {zhao_Automatic_2022},
  title = {Automatic {{Thyroid Ultrasound Image Classification Using Feature Fusion Network}}},
  author = {Zhao, Xiaohui and Shen, Xueqin and Wan, Wenbo and Lu, Yuanyuan and Hu, Shidong and Xiao, Ruoxiu and Du, Xiaohui and Li, Junlai},
  date = {2022},
  journaltitle = {IEEE Access},
  volume = {10},
  pages = {27917--27924},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2022.3156096},
  url = {https://ieeexplore.ieee.org/document/9725813/},
  urldate = {2022-05-16},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {2 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/7N8CRBHY/Zhao et al. - 2022 - Automatic Thyroid Ultrasound Image Classification .pdf}
}

@article{zhao_Conjoint_2019,
  title = {The {{Conjoint Analysis}} of {{Microstructural}} and {{Morphological Changes}} of {{Gray Matter During Aging}}},
  author = {Zhao, Xin and Wu, Qiong and Chen, Yuanyuan and Song, Xizi and Ni, Hongyan and Ming, Dong},
  date = {2019-03},
  journaltitle = {Front. Neurol.},
  volume = {10},
  pages = {184},
  abstract = {Macromorphological and microstructural changes of gray matter (GM) happen during brain normal aging. However, the mechanism of macro-microstructure association is still unclear, which is of guidance for understanding many neurodegenerative diseases. In this study, adopting structural magnetic resonance imaging (sMRI) and diffusion kurtosis imaging (DKI), GM aging pattern was characterized and its macro-microstructure associations were revealed. For 60 subjects among the ages of 47-79, the DKI and T1-weighted images were investigated with voxel-based analysis. The results showed age-related overlapped patterns between morphological and microstructural alterations during normal aging. It was worth noting that morphological changes and mean diffusivity (MD) indexes abnormalities mainly overlapped in the following regions, superior frontal gyrus, inferior frontal gyrus, cingulum gyrus, superior temporal gyrus, insula, and thalamus. Besides, overlapped with GM atrophies, mean kurtosis (MK) abnormalities were observed in superior frontal gyrus, inferior frontal gyrus, transverse temporal gyrus, insula, and thalamus. What important was that intrinsic aging independent associations between macrostructure and microstructure were found especially in media superior frontal gyrus, which revealed the potential mechanisms in the process of aging. The physiological mechanism may be associated with the elimination of neurons and synapses and the shrinkage of large neurons. Understanding the associations of GM volume changes and microstructural changes can account for the underlying mechanisms of aging and age-related neurodegenerative diseases.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found,aging,brain atrophy,gray matter,macro-microstru}
}

@inproceedings{zhao_Data_2019,
  title = {Data {{Augmentation Using Learned Transformations}} for {{One-Shot Medical Image Segmentation}}},
  booktitle = {Proc. {{IEEE Comput}}. {{Soc}}. {{Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}.},
  author = {Zhao, Amy and Balakrishnan, Guha and Durand, Fredo and Guttag, John V. and Dalca, Adrian V.},
  date = {2019},
  volume = {2019-June},
  issn = {10636919},
  doi = {10.1109/CVPR.2019.00874},
  abstract = {Image segmentation is an important task in many medical applications. Methods based on convolutional neural networks attain state-of-the-art accuracy; however, they typically rely on supervised training with large labeled datasets. Labeling medical images requires significant expertise and time, and typical hand-tuned approaches for data augmentation fail to capture the complex variations in such images. We present an automated data augmentation method for synthesizing labeled medical images. We demonstrate our method on the task of segmenting magnetic resonance imaging (MRI) brain scans. Our method requires only a single segmented scan, and leverages other unlabeled scans in a semi-supervised approach. We learn a model of transformations from the images, and use the model along with the labeled example to synthesize additional labeled examples. Each transformation is comprised of a spatial deformation field and an intensity change, enabling the synthesis of complex effects such as variations in anatomy and image acquisition procedures. We show that training a supervised segmenter with these new examples provides significant improvements over state-of-the-art methods for one-shot biomedical image segmentation.},
  isbn = {978-1-72813-293-8},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {297 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{zhao_HOTVAE_2021,
  title = {{{HOT-VAE}}: {{Learning High-Order Label Correlation}} for {{Multi-Label Classification}} via {{Attention-Based Variational Autoencoders}}},
  shorttitle = {{{HOT-VAE}}},
  booktitle = {Proc. {{AAAI Conf}}. {{Artif}}. {{Intell}}.},
  author = {Zhao, Wenting and Kong, Shufeng and Bai, Junwen and Fink, Daniel and Gomes, Carla},
  date = {2021-05-18},
  volume = {35},
  pages = {15016--15024},
  doi = {10.1609/aaai.v35i17.17762},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/17762},
  urldate = {2022-11-21},
  abstract = {Understanding how environmental characteristics affect biodiversity patterns, from individual species to communities of species, is critical for mitigating effects of global change. A central goal for conservation planning and monitoring is the ability to accurately predict the occurrence of species communities and how these communities change over space and time. This in turn leads to a challenging and long-standing problem in the field of computer science - how to perform accurate multi-label classification with hundreds of labels? The key challenge of this problem is its exponential-sized output space with regards to the number of labels to be predicted. Therefore, it is essential to facilitate the learning process by exploiting correlations (or dependency) among labels. Previous methods mostly focus on modelling the correlation on label pairs; however, complex relations between real-world objects often go beyond second order. In this paper, we propose a novel framework for multi-label classification, High-order Tie-in Variational Autoencoder (HOT-VAE), which performs adaptive high-order label correlation learning. We experimentally verify that our model outperforms the existing state-of-the-art approaches on a bird distribution dataset on both conventional F1 scores and a variety of ecological metrics. To show our method is general, we also perform empirical analysis on seven other public real-world datasets in several application domains, and Hot-VAE exhibits superior performance to previous methods.},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {9 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/5L7AD4VH/Zhao et al. - 2021 - HOT-VAE Learning High-Order Label Correlation for.pdf;/Users/personal-macbook/Zotero/storage/UTXI9UEH/Zhao et al. - 2021 - HOT-VAE Learning High-Order Label Correlation for.pdf}
}

@article{zhao_Mediating_2005,
  title = {The {{Mediating Role}} of {{Self-Efficacy}} in the {{Development}} of {{Entrepreneurial Intentions}}},
  author = {Zhao, Hao and Hills, Gerald E. and Seibert, Scott E.},
  date = {2005},
  journaltitle = {J. Appl. Psychol.},
  eprint = {16316279},
  eprinttype = {pmid},
  issn = {00219010},
  doi = {10.1037/0021-9010.90.6.1265},
  abstract = {The purpose of this study was to investigate the mediating role of self-efficacy in the development of students' intentions to become entrepreneurs. The authors used structural equation modeling with a sample of 265 master of business administration students across 5 universities to test their hypotheses. The results showed that the effects of perceived learning from entrepreneurship-related courses, previous entrepreneurial experience, and risk propensity on entrepreneurial intentions were fully mediated by entrepreneurial self-efficacy. Contrary to expectations, gender was not mediated by self-efficacy but had a direct effect such that women reported lower entrepreneurial career intentions. The authors discuss practical implications and directions for future research. Copyright 2005 by the American Psychological Association.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Career intentions,Entrepreneurship,Self-efficacy}
}

@article{zhao_Object_2019a,
  ids = {zhao_Object_2019},
  title = {Object {{Detection With Deep Learning}}: {{A Review}}},
  shorttitle = {Object {{Detection With Deep Learning}}},
  author = {Zhao, Zhong-Qiu and Zheng, Peng and Xu, Shou-Tao and Wu, Xindong},
  date = {2019-11},
  journaltitle = {IEEE Trans. Neural Netw. Learn. Syst.},
  volume = {30},
  number = {11},
  pages = {3212--3232},
  issn = {2162-2388},
  doi = {10.1109/TNNLS.2018.2876865},
  abstract = {Due to object detection's close relationship with video analysis and image understanding, it has attracted much research attention in recent years. Traditional object detection methods are built on handcrafted features and shallow trainable architectures. Their performance easily stagnates by constructing complex ensembles that combine multiple low-level image features with high-level context from object detectors and scene classifiers. With the rapid development in deep learning, more powerful tools, which are able to learn semantic, high-level, deeper features, are introduced to address the problems existing in traditional architectures. These models behave differently in network architecture, training strategy, and optimization function. In this paper, we provide a review of deep learning-based object detection frameworks. Our review begins with a brief introduction on the history of deep learning and its representative tool, namely, the convolutional neural network. Then, we focus on typical generic object detection architectures along with some modifications and useful tricks to improve detection performance further. As distinct specific detection tasks exhibit different characteristics, we also briefly survey several specific tasks, including salient object detection, face detection, and pedestrian detection. Experimental analyses are also provided to compare various methods and draw some meaningful conclusions. Finally, several promising directions and tasks are provided to serve as guidelines for future work in both object detection and relevant neural network-based learning systems.},
  eventtitle = {{{IEEE Transactions}} on {{Neural Networks}} and {{Learning Systems}}},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Computer architecture,Deep learning,Feature extraction,neural network,Neural networks,object detection,Object detection,Task analysis,Training},
  annotation = {1635 citations (Semantic Scholar/DOI) [2022-07-18]},
  file = {/Users/personal-macbook/Zotero/storage/B2ZVUJFJ/Zhao et al. - 2019 - Object Detection With Deep Learning A Review.pdf;/Users/personal-macbook/Zotero/storage/BJQ2RIAW/Zhao et al. - 2019 - Object Detection With Deep Learning A Review.html;/Users/personal-macbook/Zotero/storage/K5DUAPQF/Zhao et al. - 2019 - Object Detection With Deep Learning A Review.html;/Users/personal-macbook/Zotero/storage/L5TRJVIC/Zhao et al. - 2019 - Object Detection With Deep Learning A Review.html}
}

@inproceedings{zhao_Parallel_2009,
  ids = {zhao_Parallel_2009a},
  title = {Parallel {{K-Means Clustering Based}} on {{MapReduce}}},
  booktitle = {Cloud {{Comput}}.},
  author = {Zhao, Weizhong and Ma, Huifang and He, Qing},
  date = {2009},
  volume = {5931},
  pages = {674--679},
  publisher = {{Springer Berlin Heidelberg}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-10665-1_71},
  url = {http://link.springer.com/10.1007/978-3-642-10665-1_71},
  urldate = {2021-11-16},
  abstract = {Data clustering has been received considerable attention in many applications, such as data mining, document retrieval, image segmentation and pattern classification. The enlarging volumes of information emerging by the progress of technology, makes clustering of very large scale of data a challenging task. In order to deal with the problem, many researchers try to design efficient parallel clustering algorithms. In this paper, we propose a parallel k -means clustering algorithm based on MapReduce, which is a simple yet powerful parallel programming technique. The experimental results demonstrate that the proposed algorithm can scale well and efficiently process large datasets on commodity hardware.},
  isbn = {978-3-642-10664-4 978-3-642-10665-1},
  langid = {english},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found,Data mining,Hadoop,K-means,MapReduce,Parallel clustering},
  file = {/Users/personal-macbook/Zotero/storage/XBMZQHIU/Zhao et al. - 2009 - Parallel K-Means Clustering Based on MapReduce.pdf}
}

@inproceedings{zhao_PointWeb_2019,
  title = {{{PointWeb}}: {{Enhancing Local Neighborhood Features}} for {{Point Cloud Processing}}},
  shorttitle = {{{PointWeb}}},
  booktitle = {2019 {{IEEECVF Conf}}. {{Comput}}. {{Vis}}. {{Pattern Recognit}}. {{CVPR}}},
  author = {Zhao, Hengshuang and Jiang, Li and Fu, Chi-Wing and Jia, Jiaya},
  date = {2019-06},
  pages = {5560--5568},
  publisher = {{IEEE}},
  location = {{Long Beach, CA, USA}},
  doi = {10.1109/CVPR.2019.00571},
  url = {https://ieeexplore.ieee.org/document/8954075/},
  urldate = {2022-07-28},
  abstract = {This paper presents PointWeb, a new approach to extract contextual features from local neighborhood in a point cloud. Unlike previous work, we densely connect each point with every other in a local neighborhood, aiming to specify feature of each point based on the local region characteristics for better representing the region. A novel module, namely Adaptive Feature Adjustment (AFA) module, is presented to find the interaction between points. For each local region, an impact map carrying element-wise impact between point pairs is applied to the feature difference map. Each feature is then pulled or pushed by other features in the same region according to the adaptively learned impact indicators. The adjusted features are well encoded with region information, and thus benefit the point cloud recognition tasks, such as point cloud segmentation and classification. Experimental results show that our model outperforms the state-of-the-arts on both semantic segmentation and shape classification datasets.},
  eventtitle = {2019 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-72813-293-8},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {286 citations (Semantic Scholar/DOI) [2022-08-30]},
  file = {/Users/personal-macbook/Zotero/storage/JX9QUK6G/Zhao et al. - 2019 - PointWeb Enhancing Local Neighborhood Features fo.pdf;/Users/personal-macbook/Zotero/storage/TJYPC4B8/pointweb-enhancing-local-neighborhood.html}
}

@article{zheng_Automated_2022,
  ids = {_Automated_,zheng_Automated_2022a},
  title = {Automated {{Detection}} and {{Recognition}} of {{Thyroid Nodules}} in {{Ultrasound Images Using Improve Cascade Mask R-CNN}}},
  author = {Zheng, Yinghao and Qin, Lina and Qiu, Taorong and Zhou, Aiyun and Xu, Pan and Xue, Zhixin},
  date = {2022-04-01},
  journaltitle = {Multimed Tools Appl},
  volume = {81},
  number = {10},
  pages = {13253--13273},
  issn = {1573-7721},
  doi = {10.1007/s11042-021-10939-4},
  url = {https://doi.org/10.1007/s11042-021-10939-4},
  urldate = {2022-05-16},
  abstract = {Accurate diagnosis of thyroid nodules using ultrasonography heavily relies on the superb skills and rich experience of senior radiologists, considering the low contrast, high noise of the ultrasound image, and the diverse appearance of the nodules. Computer-aided diagnosis systems could diagnose thyroid nodules based on ultrasound characteristics to assist radiologists. However, the existing learning-based approaches for detecting and recognizing thyroid nodules have the problems of inaccurate localization and low recognition accuracy. In this study, we propose an Improved Cascade Mask R-CNN for effectively detecting and recognizing thyroid nodules. Firstly, a more effective detector is designed to better classify the ROIs and better correct the bounding boxes. Secondly, a more effective balanced L1 loss function is used to increase the gradient of the easy sample and solve the problem of imbalance between hard samples and easy samples~during training. Finally, a more~effective soft non-maximum suppression (Soft-NMS) method is used to set an attenuation function for adjacent bounding boxes, which solves the problem of possible missing detection in non-maximum suppression (NMS). The improved model is trained and verified by using real 1408 images collected from the known hospital. Under the localization accuracy of the IoU threshold of 0.5, the mAP reaches 87.1\%, and the recognition accuracy reaches 98.67\%. The experiment results show that the improved model is~effective and highly valuable to help the doctors for the recognition of benign and malignant thyroid nodules.},
  langid = {english},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Automatic detection,Improve Cascade Mask R-CNN,Recognition,Thyroid nodule,Ultrasound image},
  annotation = {1 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/IPNLMSED/Zheng et al. - 2022 - Automated detection and recognition of thyroid nod.pdf}
}

@article{zheng_Truth_2017,
  title = {Truth {{Inference}} in {{Crowdsourcing}}: {{Is}} the {{Problem Solved}}?},
  shorttitle = {Truth {{Inference}} in {{Crowdsourcing}}},
  author = {Zheng, Yudian and Li, Guoliang and Li, Yuanbing and Shan, Caihua and Cheng, Reynold},
  date = {2017-01},
  journaltitle = {Proc. VLDB Endow.},
  volume = {10},
  number = {5},
  pages = {541--552},
  issn = {2150-8097},
  doi = {10.14778/3055540.3055547},
  url = {https://dl.acm.org/doi/10.14778/3055540.3055547},
  urldate = {2022-12-28},
  abstract = {Crowdsourcing has emerged as a novel problem-solving paradigm, which facilitates addressing problems that are hard for computers, e.g., entity resolution and sentiment analysis. However, due to the openness of crowdsourcing, workers may yield low-quality answers, and a redundancy-based method is widely employed, which first assigns each task to multiple workers and then infers the correct answer (called               truth               ) for the task based on the answers of the assigned workers. A fundamental problem in this method is               Truth Inference               , which decides how to effectively infer the truth. Recently, the database community and data mining community independently study this problem and propose various algorithms. However, these algorithms are not compared extensively under the same framework and it is hard for practitioners to select appropriate algorithms. To alleviate this problem, we provide a detailed survey on 17 existing algorithms and perform a comprehensive evaluation using 5 real datasets. We make all codes and datasets public for future research. Through experiments we find that existing algorithms are not stable across different datasets and there is no algorithm that outperforms others consistently. We believe that the truth inference problem is not fully solved, and identify the limitations of existing algorithms and point out promising research directions.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {311 citations (Semantic Scholar/DOI) [2022-12-28]},
  file = {/Users/personal-macbook/Zotero/storage/MVS5TFEB/Zheng et al. - 2017 - Truth inference in crowdsourcing is the problem s.pdf;/Users/personal-macbook/Zotero/storage/VPR2IYVW/3055540.html}
}

@article{zhong_QualitySensitive_2017,
  title = {A {{Quality-Sensitive Method}} for {{Learning From Crowds}}},
  author = {Zhong, Jinhong and Yang, Peng and Tang, Ke},
  date = {2017-12-01},
  journaltitle = {IEEE Trans. Knowl. Data Eng.},
  volume = {29},
  number = {12},
  pages = {2643--2654},
  issn = {1041-4347},
  doi = {10.1109/TKDE.2017.2738643},
  url = {http://ieeexplore.ieee.org/document/8008864/},
  urldate = {2022-12-20},
  keywords = {⛔ No INSPIRE recid found,crowdsourcing,Crowdsourcing,Learning from crowds,learning from multiple annotators,Learning systems,Noise measurement,Optimization,quality-sensitive learning,Reliability,Supervised learning,Support vector machines},
  annotation = {8 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/UQ8H3BCE/Zhong et al. - 2017 - A Quality-Sensitive Method for Learning from Crowd.pdf}
}

@article{zhou_Clinical_2020,
  title = {Clinical {{Course}} and {{Risk Factors}} for {{Mortality}} of {{Adult Inpatients With COVID-19}} in {{Wuhan}}, {{China}}: {{A Retrospective Cohort Study}}},
  author = {Zhou, Fei and Yu, Ting and Du, Ronghui and Fan, Guohui and Liu, Ying and Liu, Zhibo and Xiang, Jie and Wang, Yeming and Song, Bin and Gu, Xiaoying and Guan, Lulu and Wei, Yuan and Li, Hui and Wu, Xudong and Xu, Jiuyang and Tu, Shengjin and Zhang, Yi and Chen, Hua and Cao, Bin},
  date = {2020},
  journaltitle = {The Lancet},
  volume = {395},
  number = {10229},
  eprint = {32171076},
  eprinttype = {pmid},
  pages = {1054--1062},
  publisher = {{Elsevier Ltd}},
  issn = {1474547X},
  doi = {10.1016/S0140-6736(20)30566-3},
  abstract = {Background: Since December, 2019, Wuhan, China, has experienced an outbreak of coronavirus disease 2019 (COVID-19), caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). Epidemiological and clinical characteristics of patients with COVID-19 have been reported but risk factors for mortality and a detailed clinical course of illness, including viral shedding, have not been well described. Methods: In this retrospective, multicentre cohort study, we included all adult inpatients ({$\geq$}18 years old) with laboratory-confirmed COVID-19 from Jinyintan Hospital and Wuhan Pulmonary Hospital (Wuhan, China) who had been discharged or had died by Jan 31, 2020. Demographic, clinical, treatment, and laboratory data, including serial samples for viral RNA detection, were extracted from electronic medical records and compared between survivors and non-survivors. We used univariable and multivariable logistic regression methods to explore the risk factors associated with in-hospital death. Findings: 191 patients (135 from Jinyintan Hospital and 56 from Wuhan Pulmonary Hospital) were included in this study, of whom 137 were discharged and 54 died in hospital. 91 (48\%) patients had a comorbidity, with hypertension being the most common (58 [30\%] patients), followed by diabetes (36 [19\%] patients) and coronary heart disease (15 [8\%] patients). Multivariable regression showed increasing odds of in-hospital death associated with older age (odds ratio 1{$\cdot$}10, 95\% CI 1{$\cdot$}03\textendash 1{$\cdot$}17, per year increase; p=0{$\cdot$}0043), higher Sequential Organ Failure Assessment (SOFA) score (5{$\cdot$}65, 2{$\cdot$}61\textendash 12{$\cdot$}23; p{$<$}0{$\cdot$}0001), and d-dimer greater than 1 {$\mu$}g/mL (18{$\cdot$}42, 2{$\cdot$}64\textendash 128{$\cdot$}55; p=0{$\cdot$}0033) on admission. Median duration of viral shedding was 20{$\cdot$}0 days (IQR 17{$\cdot$}0\textendash 24{$\cdot$}0) in survivors, but SARS-CoV-2 was detectable until death in non-survivors. The longest observed duration of viral shedding in survivors was 37 days. Interpretation: The potential risk factors of older age, high SOFA score, and d-dimer greater than 1 {$\mu$}g/mL could help clinicians to identify patients with poor prognosis at an early stage. Prolonged viral shedding provides the rationale for a strategy of isolation of infected patients and optimal antiviral interventions in the future. Funding: Chinese Academy of Medical Sciences Innovation Fund for Medical Sciences; National Science Grant for Distinguished Young Scholars; National Key Research and Development Program of China; The Beijing Science and Technology Project; and Major Projects \ldots},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {9987 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inreference{zhou_Ensemblelearning_2009,
  title = {Ensemble {{Learning}}},
  booktitle = {Encyclopedia of {{Biometrics}}},
  author = {Zhou, Zhi-Hua},
  editor = {Li, Stan Z. and Jain, Anil},
  date = {2009},
  pages = {270--273},
  publisher = {{Springer US}},
  location = {{Boston, MA}},
  doi = {10.1007/978-0-387-73003-5_293},
  url = {http://link.springer.com/10.1007/978-0-387-73003-5_293},
  urldate = {2023-06-24},
  isbn = {978-0-387-73002-8 978-0-387-73003-5},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found}
}

@inproceedings{zhou_Learning_2012,
  title = {Learning {{From}} the {{Wisdom}} of {{Crowds}} by {{Minimax Entropy}}},
  booktitle = {Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.},
  author = {Zhou, Dengyong and Basu, Sumit and Mao, Yi and Platt, John},
  date = {2012},
  volume = {25},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2012/file/46489c17893dfdcf028883202cefd6d1-Paper.pdf},
  keywords = {⛔ No DOI found,⛔ No INSPIRE recid found},
  file = {/Users/personal-macbook/Zotero/storage/A4RM38M5/Zhou et al. - 2012 - Learning from the Wisdom of Crowds by Minimax Entr.pdf}
}

@inproceedings{zhou_Semisupervised_2005,
  title = {Semi-{{Supervised Regression With Co-Training}}},
  booktitle = {Int. {{Jt}}. {{Conf}}. {{Artif}}. {{Intell}}.},
  author = {Zhou, Zhi Hua and Li, Ming},
  date = {2005},
  issn = {10450823},
  abstract = {In many practical machine learning and data mining applications, unlabeled training examples are readily available but labeled ones are fairly expensive to obtain. Therefore, semi-supervised learning algorithms such as co-training have attracted much attention. Previous research mainly focuses on semi-supervised classification. In this paper, a co-training style semi-supervised regression algorithm, i.e. COREG, is proposed. This algorithm uses two k -nearest neighbor regressors with different distance metrics, each of which labels the unlabeled data for the other regressor where the labeling confidence is estimated through consulting the influence of the labeling of unlabeled examples on the labeled ones. Experiments show that COREG can effectively exploit unlabeled data to improve regression estimates.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{zhou_Tritraining_2005,
  title = {Tri-{{Training}}: {{Exploiting Unlabeled Data Using Three Classifiers}}},
  author = {Zhou, Zhi Hua and Li, Ming},
  date = {2005},
  journaltitle = {IEEE Trans. Knowl. Data Eng.},
  issn = {10414347},
  doi = {10.1109/TKDE.2005.186},
  abstract = {In many practical data mining applications, such as Web page classification, unlabeled training examples are readily available, but labeled ones are fairly expensive to obtain. Therefore, semi-supervised learning algorithms such as co-training have attracted much attention. In this paper, a new co-training style semi-supervised learning algorithm, named tri-training, is proposed. This algorithm generates three classifiers from the original labeled example set. These classifiers are then refined using unlabeled examples in the tri-training process. In detail, in each round of tri-training, an unlabeled example is labeled for a classifier if the other two classifiers agree on the labeling, under certain conditions. Since tri-training neither requires the instance space to be described with sufficient and redundant views nor does it put any constraints on the supervised learning algorithm, its applicability is broader than that of previous co-training style algorithms. Experiments on UCI data sets and application to the Web page classification task indicate that tri-training can effectively exploit unlabeled data to enhance the learning performance. \textcopyright{} 2005 IEEE.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,Co-training,Data mining,Learning from unlabeled data,Machine learning,Semi-supervised learning,tri-training,Web page classification}
}

@article{zhou_UncertaintyAware_2020,
  title = {Uncertainty-{{Aware Consistency Regularization}} for {{Cross-Domain Semantic Segmentation}}},
  author = {Zhou, Qianyu and Feng, Zhengyang and Cheng, Guangliang and Tan, Xin and Shi, Jianping and Ma, Lizhuang},
  date = {2020-04},
  url = {http://arxiv.org/abs/2004.08878},
  abstract = {Unsupervised domain adaptation (UDA) aims to adapt existing models of the source domain to a new target domain with only unlabeled data. The main challenge to UDA lies in how to reduce the domain gap between the source domain and the target domain. Existing approaches of cross-domain semantic segmentation usually employ a consistency regularization on the target prediction of student model and teacher model respectively under different perturbations. However, previous works do not consider the reliability of the predicted target samples, which could harm the learning process by generating unreasonable guidance for the student model. In this paper, we propose an uncertainty-aware consistency regularization method to tackle this issue for semantic segmentation. By exploiting the latent uncertainty information of the target samples, more meaningful and reliable knowledge from the teacher model would be transferred to the student model. The experimental evaluation has shown that the proposed method outperforms the state-of-the-art methods by around \$3\% \textbackslash sim 5\%\$ improvement on two domain adaptation benchmarks, i.e. GTAV \$\textbackslash rightarrow \$ Cityscapes and SYNTHIA \$\textbackslash rightarrow \$ Cityscapes.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{zhu_Bayesian_2018,
  title = {Bayesian {{Deep Convolutional Encoder}}\textendash{{Decoder Networks}} for {{Surrogate Modeling}} and {{Uncertainty Quantification}}},
  author = {Zhu, Yinhao and Zabaras, Nicholas},
  date = {2018-08},
  journaltitle = {Journal of Computational Physics},
  volume = {366},
  pages = {415--447},
  issn = {00219991},
  doi = {10.1016/j.jcp.2018.04.018},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0021999118302341},
  urldate = {2022-12-29},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,Bayesian neural networks,Convolutional encoder\textendash decoder networks,Deep learning,Porous media flows,Uncertainty quantification},
  annotation = {405 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/EZBTG7JG/Zhu and Zabaras - 2018 - Bayesian deep convolutional encoder–decoder networ.pdf}
}

@article{zhu_Class_2004,
  title = {Class {{Noise}} vs. {{Attribute Noise}}: {{A Quantitative Study}}},
  author = {Zhu, Xingquan and Wu, Xindong},
  date = {2004},
  journaltitle = {Artif. Intell. Rev.},
  issn = {0269-2821},
  doi = {10.1007/s10462-004-0751-8},
  abstract = {Real-world data is never perfect and can often suffer from corruptions (noise) that may impact interpretations of the data, models created from the data and decisions made based on the data. Noise can reduce system performance in terms of classification accuracy, time in building a classifier and the size of the classifier. Accordingly, most existing learning algorithms have integrated various approaches to enhance their learning abilities from noisy environments, but the existence of noise can still introduce serious negative impacts. A more reasonable solution might be to employ some preprocessing mechanisms to handle noisy instances before a learner is formed. Unfortunately, rare research has been conducted to systematically explore the impact of noise, especially from the noise handling point of view. This has made various noise processing techniques less significant, specifically when dealing with noise that is introduced in attributes. In this paper, we present a systematic evaluation on the effect of noise in machine learning. Instead of taking any unified theory of noise to evaluate the noise impacts, we differentiate noise into two categories: class noise and attribute noise, and analyze their impacts on the system performance separately. Because class noise has been widely addressed in existing research efforts, we concentrate on attribute noise. We investigate the relationship between attribute noise and classification accuracy, the impact of noise at different attributes, and possible solutions in handling attribute noise. Our conclusions can be used to guide interested readers to enhance data quality by designing various noise handling mechanisms.},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {747 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@article{zhu_Constrained_2016,
  title = {Constrained {{Clustering With Imperfect Oracles}}},
  author = {Zhu, Xiatian and Loy, Chen Change and Gong, Shaogang},
  date = {2016-06},
  journaltitle = {IEEE Trans. Neural Netw. Learning Syst.},
  volume = {27},
  number = {6},
  pages = {1345--1357},
  issn = {2162-237X, 2162-2388},
  doi = {10.1109/TNNLS.2014.2387425},
  url = {http://ieeexplore.ieee.org/document/7018990/},
  urldate = {2021-11-16},
  abstract = {While clustering is usually an unsupervised operation, there are circumstances where we have access to prior belief that pairs of samples should (or should not) be assigned with the same cluster. Constrained clustering aims to exploit this prior belief as constraint (or weak supervision) to influence the cluster formation so as to obtain a data structure more closely resembling human perception. Two important issues remain open: 1) how to exploit sparse constraints effectively and 2) how to handle ill-conditioned/noisy constraints generated by imperfect oracles. In this paper, we present a novel pairwise similarity measure framework to address the above issues. Specifically, in contrast to existing constrained clustering approaches that blindly rely on all features for constraint propagation, our approach searches for neighborhoods driven by discriminative feature selection for more effective constraint diffusion. Crucially, we formulate a novel approach to handling the noisy constraint problem, which has been unrealistically ignored in the constrained clustering literature. Extensive comparative results show that our method is superior to the state-of-the-art constrained clustering approaches and can generally benefit existing pairwise similarity-based data clustering algorithms, such as spectral clustering and affinity propagation.},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found},
  annotation = {24 citations (Semantic Scholar/DOI) [2023-05-08]},
  file = {/Users/personal-macbook/Zotero/storage/ZTV6BCQ8/Zhu et al. - 2016 - Constrained Clustering With Imperfect Oracles.pdf}
}

@article{zhu_Dilated_2019,
  title = {Dilated {{Dense U-Net}} for {{Infant Hippocampus Subfield Segmentation}}},
  author = {Zhu, Hancan and Shi, Feng and Wang, Li and Hung, Sheng-Che and Chen, Meng-Hsiang and Wang, Shuai and Lin, Weili and Shen, Dinggang},
  date = {2019-04},
  journaltitle = {Front. Neuroinformatics},
  volume = {13},
  pages = {30},
  publisher = {{Frontiers Media S.A.}},
  issn = {1662-5196},
  doi = {10.3389/fninf.2019.00030},
  url = {https://www.frontiersin.org/article/10.3389/fninf.2019.00030/full},
  abstract = {Accurate and automatic segmentation of infant hippocampal subfields from magnetic resonance (MR) images is an important step for studying memory related infant neurological diseases. However, existing hippocampal subfield segmentation methods were generally designed based on adult subjects, and would compromise performance when applied to infant subjects due to insufficient tissue contrast and fast changing structural patterns of early hippocampal development. In this paper, we propose a new fully convolutional network (FCN) for infant hippocampal subfield segmentation by embedding the dilated dense network in the U-net, namely DUnet. The embedded dilated dense network can generate multi-scale features while keeping high spatial resolution, which is useful in fusing the low-level features in the contracting path with the high-level features in the expanding path. To further improve the performance, we group every pair of convolutional layers with one residual connection in the DUnet, and obtain the Residual DUnet (ResDUnet). Experimental results show that our proposed DUnet and ResDUnet improve the average Dice coefficient by 2.1 and 2.5\% for infant hippocampal subfield segmentation, respectively, when compared with the classic 3D U-net. The results also demonstrate that our methods outperform other state-of-the-art methods.},
  keywords = {\#nosource,⛔ No INSPIRE recid found,deep learning,Deep learning,dilated dense network,Dilated dense network,fully convol,Fully convolutional network,Hippocampal subfield segmentation,Infant hippocampus},
  annotation = {30 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@report{zhu_Learning_2002,
  type = {Technical Report CMU-CALD-02--107},
  ids = {Zhu2002LearningFL},
  title = {Learning {{From Labeled}} and {{Unlabeled Data With Label Propagation}}},
  author = {Zhu, Xiaojin and Ghahramani, Zoubin},
  date = {2002},
  institution = {{School of Computer Science, Carnegie Mellon University}},
  url = {http://mlg.eng.cam.ac.uk/zoubin/papers/CMU-CALD-02-107.pdf},
  abstract = {We investigate the use of unlabeled data to help labeled data in classification. We propose a simple iterative algorithm, label propagation, to propagate labels through the dataset along high density areas defined by unlabeled data. We analyze the algorithm, show its solution, and its connection to several other algorithms. We also show how to learn parameters by minimum spanning tree heuristic and entropy minimization, and the algorithms ability to perform feature selection. Experiment results are promising.},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found,learning}
}

@inproceedings{zhu_Unpaired_2017,
  title = {Unpaired {{Image-to-Image Translation Using Cycle-Consistent Adversarial Networks}}},
  booktitle = {Proc. {{IEEE Int}}. {{Conf}}. {{Comput}}. {{Vis}}.},
  author = {Zhu, Jun Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A.},
  date = {2017},
  issn = {15505499},
  doi = {10.1109/ICCV.2017.244},
  abstract = {Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain X to a target domain Y in the absence of paired examples. Our goal is to learn a mapping G : X \textrightarrow{} Y such that the distribution of images from G(X) is indistinguishable from the distribution Y using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping F : Y \textrightarrow{} X and introduce a cycle consistency loss to push F(G(X)) {$\approx$} X (and vice versa). Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transfiguration, season transfer, photo enhancement, etc. Quantitative comparisons against several prior methods demonstrate the superiority of our approach.},
  isbn = {978-1-5386-1032-9},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@thesis{zhuo_New_2018,
  title = {New {{Algorithms}} in {{Machine Learning With Applications}} in {{Personalized Medicine}}},
  author = {Zhuo, Ying Daisy},
  date = {2018},
  journaltitle = {MIT},
  volume = {PhD},
  number = {2018},
  institution = {{MIT}},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}

@article{ziyan_Joint_2008,
  title = {Joint {{Segmentation}} of {{Thalamic Nuclei From}} a {{Population}} of {{Diffusion Tensor MR Images}}},
  author = {Ziyan, Ulas and Westin, Carl-Fredrik},
  date = {2008},
  journaltitle = {Med. Image Comput. Comput. Assist. Interv.},
  volume = {11},
  pages = {279--286},
  abstract = {Several recent studies explored the use of unsupervised segmentation methods for segmenting thalamic nuclei from diffusion tensor images. These methods provide a plausible segmentation on individual subjects; however, they do not address the problem of consistently identifying the same functional areas in a population. The lack of correspondence between the segmented nuclei make it more difficult to use the results from the unsupervised segmentation tools for morphometry. In this paper we present a novel segmentation algorithm to automatically segment the gray matter nuclei while ensuring consistency between subjects in a population. This new algorithm, referred to as Consistency Clustering, finds correspondence between the nuclei as the segmentation is achieved through a single model for the whole population, similar to the brain atlases experts use to identify thalamic nuclei.},
  issue = {Pt 1},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@article{ziyan_Segmentation_2006,
  title = {Segmentation of {{Thalamic Nuclei From DTI Using Spectral Clustering}}},
  author = {Ziyan, Ulas and Tuch, David and Westin, Carl-Fredrik},
  date = {2006},
  journaltitle = {Med. Image Comput. Comput. Assist. Interv.},
  volume = {9},
  pages = {807--814},
  abstract = {Recent work shows that diffusion tensor imaging (DTI) can help resolving thalamic nuclei based on the characteristic fiber orientation of the corticothalamic/thalamocortical striations within each nucleus. In this paper we describe a novel segmentation method based on spectral clustering. We use Markovian relaxation to handle spatial information in a natural way, and we explicitly minimize the normalized cut criteria of the spectral clustering for a better optimization. Using this modified spectral clustering algorithm, we can resolve the organization of the thalamic nuclei into groups and subgroups solely based on the voxel affinity matrix, avoiding the need for explicitly defined cluster centers. The identification of nuclear subdivisions can facilitate localization of functional activation and pathology to individual nuclear subgroups.},
  issue = {Pt 2},
  keywords = {\#nosource,⛔ No DOI found,⛔ No INSPIRE recid found}
}

@inproceedings{zou_Confidence_2019,
  title = {Confidence {{Regularized Self-Training}}},
  booktitle = {Proc. {{IEEE Int}}. {{Conf}}. {{Comput}}. {{Vis}}.},
  author = {Zou, Yang and Yu, Zhiding and Liu, Xiaofeng and Kumar, B. V. K. Vijaya and Wang, Jinsong},
  date = {2019},
  issn = {15505499},
  doi = {10.1109/ICCV.2019.00608},
  abstract = {Recent advances in domain adaptation show that deep self-training presents a powerful means for unsupervised domain adaptation. These methods often involve an iterative process of predicting on target domain and then taking the confident predictions as pseudo-labels for retraining. However, since pseudo-labels can be noisy, self-training can put overconfident label belief on wrong classes, leading to deviated solutions with propagated errors. To address the problem, we propose a confidence regularized self-training (CRST) framework, formulated as regularized self-training. Our method treats pseudo-labels as continuous latent variables jointly optimized via alternating optimization. We propose two types of confidence regularization: Label regularization (LR) and model regularization (MR). CRST-LR generates soft pseudo-labels while CRST-MR encourages the smoothness on network output. Extensive experiments on image classification and semantic segmentation show that CRSTs outperform their non-regularized counterpart with state-of-the-art performance. The code and models of this work are available at https://github.com/yzou2/CRST.},
  isbn = {978-1-72814-803-8},
  keywords = {\#nosource,⛔ No INSPIRE recid found},
  annotation = {474 citations (Semantic Scholar/DOI) [2023-05-08]}
}

@inproceedings{zou_Unsupervised_2018,
  title = {Unsupervised {{Domain Adaptation}} for {{Semantic Segmentation}} via {{Class-Balanced Self-Training}}},
  booktitle = {Lect. {{Notes Comput}}. {{Sci}}. {{Subser}}. {{Lect}}. {{Notes Artif}}. {{Intell}}. {{Lect}}. {{Notes Bioinforma}}.},
  author = {Zou, Yang and Yu, Zhiding and Kumar, B. V. K. Vijaya and Wang, Jinsong},
  date = {2018},
  issn = {16113349},
  doi = {10.1007/978-3-030-01219-9_18},
  abstract = {Recent deep networks achieved state of the art performance on a variety of semantic segmentation tasks. Despite such progress, these models often face challenges in real world ``wild tasks'' where large difference between labeled training/source data and unseen test/target data exists. In particular, such difference is often referred to as ``domain gap'', and could cause significantly decreased performance which cannot be easily remedied by further increasing the representation power. Unsupervised domain adaptation (UDA) seeks to overcome such problem without target domain labels. In this paper, we propose a novel UDA framework based on an iterative self-training (ST) procedure, where the problem is formulated as latent variable loss minimization, and can be solved by alternatively generating pseudo labels on target data and re-training the model with these labels. On top of ST, we also propose a novel class-balanced self-training (CBST) framework to avoid the gradual dominance of large classes on pseudo-label generation, and introduce spatial priors to refine generated labels. Comprehensive experiments show that the proposed methods achieve state of the art semantic segmentation performance under multiple major UDA settings.},
  isbn = {978-3-030-01218-2},
  keywords = {\#nosource,⛔ No INSPIRE recid found}
}
